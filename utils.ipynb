{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package cv2.cv2 in cv2:\n",
      "\n",
      "NAME\n",
      "    cv2.cv2 - Python wrapper for OpenCV.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    cv2\n",
      "    data (package)\n",
      "    version\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        cv2.error\n",
      "    builtins.object\n",
      "        cv2.Algorithm\n",
      "            cv2.AlignExposures\n",
      "                cv2.AlignMTB\n",
      "            cv2.BackgroundSubtractor\n",
      "                cv2.BackgroundSubtractorKNN\n",
      "                cv2.BackgroundSubtractorMOG2\n",
      "            cv2.BaseCascadeClassifier\n",
      "            cv2.CLAHE\n",
      "            cv2.CalibrateCRF\n",
      "                cv2.CalibrateDebevec\n",
      "                cv2.CalibrateRobertson\n",
      "            cv2.DenseOpticalFlow\n",
      "                cv2.DISOpticalFlow\n",
      "                cv2.FarnebackOpticalFlow\n",
      "                cv2.VariationalRefinement\n",
      "            cv2.DescriptorMatcher\n",
      "                cv2.BFMatcher\n",
      "                cv2.FlannBasedMatcher\n",
      "            cv2.GeneralizedHough\n",
      "                cv2.GeneralizedHoughBallard\n",
      "                cv2.GeneralizedHoughGuil\n",
      "            cv2.LineSegmentDetector\n",
      "            cv2.MergeExposures\n",
      "                cv2.MergeDebevec\n",
      "                cv2.MergeMertens\n",
      "                cv2.MergeRobertson\n",
      "            cv2.SparseOpticalFlow\n",
      "                cv2.SparsePyrLKOpticalFlow\n",
      "            cv2.StereoMatcher\n",
      "                cv2.StereoBM\n",
      "                cv2.StereoSGBM\n",
      "            cv2.Tonemap\n",
      "                cv2.TonemapDrago\n",
      "                cv2.TonemapMantiuk\n",
      "                cv2.TonemapReinhard\n",
      "            cv2.dnn_Layer\n",
      "            cv2.ml_StatModel\n",
      "                cv2.ml_ANN_MLP\n",
      "                cv2.ml_DTrees\n",
      "                    cv2.ml_Boost\n",
      "                    cv2.ml_RTrees\n",
      "                cv2.ml_EM\n",
      "                cv2.ml_KNearest\n",
      "                cv2.ml_LogisticRegression\n",
      "                cv2.ml_NormalBayesClassifier\n",
      "                cv2.ml_SVM\n",
      "                cv2.ml_SVMSGD\n",
      "        cv2.AsyncArray\n",
      "        cv2.BOWImgDescriptorExtractor\n",
      "        cv2.BOWTrainer\n",
      "            cv2.BOWKMeansTrainer\n",
      "        cv2.CascadeClassifier\n",
      "        cv2.CirclesGridFinderParameters\n",
      "        cv2.DMatch\n",
      "        cv2.Feature2D\n",
      "            cv2.AKAZE\n",
      "            cv2.AgastFeatureDetector\n",
      "            cv2.BRISK\n",
      "            cv2.FastFeatureDetector\n",
      "            cv2.GFTTDetector\n",
      "            cv2.KAZE\n",
      "            cv2.MSER\n",
      "            cv2.ORB\n",
      "            cv2.SIFT\n",
      "            cv2.SimpleBlobDetector\n",
      "        cv2.FileNode\n",
      "        cv2.FileStorage\n",
      "        cv2.HOGDescriptor\n",
      "        cv2.KalmanFilter\n",
      "        cv2.KeyPoint\n",
      "        cv2.PyRotationWarper\n",
      "        cv2.QRCodeDetector\n",
      "        cv2.SimpleBlobDetector_Params\n",
      "        cv2.Stitcher\n",
      "        cv2.Subdiv2D\n",
      "        cv2.TickMeter\n",
      "        cv2.UMat\n",
      "        cv2.VideoCapture\n",
      "        cv2.VideoWriter\n",
      "        cv2.WarperCreator\n",
      "        cv2.cuda_BufferPool\n",
      "        cv2.cuda_DeviceInfo\n",
      "        cv2.cuda_Event\n",
      "        cv2.cuda_GpuMat\n",
      "        cv2.cuda_GpuMat_Allocator\n",
      "        cv2.cuda_HostMem\n",
      "        cv2.cuda_Stream\n",
      "        cv2.cuda_TargetArchs\n",
      "        cv2.detail_Blender\n",
      "            cv2.detail_FeatherBlender\n",
      "            cv2.detail_MultiBandBlender\n",
      "        cv2.detail_CameraParams\n",
      "        cv2.detail_Estimator\n",
      "            cv2.detail_AffineBasedEstimator\n",
      "            cv2.detail_BundleAdjusterBase\n",
      "                cv2.detail_BundleAdjusterAffine\n",
      "                cv2.detail_BundleAdjusterAffinePartial\n",
      "                cv2.detail_BundleAdjusterRay\n",
      "                cv2.detail_BundleAdjusterReproj\n",
      "                cv2.detail_NoBundleAdjuster\n",
      "            cv2.detail_HomographyBasedEstimator\n",
      "        cv2.detail_ExposureCompensator\n",
      "            cv2.detail_BlocksCompensator\n",
      "                cv2.detail_BlocksChannelsCompensator\n",
      "                cv2.detail_BlocksGainCompensator\n",
      "            cv2.detail_ChannelsCompensator\n",
      "            cv2.detail_GainCompensator\n",
      "            cv2.detail_NoExposureCompensator\n",
      "        cv2.detail_FeaturesMatcher\n",
      "            cv2.detail_BestOf2NearestMatcher\n",
      "                cv2.detail_AffineBestOf2NearestMatcher\n",
      "                cv2.detail_BestOf2NearestRangeMatcher\n",
      "        cv2.detail_GraphCutSeamFinder\n",
      "        cv2.detail_ImageFeatures\n",
      "        cv2.detail_MatchesInfo\n",
      "        cv2.detail_ProjectorBase\n",
      "            cv2.detail_SphericalProjector\n",
      "        cv2.detail_SeamFinder\n",
      "            cv2.detail_DpSeamFinder\n",
      "            cv2.detail_NoSeamFinder\n",
      "            cv2.detail_PairwiseSeamFinder\n",
      "                cv2.detail_VoronoiSeamFinder\n",
      "        cv2.detail_Timelapser\n",
      "            cv2.detail_TimelapserCrop\n",
      "        cv2.dnn_DictValue\n",
      "        cv2.dnn_Net\n",
      "            cv2.dnn_Model\n",
      "                cv2.dnn_ClassificationModel\n",
      "                cv2.dnn_DetectionModel\n",
      "                cv2.dnn_KeypointsModel\n",
      "                cv2.dnn_SegmentationModel\n",
      "        cv2.flann_Index\n",
      "        cv2.ml_ParamGrid\n",
      "        cv2.ml_TrainData\n",
      "        cv2.ocl_Device\n",
      "    \n",
      "    class AKAZE(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      AKAZE\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDescriptorChannels(...)\n",
      "     |      getDescriptorChannels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDescriptorSize(...)\n",
      "     |      getDescriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDescriptorType(...)\n",
      "     |      getDescriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDiffusivity(...)\n",
      "     |      getDiffusivity() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNOctaveLayers(...)\n",
      "     |      getNOctaveLayers() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNOctaves(...)\n",
      "     |      getNOctaves() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getThreshold(...)\n",
      "     |      getThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDescriptorChannels(...)\n",
      "     |      setDescriptorChannels(dch) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDescriptorSize(...)\n",
      "     |      setDescriptorSize(dsize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDescriptorType(...)\n",
      "     |      setDescriptorType(dtype) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDiffusivity(...)\n",
      "     |      setDiffusivity(diff) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNOctaveLayers(...)\n",
      "     |      setNOctaveLayers(octaveLayers) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNOctaves(...)\n",
      "     |      setNOctaves(octaves) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setThreshold(...)\n",
      "     |      setThreshold(threshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, descriptor_type[, descriptor_size[, descriptor_channels[, threshold[, nOctaves[, nOctaveLayers[, diffusivity]]]]]]]) -> retval\n",
      "     |      .   @brief The AKAZE constructor\n",
      "     |      .   \n",
      "     |      .       @param descriptor_type Type of the extracted descriptor: DESCRIPTOR_KAZE,\n",
      "     |      .       DESCRIPTOR_KAZE_UPRIGHT, DESCRIPTOR_MLDB or DESCRIPTOR_MLDB_UPRIGHT.\n",
      "     |      .       @param descriptor_size Size of the descriptor in bits. 0 -\\> Full size\n",
      "     |      .       @param descriptor_channels Number of channels in the descriptor (1, 2, 3)\n",
      "     |      .       @param threshold Detector response threshold to accept point\n",
      "     |      .       @param nOctaves Maximum octave evolution of the image\n",
      "     |      .       @param nOctaveLayers Default number of sublevels per scale level\n",
      "     |      .       @param diffusivity Diffusivity type. DIFF_PM_G1, DIFF_PM_G2, DIFF_WEICKERT or\n",
      "     |      .       DIFF_CHARBONNIER\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .       (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .       matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .       masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class AgastFeatureDetector(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      AgastFeatureDetector\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNonmaxSuppression(...)\n",
      "     |      getNonmaxSuppression() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getThreshold(...)\n",
      "     |      getThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getType(...)\n",
      "     |      getType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNonmaxSuppression(...)\n",
      "     |      setNonmaxSuppression(f) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setThreshold(...)\n",
      "     |      setThreshold(threshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setType(...)\n",
      "     |      setType(type) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, threshold[, nonmaxSuppression[, type]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .       (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .       matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .       masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class Algorithm(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class AlignExposures(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      AlignExposures\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, dst, times, response) -> None\n",
      "     |      .   @brief Aligns images\n",
      "     |      .   \n",
      "     |      .       @param src vector of input images\n",
      "     |      .       @param dst vector of aligned images\n",
      "     |      .       @param times vector of exposure time values for each image\n",
      "     |      .       @param response 256x1 matrix with inverse camera response function for each pixel value, it should\n",
      "     |      .       have the same number of channels as images.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class AlignMTB(AlignExposures)\n",
      "     |  Method resolution order:\n",
      "     |      AlignMTB\n",
      "     |      AlignExposures\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  calculateShift(...)\n",
      "     |      calculateShift(img0, img1) -> retval\n",
      "     |      .   @brief Calculates shift between two images, i. e. how to shift the second image to correspond it with the\n",
      "     |      .       first.\n",
      "     |      .   \n",
      "     |      .       @param img0 first image\n",
      "     |      .       @param img1 second image\n",
      "     |  \n",
      "     |  computeBitmaps(...)\n",
      "     |      computeBitmaps(img[, tb[, eb]]) -> tb, eb\n",
      "     |      .   @brief Computes median threshold and exclude bitmaps of given image.\n",
      "     |      .   \n",
      "     |      .       @param img input image\n",
      "     |      .       @param tb median threshold bitmap\n",
      "     |      .       @param eb exclude bitmap\n",
      "     |  \n",
      "     |  getCut(...)\n",
      "     |      getCut() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getExcludeRange(...)\n",
      "     |      getExcludeRange() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxBits(...)\n",
      "     |      getMaxBits() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, dst, times, response) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      process(src, dst) -> None\n",
      "     |      .   @brief Short version of process, that doesn't take extra arguments.\n",
      "     |      .   \n",
      "     |      .       @param src vector of input images\n",
      "     |      .       @param dst vector of aligned images\n",
      "     |  \n",
      "     |  setCut(...)\n",
      "     |      setCut(value) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setExcludeRange(...)\n",
      "     |      setExcludeRange(exclude_range) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxBits(...)\n",
      "     |      setMaxBits(max_bits) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  shiftMat(...)\n",
      "     |      shiftMat(src, shift[, dst]) -> dst\n",
      "     |      .   @brief Helper function, that shift Mat filling new regions with zeros.\n",
      "     |      .   \n",
      "     |      .       @param src input image\n",
      "     |      .       @param dst result image\n",
      "     |      .       @param shift shift value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class AsyncArray(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get(...)\n",
      "     |      get([, dst]) -> dst\n",
      "     |      .   Fetch the result.\n",
      "     |      .       @param[out] dst destination array\n",
      "     |      .   \n",
      "     |      .       Waits for result until container has valid result.\n",
      "     |      .       Throws exception if exception was stored as a result.\n",
      "     |      .   \n",
      "     |      .       Throws exception on invalid container state.\n",
      "     |      .   \n",
      "     |      .       @note Result or stored exception can be fetched only once.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      get(timeoutNs[, dst]) -> retval, dst\n",
      "     |      .   Retrieving the result with timeout\n",
      "     |      .       @param[out] dst destination array\n",
      "     |      .       @param[in] timeoutNs timeout in nanoseconds, -1 for infinite wait\n",
      "     |      .   \n",
      "     |      .       @returns true if result is ready, false if the timeout has expired\n",
      "     |      .   \n",
      "     |      .       @note Result or stored exception can be fetched only once.\n",
      "     |  \n",
      "     |  release(...)\n",
      "     |      release() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  valid(...)\n",
      "     |      valid() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  wait_for(...)\n",
      "     |      wait_for(timeoutNs) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BFMatcher(DescriptorMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      BFMatcher\n",
      "     |      DescriptorMatcher\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, normType[, crossCheck]]) -> retval\n",
      "     |      .   @brief Brute-force matcher create method.\n",
      "     |      .       @param normType One of NORM_L1, NORM_L2, NORM_HAMMING, NORM_HAMMING2. L1 and L2 norms are\n",
      "     |      .       preferable choices for SIFT and SURF descriptors, NORM_HAMMING should be used with ORB, BRISK and\n",
      "     |      .       BRIEF, NORM_HAMMING2 should be used with ORB when WTA_K==3 or 4 (see ORB::ORB constructor\n",
      "     |      .       description).\n",
      "     |      .       @param crossCheck If it is false, this is will be default BFMatcher behaviour when it finds the k\n",
      "     |      .       nearest neighbors for each query descriptor. If crossCheck==true, then the knnMatch() method with\n",
      "     |      .       k=1 will only return pairs (i,j) such that for i-th query descriptor the j-th descriptor in the\n",
      "     |      .       matcher's collection is the nearest and vice versa, i.e. the BFMatcher will only return consistent\n",
      "     |      .       pairs. Such technique usually produces best results with minimal number of outliers when there are\n",
      "     |      .       enough matches. This is alternative to the ratio test, used by D. Lowe in SIFT paper.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DescriptorMatcher:\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(descriptors) -> None\n",
      "     |      .   @brief Adds descriptors to train a CPU(trainDescCollectionis) or GPU(utrainDescCollectionis) descriptor\n",
      "     |      .       collection.\n",
      "     |      .   \n",
      "     |      .       If the collection is not empty, the new descriptors are added to existing train descriptors.\n",
      "     |      .   \n",
      "     |      .       @param descriptors Descriptors to add. Each descriptors[i] is a set of descriptors from the same\n",
      "     |      .       train image.\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the train descriptor collections.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone([, emptyTrainData]) -> retval\n",
      "     |      .   @brief Clones the matcher.\n",
      "     |      .   \n",
      "     |      .       @param emptyTrainData If emptyTrainData is false, the method creates a deep copy of the object,\n",
      "     |      .       that is, copies both parameters and train data. If emptyTrainData is true, the method creates an\n",
      "     |      .       object copy with the current parameters but with empty train data.\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if there are no train descriptors in the both collections.\n",
      "     |  \n",
      "     |  getTrainDescriptors(...)\n",
      "     |      getTrainDescriptors() -> retval\n",
      "     |      .   @brief Returns a constant link to the train descriptor collection trainDescCollection .\n",
      "     |  \n",
      "     |  isMaskSupported(...)\n",
      "     |      isMaskSupported() -> retval\n",
      "     |      .   @brief Returns true if the descriptor matcher supports masking permissible matches.\n",
      "     |  \n",
      "     |  knnMatch(...)\n",
      "     |      knnMatch(queryDescriptors, trainDescriptors, k[, mask[, compactResult]]) -> matches\n",
      "     |      .   @brief Finds the k best matches for each descriptor from a query set.\n",
      "     |      .   \n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .       collection stored in the class object.\n",
      "     |      .       @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .       descriptors.\n",
      "     |      .       @param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n",
      "     |      .       @param k Count of best matches found per each query descriptor or less if a query descriptor has\n",
      "     |      .       less than k possible matches in total.\n",
      "     |      .       @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .       false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .       the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |      .   \n",
      "     |      .       These extended variants of DescriptorMatcher::match methods find several best matches for each query\n",
      "     |      .       descriptor. The matches are returned in the distance increasing order. See DescriptorMatcher::match\n",
      "     |      .       for the details about query and train descriptors.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      knnMatch(queryDescriptors, k[, masks[, compactResult]]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n",
      "     |      .       @param k Count of best matches found per each query descriptor or less if a query descriptor has\n",
      "     |      .       less than k possible matches in total.\n",
      "     |      .       @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .       descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |      .       @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .       false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .       the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |  \n",
      "     |  match(...)\n",
      "     |      match(queryDescriptors, trainDescriptors[, mask]) -> matches\n",
      "     |      .   @brief Finds the best match for each descriptor from a query set.\n",
      "     |      .   \n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .       collection stored in the class object.\n",
      "     |      .       @param matches Matches. If a query descriptor is masked out in mask , no match is added for this\n",
      "     |      .       descriptor. So, matches size may be smaller than the query descriptors count.\n",
      "     |      .       @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .       descriptors.\n",
      "     |      .   \n",
      "     |      .       In the first variant of this method, the train descriptors are passed as an input argument. In the\n",
      "     |      .       second variant of the method, train descriptors collection that was set by DescriptorMatcher::add is\n",
      "     |      .       used. Optional mask (or masks) can be passed to specify which query and training descriptors can be\n",
      "     |      .       matched. Namely, queryDescriptors[i] can be matched with trainDescriptors[j] only if\n",
      "     |      .       mask.at\\<uchar\\>(i,j) is non-zero.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      match(queryDescriptors[, masks]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param matches Matches. If a query descriptor is masked out in mask , no match is added for this\n",
      "     |      .       descriptor. So, matches size may be smaller than the query descriptors count.\n",
      "     |      .       @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .       descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |  \n",
      "     |  radiusMatch(...)\n",
      "     |      radiusMatch(queryDescriptors, trainDescriptors, maxDistance[, mask[, compactResult]]) -> matches\n",
      "     |      .   @brief For each query descriptor, finds the training descriptors not farther than the specified distance.\n",
      "     |      .   \n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .       collection stored in the class object.\n",
      "     |      .       @param matches Found matches.\n",
      "     |      .       @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .       false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .       the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |      .       @param maxDistance Threshold for the distance between matched descriptors. Distance means here\n",
      "     |      .       metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\n",
      "     |      .       in Pixels)!\n",
      "     |      .       @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .       descriptors.\n",
      "     |      .   \n",
      "     |      .       For each query descriptor, the methods find such training descriptors that the distance between the\n",
      "     |      .       query descriptor and the training descriptor is equal or smaller than maxDistance. Found matches are\n",
      "     |      .       returned in the distance increasing order.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      radiusMatch(queryDescriptors, maxDistance[, masks[, compactResult]]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param matches Found matches.\n",
      "     |      .       @param maxDistance Threshold for the distance between matched descriptors. Distance means here\n",
      "     |      .       metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\n",
      "     |      .       in Pixels)!\n",
      "     |      .       @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .       descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |      .       @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .       false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .       the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train() -> None\n",
      "     |      .   @brief Trains a descriptor matcher\n",
      "     |      .   \n",
      "     |      .       Trains a descriptor matcher (for example, the flann index). In all methods to match, the method\n",
      "     |      .       train() is run every time before matching. Some descriptor matchers (for example, BruteForceMatcher)\n",
      "     |      .       have an empty implementation of this method. Other matchers really train their inner structures (for\n",
      "     |      .       example, FlannBasedMatcher trains flann::Index ).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "    \n",
      "    class BOWImgDescriptorExtractor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, imgDescriptor]) -> imgDescriptor\n",
      "     |      .   @overload\n",
      "     |      .       @param keypointDescriptors Computed descriptors to match with vocabulary.\n",
      "     |      .       @param imgDescriptor Computed output image descriptor.\n",
      "     |      .       @param pointIdxsOfClusters Indices of keypoints that belong to the cluster. This means that\n",
      "     |      .       pointIdxsOfClusters[i] are keypoint indices that belong to the i -th cluster (word of vocabulary)\n",
      "     |      .       returned if it is non-zero.\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .   @brief Returns an image descriptor size if the vocabulary is set. Otherwise, it returns 0.\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .   @brief Returns an image descriptor type.\n",
      "     |  \n",
      "     |  getVocabulary(...)\n",
      "     |      getVocabulary() -> retval\n",
      "     |      .   @brief Returns the set vocabulary.\n",
      "     |  \n",
      "     |  setVocabulary(...)\n",
      "     |      setVocabulary(vocabulary) -> None\n",
      "     |      .   @brief Sets a visual vocabulary.\n",
      "     |      .   \n",
      "     |      .       @param vocabulary Vocabulary (can be trained using the inheritor of BOWTrainer ). Each row of the\n",
      "     |      .       vocabulary is a visual word (cluster center).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BOWKMeansTrainer(BOWTrainer)\n",
      "     |  Method resolution order:\n",
      "     |      BOWKMeansTrainer\n",
      "     |      BOWTrainer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  cluster(...)\n",
      "     |      cluster() -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      cluster(descriptors) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BOWTrainer:\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(descriptors) -> None\n",
      "     |      .   @brief Adds descriptors to a training set.\n",
      "     |      .   \n",
      "     |      .       @param descriptors Descriptors to add to a training set. Each row of the descriptors matrix is a\n",
      "     |      .       descriptor.\n",
      "     |      .   \n",
      "     |      .       The training set is clustered using clustermethod to construct the vocabulary.\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorsCount(...)\n",
      "     |      descriptorsCount() -> retval\n",
      "     |      .   @brief Returns the count of all descriptors stored in the training set.\n",
      "     |  \n",
      "     |  getDescriptors(...)\n",
      "     |      getDescriptors() -> retval\n",
      "     |      .   @brief Returns a training set of descriptors.\n",
      "    \n",
      "    class BOWTrainer(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(descriptors) -> None\n",
      "     |      .   @brief Adds descriptors to a training set.\n",
      "     |      .   \n",
      "     |      .       @param descriptors Descriptors to add to a training set. Each row of the descriptors matrix is a\n",
      "     |      .       descriptor.\n",
      "     |      .   \n",
      "     |      .       The training set is clustered using clustermethod to construct the vocabulary.\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  cluster(...)\n",
      "     |      cluster() -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      cluster(descriptors) -> retval\n",
      "     |      .   @brief Clusters train descriptors.\n",
      "     |      .   \n",
      "     |      .       @param descriptors Descriptors to cluster. Each row of the descriptors matrix is a descriptor.\n",
      "     |      .       Descriptors are not added to the inner train descriptor set.\n",
      "     |      .   \n",
      "     |      .       The vocabulary consists of cluster centers. So, this method returns the vocabulary. In the first\n",
      "     |      .       variant of the method, train descriptors stored in the object are clustered. In the second variant,\n",
      "     |      .       input descriptors are clustered.\n",
      "     |  \n",
      "     |  descriptorsCount(...)\n",
      "     |      descriptorsCount() -> retval\n",
      "     |      .   @brief Returns the count of all descriptors stored in the training set.\n",
      "     |  \n",
      "     |  getDescriptors(...)\n",
      "     |      getDescriptors() -> retval\n",
      "     |      .   @brief Returns a training set of descriptors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BRISK(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      BRISK\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getOctaves(...)\n",
      "     |      getOctaves() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getThreshold(...)\n",
      "     |      getThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setOctaves(...)\n",
      "     |      setOctaves(octaves) -> None\n",
      "     |      .   @brief Set detection octaves.\n",
      "     |      .       @param octaves detection octaves. Use 0 to do single scale.\n",
      "     |  \n",
      "     |  setThreshold(...)\n",
      "     |      setThreshold(threshold) -> None\n",
      "     |      .   @brief Set detection threshold.\n",
      "     |      .       @param threshold AGAST detection threshold score.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, thresh[, octaves[, patternScale]]]) -> retval\n",
      "     |      .   @brief The BRISK constructor\n",
      "     |      .   \n",
      "     |      .       @param thresh AGAST detection threshold score.\n",
      "     |      .       @param octaves detection octaves. Use 0 to do single scale.\n",
      "     |      .       @param patternScale apply this scale to the pattern used for sampling the neighbourhood of a\n",
      "     |      .       keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      create(radiusList, numberList[, dMax[, dMin[, indexChange]]]) -> retval\n",
      "     |      .   @brief The BRISK constructor for a custom pattern\n",
      "     |      .   \n",
      "     |      .       @param radiusList defines the radii (in pixels) where the samples around a keypoint are taken (for\n",
      "     |      .       keypoint scale 1).\n",
      "     |      .       @param numberList defines the number of sampling points on the sampling circle. Must be the same\n",
      "     |      .       size as radiusList..\n",
      "     |      .       @param dMax threshold for the short pairings used for descriptor formation (in pixels for keypoint\n",
      "     |      .       scale 1).\n",
      "     |      .       @param dMin threshold for the long pairings used for orientation determination (in pixels for\n",
      "     |      .       keypoint scale 1).\n",
      "     |      .   @param indexChange index remapping of the bits.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      create(thresh, octaves, radiusList, numberList[, dMax[, dMin[, indexChange]]]) -> retval\n",
      "     |      .   @brief The BRISK constructor for a custom pattern, detection threshold and octaves\n",
      "     |      .   \n",
      "     |      .       @param thresh AGAST detection threshold score.\n",
      "     |      .       @param octaves detection octaves. Use 0 to do single scale.\n",
      "     |      .       @param radiusList defines the radii (in pixels) where the samples around a keypoint are taken (for\n",
      "     |      .       keypoint scale 1).\n",
      "     |      .       @param numberList defines the number of sampling points on the sampling circle. Must be the same\n",
      "     |      .       size as radiusList..\n",
      "     |      .       @param dMax threshold for the short pairings used for descriptor formation (in pixels for keypoint\n",
      "     |      .       scale 1).\n",
      "     |      .       @param dMin threshold for the long pairings used for orientation determination (in pixels for\n",
      "     |      .       keypoint scale 1).\n",
      "     |      .   @param indexChange index remapping of the bits.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .       (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .       matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .       masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class BackgroundSubtractor(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      BackgroundSubtractor\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(image[, fgmask[, learningRate]]) -> fgmask\n",
      "     |      .   @brief Computes a foreground mask.\n",
      "     |      .   \n",
      "     |      .       @param image Next video frame.\n",
      "     |      .       @param fgmask The output foreground mask as an 8-bit binary image.\n",
      "     |      .       @param learningRate The value between 0 and 1 that indicates how fast the background model is\n",
      "     |      .       learnt. Negative parameter value makes the algorithm to use some automatically chosen learning\n",
      "     |      .       rate. 0 means that the background model is not updated at all, 1 means that the background model\n",
      "     |      .       is completely reinitialized from the last frame.\n",
      "     |  \n",
      "     |  getBackgroundImage(...)\n",
      "     |      getBackgroundImage([, backgroundImage]) -> backgroundImage\n",
      "     |      .   @brief Computes a background image.\n",
      "     |      .   \n",
      "     |      .       @param backgroundImage The output background image.\n",
      "     |      .   \n",
      "     |      .       @note Sometimes the background image can be very blurry, as it contain the average background\n",
      "     |      .       statistics.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class BackgroundSubtractorKNN(BackgroundSubtractor)\n",
      "     |  Method resolution order:\n",
      "     |      BackgroundSubtractorKNN\n",
      "     |      BackgroundSubtractor\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDetectShadows(...)\n",
      "     |      getDetectShadows() -> retval\n",
      "     |      .   @brief Returns the shadow detection flag\n",
      "     |      .   \n",
      "     |      .       If true, the algorithm detects shadows and marks them. See createBackgroundSubtractorKNN for\n",
      "     |      .       details.\n",
      "     |  \n",
      "     |  getDist2Threshold(...)\n",
      "     |      getDist2Threshold() -> retval\n",
      "     |      .   @brief Returns the threshold on the squared distance between the pixel and the sample\n",
      "     |      .   \n",
      "     |      .       The threshold on the squared distance between the pixel and the sample to decide whether a pixel is\n",
      "     |      .       close to a data sample.\n",
      "     |  \n",
      "     |  getHistory(...)\n",
      "     |      getHistory() -> retval\n",
      "     |      .   @brief Returns the number of last frames that affect the background model\n",
      "     |  \n",
      "     |  getNSamples(...)\n",
      "     |      getNSamples() -> retval\n",
      "     |      .   @brief Returns the number of data samples in the background model\n",
      "     |  \n",
      "     |  getShadowThreshold(...)\n",
      "     |      getShadowThreshold() -> retval\n",
      "     |      .   @brief Returns the shadow threshold\n",
      "     |      .   \n",
      "     |      .       A shadow is detected if pixel is a darker version of the background. The shadow threshold (Tau in\n",
      "     |      .       the paper) is a threshold defining how much darker the shadow can be. Tau= 0.5 means that if a pixel\n",
      "     |      .       is more than twice darker then it is not shadow. See Prati, Mikic, Trivedi and Cucchiara,\n",
      "     |      .       *Detecting Moving Shadows...*, IEEE PAMI,2003.\n",
      "     |  \n",
      "     |  getShadowValue(...)\n",
      "     |      getShadowValue() -> retval\n",
      "     |      .   @brief Returns the shadow value\n",
      "     |      .   \n",
      "     |      .       Shadow value is the value used to mark shadows in the foreground mask. Default value is 127. Value 0\n",
      "     |      .       in the mask always means background, 255 means foreground.\n",
      "     |  \n",
      "     |  getkNNSamples(...)\n",
      "     |      getkNNSamples() -> retval\n",
      "     |      .   @brief Returns the number of neighbours, the k in the kNN.\n",
      "     |      .   \n",
      "     |      .       K is the number of samples that need to be within dist2Threshold in order to decide that that\n",
      "     |      .       pixel is matching the kNN background model.\n",
      "     |  \n",
      "     |  setDetectShadows(...)\n",
      "     |      setDetectShadows(detectShadows) -> None\n",
      "     |      .   @brief Enables or disables shadow detection\n",
      "     |  \n",
      "     |  setDist2Threshold(...)\n",
      "     |      setDist2Threshold(_dist2Threshold) -> None\n",
      "     |      .   @brief Sets the threshold on the squared distance\n",
      "     |  \n",
      "     |  setHistory(...)\n",
      "     |      setHistory(history) -> None\n",
      "     |      .   @brief Sets the number of last frames that affect the background model\n",
      "     |  \n",
      "     |  setNSamples(...)\n",
      "     |      setNSamples(_nN) -> None\n",
      "     |      .   @brief Sets the number of data samples in the background model.\n",
      "     |      .   \n",
      "     |      .       The model needs to be reinitalized to reserve memory.\n",
      "     |  \n",
      "     |  setShadowThreshold(...)\n",
      "     |      setShadowThreshold(threshold) -> None\n",
      "     |      .   @brief Sets the shadow threshold\n",
      "     |  \n",
      "     |  setShadowValue(...)\n",
      "     |      setShadowValue(value) -> None\n",
      "     |      .   @brief Sets the shadow value\n",
      "     |  \n",
      "     |  setkNNSamples(...)\n",
      "     |      setkNNSamples(_nkNN) -> None\n",
      "     |      .   @brief Sets the k in the kNN. How many nearest neighbours need to match.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BackgroundSubtractor:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(image[, fgmask[, learningRate]]) -> fgmask\n",
      "     |      .   @brief Computes a foreground mask.\n",
      "     |      .   \n",
      "     |      .       @param image Next video frame.\n",
      "     |      .       @param fgmask The output foreground mask as an 8-bit binary image.\n",
      "     |      .       @param learningRate The value between 0 and 1 that indicates how fast the background model is\n",
      "     |      .       learnt. Negative parameter value makes the algorithm to use some automatically chosen learning\n",
      "     |      .       rate. 0 means that the background model is not updated at all, 1 means that the background model\n",
      "     |      .       is completely reinitialized from the last frame.\n",
      "     |  \n",
      "     |  getBackgroundImage(...)\n",
      "     |      getBackgroundImage([, backgroundImage]) -> backgroundImage\n",
      "     |      .   @brief Computes a background image.\n",
      "     |      .   \n",
      "     |      .       @param backgroundImage The output background image.\n",
      "     |      .   \n",
      "     |      .       @note Sometimes the background image can be very blurry, as it contain the average background\n",
      "     |      .       statistics.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class BackgroundSubtractorMOG2(BackgroundSubtractor)\n",
      "     |  Method resolution order:\n",
      "     |      BackgroundSubtractorMOG2\n",
      "     |      BackgroundSubtractor\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(image[, fgmask[, learningRate]]) -> fgmask\n",
      "     |      .   @brief Computes a foreground mask.\n",
      "     |      .   \n",
      "     |      .       @param image Next video frame. Floating point frame will be used without scaling and should be in range \\f$[0,255]\\f$.\n",
      "     |      .       @param fgmask The output foreground mask as an 8-bit binary image.\n",
      "     |      .       @param learningRate The value between 0 and 1 that indicates how fast the background model is\n",
      "     |      .       learnt. Negative parameter value makes the algorithm to use some automatically chosen learning\n",
      "     |      .       rate. 0 means that the background model is not updated at all, 1 means that the background model\n",
      "     |      .       is completely reinitialized from the last frame.\n",
      "     |  \n",
      "     |  getBackgroundRatio(...)\n",
      "     |      getBackgroundRatio() -> retval\n",
      "     |      .   @brief Returns the \"background ratio\" parameter of the algorithm\n",
      "     |      .   \n",
      "     |      .       If a foreground pixel keeps semi-constant value for about backgroundRatio\\*history frames, it's\n",
      "     |      .       considered background and added to the model as a center of a new component. It corresponds to TB\n",
      "     |      .       parameter in the paper.\n",
      "     |  \n",
      "     |  getComplexityReductionThreshold(...)\n",
      "     |      getComplexityReductionThreshold() -> retval\n",
      "     |      .   @brief Returns the complexity reduction threshold\n",
      "     |      .   \n",
      "     |      .       This parameter defines the number of samples needed to accept to prove the component exists. CT=0.05\n",
      "     |      .       is a default value for all the samples. By setting CT=0 you get an algorithm very similar to the\n",
      "     |      .       standard Stauffer&Grimson algorithm.\n",
      "     |  \n",
      "     |  getDetectShadows(...)\n",
      "     |      getDetectShadows() -> retval\n",
      "     |      .   @brief Returns the shadow detection flag\n",
      "     |      .   \n",
      "     |      .       If true, the algorithm detects shadows and marks them. See createBackgroundSubtractorMOG2 for\n",
      "     |      .       details.\n",
      "     |  \n",
      "     |  getHistory(...)\n",
      "     |      getHistory() -> retval\n",
      "     |      .   @brief Returns the number of last frames that affect the background model\n",
      "     |  \n",
      "     |  getNMixtures(...)\n",
      "     |      getNMixtures() -> retval\n",
      "     |      .   @brief Returns the number of gaussian components in the background model\n",
      "     |  \n",
      "     |  getShadowThreshold(...)\n",
      "     |      getShadowThreshold() -> retval\n",
      "     |      .   @brief Returns the shadow threshold\n",
      "     |      .   \n",
      "     |      .       A shadow is detected if pixel is a darker version of the background. The shadow threshold (Tau in\n",
      "     |      .       the paper) is a threshold defining how much darker the shadow can be. Tau= 0.5 means that if a pixel\n",
      "     |      .       is more than twice darker then it is not shadow. See Prati, Mikic, Trivedi and Cucchiara,\n",
      "     |      .       *Detecting Moving Shadows...*, IEEE PAMI,2003.\n",
      "     |  \n",
      "     |  getShadowValue(...)\n",
      "     |      getShadowValue() -> retval\n",
      "     |      .   @brief Returns the shadow value\n",
      "     |      .   \n",
      "     |      .       Shadow value is the value used to mark shadows in the foreground mask. Default value is 127. Value 0\n",
      "     |      .       in the mask always means background, 255 means foreground.\n",
      "     |  \n",
      "     |  getVarInit(...)\n",
      "     |      getVarInit() -> retval\n",
      "     |      .   @brief Returns the initial variance of each gaussian component\n",
      "     |  \n",
      "     |  getVarMax(...)\n",
      "     |      getVarMax() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarMin(...)\n",
      "     |      getVarMin() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarThreshold(...)\n",
      "     |      getVarThreshold() -> retval\n",
      "     |      .   @brief Returns the variance threshold for the pixel-model match\n",
      "     |      .   \n",
      "     |      .       The main threshold on the squared Mahalanobis distance to decide if the sample is well described by\n",
      "     |      .       the background model or not. Related to Cthr from the paper.\n",
      "     |  \n",
      "     |  getVarThresholdGen(...)\n",
      "     |      getVarThresholdGen() -> retval\n",
      "     |      .   @brief Returns the variance threshold for the pixel-model match used for new mixture component generation\n",
      "     |      .   \n",
      "     |      .       Threshold for the squared Mahalanobis distance that helps decide when a sample is close to the\n",
      "     |      .       existing components (corresponds to Tg in the paper). If a pixel is not close to any component, it\n",
      "     |      .       is considered foreground or added as a new component. 3 sigma =\\> Tg=3\\*3=9 is default. A smaller Tg\n",
      "     |      .       value generates more components. A higher Tg value may result in a small number of components but\n",
      "     |      .       they can grow too large.\n",
      "     |  \n",
      "     |  setBackgroundRatio(...)\n",
      "     |      setBackgroundRatio(ratio) -> None\n",
      "     |      .   @brief Sets the \"background ratio\" parameter of the algorithm\n",
      "     |  \n",
      "     |  setComplexityReductionThreshold(...)\n",
      "     |      setComplexityReductionThreshold(ct) -> None\n",
      "     |      .   @brief Sets the complexity reduction threshold\n",
      "     |  \n",
      "     |  setDetectShadows(...)\n",
      "     |      setDetectShadows(detectShadows) -> None\n",
      "     |      .   @brief Enables or disables shadow detection\n",
      "     |  \n",
      "     |  setHistory(...)\n",
      "     |      setHistory(history) -> None\n",
      "     |      .   @brief Sets the number of last frames that affect the background model\n",
      "     |  \n",
      "     |  setNMixtures(...)\n",
      "     |      setNMixtures(nmixtures) -> None\n",
      "     |      .   @brief Sets the number of gaussian components in the background model.\n",
      "     |      .   \n",
      "     |      .       The model needs to be reinitalized to reserve memory.\n",
      "     |  \n",
      "     |  setShadowThreshold(...)\n",
      "     |      setShadowThreshold(threshold) -> None\n",
      "     |      .   @brief Sets the shadow threshold\n",
      "     |  \n",
      "     |  setShadowValue(...)\n",
      "     |      setShadowValue(value) -> None\n",
      "     |      .   @brief Sets the shadow value\n",
      "     |  \n",
      "     |  setVarInit(...)\n",
      "     |      setVarInit(varInit) -> None\n",
      "     |      .   @brief Sets the initial variance of each gaussian component\n",
      "     |  \n",
      "     |  setVarMax(...)\n",
      "     |      setVarMax(varMax) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setVarMin(...)\n",
      "     |      setVarMin(varMin) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setVarThreshold(...)\n",
      "     |      setVarThreshold(varThreshold) -> None\n",
      "     |      .   @brief Sets the variance threshold for the pixel-model match\n",
      "     |  \n",
      "     |  setVarThresholdGen(...)\n",
      "     |      setVarThresholdGen(varThresholdGen) -> None\n",
      "     |      .   @brief Sets the variance threshold for the pixel-model match used for new mixture component generation\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BackgroundSubtractor:\n",
      "     |  \n",
      "     |  getBackgroundImage(...)\n",
      "     |      getBackgroundImage([, backgroundImage]) -> backgroundImage\n",
      "     |      .   @brief Computes a background image.\n",
      "     |      .   \n",
      "     |      .       @param backgroundImage The output background image.\n",
      "     |      .   \n",
      "     |      .       @note Sometimes the background image can be very blurry, as it contain the average background\n",
      "     |      .       statistics.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class BaseCascadeClassifier(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      BaseCascadeClassifier\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class CLAHE(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      CLAHE\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(src[, dst]) -> dst\n",
      "     |      .   @brief Equalizes the histogram of a grayscale image using Contrast Limited Adaptive Histogram Equalization.\n",
      "     |      .   \n",
      "     |      .       @param src Source image of type CV_8UC1 or CV_16UC1.\n",
      "     |      .       @param dst Destination image.\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  getClipLimit(...)\n",
      "     |      getClipLimit() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTilesGridSize(...)\n",
      "     |      getTilesGridSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setClipLimit(...)\n",
      "     |      setClipLimit(clipLimit) -> None\n",
      "     |      .   @brief Sets threshold for contrast limiting.\n",
      "     |      .   \n",
      "     |      .       @param clipLimit threshold value.\n",
      "     |  \n",
      "     |  setTilesGridSize(...)\n",
      "     |      setTilesGridSize(tileGridSize) -> None\n",
      "     |      .   @brief Sets size of grid for histogram equalization. Input image will be divided into\n",
      "     |      .       equally sized rectangular tiles.\n",
      "     |      .   \n",
      "     |      .       @param tileGridSize defines the number of tiles in row and column.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class CalibrateCRF(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      CalibrateCRF\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times[, dst]) -> dst\n",
      "     |      .   @brief Recovers inverse camera response.\n",
      "     |      .   \n",
      "     |      .       @param src vector of input images\n",
      "     |      .       @param dst 256x1 matrix with inverse camera response function\n",
      "     |      .       @param times vector of exposure time values for each image\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class CalibrateDebevec(CalibrateCRF)\n",
      "     |  Method resolution order:\n",
      "     |      CalibrateDebevec\n",
      "     |      CalibrateCRF\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getLambda(...)\n",
      "     |      getLambda() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getRandom(...)\n",
      "     |      getRandom() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSamples(...)\n",
      "     |      getSamples() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setLambda(...)\n",
      "     |      setLambda(lambda) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRandom(...)\n",
      "     |      setRandom(random) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSamples(...)\n",
      "     |      setSamples(samples) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CalibrateCRF:\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times[, dst]) -> dst\n",
      "     |      .   @brief Recovers inverse camera response.\n",
      "     |      .   \n",
      "     |      .       @param src vector of input images\n",
      "     |      .       @param dst 256x1 matrix with inverse camera response function\n",
      "     |      .       @param times vector of exposure time values for each image\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class CalibrateRobertson(CalibrateCRF)\n",
      "     |  Method resolution order:\n",
      "     |      CalibrateRobertson\n",
      "     |      CalibrateCRF\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getMaxIter(...)\n",
      "     |      getMaxIter() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getRadiance(...)\n",
      "     |      getRadiance() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getThreshold(...)\n",
      "     |      getThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxIter(...)\n",
      "     |      setMaxIter(max_iter) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setThreshold(...)\n",
      "     |      setThreshold(threshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CalibrateCRF:\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times[, dst]) -> dst\n",
      "     |      .   @brief Recovers inverse camera response.\n",
      "     |      .   \n",
      "     |      .       @param src vector of input images\n",
      "     |      .       @param dst 256x1 matrix with inverse camera response function\n",
      "     |      .       @param times vector of exposure time values for each image\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class CascadeClassifier(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  detectMultiScale(...)\n",
      "     |      detectMultiScale(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]]) -> objects\n",
      "     |      .   @brief Detects objects of different sizes in the input image. The detected objects are returned as a list\n",
      "     |      .       of rectangles.\n",
      "     |      .   \n",
      "     |      .       @param image Matrix of the type CV_8U containing an image where objects are detected.\n",
      "     |      .       @param objects Vector of rectangles where each rectangle contains the detected object, the\n",
      "     |      .       rectangles may be partially outside the original image.\n",
      "     |      .       @param scaleFactor Parameter specifying how much the image size is reduced at each image scale.\n",
      "     |      .       @param minNeighbors Parameter specifying how many neighbors each candidate rectangle should have\n",
      "     |      .       to retain it.\n",
      "     |      .       @param flags Parameter with the same meaning for an old cascade as in the function\n",
      "     |      .       cvHaarDetectObjects. It is not used for a new cascade.\n",
      "     |      .       @param minSize Minimum possible object size. Objects smaller than that are ignored.\n",
      "     |      .       @param maxSize Maximum possible object size. Objects larger than that are ignored. If `maxSize == minSize` model is evaluated on single scale.\n",
      "     |      .   \n",
      "     |      .       The function is parallelized with the TBB library.\n",
      "     |      .   \n",
      "     |      .       @note\n",
      "     |      .          -   (Python) A face detection example using cascade classifiers can be found at\n",
      "     |      .               opencv_source_code/samples/python/facedetect.py\n",
      "     |  \n",
      "     |  detectMultiScale2(...)\n",
      "     |      detectMultiScale2(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]]) -> objects, numDetections\n",
      "     |      .   @overload\n",
      "     |      .       @param image Matrix of the type CV_8U containing an image where objects are detected.\n",
      "     |      .       @param objects Vector of rectangles where each rectangle contains the detected object, the\n",
      "     |      .       rectangles may be partially outside the original image.\n",
      "     |      .       @param numDetections Vector of detection numbers for the corresponding objects. An object's number\n",
      "     |      .       of detections is the number of neighboring positively classified rectangles that were joined\n",
      "     |      .       together to form the object.\n",
      "     |      .       @param scaleFactor Parameter specifying how much the image size is reduced at each image scale.\n",
      "     |      .       @param minNeighbors Parameter specifying how many neighbors each candidate rectangle should have\n",
      "     |      .       to retain it.\n",
      "     |      .       @param flags Parameter with the same meaning for an old cascade as in the function\n",
      "     |      .       cvHaarDetectObjects. It is not used for a new cascade.\n",
      "     |      .       @param minSize Minimum possible object size. Objects smaller than that are ignored.\n",
      "     |      .       @param maxSize Maximum possible object size. Objects larger than that are ignored. If `maxSize == minSize` model is evaluated on single scale.\n",
      "     |  \n",
      "     |  detectMultiScale3(...)\n",
      "     |      detectMultiScale3(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize[, outputRejectLevels]]]]]]) -> objects, rejectLevels, levelWeights\n",
      "     |      .   @overload\n",
      "     |      .       This function allows you to retrieve the final stage decision certainty of classification.\n",
      "     |      .       For this, one needs to set `outputRejectLevels` on true and provide the `rejectLevels` and `levelWeights` parameter.\n",
      "     |      .       For each resulting detection, `levelWeights` will then contain the certainty of classification at the final stage.\n",
      "     |      .       This value can then be used to separate strong from weaker classifications.\n",
      "     |      .   \n",
      "     |      .       A code sample on how to use it efficiently can be found below:\n",
      "     |      .       @code\n",
      "     |      .       Mat img;\n",
      "     |      .       vector<double> weights;\n",
      "     |      .       vector<int> levels;\n",
      "     |      .       vector<Rect> detections;\n",
      "     |      .       CascadeClassifier model(\"/path/to/your/model.xml\");\n",
      "     |      .       model.detectMultiScale(img, detections, levels, weights, 1.1, 3, 0, Size(), Size(), true);\n",
      "     |      .       cerr << \"Detection \" << detections[0] << \" with weight \" << weights[0] << endl;\n",
      "     |      .       @endcode\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Checks whether the classifier has been loaded.\n",
      "     |  \n",
      "     |  getFeatureType(...)\n",
      "     |      getFeatureType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getOriginalWindowSize(...)\n",
      "     |      getOriginalWindowSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isOldFormatCascade(...)\n",
      "     |      isOldFormatCascade() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filename) -> retval\n",
      "     |      .   @brief Loads a classifier from a file.\n",
      "     |      .   \n",
      "     |      .       @param filename Name of the file from which the classifier is loaded. The file may contain an old\n",
      "     |      .       HAAR classifier trained by the haartraining application or a new cascade classifier trained by the\n",
      "     |      .       traincascade application.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(node) -> retval\n",
      "     |      .   @brief Reads a classifier from a FileStorage node.\n",
      "     |      .   \n",
      "     |      .       @note The file may contain a new cascade classifier (trained traincascade application) only.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  convert(...)\n",
      "     |      convert(oldcascade, newcascade) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class CirclesGridFinderParameters(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  convexHullFactor\n",
      "     |      convexHullFactor\n",
      "     |  \n",
      "     |  densityNeighborhoodSize\n",
      "     |      densityNeighborhoodSize\n",
      "     |  \n",
      "     |  edgeGain\n",
      "     |      edgeGain\n",
      "     |  \n",
      "     |  edgePenalty\n",
      "     |      edgePenalty\n",
      "     |  \n",
      "     |  existingVertexGain\n",
      "     |      existingVertexGain\n",
      "     |  \n",
      "     |  keypointScale\n",
      "     |      keypointScale\n",
      "     |  \n",
      "     |  kmeansAttempts\n",
      "     |      kmeansAttempts\n",
      "     |  \n",
      "     |  maxRectifiedDistance\n",
      "     |      maxRectifiedDistance\n",
      "     |  \n",
      "     |  minDensity\n",
      "     |      minDensity\n",
      "     |  \n",
      "     |  minDistanceToAddKeypoint\n",
      "     |      minDistanceToAddKeypoint\n",
      "     |  \n",
      "     |  minGraphConfidence\n",
      "     |      minGraphConfidence\n",
      "     |  \n",
      "     |  minRNGEdgeSwitchDist\n",
      "     |      minRNGEdgeSwitchDist\n",
      "     |  \n",
      "     |  squareSize\n",
      "     |      squareSize\n",
      "     |  \n",
      "     |  vertexGain\n",
      "     |      vertexGain\n",
      "     |  \n",
      "     |  vertexPenalty\n",
      "     |      vertexPenalty\n",
      "    \n",
      "    class DISOpticalFlow(DenseOpticalFlow)\n",
      "     |  Method resolution order:\n",
      "     |      DISOpticalFlow\n",
      "     |      DenseOpticalFlow\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getFinestScale(...)\n",
      "     |      getFinestScale() -> retval\n",
      "     |      .   @brief Finest level of the Gaussian pyramid on which the flow is computed (zero level\n",
      "     |      .           corresponds to the original image resolution). The final flow is obtained by bilinear upscaling.\n",
      "     |      .   @see setFinestScale\n",
      "     |  \n",
      "     |  getGradientDescentIterations(...)\n",
      "     |      getGradientDescentIterations() -> retval\n",
      "     |      .   @brief Maximum number of gradient descent iterations in the patch inverse search stage. Higher values\n",
      "     |      .           may improve quality in some cases.\n",
      "     |      .   @see setGradientDescentIterations\n",
      "     |  \n",
      "     |  getPatchSize(...)\n",
      "     |      getPatchSize() -> retval\n",
      "     |      .   @brief Size of an image patch for matching (in pixels). Normally, default 8x8 patches work well\n",
      "     |      .           enough in most cases.\n",
      "     |      .   @see setPatchSize\n",
      "     |  \n",
      "     |  getPatchStride(...)\n",
      "     |      getPatchStride() -> retval\n",
      "     |      .   @brief Stride between neighbor patches. Must be less than patch size. Lower values correspond\n",
      "     |      .           to higher flow quality.\n",
      "     |      .   @see setPatchStride\n",
      "     |  \n",
      "     |  getUseMeanNormalization(...)\n",
      "     |      getUseMeanNormalization() -> retval\n",
      "     |      .   @brief Whether to use mean-normalization of patches when computing patch distance. It is turned on\n",
      "     |      .           by default as it typically provides a noticeable quality boost because of increased robustness to\n",
      "     |      .           illumination variations. Turn it off if you are certain that your sequence doesn't contain any changes\n",
      "     |      .           in illumination.\n",
      "     |      .   @see setUseMeanNormalization\n",
      "     |  \n",
      "     |  getUseSpatialPropagation(...)\n",
      "     |      getUseSpatialPropagation() -> retval\n",
      "     |      .   @brief Whether to use spatial propagation of good optical flow vectors. This option is turned on by\n",
      "     |      .           default, as it tends to work better on average and can sometimes help recover from major errors\n",
      "     |      .           introduced by the coarse-to-fine scheme employed by the DIS optical flow algorithm. Turning this\n",
      "     |      .           option off can make the output flow field a bit smoother, however.\n",
      "     |      .   @see setUseSpatialPropagation\n",
      "     |  \n",
      "     |  getVariationalRefinementAlpha(...)\n",
      "     |      getVariationalRefinementAlpha() -> retval\n",
      "     |      .   @brief Weight of the smoothness term\n",
      "     |      .   @see setVariationalRefinementAlpha\n",
      "     |  \n",
      "     |  getVariationalRefinementDelta(...)\n",
      "     |      getVariationalRefinementDelta() -> retval\n",
      "     |      .   @brief Weight of the color constancy term\n",
      "     |      .   @see setVariationalRefinementDelta\n",
      "     |  \n",
      "     |  getVariationalRefinementGamma(...)\n",
      "     |      getVariationalRefinementGamma() -> retval\n",
      "     |      .   @brief Weight of the gradient constancy term\n",
      "     |      .   @see setVariationalRefinementGamma\n",
      "     |  \n",
      "     |  getVariationalRefinementIterations(...)\n",
      "     |      getVariationalRefinementIterations() -> retval\n",
      "     |      .   @brief Number of fixed point iterations of variational refinement per scale. Set to zero to\n",
      "     |      .           disable variational refinement completely. Higher values will typically result in more smooth and\n",
      "     |      .           high-quality flow.\n",
      "     |      .   @see setGradientDescentIterations\n",
      "     |  \n",
      "     |  setFinestScale(...)\n",
      "     |      setFinestScale(val) -> None\n",
      "     |      .   @copybrief getFinestScale @see getFinestScale\n",
      "     |  \n",
      "     |  setGradientDescentIterations(...)\n",
      "     |      setGradientDescentIterations(val) -> None\n",
      "     |      .   @copybrief getGradientDescentIterations @see getGradientDescentIterations\n",
      "     |  \n",
      "     |  setPatchSize(...)\n",
      "     |      setPatchSize(val) -> None\n",
      "     |      .   @copybrief getPatchSize @see getPatchSize\n",
      "     |  \n",
      "     |  setPatchStride(...)\n",
      "     |      setPatchStride(val) -> None\n",
      "     |      .   @copybrief getPatchStride @see getPatchStride\n",
      "     |  \n",
      "     |  setUseMeanNormalization(...)\n",
      "     |      setUseMeanNormalization(val) -> None\n",
      "     |      .   @copybrief getUseMeanNormalization @see getUseMeanNormalization\n",
      "     |  \n",
      "     |  setUseSpatialPropagation(...)\n",
      "     |      setUseSpatialPropagation(val) -> None\n",
      "     |      .   @copybrief getUseSpatialPropagation @see getUseSpatialPropagation\n",
      "     |  \n",
      "     |  setVariationalRefinementAlpha(...)\n",
      "     |      setVariationalRefinementAlpha(val) -> None\n",
      "     |      .   @copybrief getVariationalRefinementAlpha @see getVariationalRefinementAlpha\n",
      "     |  \n",
      "     |  setVariationalRefinementDelta(...)\n",
      "     |      setVariationalRefinementDelta(val) -> None\n",
      "     |      .   @copybrief getVariationalRefinementDelta @see getVariationalRefinementDelta\n",
      "     |  \n",
      "     |  setVariationalRefinementGamma(...)\n",
      "     |      setVariationalRefinementGamma(val) -> None\n",
      "     |      .   @copybrief getVariationalRefinementGamma @see getVariationalRefinementGamma\n",
      "     |  \n",
      "     |  setVariationalRefinementIterations(...)\n",
      "     |      setVariationalRefinementIterations(val) -> None\n",
      "     |      .   @copybrief getGradientDescentIterations @see getGradientDescentIterations\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, preset]) -> retval\n",
      "     |      .   @brief Creates an instance of DISOpticalFlow\n",
      "     |      .   \n",
      "     |      .       @param preset one of PRESET_ULTRAFAST, PRESET_FAST and PRESET_MEDIUM\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DenseOpticalFlow:\n",
      "     |  \n",
      "     |  calc(...)\n",
      "     |      calc(I0, I1, flow) -> flow\n",
      "     |      .   @brief Calculates an optical flow.\n",
      "     |      .   \n",
      "     |      .       @param I0 first 8-bit single-channel input image.\n",
      "     |      .       @param I1 second input image of the same size and the same type as prev.\n",
      "     |      .       @param flow computed flow image that has the same size as prev and type CV_32FC2.\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .   @brief Releases all inner buffers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class DMatch(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  distance\n",
      "     |      distance\n",
      "     |  \n",
      "     |  imgIdx\n",
      "     |      imgIdx\n",
      "     |  \n",
      "     |  queryIdx\n",
      "     |      queryIdx\n",
      "     |  \n",
      "     |  trainIdx\n",
      "     |      trainIdx\n",
      "    \n",
      "    class DenseOpticalFlow(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      DenseOpticalFlow\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  calc(...)\n",
      "     |      calc(I0, I1, flow) -> flow\n",
      "     |      .   @brief Calculates an optical flow.\n",
      "     |      .   \n",
      "     |      .       @param I0 first 8-bit single-channel input image.\n",
      "     |      .       @param I1 second input image of the same size and the same type as prev.\n",
      "     |      .       @param flow computed flow image that has the same size as prev and type CV_32FC2.\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .   @brief Releases all inner buffers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class DescriptorMatcher(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      DescriptorMatcher\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(descriptors) -> None\n",
      "     |      .   @brief Adds descriptors to train a CPU(trainDescCollectionis) or GPU(utrainDescCollectionis) descriptor\n",
      "     |      .       collection.\n",
      "     |      .   \n",
      "     |      .       If the collection is not empty, the new descriptors are added to existing train descriptors.\n",
      "     |      .   \n",
      "     |      .       @param descriptors Descriptors to add. Each descriptors[i] is a set of descriptors from the same\n",
      "     |      .       train image.\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the train descriptor collections.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone([, emptyTrainData]) -> retval\n",
      "     |      .   @brief Clones the matcher.\n",
      "     |      .   \n",
      "     |      .       @param emptyTrainData If emptyTrainData is false, the method creates a deep copy of the object,\n",
      "     |      .       that is, copies both parameters and train data. If emptyTrainData is true, the method creates an\n",
      "     |      .       object copy with the current parameters but with empty train data.\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if there are no train descriptors in the both collections.\n",
      "     |  \n",
      "     |  getTrainDescriptors(...)\n",
      "     |      getTrainDescriptors() -> retval\n",
      "     |      .   @brief Returns a constant link to the train descriptor collection trainDescCollection .\n",
      "     |  \n",
      "     |  isMaskSupported(...)\n",
      "     |      isMaskSupported() -> retval\n",
      "     |      .   @brief Returns true if the descriptor matcher supports masking permissible matches.\n",
      "     |  \n",
      "     |  knnMatch(...)\n",
      "     |      knnMatch(queryDescriptors, trainDescriptors, k[, mask[, compactResult]]) -> matches\n",
      "     |      .   @brief Finds the k best matches for each descriptor from a query set.\n",
      "     |      .   \n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .       collection stored in the class object.\n",
      "     |      .       @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .       descriptors.\n",
      "     |      .       @param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n",
      "     |      .       @param k Count of best matches found per each query descriptor or less if a query descriptor has\n",
      "     |      .       less than k possible matches in total.\n",
      "     |      .       @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .       false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .       the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |      .   \n",
      "     |      .       These extended variants of DescriptorMatcher::match methods find several best matches for each query\n",
      "     |      .       descriptor. The matches are returned in the distance increasing order. See DescriptorMatcher::match\n",
      "     |      .       for the details about query and train descriptors.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      knnMatch(queryDescriptors, k[, masks[, compactResult]]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n",
      "     |      .       @param k Count of best matches found per each query descriptor or less if a query descriptor has\n",
      "     |      .       less than k possible matches in total.\n",
      "     |      .       @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .       descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |      .       @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .       false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .       the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |  \n",
      "     |  match(...)\n",
      "     |      match(queryDescriptors, trainDescriptors[, mask]) -> matches\n",
      "     |      .   @brief Finds the best match for each descriptor from a query set.\n",
      "     |      .   \n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .       collection stored in the class object.\n",
      "     |      .       @param matches Matches. If a query descriptor is masked out in mask , no match is added for this\n",
      "     |      .       descriptor. So, matches size may be smaller than the query descriptors count.\n",
      "     |      .       @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .       descriptors.\n",
      "     |      .   \n",
      "     |      .       In the first variant of this method, the train descriptors are passed as an input argument. In the\n",
      "     |      .       second variant of the method, train descriptors collection that was set by DescriptorMatcher::add is\n",
      "     |      .       used. Optional mask (or masks) can be passed to specify which query and training descriptors can be\n",
      "     |      .       matched. Namely, queryDescriptors[i] can be matched with trainDescriptors[j] only if\n",
      "     |      .       mask.at\\<uchar\\>(i,j) is non-zero.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      match(queryDescriptors[, masks]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param matches Matches. If a query descriptor is masked out in mask , no match is added for this\n",
      "     |      .       descriptor. So, matches size may be smaller than the query descriptors count.\n",
      "     |      .       @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .       descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |  \n",
      "     |  radiusMatch(...)\n",
      "     |      radiusMatch(queryDescriptors, trainDescriptors, maxDistance[, mask[, compactResult]]) -> matches\n",
      "     |      .   @brief For each query descriptor, finds the training descriptors not farther than the specified distance.\n",
      "     |      .   \n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .       collection stored in the class object.\n",
      "     |      .       @param matches Found matches.\n",
      "     |      .       @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .       false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .       the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |      .       @param maxDistance Threshold for the distance between matched descriptors. Distance means here\n",
      "     |      .       metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\n",
      "     |      .       in Pixels)!\n",
      "     |      .       @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .       descriptors.\n",
      "     |      .   \n",
      "     |      .       For each query descriptor, the methods find such training descriptors that the distance between the\n",
      "     |      .       query descriptor and the training descriptor is equal or smaller than maxDistance. Found matches are\n",
      "     |      .       returned in the distance increasing order.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      radiusMatch(queryDescriptors, maxDistance[, masks[, compactResult]]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param matches Found matches.\n",
      "     |      .       @param maxDistance Threshold for the distance between matched descriptors. Distance means here\n",
      "     |      .       metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\n",
      "     |      .       in Pixels)!\n",
      "     |      .       @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .       descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |      .       @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .       false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .       the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train() -> None\n",
      "     |      .   @brief Trains a descriptor matcher\n",
      "     |      .   \n",
      "     |      .       Trains a descriptor matcher (for example, the flann index). In all methods to match, the method\n",
      "     |      .       train() is run every time before matching. Some descriptor matchers (for example, BruteForceMatcher)\n",
      "     |      .       have an empty implementation of this method. Other matchers really train their inner structures (for\n",
      "     |      .       example, FlannBasedMatcher trains flann::Index ).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create(descriptorMatcherType) -> retval\n",
      "     |      .   @brief Creates a descriptor matcher of a given type with the default parameters (using default\n",
      "     |      .       constructor).\n",
      "     |      .   \n",
      "     |      .       @param descriptorMatcherType Descriptor matcher type. Now the following matcher types are\n",
      "     |      .       supported:\n",
      "     |      .       -   `BruteForce` (it uses L2 )\n",
      "     |      .       -   `BruteForce-L1`\n",
      "     |      .       -   `BruteForce-Hamming`\n",
      "     |      .       -   `BruteForce-Hamming(2)`\n",
      "     |      .       -   `FlannBased`\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      create(matcherType) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "    \n",
      "    class FarnebackOpticalFlow(DenseOpticalFlow)\n",
      "     |  Method resolution order:\n",
      "     |      FarnebackOpticalFlow\n",
      "     |      DenseOpticalFlow\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getFastPyramids(...)\n",
      "     |      getFastPyramids() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getFlags(...)\n",
      "     |      getFlags() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNumIters(...)\n",
      "     |      getNumIters() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNumLevels(...)\n",
      "     |      getNumLevels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPolyN(...)\n",
      "     |      getPolyN() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPolySigma(...)\n",
      "     |      getPolySigma() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPyrScale(...)\n",
      "     |      getPyrScale() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getWinSize(...)\n",
      "     |      getWinSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setFastPyramids(...)\n",
      "     |      setFastPyramids(fastPyramids) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setFlags(...)\n",
      "     |      setFlags(flags) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNumIters(...)\n",
      "     |      setNumIters(numIters) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNumLevels(...)\n",
      "     |      setNumLevels(numLevels) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPolyN(...)\n",
      "     |      setPolyN(polyN) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPolySigma(...)\n",
      "     |      setPolySigma(polySigma) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPyrScale(...)\n",
      "     |      setPyrScale(pyrScale) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setWinSize(...)\n",
      "     |      setWinSize(winSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, numLevels[, pyrScale[, fastPyramids[, winSize[, numIters[, polyN[, polySigma[, flags]]]]]]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DenseOpticalFlow:\n",
      "     |  \n",
      "     |  calc(...)\n",
      "     |      calc(I0, I1, flow) -> flow\n",
      "     |      .   @brief Calculates an optical flow.\n",
      "     |      .   \n",
      "     |      .       @param I0 first 8-bit single-channel input image.\n",
      "     |      .       @param I1 second input image of the same size and the same type as prev.\n",
      "     |      .       @param flow computed flow image that has the same size as prev and type CV_32FC2.\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .   @brief Releases all inner buffers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class FastFeatureDetector(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      FastFeatureDetector\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNonmaxSuppression(...)\n",
      "     |      getNonmaxSuppression() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getThreshold(...)\n",
      "     |      getThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getType(...)\n",
      "     |      getType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNonmaxSuppression(...)\n",
      "     |      setNonmaxSuppression(f) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setThreshold(...)\n",
      "     |      setThreshold(threshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setType(...)\n",
      "     |      setType(type) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, threshold[, nonmaxSuppression[, type]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .       (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .       matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .       masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class Feature2D(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .       (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .       matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .       masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FileNode(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  at(...)\n",
      "     |      at(i) -> retval\n",
      "     |      .   @overload\n",
      "     |      .        @param i Index of an element in the sequence node.\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNode(...)\n",
      "     |      getNode(nodename) -> retval\n",
      "     |      .   @overload\n",
      "     |      .        @param nodename Name of an element in the mapping node.\n",
      "     |  \n",
      "     |  isInt(...)\n",
      "     |      isInt() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isMap(...)\n",
      "     |      isMap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isNamed(...)\n",
      "     |      isNamed() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isNone(...)\n",
      "     |      isNone() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isReal(...)\n",
      "     |      isReal() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isSeq(...)\n",
      "     |      isSeq() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isString(...)\n",
      "     |      isString() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  keys(...)\n",
      "     |      keys() -> retval\n",
      "     |      .   @brief Returns keys of a mapping node.\n",
      "     |      .        @returns Keys of a mapping node.\n",
      "     |  \n",
      "     |  mat(...)\n",
      "     |      mat() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  name(...)\n",
      "     |      name() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  rawSize(...)\n",
      "     |      rawSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  real(...)\n",
      "     |      real() -> retval\n",
      "     |      .   Internal method used when reading FileStorage.\n",
      "     |      .        Sets the type (int, real or string) and value of the previously created node.\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  string(...)\n",
      "     |      string() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type() -> retval\n",
      "     |      .   @brief Returns type of the node.\n",
      "     |      .        @returns Type of the node. See FileNode::Type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FileStorage(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  endWriteStruct(...)\n",
      "     |      endWriteStruct() -> None\n",
      "     |      .   @brief Finishes writing nested structure (should pair startWriteStruct())\n",
      "     |  \n",
      "     |  getFirstTopLevelNode(...)\n",
      "     |      getFirstTopLevelNode() -> retval\n",
      "     |      .   @brief Returns the first element of the top-level mapping.\n",
      "     |      .        @returns The first element of the top-level mapping.\n",
      "     |  \n",
      "     |  getFormat(...)\n",
      "     |      getFormat() -> retval\n",
      "     |      .   @brief Returns the current format.\n",
      "     |      .        * @returns The current format, see FileStorage::Mode\n",
      "     |  \n",
      "     |  getNode(...)\n",
      "     |      getNode(nodename) -> retval\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  isOpened(...)\n",
      "     |      isOpened() -> retval\n",
      "     |      .   @brief Checks whether the file is opened.\n",
      "     |      .   \n",
      "     |      .        @returns true if the object is associated with the current file and false otherwise. It is a\n",
      "     |      .        good practice to call this method after you tried to open a file.\n",
      "     |  \n",
      "     |  open(...)\n",
      "     |      open(filename, flags[, encoding]) -> retval\n",
      "     |      .   @brief Opens a file.\n",
      "     |      .   \n",
      "     |      .        See description of parameters in FileStorage::FileStorage. The method calls FileStorage::release\n",
      "     |      .        before opening the file.\n",
      "     |      .        @param filename Name of the file to open or the text string to read the data from.\n",
      "     |      .        Extension of the file (.xml, .yml/.yaml or .json) determines its format (XML, YAML or JSON\n",
      "     |      .        respectively). Also you can append .gz to work with compressed files, for example myHugeMatrix.xml.gz. If both\n",
      "     |      .        FileStorage::WRITE and FileStorage::MEMORY flags are specified, source is used just to specify\n",
      "     |      .        the output file format (e.g. mydata.xml, .yml etc.). A file name can also contain parameters.\n",
      "     |      .        You can use this format, \"*?base64\" (e.g. \"file.json?base64\" (case sensitive)), as an alternative to\n",
      "     |      .        FileStorage::BASE64 flag.\n",
      "     |      .        @param flags Mode of operation. One of FileStorage::Mode\n",
      "     |      .        @param encoding Encoding of the file. Note that UTF-16 XML encoding is not supported currently and\n",
      "     |      .        you should use 8-bit encoding instead of it.\n",
      "     |  \n",
      "     |  release(...)\n",
      "     |      release() -> None\n",
      "     |      .   @brief Closes the file and releases all the memory buffers.\n",
      "     |      .   \n",
      "     |      .        Call this method after all I/O operations with the storage are finished.\n",
      "     |  \n",
      "     |  releaseAndGetString(...)\n",
      "     |      releaseAndGetString() -> retval\n",
      "     |      .   @brief Closes the file and releases all the memory buffers.\n",
      "     |      .   \n",
      "     |      .        Call this method after all I/O operations with the storage are finished. If the storage was\n",
      "     |      .        opened for writing data and FileStorage::WRITE was specified\n",
      "     |  \n",
      "     |  root(...)\n",
      "     |      root([, streamidx]) -> retval\n",
      "     |      .   @brief Returns the top-level mapping\n",
      "     |      .        @param streamidx Zero-based index of the stream. In most cases there is only one stream in the file.\n",
      "     |      .        However, YAML supports multiple streams and so there can be several.\n",
      "     |      .        @returns The top-level mapping.\n",
      "     |  \n",
      "     |  startWriteStruct(...)\n",
      "     |      startWriteStruct(name, flags[, typeName]) -> None\n",
      "     |      .   @brief Starts to write a nested structure (sequence or a mapping).\n",
      "     |      .       @param name name of the structure (if it's a member of parent mapping, otherwise it should be empty\n",
      "     |      .       @param flags type of the structure (FileNode::MAP or FileNode::SEQ (both with optional FileNode::FLOW)).\n",
      "     |      .       @param typeName usually an empty string\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(name, val) -> None\n",
      "     |      .   * @brief Simplified writing API to use with bindings.\n",
      "     |      .        * @param name Name of the written object\n",
      "     |      .        * @param val Value of the written object\n",
      "     |  \n",
      "     |  writeComment(...)\n",
      "     |      writeComment(comment[, append]) -> None\n",
      "     |      .   @brief Writes a comment.\n",
      "     |      .   \n",
      "     |      .        The function writes a comment into file storage. The comments are skipped when the storage is read.\n",
      "     |      .        @param comment The written comment, single-line or multi-line\n",
      "     |      .        @param append If true, the function tries to put the comment at the end of current line.\n",
      "     |      .        Else if the comment is multi-line, or if it does not fit at the end of the current\n",
      "     |      .        line, the comment starts a new line.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FlannBasedMatcher(DescriptorMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      FlannBasedMatcher\n",
      "     |      DescriptorMatcher\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DescriptorMatcher:\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(descriptors) -> None\n",
      "     |      .   @brief Adds descriptors to train a CPU(trainDescCollectionis) or GPU(utrainDescCollectionis) descriptor\n",
      "     |      .       collection.\n",
      "     |      .   \n",
      "     |      .       If the collection is not empty, the new descriptors are added to existing train descriptors.\n",
      "     |      .   \n",
      "     |      .       @param descriptors Descriptors to add. Each descriptors[i] is a set of descriptors from the same\n",
      "     |      .       train image.\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the train descriptor collections.\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone([, emptyTrainData]) -> retval\n",
      "     |      .   @brief Clones the matcher.\n",
      "     |      .   \n",
      "     |      .       @param emptyTrainData If emptyTrainData is false, the method creates a deep copy of the object,\n",
      "     |      .       that is, copies both parameters and train data. If emptyTrainData is true, the method creates an\n",
      "     |      .       object copy with the current parameters but with empty train data.\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if there are no train descriptors in the both collections.\n",
      "     |  \n",
      "     |  getTrainDescriptors(...)\n",
      "     |      getTrainDescriptors() -> retval\n",
      "     |      .   @brief Returns a constant link to the train descriptor collection trainDescCollection .\n",
      "     |  \n",
      "     |  isMaskSupported(...)\n",
      "     |      isMaskSupported() -> retval\n",
      "     |      .   @brief Returns true if the descriptor matcher supports masking permissible matches.\n",
      "     |  \n",
      "     |  knnMatch(...)\n",
      "     |      knnMatch(queryDescriptors, trainDescriptors, k[, mask[, compactResult]]) -> matches\n",
      "     |      .   @brief Finds the k best matches for each descriptor from a query set.\n",
      "     |      .   \n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .       collection stored in the class object.\n",
      "     |      .       @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .       descriptors.\n",
      "     |      .       @param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n",
      "     |      .       @param k Count of best matches found per each query descriptor or less if a query descriptor has\n",
      "     |      .       less than k possible matches in total.\n",
      "     |      .       @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .       false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .       the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |      .   \n",
      "     |      .       These extended variants of DescriptorMatcher::match methods find several best matches for each query\n",
      "     |      .       descriptor. The matches are returned in the distance increasing order. See DescriptorMatcher::match\n",
      "     |      .       for the details about query and train descriptors.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      knnMatch(queryDescriptors, k[, masks[, compactResult]]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param matches Matches. Each matches[i] is k or less matches for the same query descriptor.\n",
      "     |      .       @param k Count of best matches found per each query descriptor or less if a query descriptor has\n",
      "     |      .       less than k possible matches in total.\n",
      "     |      .       @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .       descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |      .       @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .       false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .       the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |  \n",
      "     |  match(...)\n",
      "     |      match(queryDescriptors, trainDescriptors[, mask]) -> matches\n",
      "     |      .   @brief Finds the best match for each descriptor from a query set.\n",
      "     |      .   \n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .       collection stored in the class object.\n",
      "     |      .       @param matches Matches. If a query descriptor is masked out in mask , no match is added for this\n",
      "     |      .       descriptor. So, matches size may be smaller than the query descriptors count.\n",
      "     |      .       @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .       descriptors.\n",
      "     |      .   \n",
      "     |      .       In the first variant of this method, the train descriptors are passed as an input argument. In the\n",
      "     |      .       second variant of the method, train descriptors collection that was set by DescriptorMatcher::add is\n",
      "     |      .       used. Optional mask (or masks) can be passed to specify which query and training descriptors can be\n",
      "     |      .       matched. Namely, queryDescriptors[i] can be matched with trainDescriptors[j] only if\n",
      "     |      .       mask.at\\<uchar\\>(i,j) is non-zero.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      match(queryDescriptors[, masks]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param matches Matches. If a query descriptor is masked out in mask , no match is added for this\n",
      "     |      .       descriptor. So, matches size may be smaller than the query descriptors count.\n",
      "     |      .       @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .       descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |  \n",
      "     |  radiusMatch(...)\n",
      "     |      radiusMatch(queryDescriptors, trainDescriptors, maxDistance[, mask[, compactResult]]) -> matches\n",
      "     |      .   @brief For each query descriptor, finds the training descriptors not farther than the specified distance.\n",
      "     |      .   \n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param trainDescriptors Train set of descriptors. This set is not added to the train descriptors\n",
      "     |      .       collection stored in the class object.\n",
      "     |      .       @param matches Found matches.\n",
      "     |      .       @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .       false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .       the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |      .       @param maxDistance Threshold for the distance between matched descriptors. Distance means here\n",
      "     |      .       metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\n",
      "     |      .       in Pixels)!\n",
      "     |      .       @param mask Mask specifying permissible matches between an input query and train matrices of\n",
      "     |      .       descriptors.\n",
      "     |      .   \n",
      "     |      .       For each query descriptor, the methods find such training descriptors that the distance between the\n",
      "     |      .       query descriptor and the training descriptor is equal or smaller than maxDistance. Found matches are\n",
      "     |      .       returned in the distance increasing order.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      radiusMatch(queryDescriptors, maxDistance[, masks[, compactResult]]) -> matches\n",
      "     |      .   @overload\n",
      "     |      .       @param queryDescriptors Query set of descriptors.\n",
      "     |      .       @param matches Found matches.\n",
      "     |      .       @param maxDistance Threshold for the distance between matched descriptors. Distance means here\n",
      "     |      .       metric distance (e.g. Hamming distance), not the distance between coordinates (which is measured\n",
      "     |      .       in Pixels)!\n",
      "     |      .       @param masks Set of masks. Each masks[i] specifies permissible matches between the input query\n",
      "     |      .       descriptors and stored train descriptors from the i-th image trainDescCollection[i].\n",
      "     |      .       @param compactResult Parameter used when the mask (or masks) is not empty. If compactResult is\n",
      "     |      .       false, the matches vector has the same size as queryDescriptors rows. If compactResult is true,\n",
      "     |      .       the matches vector does not contain matches for fully masked-out query descriptors.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train() -> None\n",
      "     |      .   @brief Trains a descriptor matcher\n",
      "     |      .   \n",
      "     |      .       Trains a descriptor matcher (for example, the flann index). In all methods to match, the method\n",
      "     |      .       train() is run every time before matching. Some descriptor matchers (for example, BruteForceMatcher)\n",
      "     |      .       have an empty implementation of this method. Other matchers really train their inner structures (for\n",
      "     |      .       example, FlannBasedMatcher trains flann::Index ).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "    \n",
      "    class GFTTDetector(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      GFTTDetector\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getHarrisDetector(...)\n",
      "     |      getHarrisDetector() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getK(...)\n",
      "     |      getK() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxFeatures(...)\n",
      "     |      getMaxFeatures() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDistance(...)\n",
      "     |      getMinDistance() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getQualityLevel(...)\n",
      "     |      getQualityLevel() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(blockSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setHarrisDetector(...)\n",
      "     |      setHarrisDetector(val) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setK(...)\n",
      "     |      setK(k) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxFeatures(...)\n",
      "     |      setMaxFeatures(maxFeatures) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDistance(...)\n",
      "     |      setMinDistance(minDistance) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setQualityLevel(...)\n",
      "     |      setQualityLevel(qlevel) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, maxCorners[, qualityLevel[, minDistance[, blockSize[, useHarrisDetector[, k]]]]]]) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      create(maxCorners, qualityLevel, minDistance, blockSize, gradiantSize[, useHarrisDetector[, k]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .       (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .       matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .       masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class GeneralizedHough(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      GeneralizedHough\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, positions[, votes]]) -> positions, votes\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(edges, dx, dy[, positions[, votes]]) -> positions, votes\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCannyHighThresh(...)\n",
      "     |      getCannyHighThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCannyLowThresh(...)\n",
      "     |      getCannyLowThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDp(...)\n",
      "     |      getDp() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxBufferSize(...)\n",
      "     |      getMaxBufferSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDist(...)\n",
      "     |      getMinDist() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCannyHighThresh(...)\n",
      "     |      setCannyHighThresh(cannyHighThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCannyLowThresh(...)\n",
      "     |      setCannyLowThresh(cannyLowThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDp(...)\n",
      "     |      setDp(dp) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxBufferSize(...)\n",
      "     |      setMaxBufferSize(maxBufferSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDist(...)\n",
      "     |      setMinDist(minDist) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTemplate(...)\n",
      "     |      setTemplate(templ[, templCenter]) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setTemplate(edges, dx, dy[, templCenter]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class GeneralizedHoughBallard(GeneralizedHough)\n",
      "     |  Method resolution order:\n",
      "     |      GeneralizedHoughBallard\n",
      "     |      GeneralizedHough\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getLevels(...)\n",
      "     |      getLevels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVotesThreshold(...)\n",
      "     |      getVotesThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setLevels(...)\n",
      "     |      setLevels(levels) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setVotesThreshold(...)\n",
      "     |      setVotesThreshold(votesThreshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GeneralizedHough:\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, positions[, votes]]) -> positions, votes\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(edges, dx, dy[, positions[, votes]]) -> positions, votes\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCannyHighThresh(...)\n",
      "     |      getCannyHighThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCannyLowThresh(...)\n",
      "     |      getCannyLowThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDp(...)\n",
      "     |      getDp() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxBufferSize(...)\n",
      "     |      getMaxBufferSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDist(...)\n",
      "     |      getMinDist() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCannyHighThresh(...)\n",
      "     |      setCannyHighThresh(cannyHighThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCannyLowThresh(...)\n",
      "     |      setCannyLowThresh(cannyLowThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDp(...)\n",
      "     |      setDp(dp) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxBufferSize(...)\n",
      "     |      setMaxBufferSize(maxBufferSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDist(...)\n",
      "     |      setMinDist(minDist) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTemplate(...)\n",
      "     |      setTemplate(templ[, templCenter]) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setTemplate(edges, dx, dy[, templCenter]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class GeneralizedHoughGuil(GeneralizedHough)\n",
      "     |  Method resolution order:\n",
      "     |      GeneralizedHoughGuil\n",
      "     |      GeneralizedHough\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getAngleEpsilon(...)\n",
      "     |      getAngleEpsilon() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getAngleStep(...)\n",
      "     |      getAngleStep() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getAngleThresh(...)\n",
      "     |      getAngleThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getLevels(...)\n",
      "     |      getLevels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxAngle(...)\n",
      "     |      getMaxAngle() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxScale(...)\n",
      "     |      getMaxScale() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinAngle(...)\n",
      "     |      getMinAngle() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinScale(...)\n",
      "     |      getMinScale() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPosThresh(...)\n",
      "     |      getPosThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getScaleStep(...)\n",
      "     |      getScaleStep() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getScaleThresh(...)\n",
      "     |      getScaleThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getXi(...)\n",
      "     |      getXi() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setAngleEpsilon(...)\n",
      "     |      setAngleEpsilon(angleEpsilon) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setAngleStep(...)\n",
      "     |      setAngleStep(angleStep) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setAngleThresh(...)\n",
      "     |      setAngleThresh(angleThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setLevels(...)\n",
      "     |      setLevels(levels) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxAngle(...)\n",
      "     |      setMaxAngle(maxAngle) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxScale(...)\n",
      "     |      setMaxScale(maxScale) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinAngle(...)\n",
      "     |      setMinAngle(minAngle) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinScale(...)\n",
      "     |      setMinScale(minScale) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPosThresh(...)\n",
      "     |      setPosThresh(posThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setScaleStep(...)\n",
      "     |      setScaleStep(scaleStep) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setScaleThresh(...)\n",
      "     |      setScaleThresh(scaleThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setXi(...)\n",
      "     |      setXi(xi) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from GeneralizedHough:\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, positions[, votes]]) -> positions, votes\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(edges, dx, dy[, positions[, votes]]) -> positions, votes\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCannyHighThresh(...)\n",
      "     |      getCannyHighThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCannyLowThresh(...)\n",
      "     |      getCannyLowThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDp(...)\n",
      "     |      getDp() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxBufferSize(...)\n",
      "     |      getMaxBufferSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDist(...)\n",
      "     |      getMinDist() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCannyHighThresh(...)\n",
      "     |      setCannyHighThresh(cannyHighThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCannyLowThresh(...)\n",
      "     |      setCannyLowThresh(cannyLowThresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDp(...)\n",
      "     |      setDp(dp) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxBufferSize(...)\n",
      "     |      setMaxBufferSize(maxBufferSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDist(...)\n",
      "     |      setMinDist(minDist) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTemplate(...)\n",
      "     |      setTemplate(templ[, templCenter]) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setTemplate(edges, dx, dy[, templCenter]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class HOGDescriptor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  checkDetectorSize(...)\n",
      "     |      checkDetectorSize() -> retval\n",
      "     |      .   @brief Checks if detector size equal to descriptor size.\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(img[, winStride[, padding[, locations]]]) -> descriptors\n",
      "     |      .   @brief Computes HOG descriptors of given image.\n",
      "     |      .       @param img Matrix of the type CV_8U containing an image where HOG features will be calculated.\n",
      "     |      .       @param descriptors Matrix of the type CV_32F\n",
      "     |      .       @param winStride Window stride. It must be a multiple of block stride.\n",
      "     |      .       @param padding Padding\n",
      "     |      .       @param locations Vector of Point\n",
      "     |  \n",
      "     |  computeGradient(...)\n",
      "     |      computeGradient(img, grad, angleOfs[, paddingTL[, paddingBR]]) -> grad, angleOfs\n",
      "     |      .   @brief  Computes gradients and quantized gradient orientations.\n",
      "     |      .       @param img Matrix contains the image to be computed\n",
      "     |      .       @param grad Matrix of type CV_32FC2 contains computed gradients\n",
      "     |      .       @param angleOfs Matrix of type CV_8UC2 contains quantized gradient orientations\n",
      "     |      .       @param paddingTL Padding from top-left\n",
      "     |      .       @param paddingBR Padding from bottom-right\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(img[, hitThreshold[, winStride[, padding[, searchLocations]]]]) -> foundLocations, weights\n",
      "     |      .   @brief Performs object detection without a multi-scale window.\n",
      "     |      .       @param img Matrix of the type CV_8U or CV_8UC3 containing an image where objects are detected.\n",
      "     |      .       @param foundLocations Vector of point where each point contains left-top corner point of detected object boundaries.\n",
      "     |      .       @param weights Vector that will contain confidence values for each detected object.\n",
      "     |      .       @param hitThreshold Threshold for the distance between features and SVM classifying plane.\n",
      "     |      .       Usually it is 0 and should be specified in the detector coefficients (as the last free coefficient).\n",
      "     |      .       But if the free coefficient is omitted (which is allowed), you can specify it manually here.\n",
      "     |      .       @param winStride Window stride. It must be a multiple of block stride.\n",
      "     |      .       @param padding Padding\n",
      "     |      .       @param searchLocations Vector of Point includes set of requested locations to be evaluated.\n",
      "     |  \n",
      "     |  detectMultiScale(...)\n",
      "     |      detectMultiScale(img[, hitThreshold[, winStride[, padding[, scale[, finalThreshold[, useMeanshiftGrouping]]]]]]) -> foundLocations, foundWeights\n",
      "     |      .   @brief Detects objects of different sizes in the input image. The detected objects are returned as a list\n",
      "     |      .       of rectangles.\n",
      "     |      .       @param img Matrix of the type CV_8U or CV_8UC3 containing an image where objects are detected.\n",
      "     |      .       @param foundLocations Vector of rectangles where each rectangle contains the detected object.\n",
      "     |      .       @param foundWeights Vector that will contain confidence values for each detected object.\n",
      "     |      .       @param hitThreshold Threshold for the distance between features and SVM classifying plane.\n",
      "     |      .       Usually it is 0 and should be specified in the detector coefficients (as the last free coefficient).\n",
      "     |      .       But if the free coefficient is omitted (which is allowed), you can specify it manually here.\n",
      "     |      .       @param winStride Window stride. It must be a multiple of block stride.\n",
      "     |      .       @param padding Padding\n",
      "     |      .       @param scale Coefficient of the detection window increase.\n",
      "     |      .       @param finalThreshold Final threshold\n",
      "     |      .       @param useMeanshiftGrouping indicates grouping algorithm\n",
      "     |  \n",
      "     |  getDescriptorSize(...)\n",
      "     |      getDescriptorSize() -> retval\n",
      "     |      .   @brief Returns the number of coefficients required for the classification.\n",
      "     |  \n",
      "     |  getWinSigma(...)\n",
      "     |      getWinSigma() -> retval\n",
      "     |      .   @brief Returns winSigma value\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filename[, objname]) -> retval\n",
      "     |      .   @brief loads HOGDescriptor parameters and coefficients for the linear SVM classifier from a file.\n",
      "     |      .       @param filename Path of the file to read.\n",
      "     |      .       @param objname The optional name of the node to read (if empty, the first top-level node will be used).\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename[, objname]) -> None\n",
      "     |      .   @brief saves HOGDescriptor parameters and coefficients for the linear SVM classifier to a file\n",
      "     |      .       @param filename File name\n",
      "     |      .       @param objname Object name\n",
      "     |  \n",
      "     |  setSVMDetector(...)\n",
      "     |      setSVMDetector(svmdetector) -> None\n",
      "     |      .   @brief Sets coefficients for the linear SVM classifier.\n",
      "     |      .       @param svmdetector coefficients for the linear SVM classifier.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  getDaimlerPeopleDetector(...)\n",
      "     |      getDaimlerPeopleDetector() -> retval\n",
      "     |      .   @brief Returns coefficients of the classifier trained for people detection (for 48x96 windows).\n",
      "     |  \n",
      "     |  getDefaultPeopleDetector(...)\n",
      "     |      getDefaultPeopleDetector() -> retval\n",
      "     |      .   @brief Returns coefficients of the classifier trained for people detection (for 64x128 windows).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  L2HysThreshold\n",
      "     |      L2HysThreshold\n",
      "     |  \n",
      "     |  blockSize\n",
      "     |      blockSize\n",
      "     |  \n",
      "     |  blockStride\n",
      "     |      blockStride\n",
      "     |  \n",
      "     |  cellSize\n",
      "     |      cellSize\n",
      "     |  \n",
      "     |  derivAperture\n",
      "     |      derivAperture\n",
      "     |  \n",
      "     |  gammaCorrection\n",
      "     |      gammaCorrection\n",
      "     |  \n",
      "     |  histogramNormType\n",
      "     |      histogramNormType\n",
      "     |  \n",
      "     |  nbins\n",
      "     |      nbins\n",
      "     |  \n",
      "     |  nlevels\n",
      "     |      nlevels\n",
      "     |  \n",
      "     |  signedGradient\n",
      "     |      signedGradient\n",
      "     |  \n",
      "     |  svmDetector\n",
      "     |      svmDetector\n",
      "     |  \n",
      "     |  winSigma\n",
      "     |      winSigma\n",
      "     |  \n",
      "     |  winSize\n",
      "     |      winSize\n",
      "    \n",
      "    class KAZE(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      KAZE\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDiffusivity(...)\n",
      "     |      getDiffusivity() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getExtended(...)\n",
      "     |      getExtended() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNOctaveLayers(...)\n",
      "     |      getNOctaveLayers() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNOctaves(...)\n",
      "     |      getNOctaves() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getThreshold(...)\n",
      "     |      getThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getUpright(...)\n",
      "     |      getUpright() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDiffusivity(...)\n",
      "     |      setDiffusivity(diff) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setExtended(...)\n",
      "     |      setExtended(extended) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNOctaveLayers(...)\n",
      "     |      setNOctaveLayers(octaveLayers) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNOctaves(...)\n",
      "     |      setNOctaves(octaves) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setThreshold(...)\n",
      "     |      setThreshold(threshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpright(...)\n",
      "     |      setUpright(upright) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, extended[, upright[, threshold[, nOctaves[, nOctaveLayers[, diffusivity]]]]]]) -> retval\n",
      "     |      .   @brief The KAZE constructor\n",
      "     |      .   \n",
      "     |      .       @param extended Set to enable extraction of extended (128-byte) descriptor.\n",
      "     |      .       @param upright Set to enable use of upright descriptors (non rotation-invariant).\n",
      "     |      .       @param threshold Detector response threshold to accept point\n",
      "     |      .       @param nOctaves Maximum octave evolution of the image\n",
      "     |      .       @param nOctaveLayers Default number of sublevels per scale level\n",
      "     |      .       @param diffusivity Diffusivity type. DIFF_PM_G1, DIFF_PM_G2, DIFF_WEICKERT or\n",
      "     |      .       DIFF_CHARBONNIER\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .       (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .       matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .       masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class KalmanFilter(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  correct(...)\n",
      "     |      correct(measurement) -> retval\n",
      "     |      .   @brief Updates the predicted state from the measurement.\n",
      "     |      .   \n",
      "     |      .       @param measurement The measured system parameters\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict([, control]) -> retval\n",
      "     |      .   @brief Computes a predicted state.\n",
      "     |      .   \n",
      "     |      .       @param control The optional input control\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  controlMatrix\n",
      "     |      controlMatrix\n",
      "     |  \n",
      "     |  errorCovPost\n",
      "     |      errorCovPost\n",
      "     |  \n",
      "     |  errorCovPre\n",
      "     |      errorCovPre\n",
      "     |  \n",
      "     |  gain\n",
      "     |      gain\n",
      "     |  \n",
      "     |  measurementMatrix\n",
      "     |      measurementMatrix\n",
      "     |  \n",
      "     |  measurementNoiseCov\n",
      "     |      measurementNoiseCov\n",
      "     |  \n",
      "     |  processNoiseCov\n",
      "     |      processNoiseCov\n",
      "     |  \n",
      "     |  statePost\n",
      "     |      statePost\n",
      "     |  \n",
      "     |  statePre\n",
      "     |      statePre\n",
      "     |  \n",
      "     |  transitionMatrix\n",
      "     |      transitionMatrix\n",
      "    \n",
      "    class KeyPoint(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  convert(...)\n",
      "     |      convert(keypoints[, keypointIndexes]) -> points2f\n",
      "     |      .   This method converts vector of keypoints to vector of points or the reverse, where each keypoint is\n",
      "     |      .       assigned the same size and the same orientation.\n",
      "     |      .   \n",
      "     |      .       @param keypoints Keypoints obtained from any feature detection algorithm like SIFT/SURF/ORB\n",
      "     |      .       @param points2f Array of (x,y) coordinates of each keypoint\n",
      "     |      .       @param keypointIndexes Array of indexes of keypoints to be converted to points. (Acts like a mask to\n",
      "     |      .       convert only specified keypoints)\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      convert(points2f[, size[, response[, octave[, class_id]]]]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .       @param points2f Array of (x,y) coordinates of each keypoint\n",
      "     |      .       @param keypoints Keypoints obtained from any feature detection algorithm like SIFT/SURF/ORB\n",
      "     |      .       @param size keypoint diameter\n",
      "     |      .       @param response keypoint detector response on the keypoint (that is, strength of the keypoint)\n",
      "     |      .       @param octave pyramid octave in which the keypoint has been detected\n",
      "     |      .       @param class_id object id\n",
      "     |  \n",
      "     |  overlap(...)\n",
      "     |      overlap(kp1, kp2) -> retval\n",
      "     |      .   This method computes overlap for pair of keypoints. Overlap is the ratio between area of keypoint\n",
      "     |      .       regions' intersection and area of keypoint regions' union (considering keypoint region as circle).\n",
      "     |      .       If they don't overlap, we get zero. If they coincide at same location with same size, we get 1.\n",
      "     |      .       @param kp1 First keypoint\n",
      "     |      .       @param kp2 Second keypoint\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  angle\n",
      "     |      angle\n",
      "     |  \n",
      "     |  class_id\n",
      "     |      class_id\n",
      "     |  \n",
      "     |  octave\n",
      "     |      octave\n",
      "     |  \n",
      "     |  pt\n",
      "     |      pt\n",
      "     |  \n",
      "     |  response\n",
      "     |      response\n",
      "     |  \n",
      "     |  size\n",
      "     |      size\n",
      "    \n",
      "    class LineSegmentDetector(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      LineSegmentDetector\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  compareSegments(...)\n",
      "     |      compareSegments(size, lines1, lines2[, _image]) -> retval, _image\n",
      "     |      .   @brief Draws two groups of lines in blue and red, counting the non overlapping (mismatching) pixels.\n",
      "     |      .   \n",
      "     |      .       @param size The size of the image, where lines1 and lines2 were found.\n",
      "     |      .       @param lines1 The first group of lines that needs to be drawn. It is visualized in blue color.\n",
      "     |      .       @param lines2 The second group of lines. They visualized in red color.\n",
      "     |      .       @param _image Optional image, where the lines will be drawn. The image should be color(3-channel)\n",
      "     |      .       in order for lines1 and lines2 to be drawn in the above mentioned colors.\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(_image[, _lines[, width[, prec[, nfa]]]]) -> _lines, width, prec, nfa\n",
      "     |      .   @brief Finds lines in the input image.\n",
      "     |      .   \n",
      "     |      .       This is the output of the default parameters of the algorithm on the above shown image.\n",
      "     |      .   \n",
      "     |      .       ![image](pics/building_lsd.png)\n",
      "     |      .   \n",
      "     |      .       @param _image A grayscale (CV_8UC1) input image. If only a roi needs to be selected, use:\n",
      "     |      .       `lsd_ptr-\\>detect(image(roi), lines, ...); lines += Scalar(roi.x, roi.y, roi.x, roi.y);`\n",
      "     |      .       @param _lines A vector of Vec4i or Vec4f elements specifying the beginning and ending point of a line. Where\n",
      "     |      .       Vec4i/Vec4f is (x1, y1, x2, y2), point 1 is the start, point 2 - end. Returned lines are strictly\n",
      "     |      .       oriented depending on the gradient.\n",
      "     |      .       @param width Vector of widths of the regions, where the lines are found. E.g. Width of line.\n",
      "     |      .       @param prec Vector of precisions with which the lines are found.\n",
      "     |      .       @param nfa Vector containing number of false alarms in the line region, with precision of 10%. The\n",
      "     |      .       bigger the value, logarithmically better the detection.\n",
      "     |      .       - -1 corresponds to 10 mean false alarms\n",
      "     |      .       - 0 corresponds to 1 mean false alarm\n",
      "     |      .       - 1 corresponds to 0.1 mean false alarms\n",
      "     |      .       This vector will be calculated only when the objects type is #LSD_REFINE_ADV.\n",
      "     |  \n",
      "     |  drawSegments(...)\n",
      "     |      drawSegments(_image, lines) -> _image\n",
      "     |      .   @brief Draws the line segments on a given image.\n",
      "     |      .       @param _image The image, where the lines will be drawn. Should be bigger or equal to the image,\n",
      "     |      .       where the lines were found.\n",
      "     |      .       @param lines A vector of the lines that needed to be drawn.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class MSER(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      MSER\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  detectRegions(...)\n",
      "     |      detectRegions(image) -> msers, bboxes\n",
      "     |      .   @brief Detect %MSER regions\n",
      "     |      .   \n",
      "     |      .       @param image input image (8UC1, 8UC3 or 8UC4, must be greater or equal than 3x3)\n",
      "     |      .       @param msers resulting list of point sets\n",
      "     |      .       @param bboxes resulting bounding boxes\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDelta(...)\n",
      "     |      getDelta() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxArea(...)\n",
      "     |      getMaxArea() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinArea(...)\n",
      "     |      getMinArea() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPass2Only(...)\n",
      "     |      getPass2Only() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDelta(...)\n",
      "     |      setDelta(delta) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxArea(...)\n",
      "     |      setMaxArea(maxArea) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinArea(...)\n",
      "     |      setMinArea(minArea) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPass2Only(...)\n",
      "     |      setPass2Only(f) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, _delta[, _min_area[, _max_area[, _max_variation[, _min_diversity[, _max_evolution[, _area_threshold[, _min_margin[, _edge_blur_size]]]]]]]]]) -> retval\n",
      "     |      .   @brief Full constructor for %MSER detector\n",
      "     |      .   \n",
      "     |      .       @param _delta it compares \\f$(size_{i}-size_{i-delta})/size_{i-delta}\\f$\n",
      "     |      .       @param _min_area prune the area which smaller than minArea\n",
      "     |      .       @param _max_area prune the area which bigger than maxArea\n",
      "     |      .       @param _max_variation prune the area have similar size to its children\n",
      "     |      .       @param _min_diversity for color image, trace back to cut off mser with diversity less than min_diversity\n",
      "     |      .       @param _max_evolution  for color image, the evolution steps\n",
      "     |      .       @param _area_threshold for color image, the area threshold to cause re-initialize\n",
      "     |      .       @param _min_margin for color image, ignore too small margin\n",
      "     |      .       @param _edge_blur_size for color image, the aperture size for edge blur\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .       (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .       matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .       masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class MergeDebevec(MergeExposures)\n",
      "     |  Method resolution order:\n",
      "     |      MergeDebevec\n",
      "     |      MergeExposures\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times, response[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      process(src, times[, dst]) -> dst\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class MergeExposures(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      MergeExposures\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times, response[, dst]) -> dst\n",
      "     |      .   @brief Merges images.\n",
      "     |      .   \n",
      "     |      .       @param src vector of input images\n",
      "     |      .       @param dst result image\n",
      "     |      .       @param times vector of exposure time values for each image\n",
      "     |      .       @param response 256x1 matrix with inverse camera response function for each pixel value, it should\n",
      "     |      .       have the same number of channels as images.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class MergeMertens(MergeExposures)\n",
      "     |  Method resolution order:\n",
      "     |      MergeMertens\n",
      "     |      MergeExposures\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getContrastWeight(...)\n",
      "     |      getContrastWeight() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getExposureWeight(...)\n",
      "     |      getExposureWeight() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSaturationWeight(...)\n",
      "     |      getSaturationWeight() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times, response[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      process(src[, dst]) -> dst\n",
      "     |      .   @brief Short version of process, that doesn't take extra arguments.\n",
      "     |      .   \n",
      "     |      .       @param src vector of input images\n",
      "     |      .       @param dst result image\n",
      "     |  \n",
      "     |  setContrastWeight(...)\n",
      "     |      setContrastWeight(contrast_weiht) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setExposureWeight(...)\n",
      "     |      setExposureWeight(exposure_weight) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSaturationWeight(...)\n",
      "     |      setSaturationWeight(saturation_weight) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class MergeRobertson(MergeExposures)\n",
      "     |  Method resolution order:\n",
      "     |      MergeRobertson\n",
      "     |      MergeExposures\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src, times, response[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      process(src, times[, dst]) -> dst\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class ORB(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      ORB\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getEdgeThreshold(...)\n",
      "     |      getEdgeThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getFastThreshold(...)\n",
      "     |      getFastThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getFirstLevel(...)\n",
      "     |      getFirstLevel() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxFeatures(...)\n",
      "     |      getMaxFeatures() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNLevels(...)\n",
      "     |      getNLevels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPatchSize(...)\n",
      "     |      getPatchSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getScaleFactor(...)\n",
      "     |      getScaleFactor() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getScoreType(...)\n",
      "     |      getScoreType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getWTA_K(...)\n",
      "     |      getWTA_K() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setEdgeThreshold(...)\n",
      "     |      setEdgeThreshold(edgeThreshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setFastThreshold(...)\n",
      "     |      setFastThreshold(fastThreshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setFirstLevel(...)\n",
      "     |      setFirstLevel(firstLevel) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxFeatures(...)\n",
      "     |      setMaxFeatures(maxFeatures) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNLevels(...)\n",
      "     |      setNLevels(nlevels) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPatchSize(...)\n",
      "     |      setPatchSize(patchSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setScaleFactor(...)\n",
      "     |      setScaleFactor(scaleFactor) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setScoreType(...)\n",
      "     |      setScoreType(scoreType) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setWTA_K(...)\n",
      "     |      setWTA_K(wta_k) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, nfeatures[, scaleFactor[, nlevels[, edgeThreshold[, firstLevel[, WTA_K[, scoreType[, patchSize[, fastThreshold]]]]]]]]]) -> retval\n",
      "     |      .   @brief The ORB constructor\n",
      "     |      .   \n",
      "     |      .       @param nfeatures The maximum number of features to retain.\n",
      "     |      .       @param scaleFactor Pyramid decimation ratio, greater than 1. scaleFactor==2 means the classical\n",
      "     |      .       pyramid, where each next level has 4x less pixels than the previous, but such a big scale factor\n",
      "     |      .       will degrade feature matching scores dramatically. On the other hand, too close to 1 scale factor\n",
      "     |      .       will mean that to cover certain scale range you will need more pyramid levels and so the speed\n",
      "     |      .       will suffer.\n",
      "     |      .       @param nlevels The number of pyramid levels. The smallest level will have linear size equal to\n",
      "     |      .       input_image_linear_size/pow(scaleFactor, nlevels - firstLevel).\n",
      "     |      .       @param edgeThreshold This is size of the border where the features are not detected. It should\n",
      "     |      .       roughly match the patchSize parameter.\n",
      "     |      .       @param firstLevel The level of pyramid to put source image to. Previous layers are filled\n",
      "     |      .       with upscaled source image.\n",
      "     |      .       @param WTA_K The number of points that produce each element of the oriented BRIEF descriptor. The\n",
      "     |      .       default value 2 means the BRIEF where we take a random point pair and compare their brightnesses,\n",
      "     |      .       so we get 0/1 response. Other possible values are 3 and 4. For example, 3 means that we take 3\n",
      "     |      .       random points (of course, those point coordinates are random, but they are generated from the\n",
      "     |      .       pre-defined seed, so each element of BRIEF descriptor is computed deterministically from the pixel\n",
      "     |      .       rectangle), find point of maximum brightness and output index of the winner (0, 1 or 2). Such\n",
      "     |      .       output will occupy 2 bits, and therefore it will need a special variant of Hamming distance,\n",
      "     |      .       denoted as NORM_HAMMING2 (2 bits per bin). When WTA_K=4, we take 4 random points to compute each\n",
      "     |      .       bin (that will also occupy 2 bits with possible values 0, 1, 2 or 3).\n",
      "     |      .       @param scoreType The default HARRIS_SCORE means that Harris algorithm is used to rank features\n",
      "     |      .       (the score is written to KeyPoint::score and is used to retain best nfeatures features);\n",
      "     |      .       FAST_SCORE is alternative value of the parameter that produces slightly less stable keypoints,\n",
      "     |      .       but it is a little faster to compute.\n",
      "     |      .       @param patchSize size of the patch used by the oriented BRIEF descriptor. Of course, on smaller\n",
      "     |      .       pyramid layers the perceived image area covered by a feature will be larger.\n",
      "     |      .       @param fastThreshold the fast threshold\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .       (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .       matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .       masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class PyRotationWarper(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  buildMaps(...)\n",
      "     |      buildMaps(src_size, K, R[, xmap[, ymap]]) -> retval, xmap, ymap\n",
      "     |      .   @brief Builds the projection maps according to the given camera data.\n",
      "     |      .   \n",
      "     |      .           @param src_size Source image size\n",
      "     |      .           @param K Camera intrinsic parameters\n",
      "     |      .           @param R Camera rotation matrix\n",
      "     |      .           @param xmap Projection map for the x axis\n",
      "     |      .           @param ymap Projection map for the y axis\n",
      "     |      .           @return Projected image minimum bounding box\n",
      "     |  \n",
      "     |  getScale(...)\n",
      "     |      getScale() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setScale(...)\n",
      "     |      setScale(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  warp(...)\n",
      "     |      warp(src, K, R, interp_mode, border_mode[, dst]) -> retval, dst\n",
      "     |      .   @brief Projects the image.\n",
      "     |      .   \n",
      "     |      .           @param src Source image\n",
      "     |      .           @param K Camera intrinsic parameters\n",
      "     |      .           @param R Camera rotation matrix\n",
      "     |      .           @param interp_mode Interpolation mode\n",
      "     |      .           @param border_mode Border extrapolation mode\n",
      "     |      .           @param dst Projected image\n",
      "     |      .           @return Project image top-left corner\n",
      "     |  \n",
      "     |  warpBackward(...)\n",
      "     |      warpBackward(src, K, R, interp_mode, border_mode, dst_size[, dst]) -> dst\n",
      "     |      .   @brief Projects the image backward.\n",
      "     |      .   \n",
      "     |      .           @param src Projected image\n",
      "     |      .           @param K Camera intrinsic parameters\n",
      "     |      .           @param R Camera rotation matrix\n",
      "     |      .           @param interp_mode Interpolation mode\n",
      "     |      .           @param border_mode Border extrapolation mode\n",
      "     |      .           @param dst_size Backward-projected image size\n",
      "     |      .           @param dst Backward-projected image\n",
      "     |  \n",
      "     |  warpPoint(...)\n",
      "     |      warpPoint(pt, K, R) -> retval\n",
      "     |      .   @brief Projects the image point.\n",
      "     |      .   \n",
      "     |      .           @param pt Source point\n",
      "     |      .           @param K Camera intrinsic parameters\n",
      "     |      .           @param R Camera rotation matrix\n",
      "     |      .           @return Projected point\n",
      "     |  \n",
      "     |  warpRoi(...)\n",
      "     |      warpRoi(src_size, K, R) -> retval\n",
      "     |      .   @param src_size Source image bounding box\n",
      "     |      .           @param K Camera intrinsic parameters\n",
      "     |      .           @param R Camera rotation matrix\n",
      "     |      .           @return Projected image minimum bounding box\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class QRCodeDetector(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  decode(...)\n",
      "     |      decode(img, points[, straight_qrcode]) -> retval, straight_qrcode\n",
      "     |      .   @brief Decodes QR code in image once it's found by the detect() method.\n",
      "     |      .   \n",
      "     |      .        Returns UTF8-encoded output string or empty string if the code cannot be decoded.\n",
      "     |      .        @param img grayscale or color (BGR) image containing QR code.\n",
      "     |      .        @param points Quadrangle vertices found by detect() method (or some other algorithm).\n",
      "     |      .        @param straight_qrcode The optional output image containing rectified and binarized QR code\n",
      "     |  \n",
      "     |  decodeMulti(...)\n",
      "     |      decodeMulti(img, points[, straight_qrcode]) -> retval, decoded_info, straight_qrcode\n",
      "     |      .   @brief Decodes QR codes in image once it's found by the detect() method.\n",
      "     |      .        @param img grayscale or color (BGR) image containing QR codes.\n",
      "     |      .        @param decoded_info UTF8-encoded output vector of string or empty vector of string if the codes cannot be decoded.\n",
      "     |      .        @param points vector of Quadrangle vertices found by detect() method (or some other algorithm).\n",
      "     |      .        @param straight_qrcode The optional output vector of images containing rectified and binarized QR codes\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(img[, points]) -> retval, points\n",
      "     |      .   @brief Detects QR code in image and returns the quadrangle containing the code.\n",
      "     |      .        @param img grayscale or color (BGR) image containing (or not) QR code.\n",
      "     |      .        @param points Output vector of vertices of the minimum-area quadrangle containing the code.\n",
      "     |  \n",
      "     |  detectAndDecode(...)\n",
      "     |      detectAndDecode(img[, points[, straight_qrcode]]) -> retval, points, straight_qrcode\n",
      "     |      .   @brief Both detects and decodes QR code\n",
      "     |      .   \n",
      "     |      .        @param img grayscale or color (BGR) image containing QR code.\n",
      "     |      .        @param points optional output array of vertices of the found QR code quadrangle. Will be empty if not found.\n",
      "     |      .        @param straight_qrcode The optional output image containing rectified and binarized QR code\n",
      "     |  \n",
      "     |  detectAndDecodeMulti(...)\n",
      "     |      detectAndDecodeMulti(img[, points[, straight_qrcode]]) -> retval, decoded_info, points, straight_qrcode\n",
      "     |      .   @brief Both detects and decodes QR codes\n",
      "     |      .       @param img grayscale or color (BGR) image containing QR codes.\n",
      "     |      .       @param decoded_info UTF8-encoded output vector of string or empty vector of string if the codes cannot be decoded.\n",
      "     |      .       @param points optional output vector of vertices of the found QR code quadrangles. Will be empty if not found.\n",
      "     |      .       @param straight_qrcode The optional output vector of images containing rectified and binarized QR codes\n",
      "     |  \n",
      "     |  detectMulti(...)\n",
      "     |      detectMulti(img[, points]) -> retval, points\n",
      "     |      .   @brief Detects QR codes in image and returns the vector of the quadrangles containing the codes.\n",
      "     |      .        @param img grayscale or color (BGR) image containing (or not) QR codes.\n",
      "     |      .        @param points Output vector of vector of vertices of the minimum-area quadrangle containing the codes.\n",
      "     |  \n",
      "     |  setEpsX(...)\n",
      "     |      setEpsX(epsX) -> None\n",
      "     |      .   @brief sets the epsilon used during the horizontal scan of QR code stop marker detection.\n",
      "     |      .        @param epsX Epsilon neighborhood, which allows you to determine the horizontal pattern\n",
      "     |      .        of the scheme 1:1:3:1:1 according to QR code standard.\n",
      "     |  \n",
      "     |  setEpsY(...)\n",
      "     |      setEpsY(epsY) -> None\n",
      "     |      .   @brief sets the epsilon used during the vertical scan of QR code stop marker detection.\n",
      "     |      .        @param epsY Epsilon neighborhood, which allows you to determine the vertical pattern\n",
      "     |      .        of the scheme 1:1:3:1:1 according to QR code standard.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class SIFT(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      SIFT\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, nfeatures[, nOctaveLayers[, contrastThreshold[, edgeThreshold[, sigma]]]]]) -> retval\n",
      "     |      .   @param nfeatures The number of best features to retain. The features are ranked by their scores\n",
      "     |      .       (measured in SIFT algorithm as the local contrast)\n",
      "     |      .   \n",
      "     |      .       @param nOctaveLayers The number of layers in each octave. 3 is the value used in D. Lowe paper. The\n",
      "     |      .       number of octaves is computed automatically from the image resolution.\n",
      "     |      .   \n",
      "     |      .       @param contrastThreshold The contrast threshold used to filter out weak features in semi-uniform\n",
      "     |      .       (low-contrast) regions. The larger the threshold, the less features are produced by the detector.\n",
      "     |      .   \n",
      "     |      .       @note The contrast threshold will be divided by nOctaveLayers when the filtering is applied. When\n",
      "     |      .       nOctaveLayers is set to default and if you want to use the value used in D. Lowe paper, 0.03, set\n",
      "     |      .       this argument to 0.09.\n",
      "     |      .   \n",
      "     |      .       @param edgeThreshold The threshold used to filter out edge-like features. Note that the its meaning\n",
      "     |      .       is different from the contrastThreshold, i.e. the larger the edgeThreshold, the less features are\n",
      "     |      .       filtered out (more features are retained).\n",
      "     |      .   \n",
      "     |      .       @param sigma The sigma of the Gaussian applied to the input image at the octave \\#0. If your image\n",
      "     |      .       is captured with a weak camera with soft lenses, you might want to reduce the number.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .       (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .       matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .       masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class SimpleBlobDetector(Feature2D)\n",
      "     |  Method resolution order:\n",
      "     |      SimpleBlobDetector\n",
      "     |      Feature2D\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, parameters]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Feature2D:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      "     |      .       (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      "     |      .   @overload\n",
      "     |      .   \n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      "     |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      "     |      .       with several dominant orientations (for each orientation).\n",
      "     |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      "     |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      "     |      .       descriptor for keypoint j-th keypoint.\n",
      "     |  \n",
      "     |  defaultNorm(...)\n",
      "     |      defaultNorm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorSize(...)\n",
      "     |      descriptorSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  descriptorType(...)\n",
      "     |      descriptorType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(image[, mask]) -> keypoints\n",
      "     |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      "     |      .   \n",
      "     |      .       @param image Image.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      "     |      .       matrix with non-zero values in the region of interest.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      detect(images[, masks]) -> keypoints\n",
      "     |      .   @overload\n",
      "     |      .       @param images Image set.\n",
      "     |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      "     |      .       of keypoints detected in images[i] .\n",
      "     |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .       masks[i] is a mask for images[i].\n",
      "     |  \n",
      "     |  detectAndCompute(...)\n",
      "     |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      "     |      .   Detects keypoints and computes the descriptors\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      read(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fileName) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .\n",
      "    \n",
      "    class SimpleBlobDetector_Params(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  blobColor\n",
      "     |      blobColor\n",
      "     |  \n",
      "     |  filterByArea\n",
      "     |      filterByArea\n",
      "     |  \n",
      "     |  filterByCircularity\n",
      "     |      filterByCircularity\n",
      "     |  \n",
      "     |  filterByColor\n",
      "     |      filterByColor\n",
      "     |  \n",
      "     |  filterByConvexity\n",
      "     |      filterByConvexity\n",
      "     |  \n",
      "     |  filterByInertia\n",
      "     |      filterByInertia\n",
      "     |  \n",
      "     |  maxArea\n",
      "     |      maxArea\n",
      "     |  \n",
      "     |  maxCircularity\n",
      "     |      maxCircularity\n",
      "     |  \n",
      "     |  maxConvexity\n",
      "     |      maxConvexity\n",
      "     |  \n",
      "     |  maxInertiaRatio\n",
      "     |      maxInertiaRatio\n",
      "     |  \n",
      "     |  maxThreshold\n",
      "     |      maxThreshold\n",
      "     |  \n",
      "     |  minArea\n",
      "     |      minArea\n",
      "     |  \n",
      "     |  minCircularity\n",
      "     |      minCircularity\n",
      "     |  \n",
      "     |  minConvexity\n",
      "     |      minConvexity\n",
      "     |  \n",
      "     |  minDistBetweenBlobs\n",
      "     |      minDistBetweenBlobs\n",
      "     |  \n",
      "     |  minInertiaRatio\n",
      "     |      minInertiaRatio\n",
      "     |  \n",
      "     |  minRepeatability\n",
      "     |      minRepeatability\n",
      "     |  \n",
      "     |  minThreshold\n",
      "     |      minThreshold\n",
      "     |  \n",
      "     |  thresholdStep\n",
      "     |      thresholdStep\n",
      "    \n",
      "    class SparseOpticalFlow(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      SparseOpticalFlow\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  calc(...)\n",
      "     |      calc(prevImg, nextImg, prevPts, nextPts[, status[, err]]) -> nextPts, status, err\n",
      "     |      .   @brief Calculates a sparse optical flow.\n",
      "     |      .   \n",
      "     |      .       @param prevImg First input image.\n",
      "     |      .       @param nextImg Second input image of the same size and the same type as prevImg.\n",
      "     |      .       @param prevPts Vector of 2D points for which the flow needs to be found.\n",
      "     |      .       @param nextPts Output vector of 2D points containing the calculated new positions of input features in the second image.\n",
      "     |      .       @param status Output status vector. Each element of the vector is set to 1 if the\n",
      "     |      .                     flow for the corresponding features has been found. Otherwise, it is set to 0.\n",
      "     |      .       @param err Optional output vector that contains error response for each point (inverse confidence).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class SparsePyrLKOpticalFlow(SparseOpticalFlow)\n",
      "     |  Method resolution order:\n",
      "     |      SparsePyrLKOpticalFlow\n",
      "     |      SparseOpticalFlow\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getFlags(...)\n",
      "     |      getFlags() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMaxLevel(...)\n",
      "     |      getMaxLevel() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinEigThreshold(...)\n",
      "     |      getMinEigThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getWinSize(...)\n",
      "     |      getWinSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setFlags(...)\n",
      "     |      setFlags(flags) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMaxLevel(...)\n",
      "     |      setMaxLevel(maxLevel) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinEigThreshold(...)\n",
      "     |      setMinEigThreshold(minEigThreshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(crit) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setWinSize(...)\n",
      "     |      setWinSize(winSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, winSize[, maxLevel[, crit[, flags[, minEigThreshold]]]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from SparseOpticalFlow:\n",
      "     |  \n",
      "     |  calc(...)\n",
      "     |      calc(prevImg, nextImg, prevPts, nextPts[, status[, err]]) -> nextPts, status, err\n",
      "     |      .   @brief Calculates a sparse optical flow.\n",
      "     |      .   \n",
      "     |      .       @param prevImg First input image.\n",
      "     |      .       @param nextImg Second input image of the same size and the same type as prevImg.\n",
      "     |      .       @param prevPts Vector of 2D points for which the flow needs to be found.\n",
      "     |      .       @param nextPts Output vector of 2D points containing the calculated new positions of input features in the second image.\n",
      "     |      .       @param status Output status vector. Each element of the vector is set to 1 if the\n",
      "     |      .                     flow for the corresponding features has been found. Otherwise, it is set to 0.\n",
      "     |      .       @param err Optional output vector that contains error response for each point (inverse confidence).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class StereoBM(StereoMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      StereoBM\n",
      "     |      StereoMatcher\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getPreFilterCap(...)\n",
      "     |      getPreFilterCap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPreFilterSize(...)\n",
      "     |      getPreFilterSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPreFilterType(...)\n",
      "     |      getPreFilterType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getROI1(...)\n",
      "     |      getROI1() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getROI2(...)\n",
      "     |      getROI2() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSmallerBlockSize(...)\n",
      "     |      getSmallerBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTextureThreshold(...)\n",
      "     |      getTextureThreshold() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getUniquenessRatio(...)\n",
      "     |      getUniquenessRatio() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPreFilterCap(...)\n",
      "     |      setPreFilterCap(preFilterCap) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPreFilterSize(...)\n",
      "     |      setPreFilterSize(preFilterSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPreFilterType(...)\n",
      "     |      setPreFilterType(preFilterType) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setROI1(...)\n",
      "     |      setROI1(roi1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setROI2(...)\n",
      "     |      setROI2(roi2) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSmallerBlockSize(...)\n",
      "     |      setSmallerBlockSize(blockSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTextureThreshold(...)\n",
      "     |      setTextureThreshold(textureThreshold) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUniquenessRatio(...)\n",
      "     |      setUniquenessRatio(uniquenessRatio) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, numDisparities[, blockSize]]) -> retval\n",
      "     |      .   @brief Creates StereoBM object\n",
      "     |      .   \n",
      "     |      .       @param numDisparities the disparity search range. For each pixel algorithm will find the best\n",
      "     |      .       disparity from 0 (default minimum disparity) to numDisparities. The search range can then be\n",
      "     |      .       shifted by changing the minimum disparity.\n",
      "     |      .       @param blockSize the linear size of the blocks compared by the algorithm. The size should be odd\n",
      "     |      .       (as the block is centered at the current pixel). Larger block size implies smoother, though less\n",
      "     |      .       accurate disparity map. Smaller block size gives more detailed disparity map, but there is higher\n",
      "     |      .       chance for algorithm to find a wrong correspondence.\n",
      "     |      .   \n",
      "     |      .       The function create StereoBM object. You can then call StereoBM::compute() to compute disparity for\n",
      "     |      .       a specific stereo pair.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatcher:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(left, right[, disparity]) -> disparity\n",
      "     |      .   @brief Computes disparity map for the specified stereo pair\n",
      "     |      .   \n",
      "     |      .       @param left Left 8-bit single-channel image.\n",
      "     |      .       @param right Right image of the same size and the same type as the left one.\n",
      "     |      .       @param disparity Output disparity map. It has the same size as the input images. Some algorithms,\n",
      "     |      .       like StereoBM or StereoSGBM compute 16-bit fixed-point disparity map (where each disparity value\n",
      "     |      .       has 4 fractional bits), whereas other algorithms output 32-bit floating-point disparity map.\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDisp12MaxDiff(...)\n",
      "     |      getDisp12MaxDiff() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDisparity(...)\n",
      "     |      getMinDisparity() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNumDisparities(...)\n",
      "     |      getNumDisparities() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSpeckleRange(...)\n",
      "     |      getSpeckleRange() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSpeckleWindowSize(...)\n",
      "     |      getSpeckleWindowSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(blockSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDisp12MaxDiff(...)\n",
      "     |      setDisp12MaxDiff(disp12MaxDiff) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDisparity(...)\n",
      "     |      setMinDisparity(minDisparity) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNumDisparities(...)\n",
      "     |      setNumDisparities(numDisparities) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSpeckleRange(...)\n",
      "     |      setSpeckleRange(speckleRange) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSpeckleWindowSize(...)\n",
      "     |      setSpeckleWindowSize(speckleWindowSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class StereoMatcher(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      StereoMatcher\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(left, right[, disparity]) -> disparity\n",
      "     |      .   @brief Computes disparity map for the specified stereo pair\n",
      "     |      .   \n",
      "     |      .       @param left Left 8-bit single-channel image.\n",
      "     |      .       @param right Right image of the same size and the same type as the left one.\n",
      "     |      .       @param disparity Output disparity map. It has the same size as the input images. Some algorithms,\n",
      "     |      .       like StereoBM or StereoSGBM compute 16-bit fixed-point disparity map (where each disparity value\n",
      "     |      .       has 4 fractional bits), whereas other algorithms output 32-bit floating-point disparity map.\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDisp12MaxDiff(...)\n",
      "     |      getDisp12MaxDiff() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDisparity(...)\n",
      "     |      getMinDisparity() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNumDisparities(...)\n",
      "     |      getNumDisparities() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSpeckleRange(...)\n",
      "     |      getSpeckleRange() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSpeckleWindowSize(...)\n",
      "     |      getSpeckleWindowSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(blockSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDisp12MaxDiff(...)\n",
      "     |      setDisp12MaxDiff(disp12MaxDiff) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDisparity(...)\n",
      "     |      setMinDisparity(minDisparity) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNumDisparities(...)\n",
      "     |      setNumDisparities(numDisparities) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSpeckleRange(...)\n",
      "     |      setSpeckleRange(speckleRange) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSpeckleWindowSize(...)\n",
      "     |      setSpeckleWindowSize(speckleWindowSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class StereoSGBM(StereoMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      StereoSGBM\n",
      "     |      StereoMatcher\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getMode(...)\n",
      "     |      getMode() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getP1(...)\n",
      "     |      getP1() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getP2(...)\n",
      "     |      getP2() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getPreFilterCap(...)\n",
      "     |      getPreFilterCap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getUniquenessRatio(...)\n",
      "     |      getUniquenessRatio() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMode(...)\n",
      "     |      setMode(mode) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setP1(...)\n",
      "     |      setP1(P1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setP2(...)\n",
      "     |      setP2(P2) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPreFilterCap(...)\n",
      "     |      setPreFilterCap(preFilterCap) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUniquenessRatio(...)\n",
      "     |      setUniquenessRatio(uniquenessRatio) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, minDisparity[, numDisparities[, blockSize[, P1[, P2[, disp12MaxDiff[, preFilterCap[, uniquenessRatio[, speckleWindowSize[, speckleRange[, mode]]]]]]]]]]]) -> retval\n",
      "     |      .   @brief Creates StereoSGBM object\n",
      "     |      .   \n",
      "     |      .       @param minDisparity Minimum possible disparity value. Normally, it is zero but sometimes\n",
      "     |      .       rectification algorithms can shift images, so this parameter needs to be adjusted accordingly.\n",
      "     |      .       @param numDisparities Maximum disparity minus minimum disparity. The value is always greater than\n",
      "     |      .       zero. In the current implementation, this parameter must be divisible by 16.\n",
      "     |      .       @param blockSize Matched block size. It must be an odd number \\>=1 . Normally, it should be\n",
      "     |      .       somewhere in the 3..11 range.\n",
      "     |      .       @param P1 The first parameter controlling the disparity smoothness. See below.\n",
      "     |      .       @param P2 The second parameter controlling the disparity smoothness. The larger the values are,\n",
      "     |      .       the smoother the disparity is. P1 is the penalty on the disparity change by plus or minus 1\n",
      "     |      .       between neighbor pixels. P2 is the penalty on the disparity change by more than 1 between neighbor\n",
      "     |      .       pixels. The algorithm requires P2 \\> P1 . See stereo_match.cpp sample where some reasonably good\n",
      "     |      .       P1 and P2 values are shown (like 8\\*number_of_image_channels\\*blockSize\\*blockSize and\n",
      "     |      .       32\\*number_of_image_channels\\*blockSize\\*blockSize , respectively).\n",
      "     |      .       @param disp12MaxDiff Maximum allowed difference (in integer pixel units) in the left-right\n",
      "     |      .       disparity check. Set it to a non-positive value to disable the check.\n",
      "     |      .       @param preFilterCap Truncation value for the prefiltered image pixels. The algorithm first\n",
      "     |      .       computes x-derivative at each pixel and clips its value by [-preFilterCap, preFilterCap] interval.\n",
      "     |      .       The result values are passed to the Birchfield-Tomasi pixel cost function.\n",
      "     |      .       @param uniquenessRatio Margin in percentage by which the best (minimum) computed cost function\n",
      "     |      .       value should \"win\" the second best value to consider the found match correct. Normally, a value\n",
      "     |      .       within the 5-15 range is good enough.\n",
      "     |      .       @param speckleWindowSize Maximum size of smooth disparity regions to consider their noise speckles\n",
      "     |      .       and invalidate. Set it to 0 to disable speckle filtering. Otherwise, set it somewhere in the\n",
      "     |      .       50-200 range.\n",
      "     |      .       @param speckleRange Maximum disparity variation within each connected component. If you do speckle\n",
      "     |      .       filtering, set the parameter to a positive value, it will be implicitly multiplied by 16.\n",
      "     |      .       Normally, 1 or 2 is good enough.\n",
      "     |      .       @param mode Set it to StereoSGBM::MODE_HH to run the full-scale two-pass dynamic programming\n",
      "     |      .       algorithm. It will consume O(W\\*H\\*numDisparities) bytes, which is large for 640x480 stereo and\n",
      "     |      .       huge for HD-size pictures. By default, it is set to false .\n",
      "     |      .   \n",
      "     |      .       The first constructor initializes StereoSGBM with all the default parameters. So, you only have to\n",
      "     |      .       set StereoSGBM::numDisparities at minimum. The second constructor enables you to set each parameter\n",
      "     |      .       to a custom value.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatcher:\n",
      "     |  \n",
      "     |  compute(...)\n",
      "     |      compute(left, right[, disparity]) -> disparity\n",
      "     |      .   @brief Computes disparity map for the specified stereo pair\n",
      "     |      .   \n",
      "     |      .       @param left Left 8-bit single-channel image.\n",
      "     |      .       @param right Right image of the same size and the same type as the left one.\n",
      "     |      .       @param disparity Output disparity map. It has the same size as the input images. Some algorithms,\n",
      "     |      .       like StereoBM or StereoSGBM compute 16-bit fixed-point disparity map (where each disparity value\n",
      "     |      .       has 4 fractional bits), whereas other algorithms output 32-bit floating-point disparity map.\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDisp12MaxDiff(...)\n",
      "     |      getDisp12MaxDiff() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMinDisparity(...)\n",
      "     |      getMinDisparity() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNumDisparities(...)\n",
      "     |      getNumDisparities() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSpeckleRange(...)\n",
      "     |      getSpeckleRange() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSpeckleWindowSize(...)\n",
      "     |      getSpeckleWindowSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(blockSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDisp12MaxDiff(...)\n",
      "     |      setDisp12MaxDiff(disp12MaxDiff) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMinDisparity(...)\n",
      "     |      setMinDisparity(minDisparity) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNumDisparities(...)\n",
      "     |      setNumDisparities(numDisparities) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSpeckleRange(...)\n",
      "     |      setSpeckleRange(speckleRange) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSpeckleWindowSize(...)\n",
      "     |      setSpeckleWindowSize(speckleWindowSize) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class Stitcher(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  composePanorama(...)\n",
      "     |      composePanorama([, pano]) -> retval, pano\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  compositingResol(...)\n",
      "     |      compositingResol() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  estimateTransform(...)\n",
      "     |      estimateTransform(images[, masks]) -> retval\n",
      "     |      .   @brief These functions try to match the given images and to estimate rotations of each camera.\n",
      "     |      .   \n",
      "     |      .       @note Use the functions only if you're aware of the stitching pipeline, otherwise use\n",
      "     |      .       Stitcher::stitch.\n",
      "     |      .   \n",
      "     |      .       @param images Input images.\n",
      "     |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .       @return Status code.\n",
      "     |  \n",
      "     |  interpolationFlags(...)\n",
      "     |      interpolationFlags() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  panoConfidenceThresh(...)\n",
      "     |      panoConfidenceThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  registrationResol(...)\n",
      "     |      registrationResol() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  seamEstimationResol(...)\n",
      "     |      seamEstimationResol() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setCompositingResol(...)\n",
      "     |      setCompositingResol(resol_mpx) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setInterpolationFlags(...)\n",
      "     |      setInterpolationFlags(interp_flags) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setPanoConfidenceThresh(...)\n",
      "     |      setPanoConfidenceThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRegistrationResol(...)\n",
      "     |      setRegistrationResol(resol_mpx) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSeamEstimationResol(...)\n",
      "     |      setSeamEstimationResol(resol_mpx) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setWaveCorrection(...)\n",
      "     |      setWaveCorrection(flag) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  stitch(...)\n",
      "     |      stitch(images[, pano]) -> retval, pano\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      stitch(images, masks[, pano]) -> retval, pano\n",
      "     |      .   @brief These functions try to stitch the given images.\n",
      "     |      .   \n",
      "     |      .       @param images Input images.\n",
      "     |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      "     |      .       @param pano Final pano.\n",
      "     |      .       @return Status code.\n",
      "     |  \n",
      "     |  waveCorrection(...)\n",
      "     |      waveCorrection() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  workScale(...)\n",
      "     |      workScale() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, mode]) -> retval\n",
      "     |      .   @brief Creates a Stitcher configured in one of the stitching modes.\n",
      "     |      .   \n",
      "     |      .       @param mode Scenario for stitcher operation. This is usually determined by source of images\n",
      "     |      .       to stitch and their transformation. Default parameters will be chosen for operation in given\n",
      "     |      .       scenario.\n",
      "     |      .       @return Stitcher class instance.\n",
      "    \n",
      "    class Subdiv2D(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  edgeDst(...)\n",
      "     |      edgeDst(edge) -> retval, dstpt\n",
      "     |      .   @brief Returns the edge destination.\n",
      "     |      .   \n",
      "     |      .       @param edge Subdivision edge ID.\n",
      "     |      .       @param dstpt Output vertex location.\n",
      "     |      .   \n",
      "     |      .       @returns vertex ID.\n",
      "     |  \n",
      "     |  edgeOrg(...)\n",
      "     |      edgeOrg(edge) -> retval, orgpt\n",
      "     |      .   @brief Returns the edge origin.\n",
      "     |      .   \n",
      "     |      .       @param edge Subdivision edge ID.\n",
      "     |      .       @param orgpt Output vertex location.\n",
      "     |      .   \n",
      "     |      .       @returns vertex ID.\n",
      "     |  \n",
      "     |  findNearest(...)\n",
      "     |      findNearest(pt) -> retval, nearestPt\n",
      "     |      .   @brief Finds the subdivision vertex closest to the given point.\n",
      "     |      .   \n",
      "     |      .       @param pt Input point.\n",
      "     |      .       @param nearestPt Output subdivision vertex point.\n",
      "     |      .   \n",
      "     |      .       The function is another function that locates the input point within the subdivision. It finds the\n",
      "     |      .       subdivision vertex that is the closest to the input point. It is not necessarily one of vertices\n",
      "     |      .       of the facet containing the input point, though the facet (located using locate() ) is used as a\n",
      "     |      .       starting point.\n",
      "     |      .   \n",
      "     |      .       @returns vertex ID.\n",
      "     |  \n",
      "     |  getEdge(...)\n",
      "     |      getEdge(edge, nextEdgeType) -> retval\n",
      "     |      .   @brief Returns one of the edges related to the given edge.\n",
      "     |      .   \n",
      "     |      .       @param edge Subdivision edge ID.\n",
      "     |      .       @param nextEdgeType Parameter specifying which of the related edges to return.\n",
      "     |      .       The following values are possible:\n",
      "     |      .       -   NEXT_AROUND_ORG next around the edge origin ( eOnext on the picture below if e is the input edge)\n",
      "     |      .       -   NEXT_AROUND_DST next around the edge vertex ( eDnext )\n",
      "     |      .       -   PREV_AROUND_ORG previous around the edge origin (reversed eRnext )\n",
      "     |      .       -   PREV_AROUND_DST previous around the edge destination (reversed eLnext )\n",
      "     |      .       -   NEXT_AROUND_LEFT next around the left facet ( eLnext )\n",
      "     |      .       -   NEXT_AROUND_RIGHT next around the right facet ( eRnext )\n",
      "     |      .       -   PREV_AROUND_LEFT previous around the left facet (reversed eOnext )\n",
      "     |      .       -   PREV_AROUND_RIGHT previous around the right facet (reversed eDnext )\n",
      "     |      .   \n",
      "     |      .       ![sample output](pics/quadedge.png)\n",
      "     |      .   \n",
      "     |      .       @returns edge ID related to the input edge.\n",
      "     |  \n",
      "     |  getEdgeList(...)\n",
      "     |      getEdgeList() -> edgeList\n",
      "     |      .   @brief Returns a list of all edges.\n",
      "     |      .   \n",
      "     |      .       @param edgeList Output vector.\n",
      "     |      .   \n",
      "     |      .       The function gives each edge as a 4 numbers vector, where each two are one of the edge\n",
      "     |      .       vertices. i.e. org_x = v[0], org_y = v[1], dst_x = v[2], dst_y = v[3].\n",
      "     |  \n",
      "     |  getLeadingEdgeList(...)\n",
      "     |      getLeadingEdgeList() -> leadingEdgeList\n",
      "     |      .   @brief Returns a list of the leading edge ID connected to each triangle.\n",
      "     |      .   \n",
      "     |      .       @param leadingEdgeList Output vector.\n",
      "     |      .   \n",
      "     |      .       The function gives one edge ID for each triangle.\n",
      "     |  \n",
      "     |  getTriangleList(...)\n",
      "     |      getTriangleList() -> triangleList\n",
      "     |      .   @brief Returns a list of all triangles.\n",
      "     |      .   \n",
      "     |      .       @param triangleList Output vector.\n",
      "     |      .   \n",
      "     |      .       The function gives each triangle as a 6 numbers vector, where each two are one of the triangle\n",
      "     |      .       vertices. i.e. p1_x = v[0], p1_y = v[1], p2_x = v[2], p2_y = v[3], p3_x = v[4], p3_y = v[5].\n",
      "     |  \n",
      "     |  getVertex(...)\n",
      "     |      getVertex(vertex) -> retval, firstEdge\n",
      "     |      .   @brief Returns vertex location from vertex ID.\n",
      "     |      .   \n",
      "     |      .       @param vertex vertex ID.\n",
      "     |      .       @param firstEdge Optional. The first edge ID which is connected to the vertex.\n",
      "     |      .       @returns vertex (x,y)\n",
      "     |  \n",
      "     |  getVoronoiFacetList(...)\n",
      "     |      getVoronoiFacetList(idx) -> facetList, facetCenters\n",
      "     |      .   @brief Returns a list of all Voronoi facets.\n",
      "     |      .   \n",
      "     |      .       @param idx Vector of vertices IDs to consider. For all vertices you can pass empty vector.\n",
      "     |      .       @param facetList Output vector of the Voronoi facets.\n",
      "     |      .       @param facetCenters Output vector of the Voronoi facets center points.\n",
      "     |  \n",
      "     |  initDelaunay(...)\n",
      "     |      initDelaunay(rect) -> None\n",
      "     |      .   @brief Creates a new empty Delaunay subdivision\n",
      "     |      .   \n",
      "     |      .       @param rect Rectangle that includes all of the 2D points that are to be added to the subdivision.\n",
      "     |  \n",
      "     |  insert(...)\n",
      "     |      insert(pt) -> retval\n",
      "     |      .   @brief Insert a single point into a Delaunay triangulation.\n",
      "     |      .   \n",
      "     |      .       @param pt Point to insert.\n",
      "     |      .   \n",
      "     |      .       The function inserts a single point into a subdivision and modifies the subdivision topology\n",
      "     |      .       appropriately. If a point with the same coordinates exists already, no new point is added.\n",
      "     |      .       @returns the ID of the point.\n",
      "     |      .   \n",
      "     |      .       @note If the point is outside of the triangulation specified rect a runtime error is raised.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      insert(ptvec) -> None\n",
      "     |      .   @brief Insert multiple points into a Delaunay triangulation.\n",
      "     |      .   \n",
      "     |      .       @param ptvec Points to insert.\n",
      "     |      .   \n",
      "     |      .       The function inserts a vector of points into a subdivision and modifies the subdivision topology\n",
      "     |      .       appropriately.\n",
      "     |  \n",
      "     |  locate(...)\n",
      "     |      locate(pt) -> retval, edge, vertex\n",
      "     |      .   @brief Returns the location of a point within a Delaunay triangulation.\n",
      "     |      .   \n",
      "     |      .       @param pt Point to locate.\n",
      "     |      .       @param edge Output edge that the point belongs to or is located to the right of it.\n",
      "     |      .       @param vertex Optional output vertex the input point coincides with.\n",
      "     |      .   \n",
      "     |      .       The function locates the input point within the subdivision and gives one of the triangle edges\n",
      "     |      .       or vertices.\n",
      "     |      .   \n",
      "     |      .       @returns an integer which specify one of the following five cases for point location:\n",
      "     |      .       -  The point falls into some facet. The function returns #PTLOC_INSIDE and edge will contain one of\n",
      "     |      .          edges of the facet.\n",
      "     |      .       -  The point falls onto the edge. The function returns #PTLOC_ON_EDGE and edge will contain this edge.\n",
      "     |      .       -  The point coincides with one of the subdivision vertices. The function returns #PTLOC_VERTEX and\n",
      "     |      .          vertex will contain a pointer to the vertex.\n",
      "     |      .       -  The point is outside the subdivision reference rectangle. The function returns #PTLOC_OUTSIDE_RECT\n",
      "     |      .          and no pointers are filled.\n",
      "     |      .       -  One of input arguments is invalid. A runtime error is raised or, if silent or \"parent\" error\n",
      "     |      .          processing mode is selected, #PTLOC_ERROR is returned.\n",
      "     |  \n",
      "     |  nextEdge(...)\n",
      "     |      nextEdge(edge) -> retval\n",
      "     |      .   @brief Returns next edge around the edge origin.\n",
      "     |      .   \n",
      "     |      .       @param edge Subdivision edge ID.\n",
      "     |      .   \n",
      "     |      .       @returns an integer which is next edge ID around the edge origin: eOnext on the\n",
      "     |      .       picture above if e is the input edge).\n",
      "     |  \n",
      "     |  rotateEdge(...)\n",
      "     |      rotateEdge(edge, rotate) -> retval\n",
      "     |      .   @brief Returns another edge of the same quad-edge.\n",
      "     |      .   \n",
      "     |      .       @param edge Subdivision edge ID.\n",
      "     |      .       @param rotate Parameter specifying which of the edges of the same quad-edge as the input\n",
      "     |      .       one to return. The following values are possible:\n",
      "     |      .       -   0 - the input edge ( e on the picture below if e is the input edge)\n",
      "     |      .       -   1 - the rotated edge ( eRot )\n",
      "     |      .       -   2 - the reversed edge (reversed e (in green))\n",
      "     |      .       -   3 - the reversed rotated edge (reversed eRot (in green))\n",
      "     |      .   \n",
      "     |      .       @returns one of the edges ID of the same quad-edge as the input edge.\n",
      "     |  \n",
      "     |  symEdge(...)\n",
      "     |      symEdge(edge) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class TickMeter(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getAvgTimeMilli(...)\n",
      "     |      getAvgTimeMilli() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getAvgTimeSec(...)\n",
      "     |      getAvgTimeSec() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCounter(...)\n",
      "     |      getCounter() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getFPS(...)\n",
      "     |      getFPS() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTimeMicro(...)\n",
      "     |      getTimeMicro() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTimeMilli(...)\n",
      "     |      getTimeMilli() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTimeSec(...)\n",
      "     |      getTimeSec() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTimeTicks(...)\n",
      "     |      getTimeTicks() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  reset(...)\n",
      "     |      reset() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  start(...)\n",
      "     |      start() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  stop(...)\n",
      "     |      stop() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Tonemap(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      Tonemap\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getGamma(...)\n",
      "     |      getGamma() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src[, dst]) -> dst\n",
      "     |      .   @brief Tonemaps image\n",
      "     |      .   \n",
      "     |      .       @param src source image - CV_32FC3 Mat (float 32 bits 3 channels)\n",
      "     |      .       @param dst destination image - CV_32FC3 Mat with values in [0, 1] range\n",
      "     |  \n",
      "     |  setGamma(...)\n",
      "     |      setGamma(gamma) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class TonemapDrago(Tonemap)\n",
      "     |  Method resolution order:\n",
      "     |      TonemapDrago\n",
      "     |      Tonemap\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getBias(...)\n",
      "     |      getBias() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSaturation(...)\n",
      "     |      getSaturation() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBias(...)\n",
      "     |      setBias(bias) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSaturation(...)\n",
      "     |      setSaturation(saturation) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Tonemap:\n",
      "     |  \n",
      "     |  getGamma(...)\n",
      "     |      getGamma() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src[, dst]) -> dst\n",
      "     |      .   @brief Tonemaps image\n",
      "     |      .   \n",
      "     |      .       @param src source image - CV_32FC3 Mat (float 32 bits 3 channels)\n",
      "     |      .       @param dst destination image - CV_32FC3 Mat with values in [0, 1] range\n",
      "     |  \n",
      "     |  setGamma(...)\n",
      "     |      setGamma(gamma) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class TonemapMantiuk(Tonemap)\n",
      "     |  Method resolution order:\n",
      "     |      TonemapMantiuk\n",
      "     |      Tonemap\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getSaturation(...)\n",
      "     |      getSaturation() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getScale(...)\n",
      "     |      getScale() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSaturation(...)\n",
      "     |      setSaturation(saturation) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setScale(...)\n",
      "     |      setScale(scale) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Tonemap:\n",
      "     |  \n",
      "     |  getGamma(...)\n",
      "     |      getGamma() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src[, dst]) -> dst\n",
      "     |      .   @brief Tonemaps image\n",
      "     |      .   \n",
      "     |      .       @param src source image - CV_32FC3 Mat (float 32 bits 3 channels)\n",
      "     |      .       @param dst destination image - CV_32FC3 Mat with values in [0, 1] range\n",
      "     |  \n",
      "     |  setGamma(...)\n",
      "     |      setGamma(gamma) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class TonemapReinhard(Tonemap)\n",
      "     |  Method resolution order:\n",
      "     |      TonemapReinhard\n",
      "     |      Tonemap\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getColorAdaptation(...)\n",
      "     |      getColorAdaptation() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getIntensity(...)\n",
      "     |      getIntensity() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getLightAdaptation(...)\n",
      "     |      getLightAdaptation() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setColorAdaptation(...)\n",
      "     |      setColorAdaptation(color_adapt) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setIntensity(...)\n",
      "     |      setIntensity(intensity) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setLightAdaptation(...)\n",
      "     |      setLightAdaptation(light_adapt) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Tonemap:\n",
      "     |  \n",
      "     |  getGamma(...)\n",
      "     |      getGamma() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(src[, dst]) -> dst\n",
      "     |      .   @brief Tonemaps image\n",
      "     |      .   \n",
      "     |      .       @param src source image - CV_32FC3 Mat (float 32 bits 3 channels)\n",
      "     |      .       @param dst destination image - CV_32FC3 Mat with values in [0, 1] range\n",
      "     |  \n",
      "     |  setGamma(...)\n",
      "     |      setGamma(gamma) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class UMat(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get(...)\n",
      "     |      get() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  handle(...)\n",
      "     |      handle(accessFlags) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isContinuous(...)\n",
      "     |      isContinuous() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isSubmatrix(...)\n",
      "     |      isSubmatrix() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  context(...)\n",
      "     |      context() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  queue(...)\n",
      "     |      queue() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  offset\n",
      "     |      offset\n",
      "    \n",
      "    class VariationalRefinement(DenseOpticalFlow)\n",
      "     |  Method resolution order:\n",
      "     |      VariationalRefinement\n",
      "     |      DenseOpticalFlow\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  calcUV(...)\n",
      "     |      calcUV(I0, I1, flow_u, flow_v) -> flow_u, flow_v\n",
      "     |      .   @brief @ref calc function overload to handle separate horizontal (u) and vertical (v) flow components\n",
      "     |      .   (to avoid extra splits/merges)\n",
      "     |  \n",
      "     |  getAlpha(...)\n",
      "     |      getAlpha() -> retval\n",
      "     |      .   @brief Weight of the smoothness term\n",
      "     |      .   @see setAlpha\n",
      "     |  \n",
      "     |  getDelta(...)\n",
      "     |      getDelta() -> retval\n",
      "     |      .   @brief Weight of the color constancy term\n",
      "     |      .   @see setDelta\n",
      "     |  \n",
      "     |  getFixedPointIterations(...)\n",
      "     |      getFixedPointIterations() -> retval\n",
      "     |      .   @brief Number of outer (fixed-point) iterations in the minimization procedure.\n",
      "     |      .   @see setFixedPointIterations\n",
      "     |  \n",
      "     |  getGamma(...)\n",
      "     |      getGamma() -> retval\n",
      "     |      .   @brief Weight of the gradient constancy term\n",
      "     |      .   @see setGamma\n",
      "     |  \n",
      "     |  getOmega(...)\n",
      "     |      getOmega() -> retval\n",
      "     |      .   @brief Relaxation factor in SOR\n",
      "     |      .   @see setOmega\n",
      "     |  \n",
      "     |  getSorIterations(...)\n",
      "     |      getSorIterations() -> retval\n",
      "     |      .   @brief Number of inner successive over-relaxation (SOR) iterations\n",
      "     |      .           in the minimization procedure to solve the respective linear system.\n",
      "     |      .   @see setSorIterations\n",
      "     |  \n",
      "     |  setAlpha(...)\n",
      "     |      setAlpha(val) -> None\n",
      "     |      .   @copybrief getAlpha @see getAlpha\n",
      "     |  \n",
      "     |  setDelta(...)\n",
      "     |      setDelta(val) -> None\n",
      "     |      .   @copybrief getDelta @see getDelta\n",
      "     |  \n",
      "     |  setFixedPointIterations(...)\n",
      "     |      setFixedPointIterations(val) -> None\n",
      "     |      .   @copybrief getFixedPointIterations @see getFixedPointIterations\n",
      "     |  \n",
      "     |  setGamma(...)\n",
      "     |      setGamma(val) -> None\n",
      "     |      .   @copybrief getGamma @see getGamma\n",
      "     |  \n",
      "     |  setOmega(...)\n",
      "     |      setOmega(val) -> None\n",
      "     |      .   @copybrief getOmega @see getOmega\n",
      "     |  \n",
      "     |  setSorIterations(...)\n",
      "     |      setSorIterations(val) -> None\n",
      "     |      .   @copybrief getSorIterations @see getSorIterations\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   @brief Creates an instance of VariationalRefinement\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DenseOpticalFlow:\n",
      "     |  \n",
      "     |  calc(...)\n",
      "     |      calc(I0, I1, flow) -> flow\n",
      "     |      .   @brief Calculates an optical flow.\n",
      "     |      .   \n",
      "     |      .       @param I0 first 8-bit single-channel input image.\n",
      "     |      .       @param I1 second input image of the same size and the same type as prev.\n",
      "     |      .       @param flow computed flow image that has the same size as prev and type CV_32FC2.\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .   @brief Releases all inner buffers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class VideoCapture(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get(...)\n",
      "     |      get(propId) -> retval\n",
      "     |      .   @brief Returns the specified VideoCapture property\n",
      "     |      .   \n",
      "     |      .       @param propId Property identifier from cv::VideoCaptureProperties (eg. cv::CAP_PROP_POS_MSEC, cv::CAP_PROP_POS_FRAMES, ...)\n",
      "     |      .       or one from @ref videoio_flags_others\n",
      "     |      .       @return Value for the specified property. Value 0 is returned when querying a property that is\n",
      "     |      .       not supported by the backend used by the VideoCapture instance.\n",
      "     |      .   \n",
      "     |      .       @note Reading / writing properties involves many layers. Some unexpected result might happens\n",
      "     |      .       along this chain.\n",
      "     |      .       @code{.txt}\n",
      "     |      .       VideoCapture -> API Backend -> Operating System -> Device Driver -> Device Hardware\n",
      "     |      .       @endcode\n",
      "     |      .       The returned value might be different from what really used by the device or it could be encoded\n",
      "     |      .       using device dependent rules (eg. steps or percentage). Effective behaviour depends from device\n",
      "     |      .       driver and API Backend\n",
      "     |  \n",
      "     |  getBackendName(...)\n",
      "     |      getBackendName() -> retval\n",
      "     |      .   @brief Returns used backend API name\n",
      "     |      .   \n",
      "     |      .        @note Stream should be opened.\n",
      "     |  \n",
      "     |  getExceptionMode(...)\n",
      "     |      getExceptionMode() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  grab(...)\n",
      "     |      grab() -> retval\n",
      "     |      .   @brief Grabs the next frame from video file or capturing device.\n",
      "     |      .   \n",
      "     |      .       @return `true` (non-zero) in the case of success.\n",
      "     |      .   \n",
      "     |      .       The method/function grabs the next frame from video file or camera and returns true (non-zero) in\n",
      "     |      .       the case of success.\n",
      "     |      .   \n",
      "     |      .       The primary use of the function is in multi-camera environments, especially when the cameras do not\n",
      "     |      .       have hardware synchronization. That is, you call VideoCapture::grab() for each camera and after that\n",
      "     |      .       call the slower method VideoCapture::retrieve() to decode and get frame from each camera. This way\n",
      "     |      .       the overhead on demosaicing or motion jpeg decompression etc. is eliminated and the retrieved frames\n",
      "     |      .       from different cameras will be closer in time.\n",
      "     |      .   \n",
      "     |      .       Also, when a connected camera is multi-head (for example, a stereo camera or a Kinect device), the\n",
      "     |      .       correct way of retrieving data from it is to call VideoCapture::grab() first and then call\n",
      "     |      .       VideoCapture::retrieve() one or more times with different values of the channel parameter.\n",
      "     |      .   \n",
      "     |      .       @ref tutorial_kinect_openni\n",
      "     |  \n",
      "     |  isOpened(...)\n",
      "     |      isOpened() -> retval\n",
      "     |      .   @brief Returns true if video capturing has been initialized already.\n",
      "     |      .   \n",
      "     |      .       If the previous call to VideoCapture constructor or VideoCapture::open() succeeded, the method returns\n",
      "     |      .       true.\n",
      "     |  \n",
      "     |  open(...)\n",
      "     |      open(filename[, apiPreference]) -> retval\n",
      "     |      .   @brief  Opens a video file or a capturing device or an IP video stream for video capturing.\n",
      "     |      .   \n",
      "     |      .       @overload\n",
      "     |      .   \n",
      "     |      .       Parameters are same as the constructor VideoCapture(const String& filename, int apiPreference = CAP_ANY)\n",
      "     |      .       @return `true` if the file has been successfully opened\n",
      "     |      .   \n",
      "     |      .       The method first calls VideoCapture::release to close the already opened file or camera.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      open(index[, apiPreference]) -> retval\n",
      "     |      .   @brief  Opens a camera for video capturing\n",
      "     |      .   \n",
      "     |      .       @overload\n",
      "     |      .   \n",
      "     |      .       Parameters are same as the constructor VideoCapture(int index, int apiPreference = CAP_ANY)\n",
      "     |      .       @return `true` if the camera has been successfully opened.\n",
      "     |      .   \n",
      "     |      .       The method first calls VideoCapture::release to close the already opened file or camera.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read([, image]) -> retval, image\n",
      "     |      .   @brief Grabs, decodes and returns the next video frame.\n",
      "     |      .   \n",
      "     |      .       @param [out] image the video frame is returned here. If no frames has been grabbed the image will be empty.\n",
      "     |      .       @return `false` if no frames has been grabbed\n",
      "     |      .   \n",
      "     |      .       The method/function combines VideoCapture::grab() and VideoCapture::retrieve() in one call. This is the\n",
      "     |      .       most convenient method for reading video files or capturing data from decode and returns the just\n",
      "     |      .       grabbed frame. If no frames has been grabbed (camera has been disconnected, or there are no more\n",
      "     |      .       frames in video file), the method returns false and the function returns empty image (with %cv::Mat, test it with Mat::empty()).\n",
      "     |      .   \n",
      "     |      .       @note In @ref videoio_c \"C API\", functions cvRetrieveFrame() and cv.RetrieveFrame() return image stored inside the video\n",
      "     |      .       capturing structure. It is not allowed to modify or release the image! You can copy the frame using\n",
      "     |      .       cvCloneImage and then do whatever you want with the copy.\n",
      "     |  \n",
      "     |  release(...)\n",
      "     |      release() -> None\n",
      "     |      .   @brief Closes video file or capturing device.\n",
      "     |      .   \n",
      "     |      .       The method is automatically called by subsequent VideoCapture::open and by VideoCapture\n",
      "     |      .       destructor.\n",
      "     |      .   \n",
      "     |      .       The C function also deallocates memory and clears \\*capture pointer.\n",
      "     |  \n",
      "     |  retrieve(...)\n",
      "     |      retrieve([, image[, flag]]) -> retval, image\n",
      "     |      .   @brief Decodes and returns the grabbed video frame.\n",
      "     |      .   \n",
      "     |      .       @param [out] image the video frame is returned here. If no frames has been grabbed the image will be empty.\n",
      "     |      .       @param flag it could be a frame index or a driver specific flag\n",
      "     |      .       @return `false` if no frames has been grabbed\n",
      "     |      .   \n",
      "     |      .       The method decodes and returns the just grabbed frame. If no frames has been grabbed\n",
      "     |      .       (camera has been disconnected, or there are no more frames in video file), the method returns false\n",
      "     |      .       and the function returns an empty image (with %cv::Mat, test it with Mat::empty()).\n",
      "     |      .   \n",
      "     |      .       @sa read()\n",
      "     |      .   \n",
      "     |      .       @note In @ref videoio_c \"C API\", functions cvRetrieveFrame() and cv.RetrieveFrame() return image stored inside the video\n",
      "     |      .       capturing structure. It is not allowed to modify or release the image! You can copy the frame using\n",
      "     |      .       cvCloneImage and then do whatever you want with the copy.\n",
      "     |  \n",
      "     |  set(...)\n",
      "     |      set(propId, value) -> retval\n",
      "     |      .   @brief Sets a property in the VideoCapture.\n",
      "     |      .   \n",
      "     |      .       @param propId Property identifier from cv::VideoCaptureProperties (eg. cv::CAP_PROP_POS_MSEC, cv::CAP_PROP_POS_FRAMES, ...)\n",
      "     |      .       or one from @ref videoio_flags_others\n",
      "     |      .       @param value Value of the property.\n",
      "     |      .       @return `true` if the property is supported by backend used by the VideoCapture instance.\n",
      "     |      .       @note Even if it returns `true` this doesn't ensure that the property\n",
      "     |      .       value has been accepted by the capture device. See note in VideoCapture::get()\n",
      "     |  \n",
      "     |  setExceptionMode(...)\n",
      "     |      setExceptionMode(enable) -> None\n",
      "     |      .   Switches exceptions mode\n",
      "     |      .        *\n",
      "     |      .        * methods raise exceptions if not successful instead of returning an error code\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class VideoWriter(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get(...)\n",
      "     |      get(propId) -> retval\n",
      "     |      .   @brief Returns the specified VideoWriter property\n",
      "     |      .   \n",
      "     |      .        @param propId Property identifier from cv::VideoWriterProperties (eg. cv::VIDEOWRITER_PROP_QUALITY)\n",
      "     |      .        or one of @ref videoio_flags_others\n",
      "     |      .   \n",
      "     |      .        @return Value for the specified property. Value 0 is returned when querying a property that is\n",
      "     |      .        not supported by the backend used by the VideoWriter instance.\n",
      "     |  \n",
      "     |  getBackendName(...)\n",
      "     |      getBackendName() -> retval\n",
      "     |      .   @brief Returns used backend API name\n",
      "     |      .   \n",
      "     |      .        @note Stream should be opened.\n",
      "     |  \n",
      "     |  isOpened(...)\n",
      "     |      isOpened() -> retval\n",
      "     |      .   @brief Returns true if video writer has been successfully initialized.\n",
      "     |  \n",
      "     |  open(...)\n",
      "     |      open(filename, fourcc, fps, frameSize[, isColor]) -> retval\n",
      "     |      .   @brief Initializes or reinitializes video writer.\n",
      "     |      .   \n",
      "     |      .       The method opens video writer. Parameters are the same as in the constructor\n",
      "     |      .       VideoWriter::VideoWriter.\n",
      "     |      .       @return `true` if video writer has been successfully initialized\n",
      "     |      .   \n",
      "     |      .       The method first calls VideoWriter::release to close the already opened file.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      open(filename, apiPreference, fourcc, fps, frameSize[, isColor]) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      open(filename, fourcc, fps, frameSize, params) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      open(filename, apiPreference, fourcc, fps, frameSize, params) -> retval\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  release(...)\n",
      "     |      release() -> None\n",
      "     |      .   @brief Closes the video writer.\n",
      "     |      .   \n",
      "     |      .       The method is automatically called by subsequent VideoWriter::open and by the VideoWriter\n",
      "     |      .       destructor.\n",
      "     |  \n",
      "     |  set(...)\n",
      "     |      set(propId, value) -> retval\n",
      "     |      .   @brief Sets a property in the VideoWriter.\n",
      "     |      .   \n",
      "     |      .        @param propId Property identifier from cv::VideoWriterProperties (eg. cv::VIDEOWRITER_PROP_QUALITY)\n",
      "     |      .        or one of @ref videoio_flags_others\n",
      "     |      .   \n",
      "     |      .        @param value Value of the property.\n",
      "     |      .        @return  `true` if the property is supported by the backend used by the VideoWriter instance.\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(image) -> None\n",
      "     |      .   @brief Writes the next video frame\n",
      "     |      .   \n",
      "     |      .       @param image The written frame. In general, color images are expected in BGR format.\n",
      "     |      .   \n",
      "     |      .       The function/method writes the specified image to video file. It must have the same size as has\n",
      "     |      .       been specified when opening the video writer.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  fourcc(...)\n",
      "     |      fourcc(c1, c2, c3, c4) -> retval\n",
      "     |      .   @brief Concatenates 4 chars to a fourcc code\n",
      "     |      .   \n",
      "     |      .       @return a fourcc code\n",
      "     |      .   \n",
      "     |      .       This static method constructs the fourcc code of the codec to be used in the constructor\n",
      "     |      .       VideoWriter::VideoWriter or VideoWriter::open.\n",
      "    \n",
      "    class WarperCreator(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class cuda_BufferPool(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getAllocator(...)\n",
      "     |      getAllocator() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getBuffer(...)\n",
      "     |      getBuffer(rows, cols, type) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getBuffer(size, type) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class cuda_DeviceInfo(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  ECCEnabled(...)\n",
      "     |      ECCEnabled() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  asyncEngineCount(...)\n",
      "     |      asyncEngineCount() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  canMapHostMemory(...)\n",
      "     |      canMapHostMemory() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  clockRate(...)\n",
      "     |      clockRate() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  computeMode(...)\n",
      "     |      computeMode() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  concurrentKernels(...)\n",
      "     |      concurrentKernels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  deviceID(...)\n",
      "     |      deviceID() -> retval\n",
      "     |      .   @brief Returns system index of the CUDA device starting with 0.\n",
      "     |  \n",
      "     |  freeMemory(...)\n",
      "     |      freeMemory() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  integrated(...)\n",
      "     |      integrated() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isCompatible(...)\n",
      "     |      isCompatible() -> retval\n",
      "     |      .   @brief Checks the CUDA module and device compatibility.\n",
      "     |      .   \n",
      "     |      .       This function returns true if the CUDA module can be run on the specified device. Otherwise, it\n",
      "     |      .       returns false .\n",
      "     |  \n",
      "     |  kernelExecTimeoutEnabled(...)\n",
      "     |      kernelExecTimeoutEnabled() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  l2CacheSize(...)\n",
      "     |      l2CacheSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  majorVersion(...)\n",
      "     |      majorVersion() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxGridSize(...)\n",
      "     |      maxGridSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurface1D(...)\n",
      "     |      maxSurface1D() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurface1DLayered(...)\n",
      "     |      maxSurface1DLayered() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurface2D(...)\n",
      "     |      maxSurface2D() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurface2DLayered(...)\n",
      "     |      maxSurface2DLayered() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurface3D(...)\n",
      "     |      maxSurface3D() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurfaceCubemap(...)\n",
      "     |      maxSurfaceCubemap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSurfaceCubemapLayered(...)\n",
      "     |      maxSurfaceCubemapLayered() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture1D(...)\n",
      "     |      maxTexture1D() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture1DLayered(...)\n",
      "     |      maxTexture1DLayered() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture1DLinear(...)\n",
      "     |      maxTexture1DLinear() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture1DMipmap(...)\n",
      "     |      maxTexture1DMipmap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture2D(...)\n",
      "     |      maxTexture2D() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture2DGather(...)\n",
      "     |      maxTexture2DGather() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture2DLayered(...)\n",
      "     |      maxTexture2DLayered() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture2DLinear(...)\n",
      "     |      maxTexture2DLinear() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture2DMipmap(...)\n",
      "     |      maxTexture2DMipmap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTexture3D(...)\n",
      "     |      maxTexture3D() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTextureCubemap(...)\n",
      "     |      maxTextureCubemap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxTextureCubemapLayered(...)\n",
      "     |      maxTextureCubemapLayered() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxThreadsDim(...)\n",
      "     |      maxThreadsDim() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxThreadsPerBlock(...)\n",
      "     |      maxThreadsPerBlock() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxThreadsPerMultiProcessor(...)\n",
      "     |      maxThreadsPerMultiProcessor() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  memPitch(...)\n",
      "     |      memPitch() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  memoryBusWidth(...)\n",
      "     |      memoryBusWidth() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  memoryClockRate(...)\n",
      "     |      memoryClockRate() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  minorVersion(...)\n",
      "     |      minorVersion() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  multiProcessorCount(...)\n",
      "     |      multiProcessorCount() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  pciBusID(...)\n",
      "     |      pciBusID() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  pciDeviceID(...)\n",
      "     |      pciDeviceID() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  pciDomainID(...)\n",
      "     |      pciDomainID() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  queryMemory(...)\n",
      "     |      queryMemory(totalMemory, freeMemory) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  regsPerBlock(...)\n",
      "     |      regsPerBlock() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  sharedMemPerBlock(...)\n",
      "     |      sharedMemPerBlock() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  surfaceAlignment(...)\n",
      "     |      surfaceAlignment() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  tccDriver(...)\n",
      "     |      tccDriver() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  textureAlignment(...)\n",
      "     |      textureAlignment() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  texturePitchAlignment(...)\n",
      "     |      texturePitchAlignment() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  totalConstMem(...)\n",
      "     |      totalConstMem() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  totalGlobalMem(...)\n",
      "     |      totalGlobalMem() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  totalMemory(...)\n",
      "     |      totalMemory() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  unifiedAddressing(...)\n",
      "     |      unifiedAddressing() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  warpSize(...)\n",
      "     |      warpSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class cuda_Event(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  queryIfComplete(...)\n",
      "     |      queryIfComplete() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  record(...)\n",
      "     |      record([, stream]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  waitForCompletion(...)\n",
      "     |      waitForCompletion() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  elapsedTime(...)\n",
      "     |      elapsedTime(start, end) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class cuda_GpuMat(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  adjustROI(...)\n",
      "     |      adjustROI(dtop, dbottom, dleft, dright) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  assignTo(...)\n",
      "     |      assignTo(m[, type]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  channels(...)\n",
      "     |      channels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  col(...)\n",
      "     |      col(x) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  colRange(...)\n",
      "     |      colRange(startcol, endcol) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      colRange(r) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  convertTo(...)\n",
      "     |      convertTo(rtype[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      convertTo(rtype, stream[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      convertTo(rtype, alpha[, dst[, beta]]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      convertTo(rtype, alpha, stream[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      convertTo(rtype, alpha, beta, stream[, dst]) -> dst\n",
      "     |      .\n",
      "     |  \n",
      "     |  copyTo(...)\n",
      "     |      copyTo([, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      copyTo(stream[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      copyTo(mask[, dst]) -> dst\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      copyTo(mask, stream[, dst]) -> dst\n",
      "     |      .\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create(rows, cols, type) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      create(size, type) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  cudaPtr(...)\n",
      "     |      cudaPtr() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  depth(...)\n",
      "     |      depth() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  download(...)\n",
      "     |      download([, dst]) -> dst\n",
      "     |      .   @brief Performs data download from GpuMat (Blocking call)\n",
      "     |      .   \n",
      "     |      .       This function copies data from device memory to host memory. As being a blocking call, it is\n",
      "     |      .       guaranteed that the copy operation is finished when this function returns.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      download(stream[, dst]) -> dst\n",
      "     |      .   @brief Performs data download from GpuMat (Non-Blocking call)\n",
      "     |      .   \n",
      "     |      .       This function copies data from device memory to host memory. As being a non-blocking call, this\n",
      "     |      .       function may return even if the copy operation is not finished.\n",
      "     |      .   \n",
      "     |      .       The copy operation may be overlapped with operations in other non-default streams if \\p stream is\n",
      "     |      .       not the default stream and \\p dst is HostMem allocated with HostMem::PAGE_LOCKED option.\n",
      "     |  \n",
      "     |  elemSize(...)\n",
      "     |      elemSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  elemSize1(...)\n",
      "     |      elemSize1() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isContinuous(...)\n",
      "     |      isContinuous() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  locateROI(...)\n",
      "     |      locateROI(wholeSize, ofs) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(cn[, rows]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  row(...)\n",
      "     |      row(y) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  rowRange(...)\n",
      "     |      rowRange(startrow, endrow) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      rowRange(r) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTo(...)\n",
      "     |      setTo(s) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setTo(s, stream) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setTo(s, mask) -> retval\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setTo(s, mask, stream) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  step1(...)\n",
      "     |      step1() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  swap(...)\n",
      "     |      swap(mat) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  updateContinuityFlag(...)\n",
      "     |      updateContinuityFlag() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  upload(...)\n",
      "     |      upload(arr) -> None\n",
      "     |      .   @brief Performs data upload to GpuMat (Blocking call)\n",
      "     |      .   \n",
      "     |      .       This function copies data from host memory to device memory. As being a blocking call, it is\n",
      "     |      .       guaranteed that the copy operation is finished when this function returns.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      upload(arr, stream) -> None\n",
      "     |      .   @brief Performs data upload to GpuMat (Non-Blocking call)\n",
      "     |      .   \n",
      "     |      .       This function copies data from host memory to device memory. As being a non-blocking call, this\n",
      "     |      .       function may return even if the copy operation is not finished.\n",
      "     |      .   \n",
      "     |      .       The copy operation may be overlapped with operations in other non-default streams if \\p stream is\n",
      "     |      .       not the default stream and \\p dst is HostMem allocated with HostMem::PAGE_LOCKED option.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  defaultAllocator(...)\n",
      "     |      defaultAllocator() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setDefaultAllocator(...)\n",
      "     |      setDefaultAllocator(allocator) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  step\n",
      "     |      step\n",
      "    \n",
      "    class cuda_GpuMat_Allocator(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class cuda_HostMem(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  channels(...)\n",
      "     |      channels() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create(rows, cols, type) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  createMatHeader(...)\n",
      "     |      createMatHeader() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  depth(...)\n",
      "     |      depth() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  elemSize(...)\n",
      "     |      elemSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  elemSize1(...)\n",
      "     |      elemSize1() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isContinuous(...)\n",
      "     |      isContinuous() -> retval\n",
      "     |      .   @brief Maps CPU memory to GPU address space and creates the cuda::GpuMat header without reference counting\n",
      "     |      .       for it.\n",
      "     |      .   \n",
      "     |      .       This can be done only if memory was allocated with the SHARED flag and if it is supported by the\n",
      "     |      .       hardware. Laptops often share video and CPU memory, so address spaces can be mapped, which\n",
      "     |      .       eliminates an extra copy.\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(cn[, rows]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  step1(...)\n",
      "     |      step1() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  swap(...)\n",
      "     |      swap(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  step\n",
      "     |      step\n",
      "    \n",
      "    class cuda_Stream(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  cudaPtr(...)\n",
      "     |      cudaPtr() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  queryIfComplete(...)\n",
      "     |      queryIfComplete() -> retval\n",
      "     |      .   @brief Returns true if the current stream queue is finished. Otherwise, it returns false.\n",
      "     |  \n",
      "     |  waitEvent(...)\n",
      "     |      waitEvent(event) -> None\n",
      "     |      .   @brief Makes a compute stream wait on an event.\n",
      "     |  \n",
      "     |  waitForCompletion(...)\n",
      "     |      waitForCompletion() -> None\n",
      "     |      .   @brief Blocks the current CPU thread until all operations in the stream are complete.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  Null(...)\n",
      "     |      Null() -> retval\n",
      "     |      .   @brief Adds a callback to be called on the host after all currently enqueued items in the stream have\n",
      "     |      .       completed.\n",
      "     |      .   \n",
      "     |      .       @note Callbacks must not make any CUDA API calls. Callbacks must not perform any synchronization\n",
      "     |      .       that may depend on outstanding device work or other callbacks that are not mandated to run earlier.\n",
      "     |      .       Callbacks without a mandated order (in independent streams) execute in undefined order and may be\n",
      "     |      .       serialized.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class cuda_TargetArchs(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  has(...)\n",
      "     |      has(major, minor) -> retval\n",
      "     |      .   @brief There is a set of methods to check whether the module contains intermediate (PTX) or binary CUDA\n",
      "     |      .       code for the given architecture(s):\n",
      "     |      .   \n",
      "     |      .       @param major Major compute capability version.\n",
      "     |      .       @param minor Minor compute capability version.\n",
      "     |  \n",
      "     |  hasBin(...)\n",
      "     |      hasBin(major, minor) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  hasEqualOrGreater(...)\n",
      "     |      hasEqualOrGreater(major, minor) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  hasEqualOrGreaterBin(...)\n",
      "     |      hasEqualOrGreaterBin(major, minor) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  hasEqualOrGreaterPtx(...)\n",
      "     |      hasEqualOrGreaterPtx(major, minor) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  hasEqualOrLessPtx(...)\n",
      "     |      hasEqualOrLessPtx(major, minor) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  hasPtx(...)\n",
      "     |      hasPtx(major, minor) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_AffineBasedEstimator(detail_Estimator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_AffineBasedEstimator\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .       @param features Features of images\n",
      "     |      .       @param pairwise_matches Pairwise matches of images\n",
      "     |      .       @param cameras Estimated camera parameters\n",
      "     |      .       @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_AffineBestOf2NearestMatcher(detail_BestOf2NearestMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      detail_AffineBestOf2NearestMatcher\n",
      "     |      detail_BestOf2NearestMatcher\n",
      "     |      detail_FeaturesMatcher\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BestOf2NearestMatcher:\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_BestOf2NearestMatcher:\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, try_use_gpu[, match_conf[, num_matches_thresh1[, num_matches_thresh2]]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_FeaturesMatcher:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features1, features2) -> matches_info\n",
      "     |      .   @overload\n",
      "     |      .       @param features1 First image features\n",
      "     |      .       @param features2 Second image features\n",
      "     |      .       @param matches_info Found matches\n",
      "     |  \n",
      "     |  apply2(...)\n",
      "     |      apply2(features[, mask]) -> pairwise_matches\n",
      "     |      .   @brief Performs images matching.\n",
      "     |      .   \n",
      "     |      .       @param features Features of the source images\n",
      "     |      .       @param pairwise_matches Found pairwise matches\n",
      "     |      .       @param mask Mask indicating which image pairs must be matched\n",
      "     |      .   \n",
      "     |      .       The function is parallelized with the TBB library.\n",
      "     |      .   \n",
      "     |      .       @sa detail::MatchesInfo\n",
      "     |  \n",
      "     |  isThreadSafe(...)\n",
      "     |      isThreadSafe() -> retval\n",
      "     |      .   @return True, if it's possible to use the same matcher instance in parallel, false otherwise\n",
      "    \n",
      "    class detail_BestOf2NearestMatcher(detail_FeaturesMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BestOf2NearestMatcher\n",
      "     |      detail_FeaturesMatcher\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, try_use_gpu[, match_conf[, num_matches_thresh1[, num_matches_thresh2]]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_FeaturesMatcher:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features1, features2) -> matches_info\n",
      "     |      .   @overload\n",
      "     |      .       @param features1 First image features\n",
      "     |      .       @param features2 Second image features\n",
      "     |      .       @param matches_info Found matches\n",
      "     |  \n",
      "     |  apply2(...)\n",
      "     |      apply2(features[, mask]) -> pairwise_matches\n",
      "     |      .   @brief Performs images matching.\n",
      "     |      .   \n",
      "     |      .       @param features Features of the source images\n",
      "     |      .       @param pairwise_matches Found pairwise matches\n",
      "     |      .       @param mask Mask indicating which image pairs must be matched\n",
      "     |      .   \n",
      "     |      .       The function is parallelized with the TBB library.\n",
      "     |      .   \n",
      "     |      .       @sa detail::MatchesInfo\n",
      "     |  \n",
      "     |  isThreadSafe(...)\n",
      "     |      isThreadSafe() -> retval\n",
      "     |      .   @return True, if it's possible to use the same matcher instance in parallel, false otherwise\n",
      "    \n",
      "    class detail_BestOf2NearestRangeMatcher(detail_BestOf2NearestMatcher)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BestOf2NearestRangeMatcher\n",
      "     |      detail_BestOf2NearestMatcher\n",
      "     |      detail_FeaturesMatcher\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BestOf2NearestMatcher:\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_BestOf2NearestMatcher:\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, try_use_gpu[, match_conf[, num_matches_thresh1[, num_matches_thresh2]]]]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_FeaturesMatcher:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features1, features2) -> matches_info\n",
      "     |      .   @overload\n",
      "     |      .       @param features1 First image features\n",
      "     |      .       @param features2 Second image features\n",
      "     |      .       @param matches_info Found matches\n",
      "     |  \n",
      "     |  apply2(...)\n",
      "     |      apply2(features[, mask]) -> pairwise_matches\n",
      "     |      .   @brief Performs images matching.\n",
      "     |      .   \n",
      "     |      .       @param features Features of the source images\n",
      "     |      .       @param pairwise_matches Found pairwise matches\n",
      "     |      .       @param mask Mask indicating which image pairs must be matched\n",
      "     |      .   \n",
      "     |      .       The function is parallelized with the TBB library.\n",
      "     |      .   \n",
      "     |      .       @sa detail::MatchesInfo\n",
      "     |  \n",
      "     |  isThreadSafe(...)\n",
      "     |      isThreadSafe() -> retval\n",
      "     |      .   @return True, if it's possible to use the same matcher instance in parallel, false otherwise\n",
      "    \n",
      "    class detail_Blender(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  blend(...)\n",
      "     |      blend(dst, dst_mask) -> dst, dst_mask\n",
      "     |      .   @brief Blends and returns the final pano.\n",
      "     |      .   \n",
      "     |      .       @param dst Final pano\n",
      "     |      .       @param dst_mask Final pano mask\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(img, mask, tl) -> None\n",
      "     |      .   @brief Processes the image.\n",
      "     |      .   \n",
      "     |      .       @param img Source image\n",
      "     |      .       @param mask Source image mask\n",
      "     |      .       @param tl Source image top-left corners\n",
      "     |  \n",
      "     |  prepare(...)\n",
      "     |      prepare(corners, sizes) -> None\n",
      "     |      .   @brief Prepares the blender for blending.\n",
      "     |      .   \n",
      "     |      .       @param corners Source images top-left corners\n",
      "     |      .       @param sizes Source image sizes\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      prepare(dst_roi) -> None\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type[, try_gpu]) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_BlocksChannelsCompensator(detail_BlocksCompensator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BlocksChannelsCompensator\n",
      "     |      detail_BlocksCompensator\n",
      "     |      detail_ExposureCompensator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BlocksCompensator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(index, corner, image, mask) -> image\n",
      "     |      .\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, umv]) -> umv\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrFeeds(...)\n",
      "     |      getNrFeeds() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrGainsFilteringIterations(...)\n",
      "     |      getNrGainsFilteringIterations() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(width, height) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setBlockSize(size) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(umv) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrFeeds(...)\n",
      "     |      setNrFeeds(nr_feeds) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrGainsFilteringIterations(...)\n",
      "     |      setNrGainsFilteringIterations(nr_iterations) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .       @param images Source images\n",
      "     |      .       @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .       to detect where image is)\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_BlocksCompensator(detail_ExposureCompensator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BlocksCompensator\n",
      "     |      detail_ExposureCompensator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(index, corner, image, mask) -> image\n",
      "     |      .\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, umv]) -> umv\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrFeeds(...)\n",
      "     |      getNrFeeds() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrGainsFilteringIterations(...)\n",
      "     |      getNrGainsFilteringIterations() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(width, height) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setBlockSize(size) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(umv) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrFeeds(...)\n",
      "     |      setNrFeeds(nr_feeds) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrGainsFilteringIterations(...)\n",
      "     |      setNrGainsFilteringIterations(nr_iterations) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .       @param images Source images\n",
      "     |      .       @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .       to detect where image is)\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_BlocksGainCompensator(detail_BlocksCompensator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BlocksGainCompensator\n",
      "     |      detail_BlocksCompensator\n",
      "     |      detail_ExposureCompensator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(index, corner, image, mask) -> image\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, umv]) -> umv\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(umv) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BlocksCompensator:\n",
      "     |  \n",
      "     |  getBlockSize(...)\n",
      "     |      getBlockSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrFeeds(...)\n",
      "     |      getNrFeeds() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrGainsFilteringIterations(...)\n",
      "     |      getNrGainsFilteringIterations() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setBlockSize(...)\n",
      "     |      setBlockSize(width, height) -> None\n",
      "     |      .   \n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setBlockSize(size) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrFeeds(...)\n",
      "     |      setNrFeeds(nr_feeds) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrGainsFilteringIterations(...)\n",
      "     |      setNrGainsFilteringIterations(nr_iterations) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .       @param images Source images\n",
      "     |      .       @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .       to detect where image is)\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_BundleAdjusterAffine(detail_BundleAdjusterBase)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BundleAdjusterAffine\n",
      "     |      detail_BundleAdjusterBase\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BundleAdjusterBase:\n",
      "     |  \n",
      "     |  confThresh(...)\n",
      "     |      confThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  refinementMask(...)\n",
      "     |      refinementMask() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setConfThresh(...)\n",
      "     |      setConfThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRefinementMask(...)\n",
      "     |      setRefinementMask(mask) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(term_criteria) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  termCriteria(...)\n",
      "     |      termCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .       @param features Features of images\n",
      "     |      .       @param pairwise_matches Pairwise matches of images\n",
      "     |      .       @param cameras Estimated camera parameters\n",
      "     |      .       @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_BundleAdjusterAffinePartial(detail_BundleAdjusterBase)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BundleAdjusterAffinePartial\n",
      "     |      detail_BundleAdjusterBase\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BundleAdjusterBase:\n",
      "     |  \n",
      "     |  confThresh(...)\n",
      "     |      confThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  refinementMask(...)\n",
      "     |      refinementMask() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setConfThresh(...)\n",
      "     |      setConfThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRefinementMask(...)\n",
      "     |      setRefinementMask(mask) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(term_criteria) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  termCriteria(...)\n",
      "     |      termCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .       @param features Features of images\n",
      "     |      .       @param pairwise_matches Pairwise matches of images\n",
      "     |      .       @param cameras Estimated camera parameters\n",
      "     |      .       @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_BundleAdjusterBase(detail_Estimator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BundleAdjusterBase\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  confThresh(...)\n",
      "     |      confThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  refinementMask(...)\n",
      "     |      refinementMask() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setConfThresh(...)\n",
      "     |      setConfThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRefinementMask(...)\n",
      "     |      setRefinementMask(mask) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(term_criteria) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  termCriteria(...)\n",
      "     |      termCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .       @param features Features of images\n",
      "     |      .       @param pairwise_matches Pairwise matches of images\n",
      "     |      .       @param cameras Estimated camera parameters\n",
      "     |      .       @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_BundleAdjusterRay(detail_BundleAdjusterBase)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BundleAdjusterRay\n",
      "     |      detail_BundleAdjusterBase\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BundleAdjusterBase:\n",
      "     |  \n",
      "     |  confThresh(...)\n",
      "     |      confThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  refinementMask(...)\n",
      "     |      refinementMask() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setConfThresh(...)\n",
      "     |      setConfThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRefinementMask(...)\n",
      "     |      setRefinementMask(mask) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(term_criteria) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  termCriteria(...)\n",
      "     |      termCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .       @param features Features of images\n",
      "     |      .       @param pairwise_matches Pairwise matches of images\n",
      "     |      .       @param cameras Estimated camera parameters\n",
      "     |      .       @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_BundleAdjusterReproj(detail_BundleAdjusterBase)\n",
      "     |  Method resolution order:\n",
      "     |      detail_BundleAdjusterReproj\n",
      "     |      detail_BundleAdjusterBase\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BundleAdjusterBase:\n",
      "     |  \n",
      "     |  confThresh(...)\n",
      "     |      confThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  refinementMask(...)\n",
      "     |      refinementMask() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setConfThresh(...)\n",
      "     |      setConfThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRefinementMask(...)\n",
      "     |      setRefinementMask(mask) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(term_criteria) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  termCriteria(...)\n",
      "     |      termCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .       @param features Features of images\n",
      "     |      .       @param pairwise_matches Pairwise matches of images\n",
      "     |      .       @param cameras Estimated camera parameters\n",
      "     |      .       @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_CameraParams(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  K(...)\n",
      "     |      K() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  R\n",
      "     |      R\n",
      "     |  \n",
      "     |  aspect\n",
      "     |      aspect\n",
      "     |  \n",
      "     |  focal\n",
      "     |      focal\n",
      "     |  \n",
      "     |  ppx\n",
      "     |      ppx\n",
      "     |  \n",
      "     |  ppy\n",
      "     |      ppy\n",
      "     |  \n",
      "     |  t\n",
      "     |      t\n",
      "    \n",
      "    class detail_ChannelsCompensator(detail_ExposureCompensator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_ChannelsCompensator\n",
      "     |      detail_ExposureCompensator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(index, corner, image, mask) -> image\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, umv]) -> umv\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrFeeds(...)\n",
      "     |      getNrFeeds() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(umv) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrFeeds(...)\n",
      "     |      setNrFeeds(nr_feeds) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .       @param images Source images\n",
      "     |      .       @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .       to detect where image is)\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_DpSeamFinder(detail_SeamFinder)\n",
      "     |  Method resolution order:\n",
      "     |      detail_DpSeamFinder\n",
      "     |      detail_SeamFinder\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  setCostFunction(...)\n",
      "     |      setCostFunction(val) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_SeamFinder:\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      find(src, corners, masks) -> masks\n",
      "     |      .   @brief Estimates seams.\n",
      "     |      .   \n",
      "     |      .       @param src Source images\n",
      "     |      .       @param corners Source image top-left corners\n",
      "     |      .       @param masks Source image masks to update\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_SeamFinder:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_Estimator(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .       @param features Features of images\n",
      "     |      .       @param pairwise_matches Pairwise matches of images\n",
      "     |      .       @param cameras Estimated camera parameters\n",
      "     |      .       @return True in case of success, false otherwise\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class detail_ExposureCompensator(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(index, corner, image, mask) -> image\n",
      "     |      .   @brief Compensate exposure in the specified image.\n",
      "     |      .   \n",
      "     |      .       @param index Image index\n",
      "     |      .       @param corner Image top-left corner\n",
      "     |      .       @param image Image to process\n",
      "     |      .       @param mask Image mask\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .       @param images Source images\n",
      "     |      .       @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .       to detect where image is)\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, arg1]) -> arg1\n",
      "     |      .\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(arg1) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_FeatherBlender(detail_Blender)\n",
      "     |  Method resolution order:\n",
      "     |      detail_FeatherBlender\n",
      "     |      detail_Blender\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  blend(...)\n",
      "     |      blend(dst, dst_mask) -> dst, dst_mask\n",
      "     |      .\n",
      "     |  \n",
      "     |  createWeightMaps(...)\n",
      "     |      createWeightMaps(masks, corners, weight_maps) -> retval, weight_maps\n",
      "     |      .\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(img, mask, tl) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  prepare(...)\n",
      "     |      prepare(dst_roi) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setSharpness(...)\n",
      "     |      setSharpness(val) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  sharpness(...)\n",
      "     |      sharpness() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_Blender:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type[, try_gpu]) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_FeaturesMatcher(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features1, features2) -> matches_info\n",
      "     |      .   @overload\n",
      "     |      .       @param features1 First image features\n",
      "     |      .       @param features2 Second image features\n",
      "     |      .       @param matches_info Found matches\n",
      "     |  \n",
      "     |  apply2(...)\n",
      "     |      apply2(features[, mask]) -> pairwise_matches\n",
      "     |      .   @brief Performs images matching.\n",
      "     |      .   \n",
      "     |      .       @param features Features of the source images\n",
      "     |      .       @param pairwise_matches Found pairwise matches\n",
      "     |      .       @param mask Mask indicating which image pairs must be matched\n",
      "     |      .   \n",
      "     |      .       The function is parallelized with the TBB library.\n",
      "     |      .   \n",
      "     |      .       @sa detail::MatchesInfo\n",
      "     |  \n",
      "     |  collectGarbage(...)\n",
      "     |      collectGarbage() -> None\n",
      "     |      .   @brief Frees unused memory allocated before if there is any.\n",
      "     |  \n",
      "     |  isThreadSafe(...)\n",
      "     |      isThreadSafe() -> retval\n",
      "     |      .   @return True, if it's possible to use the same matcher instance in parallel, false otherwise\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class detail_GainCompensator(detail_ExposureCompensator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_GainCompensator\n",
      "     |      detail_ExposureCompensator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(index, corner, image, mask) -> image\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, umv]) -> umv\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNrFeeds(...)\n",
      "     |      getNrFeeds() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(umv) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNrFeeds(...)\n",
      "     |      setNrFeeds(nr_feeds) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .       @param images Source images\n",
      "     |      .       @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .       to detect where image is)\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_GraphCutSeamFinder(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      find(src, corners, masks) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class detail_HomographyBasedEstimator(detail_Estimator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_HomographyBasedEstimator\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .       @param features Features of images\n",
      "     |      .       @param pairwise_matches Pairwise matches of images\n",
      "     |      .       @param cameras Estimated camera parameters\n",
      "     |      .       @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_ImageFeatures(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getKeypoints(...)\n",
      "     |      getKeypoints() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  descriptors\n",
      "     |      descriptors\n",
      "     |  \n",
      "     |  img_idx\n",
      "     |      img_idx\n",
      "     |  \n",
      "     |  img_size\n",
      "     |      img_size\n",
      "    \n",
      "    class detail_MatchesInfo(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getInliers(...)\n",
      "     |      getInliers() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatches(...)\n",
      "     |      getMatches() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  H\n",
      "     |      H\n",
      "     |  \n",
      "     |  confidence\n",
      "     |      confidence\n",
      "     |  \n",
      "     |  dst_img_idx\n",
      "     |      dst_img_idx\n",
      "     |  \n",
      "     |  num_inliers\n",
      "     |      num_inliers\n",
      "     |  \n",
      "     |  src_img_idx\n",
      "     |      src_img_idx\n",
      "    \n",
      "    class detail_MultiBandBlender(detail_Blender)\n",
      "     |  Method resolution order:\n",
      "     |      detail_MultiBandBlender\n",
      "     |      detail_Blender\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  blend(...)\n",
      "     |      blend(dst, dst_mask) -> dst, dst_mask\n",
      "     |      .\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(img, mask, tl) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  numBands(...)\n",
      "     |      numBands() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  prepare(...)\n",
      "     |      prepare(dst_roi) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setNumBands(...)\n",
      "     |      setNumBands(val) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_Blender:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type[, try_gpu]) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_NoBundleAdjuster(detail_BundleAdjusterBase)\n",
      "     |  Method resolution order:\n",
      "     |      detail_NoBundleAdjuster\n",
      "     |      detail_BundleAdjusterBase\n",
      "     |      detail_Estimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_BundleAdjusterBase:\n",
      "     |  \n",
      "     |  confThresh(...)\n",
      "     |      confThresh() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  refinementMask(...)\n",
      "     |      refinementMask() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setConfThresh(...)\n",
      "     |      setConfThresh(conf_thresh) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setRefinementMask(...)\n",
      "     |      setRefinementMask(mask) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(term_criteria) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  termCriteria(...)\n",
      "     |      termCriteria() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Estimator:\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(features, pairwise_matches, cameras) -> retval, cameras\n",
      "     |      .   @brief Estimates camera parameters.\n",
      "     |      .   \n",
      "     |      .       @param features Features of images\n",
      "     |      .       @param pairwise_matches Pairwise matches of images\n",
      "     |      .       @param cameras Estimated camera parameters\n",
      "     |      .       @return True in case of success, false otherwise\n",
      "    \n",
      "    class detail_NoExposureCompensator(detail_ExposureCompensator)\n",
      "     |  Method resolution order:\n",
      "     |      detail_NoExposureCompensator\n",
      "     |      detail_ExposureCompensator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(arg1, arg2, arg3, arg4) -> arg3\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMatGains(...)\n",
      "     |      getMatGains([, umv]) -> umv\n",
      "     |      .\n",
      "     |  \n",
      "     |  setMatGains(...)\n",
      "     |      setMatGains(umv) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  feed(...)\n",
      "     |      feed(corners, images, masks) -> None\n",
      "     |      .   @param corners Source image top-left corners\n",
      "     |      .       @param images Source images\n",
      "     |      .       @param masks Image masks to update (second value in pair specifies the value which should be used\n",
      "     |      .       to detect where image is)\n",
      "     |  \n",
      "     |  getUpdateGain(...)\n",
      "     |      getUpdateGain() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setUpdateGain(...)\n",
      "     |      setUpdateGain(b) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_ExposureCompensator:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_NoSeamFinder(detail_SeamFinder)\n",
      "     |  Method resolution order:\n",
      "     |      detail_NoSeamFinder\n",
      "     |      detail_SeamFinder\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      find(arg1, arg2, arg3) -> arg3\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_SeamFinder:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_PairwiseSeamFinder(detail_SeamFinder)\n",
      "     |  Method resolution order:\n",
      "     |      detail_PairwiseSeamFinder\n",
      "     |      detail_SeamFinder\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      find(src, corners, masks) -> masks\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_SeamFinder:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_ProjectorBase(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class detail_SeamFinder(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      find(src, corners, masks) -> masks\n",
      "     |      .   @brief Estimates seams.\n",
      "     |      .   \n",
      "     |      .       @param src Source images\n",
      "     |      .       @param corners Source image top-left corners\n",
      "     |      .       @param masks Source image masks to update\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_SphericalProjector(detail_ProjectorBase)\n",
      "     |  Method resolution order:\n",
      "     |      detail_SphericalProjector\n",
      "     |      detail_ProjectorBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  mapBackward(...)\n",
      "     |      mapBackward(u, v, x, y) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  mapForward(...)\n",
      "     |      mapForward(x, y, u, v) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class detail_Timelapser(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getDst(...)\n",
      "     |      getDst() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  initialize(...)\n",
      "     |      initialize(corners, sizes) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(img, mask, tl) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_TimelapserCrop(detail_Timelapser)\n",
      "     |  Method resolution order:\n",
      "     |      detail_TimelapserCrop\n",
      "     |      detail_Timelapser\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from detail_Timelapser:\n",
      "     |  \n",
      "     |  getDst(...)\n",
      "     |      getDst() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  initialize(...)\n",
      "     |      initialize(corners, sizes) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  process(...)\n",
      "     |      process(img, mask, tl) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_Timelapser:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class detail_VoronoiSeamFinder(detail_PairwiseSeamFinder)\n",
      "     |  Method resolution order:\n",
      "     |      detail_VoronoiSeamFinder\n",
      "     |      detail_PairwiseSeamFinder\n",
      "     |      detail_SeamFinder\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      find(src, corners, masks) -> masks\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from detail_SeamFinder:\n",
      "     |  \n",
      "     |  createDefault(...)\n",
      "     |      createDefault(type) -> retval\n",
      "     |      .\n",
      "    \n",
      "    class dnn_ClassificationModel(dnn_Model)\n",
      "     |  Method resolution order:\n",
      "     |      dnn_ClassificationModel\n",
      "     |      dnn_Model\n",
      "     |      dnn_Net\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  classify(...)\n",
      "     |      classify(frame) -> classId, conf\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from dnn_Model:\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(frame[, outs]) -> outs\n",
      "     |      .   @brief Given the @p input frame, create input blob, run net and return the output @p blobs.\n",
      "     |      .             *  @param[in]  frame  The input image.\n",
      "     |      .             *  @param[out] outs Allocated output blobs, which will store results of the computation.\n",
      "     |  \n",
      "     |  setInputCrop(...)\n",
      "     |      setInputCrop(crop) -> retval\n",
      "     |      .   @brief Set flag crop for frame.\n",
      "     |      .             *  @param[in] crop Flag which indicates whether image will be cropped after resize or not.\n",
      "     |  \n",
      "     |  setInputMean(...)\n",
      "     |      setInputMean(mean) -> retval\n",
      "     |      .   @brief Set mean value for frame.\n",
      "     |      .             *  @param[in] mean Scalar with mean values which are subtracted from channels.\n",
      "     |  \n",
      "     |  setInputParams(...)\n",
      "     |      setInputParams([, scale[, size[, mean[, swapRB[, crop]]]]]) -> None\n",
      "     |      .   @brief Set preprocessing parameters for frame.\n",
      "     |      .            *  @param[in] size New input size.\n",
      "     |      .            *  @param[in] mean Scalar with mean values which are subtracted from channels.\n",
      "     |      .            *  @param[in] scale Multiplier for frame values.\n",
      "     |      .            *  @param[in] swapRB Flag which indicates that swap first and last channels.\n",
      "     |      .            *  @param[in] crop Flag which indicates whether image will be cropped after resize or not.\n",
      "     |      .            *  blob(n, c, y, x) = scale * resize( frame(y, x, c) ) - mean(c) )\n",
      "     |  \n",
      "     |  setInputScale(...)\n",
      "     |      setInputScale(scale) -> retval\n",
      "     |      .   @brief Set scalefactor value for frame.\n",
      "     |      .             *  @param[in] scale Multiplier for frame values.\n",
      "     |  \n",
      "     |  setInputSize(...)\n",
      "     |      setInputSize(size) -> retval\n",
      "     |      .   @brief Set input size for frame.\n",
      "     |      .             *  @param[in] size New input size.\n",
      "     |      .             *  @note If shape of the new blob less than 0, then frame size not change.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setInputSize(width, height) -> retval\n",
      "     |      .   @brief Set input size for frame.\n",
      "     |      .            *  @param[in] width New input width.\n",
      "     |      .            *  @param[in] height New input height.\n",
      "     |      .            *  @note If shape of the new blob less than 0,\n",
      "     |      .            *  then frame size not change.\n",
      "     |  \n",
      "     |  setInputSwapRB(...)\n",
      "     |      setInputSwapRB(swapRB) -> retval\n",
      "     |      .   @brief Set flag swapRB for frame.\n",
      "     |      .             *  @param[in] swapRB Flag which indicates that swap first and last channels.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from dnn_Net:\n",
      "     |  \n",
      "     |  connect(...)\n",
      "     |      connect(outPin, inpPin) -> None\n",
      "     |      .   @brief Connects output of the first layer to input of the second layer.\n",
      "     |      .            *  @param outPin descriptor of the first layer output.\n",
      "     |      .            *  @param inpPin descriptor of the second layer input.\n",
      "     |      .            *\n",
      "     |      .            * Descriptors have the following template <DFN>&lt;layer_name&gt;[.input_number]</DFN>:\n",
      "     |      .            * - the first part of the template <DFN>layer_name</DFN> is string name of the added layer.\n",
      "     |      .            *   If this part is empty then the network input pseudo layer will be used;\n",
      "     |      .            * - the second optional part of the template <DFN>input_number</DFN>\n",
      "     |      .            *   is either number of the layer input, either label one.\n",
      "     |      .            *   If this part is omitted then the first layer input will be used.\n",
      "     |      .            *\n",
      "     |      .            *  @see setNetInputs(), Layer::inputNameToIndex(), Layer::outputNameToIndex()\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      dump() -> retval\n",
      "     |      .   @brief Dump net to String\n",
      "     |      .            *  @returns String with structure, hyperparameters, backend, target and fusion\n",
      "     |      .            *  Call method after setInput(). To see correct backend, target and fusion run after forward().\n",
      "     |  \n",
      "     |  dumpToFile(...)\n",
      "     |      dumpToFile(path) -> None\n",
      "     |      .   @brief Dump net structure, hyperparameters, backend, target and fusion to dot file\n",
      "     |      .            *  @param path   path to output file with .dot extension\n",
      "     |      .            *  @see dump()\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   Returns true if there are no layers in the network.\n",
      "     |  \n",
      "     |  enableFusion(...)\n",
      "     |      enableFusion(fusion) -> None\n",
      "     |      .   @brief Enables or disables layer fusion in the network.\n",
      "     |      .            * @param fusion true to enable the fusion, false to disable. The fusion is enabled by default.\n",
      "     |  \n",
      "     |  forward(...)\n",
      "     |      forward([, outputName]) -> retval\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @return blob for first output of specified layer.\n",
      "     |      .            *  @details By default runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward([, outputBlobs[, outputName]]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputBlobs contains all output blobs for specified layer.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @details If @p outputName is empty, runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward(outBlobNames[, outputBlobs]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .            *  @param outputBlobs contains blobs for first outputs of specified layers.\n",
      "     |      .            *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  forwardAndRetrieve(...)\n",
      "     |      forwardAndRetrieve(outBlobNames) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .            *  @param outputBlobs contains all output blobs for each layer specified in @p outBlobNames.\n",
      "     |      .            *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  forwardAsync(...)\n",
      "     |      forwardAsync([, outputName]) -> retval\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @details By default runs forward pass for the whole network.\n",
      "     |      .            *\n",
      "     |      .            *  This is an asynchronous version of forward(const String&).\n",
      "     |      .            *  dnn::DNN_BACKEND_INFERENCE_ENGINE backend is required.\n",
      "     |  \n",
      "     |  getFLOPS(...)\n",
      "     |      getFLOPS(netInputShapes) -> retval\n",
      "     |      .   @brief Computes FLOP for whole loaded model with specified input shapes.\n",
      "     |      .            * @param netInputShapes vector of shapes for all net inputs.\n",
      "     |      .            * @returns computed FLOP.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShapes) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getLayer(...)\n",
      "     |      getLayer(layerId) -> retval\n",
      "     |      .   @brief Returns pointer to layer with specified id or name which the network use.\n",
      "     |  \n",
      "     |  getLayerId(...)\n",
      "     |      getLayerId(layer) -> retval\n",
      "     |      .   @brief Converts string name of the layer to the integer identifier.\n",
      "     |      .            *  @returns id of the layer, or -1 if the layer wasn't found.\n",
      "     |  \n",
      "     |  getLayerNames(...)\n",
      "     |      getLayerNames() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getLayerTypes(...)\n",
      "     |      getLayerTypes() -> layersTypes\n",
      "     |      .   @brief Returns list of types for layer used in model.\n",
      "     |      .            * @param layersTypes output parameter for returning types.\n",
      "     |  \n",
      "     |  getLayersCount(...)\n",
      "     |      getLayersCount(layerType) -> retval\n",
      "     |      .   @brief Returns count of layers of specified type.\n",
      "     |      .            * @param layerType type.\n",
      "     |      .            * @returns count of layers\n",
      "     |  \n",
      "     |  getLayersShapes(...)\n",
      "     |      getLayersShapes(netInputShapes) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @brief Returns input and output shapes for all layers in loaded model;\n",
      "     |      .            *  preliminary inferencing isn't necessary.\n",
      "     |      .            *  @param netInputShapes shapes for all input blobs in net input layer.\n",
      "     |      .            *  @param layersIds output parameter for layer IDs.\n",
      "     |      .            *  @param inLayersShapes output parameter for input layers shapes;\n",
      "     |      .            * order is the same as in layersIds\n",
      "     |      .            *  @param outLayersShapes output parameter for output layers shapes;\n",
      "     |      .            * order is the same as in layersIds\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getLayersShapes(netInputShape) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getMemoryConsumption(...)\n",
      "     |      getMemoryConsumption(netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShapes) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getParam(...)\n",
      "     |      getParam(layer[, numParam]) -> retval\n",
      "     |      .   @brief Returns parameter blob of the layer.\n",
      "     |      .            *  @param layer name or id of the layer.\n",
      "     |      .            *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .            *  @see Layer::blobs\n",
      "     |  \n",
      "     |  getPerfProfile(...)\n",
      "     |      getPerfProfile() -> retval, timings\n",
      "     |      .   @brief Returns overall time for inference and timings (in ticks) for layers.\n",
      "     |      .            * Indexes in returned vector correspond to layers ids. Some layers can be fused with others,\n",
      "     |      .            * in this case zero ticks count will be return for that skipped layers.\n",
      "     |      .            * @param timings vector for tick timings for all layers.\n",
      "     |      .            * @return overall ticks for model inference.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayers(...)\n",
      "     |      getUnconnectedOutLayers() -> retval\n",
      "     |      .   @brief Returns indexes of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayersNames(...)\n",
      "     |      getUnconnectedOutLayersNames() -> retval\n",
      "     |      .   @brief Returns names of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  setHalideScheduler(...)\n",
      "     |      setHalideScheduler(scheduler) -> None\n",
      "     |      .   * @brief Compile Halide layers.\n",
      "     |      .            * @param[in] scheduler Path to YAML file with scheduling directives.\n",
      "     |      .            * @see setPreferableBackend\n",
      "     |      .            *\n",
      "     |      .            * Schedule layers that support Halide backend. Then compile them for\n",
      "     |      .            * specific target. For layers that not represented in scheduling file\n",
      "     |      .            * or if no manual scheduling used at all, automatic scheduling will be applied.\n",
      "     |  \n",
      "     |  setInput(...)\n",
      "     |      setInput(blob[, name[, scalefactor[, mean]]]) -> None\n",
      "     |      .   @brief Sets the new input value for the network\n",
      "     |      .            *  @param blob        A new blob. Should have CV_32F or CV_8U depth.\n",
      "     |      .            *  @param name        A name of input layer.\n",
      "     |      .            *  @param scalefactor An optional normalization scale.\n",
      "     |      .            *  @param mean        An optional mean subtraction values.\n",
      "     |      .            *  @see connect(String, String) to know format of the descriptor.\n",
      "     |      .            *\n",
      "     |      .            *  If scale or mean values are specified, a final input blob is computed\n",
      "     |      .            *  as:\n",
      "     |      .            * \\f[input(n,c,h,w) = scalefactor \\times (blob(n,c,h,w) - mean_c)\\f]\n",
      "     |  \n",
      "     |  setInputShape(...)\n",
      "     |      setInputShape(inputName, shape) -> None\n",
      "     |      .   @brief Specify shape of network input.\n",
      "     |  \n",
      "     |  setInputsNames(...)\n",
      "     |      setInputsNames(inputBlobNames) -> None\n",
      "     |      .   @brief Sets outputs names of the network input pseudo layer.\n",
      "     |      .            *\n",
      "     |      .            * Each net always has special own the network input pseudo layer with id=0.\n",
      "     |      .            * This layer stores the user blobs only and don't make any computations.\n",
      "     |      .            * In fact, this layer provides the only way to pass user data into the network.\n",
      "     |      .            * As any other layer, this layer can label its outputs and this function provides an easy way to do this.\n",
      "     |  \n",
      "     |  setParam(...)\n",
      "     |      setParam(layer, numParam, blob) -> None\n",
      "     |      .   @brief Sets the new value for the learned param of the layer.\n",
      "     |      .            *  @param layer name or id of the layer.\n",
      "     |      .            *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .            *  @param blob the new value.\n",
      "     |      .            *  @see Layer::blobs\n",
      "     |      .            *  @note If shape of the new blob differs from the previous shape,\n",
      "     |      .            *  then the following forward pass may fail.\n",
      "     |  \n",
      "     |  setPreferableBackend(...)\n",
      "     |      setPreferableBackend(backendId) -> None\n",
      "     |      .   * @brief Ask network to use specific computation backend where it supported.\n",
      "     |      .            * @param[in] backendId backend identifier.\n",
      "     |      .            * @see Backend\n",
      "     |      .            *\n",
      "     |      .            * If OpenCV is compiled with Intel's Inference Engine library, DNN_BACKEND_DEFAULT\n",
      "     |      .            * means DNN_BACKEND_INFERENCE_ENGINE. Otherwise it equals to DNN_BACKEND_OPENCV.\n",
      "     |  \n",
      "     |  setPreferableTarget(...)\n",
      "     |      setPreferableTarget(targetId) -> None\n",
      "     |      .   * @brief Ask network to make computations on specific target device.\n",
      "     |      .            * @param[in] targetId target identifier.\n",
      "     |      .            * @see Target\n",
      "     |      .            *\n",
      "     |      .            * List of supported combinations backend / target:\n",
      "     |      .            * |                        | DNN_BACKEND_OPENCV | DNN_BACKEND_INFERENCE_ENGINE | DNN_BACKEND_HALIDE |  DNN_BACKEND_CUDA |\n",
      "     |      .            * |------------------------|--------------------|------------------------------|--------------------|-------------------|\n",
      "     |      .            * | DNN_TARGET_CPU         |                  + |                            + |                  + |                   |\n",
      "     |      .            * | DNN_TARGET_OPENCL      |                  + |                            + |                  + |                   |\n",
      "     |      .            * | DNN_TARGET_OPENCL_FP16 |                  + |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_MYRIAD      |                    |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_FPGA        |                    |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_CUDA        |                    |                              |                    |                 + |\n",
      "     |      .            * | DNN_TARGET_CUDA_FP16   |                    |                              |                    |                 + |\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from dnn_Net:\n",
      "     |  \n",
      "     |  readFromModelOptimizer(...)\n",
      "     |      readFromModelOptimizer(xml, bin) -> retval\n",
      "     |      .   @brief Create a network from Intel's Model Optimizer intermediate representation (IR).\n",
      "     |      .            *  @param[in] xml XML configuration file with network's topology.\n",
      "     |      .            *  @param[in] bin Binary file with trained weights.\n",
      "     |      .            *  Networks imported from Intel's Model Optimizer are launched in Intel's Inference Engine\n",
      "     |      .            *  backend.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      readFromModelOptimizer(bufferModelConfig, bufferWeights) -> retval\n",
      "     |      .   @brief Create a network from Intel's Model Optimizer in-memory buffers with intermediate representation (IR).\n",
      "     |      .            *  @param[in] bufferModelConfig buffer with model's configuration.\n",
      "     |      .            *  @param[in] bufferWeights buffer with model's trained weights.\n",
      "     |      .            *  @returns Net object.\n",
      "    \n",
      "    class dnn_DetectionModel(dnn_Model)\n",
      "     |  Method resolution order:\n",
      "     |      dnn_DetectionModel\n",
      "     |      dnn_Model\n",
      "     |      dnn_Net\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  detect(...)\n",
      "     |      detect(frame[, confThreshold[, nmsThreshold]]) -> classIds, confidences, boxes\n",
      "     |      .   @brief Given the @p input frame, create input blob, run net and return result detections.\n",
      "     |      .             *  @param[in]  frame  The input image.\n",
      "     |      .             *  @param[out] classIds Class indexes in result detection.\n",
      "     |      .             *  @param[out] confidences A set of corresponding confidences.\n",
      "     |      .             *  @param[out] boxes A set of bounding boxes.\n",
      "     |      .             *  @param[in] confThreshold A threshold used to filter boxes by confidences.\n",
      "     |      .             *  @param[in] nmsThreshold A threshold used in non maximum suppression.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from dnn_Model:\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(frame[, outs]) -> outs\n",
      "     |      .   @brief Given the @p input frame, create input blob, run net and return the output @p blobs.\n",
      "     |      .             *  @param[in]  frame  The input image.\n",
      "     |      .             *  @param[out] outs Allocated output blobs, which will store results of the computation.\n",
      "     |  \n",
      "     |  setInputCrop(...)\n",
      "     |      setInputCrop(crop) -> retval\n",
      "     |      .   @brief Set flag crop for frame.\n",
      "     |      .             *  @param[in] crop Flag which indicates whether image will be cropped after resize or not.\n",
      "     |  \n",
      "     |  setInputMean(...)\n",
      "     |      setInputMean(mean) -> retval\n",
      "     |      .   @brief Set mean value for frame.\n",
      "     |      .             *  @param[in] mean Scalar with mean values which are subtracted from channels.\n",
      "     |  \n",
      "     |  setInputParams(...)\n",
      "     |      setInputParams([, scale[, size[, mean[, swapRB[, crop]]]]]) -> None\n",
      "     |      .   @brief Set preprocessing parameters for frame.\n",
      "     |      .            *  @param[in] size New input size.\n",
      "     |      .            *  @param[in] mean Scalar with mean values which are subtracted from channels.\n",
      "     |      .            *  @param[in] scale Multiplier for frame values.\n",
      "     |      .            *  @param[in] swapRB Flag which indicates that swap first and last channels.\n",
      "     |      .            *  @param[in] crop Flag which indicates whether image will be cropped after resize or not.\n",
      "     |      .            *  blob(n, c, y, x) = scale * resize( frame(y, x, c) ) - mean(c) )\n",
      "     |  \n",
      "     |  setInputScale(...)\n",
      "     |      setInputScale(scale) -> retval\n",
      "     |      .   @brief Set scalefactor value for frame.\n",
      "     |      .             *  @param[in] scale Multiplier for frame values.\n",
      "     |  \n",
      "     |  setInputSize(...)\n",
      "     |      setInputSize(size) -> retval\n",
      "     |      .   @brief Set input size for frame.\n",
      "     |      .             *  @param[in] size New input size.\n",
      "     |      .             *  @note If shape of the new blob less than 0, then frame size not change.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setInputSize(width, height) -> retval\n",
      "     |      .   @brief Set input size for frame.\n",
      "     |      .            *  @param[in] width New input width.\n",
      "     |      .            *  @param[in] height New input height.\n",
      "     |      .            *  @note If shape of the new blob less than 0,\n",
      "     |      .            *  then frame size not change.\n",
      "     |  \n",
      "     |  setInputSwapRB(...)\n",
      "     |      setInputSwapRB(swapRB) -> retval\n",
      "     |      .   @brief Set flag swapRB for frame.\n",
      "     |      .             *  @param[in] swapRB Flag which indicates that swap first and last channels.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from dnn_Net:\n",
      "     |  \n",
      "     |  connect(...)\n",
      "     |      connect(outPin, inpPin) -> None\n",
      "     |      .   @brief Connects output of the first layer to input of the second layer.\n",
      "     |      .            *  @param outPin descriptor of the first layer output.\n",
      "     |      .            *  @param inpPin descriptor of the second layer input.\n",
      "     |      .            *\n",
      "     |      .            * Descriptors have the following template <DFN>&lt;layer_name&gt;[.input_number]</DFN>:\n",
      "     |      .            * - the first part of the template <DFN>layer_name</DFN> is string name of the added layer.\n",
      "     |      .            *   If this part is empty then the network input pseudo layer will be used;\n",
      "     |      .            * - the second optional part of the template <DFN>input_number</DFN>\n",
      "     |      .            *   is either number of the layer input, either label one.\n",
      "     |      .            *   If this part is omitted then the first layer input will be used.\n",
      "     |      .            *\n",
      "     |      .            *  @see setNetInputs(), Layer::inputNameToIndex(), Layer::outputNameToIndex()\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      dump() -> retval\n",
      "     |      .   @brief Dump net to String\n",
      "     |      .            *  @returns String with structure, hyperparameters, backend, target and fusion\n",
      "     |      .            *  Call method after setInput(). To see correct backend, target and fusion run after forward().\n",
      "     |  \n",
      "     |  dumpToFile(...)\n",
      "     |      dumpToFile(path) -> None\n",
      "     |      .   @brief Dump net structure, hyperparameters, backend, target and fusion to dot file\n",
      "     |      .            *  @param path   path to output file with .dot extension\n",
      "     |      .            *  @see dump()\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   Returns true if there are no layers in the network.\n",
      "     |  \n",
      "     |  enableFusion(...)\n",
      "     |      enableFusion(fusion) -> None\n",
      "     |      .   @brief Enables or disables layer fusion in the network.\n",
      "     |      .            * @param fusion true to enable the fusion, false to disable. The fusion is enabled by default.\n",
      "     |  \n",
      "     |  forward(...)\n",
      "     |      forward([, outputName]) -> retval\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @return blob for first output of specified layer.\n",
      "     |      .            *  @details By default runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward([, outputBlobs[, outputName]]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputBlobs contains all output blobs for specified layer.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @details If @p outputName is empty, runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward(outBlobNames[, outputBlobs]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .            *  @param outputBlobs contains blobs for first outputs of specified layers.\n",
      "     |      .            *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  forwardAndRetrieve(...)\n",
      "     |      forwardAndRetrieve(outBlobNames) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .            *  @param outputBlobs contains all output blobs for each layer specified in @p outBlobNames.\n",
      "     |      .            *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  forwardAsync(...)\n",
      "     |      forwardAsync([, outputName]) -> retval\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @details By default runs forward pass for the whole network.\n",
      "     |      .            *\n",
      "     |      .            *  This is an asynchronous version of forward(const String&).\n",
      "     |      .            *  dnn::DNN_BACKEND_INFERENCE_ENGINE backend is required.\n",
      "     |  \n",
      "     |  getFLOPS(...)\n",
      "     |      getFLOPS(netInputShapes) -> retval\n",
      "     |      .   @brief Computes FLOP for whole loaded model with specified input shapes.\n",
      "     |      .            * @param netInputShapes vector of shapes for all net inputs.\n",
      "     |      .            * @returns computed FLOP.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShapes) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getLayer(...)\n",
      "     |      getLayer(layerId) -> retval\n",
      "     |      .   @brief Returns pointer to layer with specified id or name which the network use.\n",
      "     |  \n",
      "     |  getLayerId(...)\n",
      "     |      getLayerId(layer) -> retval\n",
      "     |      .   @brief Converts string name of the layer to the integer identifier.\n",
      "     |      .            *  @returns id of the layer, or -1 if the layer wasn't found.\n",
      "     |  \n",
      "     |  getLayerNames(...)\n",
      "     |      getLayerNames() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getLayerTypes(...)\n",
      "     |      getLayerTypes() -> layersTypes\n",
      "     |      .   @brief Returns list of types for layer used in model.\n",
      "     |      .            * @param layersTypes output parameter for returning types.\n",
      "     |  \n",
      "     |  getLayersCount(...)\n",
      "     |      getLayersCount(layerType) -> retval\n",
      "     |      .   @brief Returns count of layers of specified type.\n",
      "     |      .            * @param layerType type.\n",
      "     |      .            * @returns count of layers\n",
      "     |  \n",
      "     |  getLayersShapes(...)\n",
      "     |      getLayersShapes(netInputShapes) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @brief Returns input and output shapes for all layers in loaded model;\n",
      "     |      .            *  preliminary inferencing isn't necessary.\n",
      "     |      .            *  @param netInputShapes shapes for all input blobs in net input layer.\n",
      "     |      .            *  @param layersIds output parameter for layer IDs.\n",
      "     |      .            *  @param inLayersShapes output parameter for input layers shapes;\n",
      "     |      .            * order is the same as in layersIds\n",
      "     |      .            *  @param outLayersShapes output parameter for output layers shapes;\n",
      "     |      .            * order is the same as in layersIds\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getLayersShapes(netInputShape) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getMemoryConsumption(...)\n",
      "     |      getMemoryConsumption(netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShapes) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getParam(...)\n",
      "     |      getParam(layer[, numParam]) -> retval\n",
      "     |      .   @brief Returns parameter blob of the layer.\n",
      "     |      .            *  @param layer name or id of the layer.\n",
      "     |      .            *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .            *  @see Layer::blobs\n",
      "     |  \n",
      "     |  getPerfProfile(...)\n",
      "     |      getPerfProfile() -> retval, timings\n",
      "     |      .   @brief Returns overall time for inference and timings (in ticks) for layers.\n",
      "     |      .            * Indexes in returned vector correspond to layers ids. Some layers can be fused with others,\n",
      "     |      .            * in this case zero ticks count will be return for that skipped layers.\n",
      "     |      .            * @param timings vector for tick timings for all layers.\n",
      "     |      .            * @return overall ticks for model inference.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayers(...)\n",
      "     |      getUnconnectedOutLayers() -> retval\n",
      "     |      .   @brief Returns indexes of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayersNames(...)\n",
      "     |      getUnconnectedOutLayersNames() -> retval\n",
      "     |      .   @brief Returns names of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  setHalideScheduler(...)\n",
      "     |      setHalideScheduler(scheduler) -> None\n",
      "     |      .   * @brief Compile Halide layers.\n",
      "     |      .            * @param[in] scheduler Path to YAML file with scheduling directives.\n",
      "     |      .            * @see setPreferableBackend\n",
      "     |      .            *\n",
      "     |      .            * Schedule layers that support Halide backend. Then compile them for\n",
      "     |      .            * specific target. For layers that not represented in scheduling file\n",
      "     |      .            * or if no manual scheduling used at all, automatic scheduling will be applied.\n",
      "     |  \n",
      "     |  setInput(...)\n",
      "     |      setInput(blob[, name[, scalefactor[, mean]]]) -> None\n",
      "     |      .   @brief Sets the new input value for the network\n",
      "     |      .            *  @param blob        A new blob. Should have CV_32F or CV_8U depth.\n",
      "     |      .            *  @param name        A name of input layer.\n",
      "     |      .            *  @param scalefactor An optional normalization scale.\n",
      "     |      .            *  @param mean        An optional mean subtraction values.\n",
      "     |      .            *  @see connect(String, String) to know format of the descriptor.\n",
      "     |      .            *\n",
      "     |      .            *  If scale or mean values are specified, a final input blob is computed\n",
      "     |      .            *  as:\n",
      "     |      .            * \\f[input(n,c,h,w) = scalefactor \\times (blob(n,c,h,w) - mean_c)\\f]\n",
      "     |  \n",
      "     |  setInputShape(...)\n",
      "     |      setInputShape(inputName, shape) -> None\n",
      "     |      .   @brief Specify shape of network input.\n",
      "     |  \n",
      "     |  setInputsNames(...)\n",
      "     |      setInputsNames(inputBlobNames) -> None\n",
      "     |      .   @brief Sets outputs names of the network input pseudo layer.\n",
      "     |      .            *\n",
      "     |      .            * Each net always has special own the network input pseudo layer with id=0.\n",
      "     |      .            * This layer stores the user blobs only and don't make any computations.\n",
      "     |      .            * In fact, this layer provides the only way to pass user data into the network.\n",
      "     |      .            * As any other layer, this layer can label its outputs and this function provides an easy way to do this.\n",
      "     |  \n",
      "     |  setParam(...)\n",
      "     |      setParam(layer, numParam, blob) -> None\n",
      "     |      .   @brief Sets the new value for the learned param of the layer.\n",
      "     |      .            *  @param layer name or id of the layer.\n",
      "     |      .            *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .            *  @param blob the new value.\n",
      "     |      .            *  @see Layer::blobs\n",
      "     |      .            *  @note If shape of the new blob differs from the previous shape,\n",
      "     |      .            *  then the following forward pass may fail.\n",
      "     |  \n",
      "     |  setPreferableBackend(...)\n",
      "     |      setPreferableBackend(backendId) -> None\n",
      "     |      .   * @brief Ask network to use specific computation backend where it supported.\n",
      "     |      .            * @param[in] backendId backend identifier.\n",
      "     |      .            * @see Backend\n",
      "     |      .            *\n",
      "     |      .            * If OpenCV is compiled with Intel's Inference Engine library, DNN_BACKEND_DEFAULT\n",
      "     |      .            * means DNN_BACKEND_INFERENCE_ENGINE. Otherwise it equals to DNN_BACKEND_OPENCV.\n",
      "     |  \n",
      "     |  setPreferableTarget(...)\n",
      "     |      setPreferableTarget(targetId) -> None\n",
      "     |      .   * @brief Ask network to make computations on specific target device.\n",
      "     |      .            * @param[in] targetId target identifier.\n",
      "     |      .            * @see Target\n",
      "     |      .            *\n",
      "     |      .            * List of supported combinations backend / target:\n",
      "     |      .            * |                        | DNN_BACKEND_OPENCV | DNN_BACKEND_INFERENCE_ENGINE | DNN_BACKEND_HALIDE |  DNN_BACKEND_CUDA |\n",
      "     |      .            * |------------------------|--------------------|------------------------------|--------------------|-------------------|\n",
      "     |      .            * | DNN_TARGET_CPU         |                  + |                            + |                  + |                   |\n",
      "     |      .            * | DNN_TARGET_OPENCL      |                  + |                            + |                  + |                   |\n",
      "     |      .            * | DNN_TARGET_OPENCL_FP16 |                  + |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_MYRIAD      |                    |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_FPGA        |                    |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_CUDA        |                    |                              |                    |                 + |\n",
      "     |      .            * | DNN_TARGET_CUDA_FP16   |                    |                              |                    |                 + |\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from dnn_Net:\n",
      "     |  \n",
      "     |  readFromModelOptimizer(...)\n",
      "     |      readFromModelOptimizer(xml, bin) -> retval\n",
      "     |      .   @brief Create a network from Intel's Model Optimizer intermediate representation (IR).\n",
      "     |      .            *  @param[in] xml XML configuration file with network's topology.\n",
      "     |      .            *  @param[in] bin Binary file with trained weights.\n",
      "     |      .            *  Networks imported from Intel's Model Optimizer are launched in Intel's Inference Engine\n",
      "     |      .            *  backend.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      readFromModelOptimizer(bufferModelConfig, bufferWeights) -> retval\n",
      "     |      .   @brief Create a network from Intel's Model Optimizer in-memory buffers with intermediate representation (IR).\n",
      "     |      .            *  @param[in] bufferModelConfig buffer with model's configuration.\n",
      "     |      .            *  @param[in] bufferWeights buffer with model's trained weights.\n",
      "     |      .            *  @returns Net object.\n",
      "    \n",
      "    class dnn_DictValue(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getIntValue(...)\n",
      "     |      getIntValue([, idx]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getRealValue(...)\n",
      "     |      getRealValue([, idx]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getStringValue(...)\n",
      "     |      getStringValue([, idx]) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isInt(...)\n",
      "     |      isInt() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isReal(...)\n",
      "     |      isReal() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isString(...)\n",
      "     |      isString() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class dnn_KeypointsModel(dnn_Model)\n",
      "     |  Method resolution order:\n",
      "     |      dnn_KeypointsModel\n",
      "     |      dnn_Model\n",
      "     |      dnn_Net\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  estimate(...)\n",
      "     |      estimate(frame[, thresh]) -> retval\n",
      "     |      .   @brief Given the @p input frame, create input blob, run net\n",
      "     |      .             *  @param[in]  frame  The input image.\n",
      "     |      .             *  @param thresh minimum confidence threshold to select a keypoint\n",
      "     |      .             *  @returns a vector holding the x and y coordinates of each detected keypoint\n",
      "     |      .             *\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from dnn_Model:\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(frame[, outs]) -> outs\n",
      "     |      .   @brief Given the @p input frame, create input blob, run net and return the output @p blobs.\n",
      "     |      .             *  @param[in]  frame  The input image.\n",
      "     |      .             *  @param[out] outs Allocated output blobs, which will store results of the computation.\n",
      "     |  \n",
      "     |  setInputCrop(...)\n",
      "     |      setInputCrop(crop) -> retval\n",
      "     |      .   @brief Set flag crop for frame.\n",
      "     |      .             *  @param[in] crop Flag which indicates whether image will be cropped after resize or not.\n",
      "     |  \n",
      "     |  setInputMean(...)\n",
      "     |      setInputMean(mean) -> retval\n",
      "     |      .   @brief Set mean value for frame.\n",
      "     |      .             *  @param[in] mean Scalar with mean values which are subtracted from channels.\n",
      "     |  \n",
      "     |  setInputParams(...)\n",
      "     |      setInputParams([, scale[, size[, mean[, swapRB[, crop]]]]]) -> None\n",
      "     |      .   @brief Set preprocessing parameters for frame.\n",
      "     |      .            *  @param[in] size New input size.\n",
      "     |      .            *  @param[in] mean Scalar with mean values which are subtracted from channels.\n",
      "     |      .            *  @param[in] scale Multiplier for frame values.\n",
      "     |      .            *  @param[in] swapRB Flag which indicates that swap first and last channels.\n",
      "     |      .            *  @param[in] crop Flag which indicates whether image will be cropped after resize or not.\n",
      "     |      .            *  blob(n, c, y, x) = scale * resize( frame(y, x, c) ) - mean(c) )\n",
      "     |  \n",
      "     |  setInputScale(...)\n",
      "     |      setInputScale(scale) -> retval\n",
      "     |      .   @brief Set scalefactor value for frame.\n",
      "     |      .             *  @param[in] scale Multiplier for frame values.\n",
      "     |  \n",
      "     |  setInputSize(...)\n",
      "     |      setInputSize(size) -> retval\n",
      "     |      .   @brief Set input size for frame.\n",
      "     |      .             *  @param[in] size New input size.\n",
      "     |      .             *  @note If shape of the new blob less than 0, then frame size not change.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setInputSize(width, height) -> retval\n",
      "     |      .   @brief Set input size for frame.\n",
      "     |      .            *  @param[in] width New input width.\n",
      "     |      .            *  @param[in] height New input height.\n",
      "     |      .            *  @note If shape of the new blob less than 0,\n",
      "     |      .            *  then frame size not change.\n",
      "     |  \n",
      "     |  setInputSwapRB(...)\n",
      "     |      setInputSwapRB(swapRB) -> retval\n",
      "     |      .   @brief Set flag swapRB for frame.\n",
      "     |      .             *  @param[in] swapRB Flag which indicates that swap first and last channels.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from dnn_Net:\n",
      "     |  \n",
      "     |  connect(...)\n",
      "     |      connect(outPin, inpPin) -> None\n",
      "     |      .   @brief Connects output of the first layer to input of the second layer.\n",
      "     |      .            *  @param outPin descriptor of the first layer output.\n",
      "     |      .            *  @param inpPin descriptor of the second layer input.\n",
      "     |      .            *\n",
      "     |      .            * Descriptors have the following template <DFN>&lt;layer_name&gt;[.input_number]</DFN>:\n",
      "     |      .            * - the first part of the template <DFN>layer_name</DFN> is string name of the added layer.\n",
      "     |      .            *   If this part is empty then the network input pseudo layer will be used;\n",
      "     |      .            * - the second optional part of the template <DFN>input_number</DFN>\n",
      "     |      .            *   is either number of the layer input, either label one.\n",
      "     |      .            *   If this part is omitted then the first layer input will be used.\n",
      "     |      .            *\n",
      "     |      .            *  @see setNetInputs(), Layer::inputNameToIndex(), Layer::outputNameToIndex()\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      dump() -> retval\n",
      "     |      .   @brief Dump net to String\n",
      "     |      .            *  @returns String with structure, hyperparameters, backend, target and fusion\n",
      "     |      .            *  Call method after setInput(). To see correct backend, target and fusion run after forward().\n",
      "     |  \n",
      "     |  dumpToFile(...)\n",
      "     |      dumpToFile(path) -> None\n",
      "     |      .   @brief Dump net structure, hyperparameters, backend, target and fusion to dot file\n",
      "     |      .            *  @param path   path to output file with .dot extension\n",
      "     |      .            *  @see dump()\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   Returns true if there are no layers in the network.\n",
      "     |  \n",
      "     |  enableFusion(...)\n",
      "     |      enableFusion(fusion) -> None\n",
      "     |      .   @brief Enables or disables layer fusion in the network.\n",
      "     |      .            * @param fusion true to enable the fusion, false to disable. The fusion is enabled by default.\n",
      "     |  \n",
      "     |  forward(...)\n",
      "     |      forward([, outputName]) -> retval\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @return blob for first output of specified layer.\n",
      "     |      .            *  @details By default runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward([, outputBlobs[, outputName]]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputBlobs contains all output blobs for specified layer.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @details If @p outputName is empty, runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward(outBlobNames[, outputBlobs]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .            *  @param outputBlobs contains blobs for first outputs of specified layers.\n",
      "     |      .            *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  forwardAndRetrieve(...)\n",
      "     |      forwardAndRetrieve(outBlobNames) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .            *  @param outputBlobs contains all output blobs for each layer specified in @p outBlobNames.\n",
      "     |      .            *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  forwardAsync(...)\n",
      "     |      forwardAsync([, outputName]) -> retval\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @details By default runs forward pass for the whole network.\n",
      "     |      .            *\n",
      "     |      .            *  This is an asynchronous version of forward(const String&).\n",
      "     |      .            *  dnn::DNN_BACKEND_INFERENCE_ENGINE backend is required.\n",
      "     |  \n",
      "     |  getFLOPS(...)\n",
      "     |      getFLOPS(netInputShapes) -> retval\n",
      "     |      .   @brief Computes FLOP for whole loaded model with specified input shapes.\n",
      "     |      .            * @param netInputShapes vector of shapes for all net inputs.\n",
      "     |      .            * @returns computed FLOP.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShapes) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getLayer(...)\n",
      "     |      getLayer(layerId) -> retval\n",
      "     |      .   @brief Returns pointer to layer with specified id or name which the network use.\n",
      "     |  \n",
      "     |  getLayerId(...)\n",
      "     |      getLayerId(layer) -> retval\n",
      "     |      .   @brief Converts string name of the layer to the integer identifier.\n",
      "     |      .            *  @returns id of the layer, or -1 if the layer wasn't found.\n",
      "     |  \n",
      "     |  getLayerNames(...)\n",
      "     |      getLayerNames() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getLayerTypes(...)\n",
      "     |      getLayerTypes() -> layersTypes\n",
      "     |      .   @brief Returns list of types for layer used in model.\n",
      "     |      .            * @param layersTypes output parameter for returning types.\n",
      "     |  \n",
      "     |  getLayersCount(...)\n",
      "     |      getLayersCount(layerType) -> retval\n",
      "     |      .   @brief Returns count of layers of specified type.\n",
      "     |      .            * @param layerType type.\n",
      "     |      .            * @returns count of layers\n",
      "     |  \n",
      "     |  getLayersShapes(...)\n",
      "     |      getLayersShapes(netInputShapes) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @brief Returns input and output shapes for all layers in loaded model;\n",
      "     |      .            *  preliminary inferencing isn't necessary.\n",
      "     |      .            *  @param netInputShapes shapes for all input blobs in net input layer.\n",
      "     |      .            *  @param layersIds output parameter for layer IDs.\n",
      "     |      .            *  @param inLayersShapes output parameter for input layers shapes;\n",
      "     |      .            * order is the same as in layersIds\n",
      "     |      .            *  @param outLayersShapes output parameter for output layers shapes;\n",
      "     |      .            * order is the same as in layersIds\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getLayersShapes(netInputShape) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getMemoryConsumption(...)\n",
      "     |      getMemoryConsumption(netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShapes) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getParam(...)\n",
      "     |      getParam(layer[, numParam]) -> retval\n",
      "     |      .   @brief Returns parameter blob of the layer.\n",
      "     |      .            *  @param layer name or id of the layer.\n",
      "     |      .            *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .            *  @see Layer::blobs\n",
      "     |  \n",
      "     |  getPerfProfile(...)\n",
      "     |      getPerfProfile() -> retval, timings\n",
      "     |      .   @brief Returns overall time for inference and timings (in ticks) for layers.\n",
      "     |      .            * Indexes in returned vector correspond to layers ids. Some layers can be fused with others,\n",
      "     |      .            * in this case zero ticks count will be return for that skipped layers.\n",
      "     |      .            * @param timings vector for tick timings for all layers.\n",
      "     |      .            * @return overall ticks for model inference.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayers(...)\n",
      "     |      getUnconnectedOutLayers() -> retval\n",
      "     |      .   @brief Returns indexes of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayersNames(...)\n",
      "     |      getUnconnectedOutLayersNames() -> retval\n",
      "     |      .   @brief Returns names of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  setHalideScheduler(...)\n",
      "     |      setHalideScheduler(scheduler) -> None\n",
      "     |      .   * @brief Compile Halide layers.\n",
      "     |      .            * @param[in] scheduler Path to YAML file with scheduling directives.\n",
      "     |      .            * @see setPreferableBackend\n",
      "     |      .            *\n",
      "     |      .            * Schedule layers that support Halide backend. Then compile them for\n",
      "     |      .            * specific target. For layers that not represented in scheduling file\n",
      "     |      .            * or if no manual scheduling used at all, automatic scheduling will be applied.\n",
      "     |  \n",
      "     |  setInput(...)\n",
      "     |      setInput(blob[, name[, scalefactor[, mean]]]) -> None\n",
      "     |      .   @brief Sets the new input value for the network\n",
      "     |      .            *  @param blob        A new blob. Should have CV_32F or CV_8U depth.\n",
      "     |      .            *  @param name        A name of input layer.\n",
      "     |      .            *  @param scalefactor An optional normalization scale.\n",
      "     |      .            *  @param mean        An optional mean subtraction values.\n",
      "     |      .            *  @see connect(String, String) to know format of the descriptor.\n",
      "     |      .            *\n",
      "     |      .            *  If scale or mean values are specified, a final input blob is computed\n",
      "     |      .            *  as:\n",
      "     |      .            * \\f[input(n,c,h,w) = scalefactor \\times (blob(n,c,h,w) - mean_c)\\f]\n",
      "     |  \n",
      "     |  setInputShape(...)\n",
      "     |      setInputShape(inputName, shape) -> None\n",
      "     |      .   @brief Specify shape of network input.\n",
      "     |  \n",
      "     |  setInputsNames(...)\n",
      "     |      setInputsNames(inputBlobNames) -> None\n",
      "     |      .   @brief Sets outputs names of the network input pseudo layer.\n",
      "     |      .            *\n",
      "     |      .            * Each net always has special own the network input pseudo layer with id=0.\n",
      "     |      .            * This layer stores the user blobs only and don't make any computations.\n",
      "     |      .            * In fact, this layer provides the only way to pass user data into the network.\n",
      "     |      .            * As any other layer, this layer can label its outputs and this function provides an easy way to do this.\n",
      "     |  \n",
      "     |  setParam(...)\n",
      "     |      setParam(layer, numParam, blob) -> None\n",
      "     |      .   @brief Sets the new value for the learned param of the layer.\n",
      "     |      .            *  @param layer name or id of the layer.\n",
      "     |      .            *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .            *  @param blob the new value.\n",
      "     |      .            *  @see Layer::blobs\n",
      "     |      .            *  @note If shape of the new blob differs from the previous shape,\n",
      "     |      .            *  then the following forward pass may fail.\n",
      "     |  \n",
      "     |  setPreferableBackend(...)\n",
      "     |      setPreferableBackend(backendId) -> None\n",
      "     |      .   * @brief Ask network to use specific computation backend where it supported.\n",
      "     |      .            * @param[in] backendId backend identifier.\n",
      "     |      .            * @see Backend\n",
      "     |      .            *\n",
      "     |      .            * If OpenCV is compiled with Intel's Inference Engine library, DNN_BACKEND_DEFAULT\n",
      "     |      .            * means DNN_BACKEND_INFERENCE_ENGINE. Otherwise it equals to DNN_BACKEND_OPENCV.\n",
      "     |  \n",
      "     |  setPreferableTarget(...)\n",
      "     |      setPreferableTarget(targetId) -> None\n",
      "     |      .   * @brief Ask network to make computations on specific target device.\n",
      "     |      .            * @param[in] targetId target identifier.\n",
      "     |      .            * @see Target\n",
      "     |      .            *\n",
      "     |      .            * List of supported combinations backend / target:\n",
      "     |      .            * |                        | DNN_BACKEND_OPENCV | DNN_BACKEND_INFERENCE_ENGINE | DNN_BACKEND_HALIDE |  DNN_BACKEND_CUDA |\n",
      "     |      .            * |------------------------|--------------------|------------------------------|--------------------|-------------------|\n",
      "     |      .            * | DNN_TARGET_CPU         |                  + |                            + |                  + |                   |\n",
      "     |      .            * | DNN_TARGET_OPENCL      |                  + |                            + |                  + |                   |\n",
      "     |      .            * | DNN_TARGET_OPENCL_FP16 |                  + |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_MYRIAD      |                    |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_FPGA        |                    |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_CUDA        |                    |                              |                    |                 + |\n",
      "     |      .            * | DNN_TARGET_CUDA_FP16   |                    |                              |                    |                 + |\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from dnn_Net:\n",
      "     |  \n",
      "     |  readFromModelOptimizer(...)\n",
      "     |      readFromModelOptimizer(xml, bin) -> retval\n",
      "     |      .   @brief Create a network from Intel's Model Optimizer intermediate representation (IR).\n",
      "     |      .            *  @param[in] xml XML configuration file with network's topology.\n",
      "     |      .            *  @param[in] bin Binary file with trained weights.\n",
      "     |      .            *  Networks imported from Intel's Model Optimizer are launched in Intel's Inference Engine\n",
      "     |      .            *  backend.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      readFromModelOptimizer(bufferModelConfig, bufferWeights) -> retval\n",
      "     |      .   @brief Create a network from Intel's Model Optimizer in-memory buffers with intermediate representation (IR).\n",
      "     |      .            *  @param[in] bufferModelConfig buffer with model's configuration.\n",
      "     |      .            *  @param[in] bufferWeights buffer with model's trained weights.\n",
      "     |      .            *  @returns Net object.\n",
      "    \n",
      "    class dnn_Layer(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      dnn_Layer\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  finalize(...)\n",
      "     |      finalize(inputs[, outputs]) -> outputs\n",
      "     |      .   @brief Computes and sets internal parameters according to inputs, outputs and blobs.\n",
      "     |      .            *  @param[in]  inputs  vector of already allocated input blobs\n",
      "     |      .            *  @param[out] outputs vector of already allocated output blobs\n",
      "     |      .            *\n",
      "     |      .            * If this method is called after network has allocated all memory for input and output blobs\n",
      "     |      .            * and before inferencing.\n",
      "     |  \n",
      "     |  outputNameToIndex(...)\n",
      "     |      outputNameToIndex(outputName) -> retval\n",
      "     |      .   @brief Returns index of output blob in output array.\n",
      "     |      .            *  @see inputNameToIndex()\n",
      "     |  \n",
      "     |  run(...)\n",
      "     |      run(inputs, internals[, outputs]) -> outputs, internals\n",
      "     |      .   @brief Allocates layer and computes output.\n",
      "     |      .            *  @deprecated This method will be removed in the future release.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  blobs\n",
      "     |      blobs\n",
      "     |  \n",
      "     |  name\n",
      "     |      name\n",
      "     |  \n",
      "     |  preferableTarget\n",
      "     |      preferableTarget\n",
      "     |  \n",
      "     |  type\n",
      "     |      type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   @brief Returns true if the Algorithm is empty (e.g. in the very beginning or after unsuccessful read\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class dnn_Model(dnn_Net)\n",
      "     |  Method resolution order:\n",
      "     |      dnn_Model\n",
      "     |      dnn_Net\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(frame[, outs]) -> outs\n",
      "     |      .   @brief Given the @p input frame, create input blob, run net and return the output @p blobs.\n",
      "     |      .             *  @param[in]  frame  The input image.\n",
      "     |      .             *  @param[out] outs Allocated output blobs, which will store results of the computation.\n",
      "     |  \n",
      "     |  setInputCrop(...)\n",
      "     |      setInputCrop(crop) -> retval\n",
      "     |      .   @brief Set flag crop for frame.\n",
      "     |      .             *  @param[in] crop Flag which indicates whether image will be cropped after resize or not.\n",
      "     |  \n",
      "     |  setInputMean(...)\n",
      "     |      setInputMean(mean) -> retval\n",
      "     |      .   @brief Set mean value for frame.\n",
      "     |      .             *  @param[in] mean Scalar with mean values which are subtracted from channels.\n",
      "     |  \n",
      "     |  setInputParams(...)\n",
      "     |      setInputParams([, scale[, size[, mean[, swapRB[, crop]]]]]) -> None\n",
      "     |      .   @brief Set preprocessing parameters for frame.\n",
      "     |      .            *  @param[in] size New input size.\n",
      "     |      .            *  @param[in] mean Scalar with mean values which are subtracted from channels.\n",
      "     |      .            *  @param[in] scale Multiplier for frame values.\n",
      "     |      .            *  @param[in] swapRB Flag which indicates that swap first and last channels.\n",
      "     |      .            *  @param[in] crop Flag which indicates whether image will be cropped after resize or not.\n",
      "     |      .            *  blob(n, c, y, x) = scale * resize( frame(y, x, c) ) - mean(c) )\n",
      "     |  \n",
      "     |  setInputScale(...)\n",
      "     |      setInputScale(scale) -> retval\n",
      "     |      .   @brief Set scalefactor value for frame.\n",
      "     |      .             *  @param[in] scale Multiplier for frame values.\n",
      "     |  \n",
      "     |  setInputSize(...)\n",
      "     |      setInputSize(size) -> retval\n",
      "     |      .   @brief Set input size for frame.\n",
      "     |      .             *  @param[in] size New input size.\n",
      "     |      .             *  @note If shape of the new blob less than 0, then frame size not change.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setInputSize(width, height) -> retval\n",
      "     |      .   @brief Set input size for frame.\n",
      "     |      .            *  @param[in] width New input width.\n",
      "     |      .            *  @param[in] height New input height.\n",
      "     |      .            *  @note If shape of the new blob less than 0,\n",
      "     |      .            *  then frame size not change.\n",
      "     |  \n",
      "     |  setInputSwapRB(...)\n",
      "     |      setInputSwapRB(swapRB) -> retval\n",
      "     |      .   @brief Set flag swapRB for frame.\n",
      "     |      .             *  @param[in] swapRB Flag which indicates that swap first and last channels.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from dnn_Net:\n",
      "     |  \n",
      "     |  connect(...)\n",
      "     |      connect(outPin, inpPin) -> None\n",
      "     |      .   @brief Connects output of the first layer to input of the second layer.\n",
      "     |      .            *  @param outPin descriptor of the first layer output.\n",
      "     |      .            *  @param inpPin descriptor of the second layer input.\n",
      "     |      .            *\n",
      "     |      .            * Descriptors have the following template <DFN>&lt;layer_name&gt;[.input_number]</DFN>:\n",
      "     |      .            * - the first part of the template <DFN>layer_name</DFN> is string name of the added layer.\n",
      "     |      .            *   If this part is empty then the network input pseudo layer will be used;\n",
      "     |      .            * - the second optional part of the template <DFN>input_number</DFN>\n",
      "     |      .            *   is either number of the layer input, either label one.\n",
      "     |      .            *   If this part is omitted then the first layer input will be used.\n",
      "     |      .            *\n",
      "     |      .            *  @see setNetInputs(), Layer::inputNameToIndex(), Layer::outputNameToIndex()\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      dump() -> retval\n",
      "     |      .   @brief Dump net to String\n",
      "     |      .            *  @returns String with structure, hyperparameters, backend, target and fusion\n",
      "     |      .            *  Call method after setInput(). To see correct backend, target and fusion run after forward().\n",
      "     |  \n",
      "     |  dumpToFile(...)\n",
      "     |      dumpToFile(path) -> None\n",
      "     |      .   @brief Dump net structure, hyperparameters, backend, target and fusion to dot file\n",
      "     |      .            *  @param path   path to output file with .dot extension\n",
      "     |      .            *  @see dump()\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   Returns true if there are no layers in the network.\n",
      "     |  \n",
      "     |  enableFusion(...)\n",
      "     |      enableFusion(fusion) -> None\n",
      "     |      .   @brief Enables or disables layer fusion in the network.\n",
      "     |      .            * @param fusion true to enable the fusion, false to disable. The fusion is enabled by default.\n",
      "     |  \n",
      "     |  forward(...)\n",
      "     |      forward([, outputName]) -> retval\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @return blob for first output of specified layer.\n",
      "     |      .            *  @details By default runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward([, outputBlobs[, outputName]]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputBlobs contains all output blobs for specified layer.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @details If @p outputName is empty, runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward(outBlobNames[, outputBlobs]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .            *  @param outputBlobs contains blobs for first outputs of specified layers.\n",
      "     |      .            *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  forwardAndRetrieve(...)\n",
      "     |      forwardAndRetrieve(outBlobNames) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .            *  @param outputBlobs contains all output blobs for each layer specified in @p outBlobNames.\n",
      "     |      .            *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  forwardAsync(...)\n",
      "     |      forwardAsync([, outputName]) -> retval\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @details By default runs forward pass for the whole network.\n",
      "     |      .            *\n",
      "     |      .            *  This is an asynchronous version of forward(const String&).\n",
      "     |      .            *  dnn::DNN_BACKEND_INFERENCE_ENGINE backend is required.\n",
      "     |  \n",
      "     |  getFLOPS(...)\n",
      "     |      getFLOPS(netInputShapes) -> retval\n",
      "     |      .   @brief Computes FLOP for whole loaded model with specified input shapes.\n",
      "     |      .            * @param netInputShapes vector of shapes for all net inputs.\n",
      "     |      .            * @returns computed FLOP.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShapes) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getLayer(...)\n",
      "     |      getLayer(layerId) -> retval\n",
      "     |      .   @brief Returns pointer to layer with specified id or name which the network use.\n",
      "     |  \n",
      "     |  getLayerId(...)\n",
      "     |      getLayerId(layer) -> retval\n",
      "     |      .   @brief Converts string name of the layer to the integer identifier.\n",
      "     |      .            *  @returns id of the layer, or -1 if the layer wasn't found.\n",
      "     |  \n",
      "     |  getLayerNames(...)\n",
      "     |      getLayerNames() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getLayerTypes(...)\n",
      "     |      getLayerTypes() -> layersTypes\n",
      "     |      .   @brief Returns list of types for layer used in model.\n",
      "     |      .            * @param layersTypes output parameter for returning types.\n",
      "     |  \n",
      "     |  getLayersCount(...)\n",
      "     |      getLayersCount(layerType) -> retval\n",
      "     |      .   @brief Returns count of layers of specified type.\n",
      "     |      .            * @param layerType type.\n",
      "     |      .            * @returns count of layers\n",
      "     |  \n",
      "     |  getLayersShapes(...)\n",
      "     |      getLayersShapes(netInputShapes) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @brief Returns input and output shapes for all layers in loaded model;\n",
      "     |      .            *  preliminary inferencing isn't necessary.\n",
      "     |      .            *  @param netInputShapes shapes for all input blobs in net input layer.\n",
      "     |      .            *  @param layersIds output parameter for layer IDs.\n",
      "     |      .            *  @param inLayersShapes output parameter for input layers shapes;\n",
      "     |      .            * order is the same as in layersIds\n",
      "     |      .            *  @param outLayersShapes output parameter for output layers shapes;\n",
      "     |      .            * order is the same as in layersIds\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getLayersShapes(netInputShape) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getMemoryConsumption(...)\n",
      "     |      getMemoryConsumption(netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShapes) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getParam(...)\n",
      "     |      getParam(layer[, numParam]) -> retval\n",
      "     |      .   @brief Returns parameter blob of the layer.\n",
      "     |      .            *  @param layer name or id of the layer.\n",
      "     |      .            *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .            *  @see Layer::blobs\n",
      "     |  \n",
      "     |  getPerfProfile(...)\n",
      "     |      getPerfProfile() -> retval, timings\n",
      "     |      .   @brief Returns overall time for inference and timings (in ticks) for layers.\n",
      "     |      .            * Indexes in returned vector correspond to layers ids. Some layers can be fused with others,\n",
      "     |      .            * in this case zero ticks count will be return for that skipped layers.\n",
      "     |      .            * @param timings vector for tick timings for all layers.\n",
      "     |      .            * @return overall ticks for model inference.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayers(...)\n",
      "     |      getUnconnectedOutLayers() -> retval\n",
      "     |      .   @brief Returns indexes of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayersNames(...)\n",
      "     |      getUnconnectedOutLayersNames() -> retval\n",
      "     |      .   @brief Returns names of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  setHalideScheduler(...)\n",
      "     |      setHalideScheduler(scheduler) -> None\n",
      "     |      .   * @brief Compile Halide layers.\n",
      "     |      .            * @param[in] scheduler Path to YAML file with scheduling directives.\n",
      "     |      .            * @see setPreferableBackend\n",
      "     |      .            *\n",
      "     |      .            * Schedule layers that support Halide backend. Then compile them for\n",
      "     |      .            * specific target. For layers that not represented in scheduling file\n",
      "     |      .            * or if no manual scheduling used at all, automatic scheduling will be applied.\n",
      "     |  \n",
      "     |  setInput(...)\n",
      "     |      setInput(blob[, name[, scalefactor[, mean]]]) -> None\n",
      "     |      .   @brief Sets the new input value for the network\n",
      "     |      .            *  @param blob        A new blob. Should have CV_32F or CV_8U depth.\n",
      "     |      .            *  @param name        A name of input layer.\n",
      "     |      .            *  @param scalefactor An optional normalization scale.\n",
      "     |      .            *  @param mean        An optional mean subtraction values.\n",
      "     |      .            *  @see connect(String, String) to know format of the descriptor.\n",
      "     |      .            *\n",
      "     |      .            *  If scale or mean values are specified, a final input blob is computed\n",
      "     |      .            *  as:\n",
      "     |      .            * \\f[input(n,c,h,w) = scalefactor \\times (blob(n,c,h,w) - mean_c)\\f]\n",
      "     |  \n",
      "     |  setInputShape(...)\n",
      "     |      setInputShape(inputName, shape) -> None\n",
      "     |      .   @brief Specify shape of network input.\n",
      "     |  \n",
      "     |  setInputsNames(...)\n",
      "     |      setInputsNames(inputBlobNames) -> None\n",
      "     |      .   @brief Sets outputs names of the network input pseudo layer.\n",
      "     |      .            *\n",
      "     |      .            * Each net always has special own the network input pseudo layer with id=0.\n",
      "     |      .            * This layer stores the user blobs only and don't make any computations.\n",
      "     |      .            * In fact, this layer provides the only way to pass user data into the network.\n",
      "     |      .            * As any other layer, this layer can label its outputs and this function provides an easy way to do this.\n",
      "     |  \n",
      "     |  setParam(...)\n",
      "     |      setParam(layer, numParam, blob) -> None\n",
      "     |      .   @brief Sets the new value for the learned param of the layer.\n",
      "     |      .            *  @param layer name or id of the layer.\n",
      "     |      .            *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .            *  @param blob the new value.\n",
      "     |      .            *  @see Layer::blobs\n",
      "     |      .            *  @note If shape of the new blob differs from the previous shape,\n",
      "     |      .            *  then the following forward pass may fail.\n",
      "     |  \n",
      "     |  setPreferableBackend(...)\n",
      "     |      setPreferableBackend(backendId) -> None\n",
      "     |      .   * @brief Ask network to use specific computation backend where it supported.\n",
      "     |      .            * @param[in] backendId backend identifier.\n",
      "     |      .            * @see Backend\n",
      "     |      .            *\n",
      "     |      .            * If OpenCV is compiled with Intel's Inference Engine library, DNN_BACKEND_DEFAULT\n",
      "     |      .            * means DNN_BACKEND_INFERENCE_ENGINE. Otherwise it equals to DNN_BACKEND_OPENCV.\n",
      "     |  \n",
      "     |  setPreferableTarget(...)\n",
      "     |      setPreferableTarget(targetId) -> None\n",
      "     |      .   * @brief Ask network to make computations on specific target device.\n",
      "     |      .            * @param[in] targetId target identifier.\n",
      "     |      .            * @see Target\n",
      "     |      .            *\n",
      "     |      .            * List of supported combinations backend / target:\n",
      "     |      .            * |                        | DNN_BACKEND_OPENCV | DNN_BACKEND_INFERENCE_ENGINE | DNN_BACKEND_HALIDE |  DNN_BACKEND_CUDA |\n",
      "     |      .            * |------------------------|--------------------|------------------------------|--------------------|-------------------|\n",
      "     |      .            * | DNN_TARGET_CPU         |                  + |                            + |                  + |                   |\n",
      "     |      .            * | DNN_TARGET_OPENCL      |                  + |                            + |                  + |                   |\n",
      "     |      .            * | DNN_TARGET_OPENCL_FP16 |                  + |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_MYRIAD      |                    |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_FPGA        |                    |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_CUDA        |                    |                              |                    |                 + |\n",
      "     |      .            * | DNN_TARGET_CUDA_FP16   |                    |                              |                    |                 + |\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from dnn_Net:\n",
      "     |  \n",
      "     |  readFromModelOptimizer(...)\n",
      "     |      readFromModelOptimizer(xml, bin) -> retval\n",
      "     |      .   @brief Create a network from Intel's Model Optimizer intermediate representation (IR).\n",
      "     |      .            *  @param[in] xml XML configuration file with network's topology.\n",
      "     |      .            *  @param[in] bin Binary file with trained weights.\n",
      "     |      .            *  Networks imported from Intel's Model Optimizer are launched in Intel's Inference Engine\n",
      "     |      .            *  backend.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      readFromModelOptimizer(bufferModelConfig, bufferWeights) -> retval\n",
      "     |      .   @brief Create a network from Intel's Model Optimizer in-memory buffers with intermediate representation (IR).\n",
      "     |      .            *  @param[in] bufferModelConfig buffer with model's configuration.\n",
      "     |      .            *  @param[in] bufferWeights buffer with model's trained weights.\n",
      "     |      .            *  @returns Net object.\n",
      "    \n",
      "    class dnn_Net(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  connect(...)\n",
      "     |      connect(outPin, inpPin) -> None\n",
      "     |      .   @brief Connects output of the first layer to input of the second layer.\n",
      "     |      .            *  @param outPin descriptor of the first layer output.\n",
      "     |      .            *  @param inpPin descriptor of the second layer input.\n",
      "     |      .            *\n",
      "     |      .            * Descriptors have the following template <DFN>&lt;layer_name&gt;[.input_number]</DFN>:\n",
      "     |      .            * - the first part of the template <DFN>layer_name</DFN> is string name of the added layer.\n",
      "     |      .            *   If this part is empty then the network input pseudo layer will be used;\n",
      "     |      .            * - the second optional part of the template <DFN>input_number</DFN>\n",
      "     |      .            *   is either number of the layer input, either label one.\n",
      "     |      .            *   If this part is omitted then the first layer input will be used.\n",
      "     |      .            *\n",
      "     |      .            *  @see setNetInputs(), Layer::inputNameToIndex(), Layer::outputNameToIndex()\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      dump() -> retval\n",
      "     |      .   @brief Dump net to String\n",
      "     |      .            *  @returns String with structure, hyperparameters, backend, target and fusion\n",
      "     |      .            *  Call method after setInput(). To see correct backend, target and fusion run after forward().\n",
      "     |  \n",
      "     |  dumpToFile(...)\n",
      "     |      dumpToFile(path) -> None\n",
      "     |      .   @brief Dump net structure, hyperparameters, backend, target and fusion to dot file\n",
      "     |      .            *  @param path   path to output file with .dot extension\n",
      "     |      .            *  @see dump()\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   Returns true if there are no layers in the network.\n",
      "     |  \n",
      "     |  enableFusion(...)\n",
      "     |      enableFusion(fusion) -> None\n",
      "     |      .   @brief Enables or disables layer fusion in the network.\n",
      "     |      .            * @param fusion true to enable the fusion, false to disable. The fusion is enabled by default.\n",
      "     |  \n",
      "     |  forward(...)\n",
      "     |      forward([, outputName]) -> retval\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @return blob for first output of specified layer.\n",
      "     |      .            *  @details By default runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward([, outputBlobs[, outputName]]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputBlobs contains all output blobs for specified layer.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @details If @p outputName is empty, runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward(outBlobNames[, outputBlobs]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .            *  @param outputBlobs contains blobs for first outputs of specified layers.\n",
      "     |      .            *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  forwardAndRetrieve(...)\n",
      "     |      forwardAndRetrieve(outBlobNames) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .            *  @param outputBlobs contains all output blobs for each layer specified in @p outBlobNames.\n",
      "     |      .            *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  forwardAsync(...)\n",
      "     |      forwardAsync([, outputName]) -> retval\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @details By default runs forward pass for the whole network.\n",
      "     |      .            *\n",
      "     |      .            *  This is an asynchronous version of forward(const String&).\n",
      "     |      .            *  dnn::DNN_BACKEND_INFERENCE_ENGINE backend is required.\n",
      "     |  \n",
      "     |  getFLOPS(...)\n",
      "     |      getFLOPS(netInputShapes) -> retval\n",
      "     |      .   @brief Computes FLOP for whole loaded model with specified input shapes.\n",
      "     |      .            * @param netInputShapes vector of shapes for all net inputs.\n",
      "     |      .            * @returns computed FLOP.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShapes) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getLayer(...)\n",
      "     |      getLayer(layerId) -> retval\n",
      "     |      .   @brief Returns pointer to layer with specified id or name which the network use.\n",
      "     |  \n",
      "     |  getLayerId(...)\n",
      "     |      getLayerId(layer) -> retval\n",
      "     |      .   @brief Converts string name of the layer to the integer identifier.\n",
      "     |      .            *  @returns id of the layer, or -1 if the layer wasn't found.\n",
      "     |  \n",
      "     |  getLayerNames(...)\n",
      "     |      getLayerNames() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getLayerTypes(...)\n",
      "     |      getLayerTypes() -> layersTypes\n",
      "     |      .   @brief Returns list of types for layer used in model.\n",
      "     |      .            * @param layersTypes output parameter for returning types.\n",
      "     |  \n",
      "     |  getLayersCount(...)\n",
      "     |      getLayersCount(layerType) -> retval\n",
      "     |      .   @brief Returns count of layers of specified type.\n",
      "     |      .            * @param layerType type.\n",
      "     |      .            * @returns count of layers\n",
      "     |  \n",
      "     |  getLayersShapes(...)\n",
      "     |      getLayersShapes(netInputShapes) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @brief Returns input and output shapes for all layers in loaded model;\n",
      "     |      .            *  preliminary inferencing isn't necessary.\n",
      "     |      .            *  @param netInputShapes shapes for all input blobs in net input layer.\n",
      "     |      .            *  @param layersIds output parameter for layer IDs.\n",
      "     |      .            *  @param inLayersShapes output parameter for input layers shapes;\n",
      "     |      .            * order is the same as in layersIds\n",
      "     |      .            *  @param outLayersShapes output parameter for output layers shapes;\n",
      "     |      .            * order is the same as in layersIds\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getLayersShapes(netInputShape) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getMemoryConsumption(...)\n",
      "     |      getMemoryConsumption(netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShapes) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getParam(...)\n",
      "     |      getParam(layer[, numParam]) -> retval\n",
      "     |      .   @brief Returns parameter blob of the layer.\n",
      "     |      .            *  @param layer name or id of the layer.\n",
      "     |      .            *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .            *  @see Layer::blobs\n",
      "     |  \n",
      "     |  getPerfProfile(...)\n",
      "     |      getPerfProfile() -> retval, timings\n",
      "     |      .   @brief Returns overall time for inference and timings (in ticks) for layers.\n",
      "     |      .            * Indexes in returned vector correspond to layers ids. Some layers can be fused with others,\n",
      "     |      .            * in this case zero ticks count will be return for that skipped layers.\n",
      "     |      .            * @param timings vector for tick timings for all layers.\n",
      "     |      .            * @return overall ticks for model inference.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayers(...)\n",
      "     |      getUnconnectedOutLayers() -> retval\n",
      "     |      .   @brief Returns indexes of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayersNames(...)\n",
      "     |      getUnconnectedOutLayersNames() -> retval\n",
      "     |      .   @brief Returns names of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  setHalideScheduler(...)\n",
      "     |      setHalideScheduler(scheduler) -> None\n",
      "     |      .   * @brief Compile Halide layers.\n",
      "     |      .            * @param[in] scheduler Path to YAML file with scheduling directives.\n",
      "     |      .            * @see setPreferableBackend\n",
      "     |      .            *\n",
      "     |      .            * Schedule layers that support Halide backend. Then compile them for\n",
      "     |      .            * specific target. For layers that not represented in scheduling file\n",
      "     |      .            * or if no manual scheduling used at all, automatic scheduling will be applied.\n",
      "     |  \n",
      "     |  setInput(...)\n",
      "     |      setInput(blob[, name[, scalefactor[, mean]]]) -> None\n",
      "     |      .   @brief Sets the new input value for the network\n",
      "     |      .            *  @param blob        A new blob. Should have CV_32F or CV_8U depth.\n",
      "     |      .            *  @param name        A name of input layer.\n",
      "     |      .            *  @param scalefactor An optional normalization scale.\n",
      "     |      .            *  @param mean        An optional mean subtraction values.\n",
      "     |      .            *  @see connect(String, String) to know format of the descriptor.\n",
      "     |      .            *\n",
      "     |      .            *  If scale or mean values are specified, a final input blob is computed\n",
      "     |      .            *  as:\n",
      "     |      .            * \\f[input(n,c,h,w) = scalefactor \\times (blob(n,c,h,w) - mean_c)\\f]\n",
      "     |  \n",
      "     |  setInputShape(...)\n",
      "     |      setInputShape(inputName, shape) -> None\n",
      "     |      .   @brief Specify shape of network input.\n",
      "     |  \n",
      "     |  setInputsNames(...)\n",
      "     |      setInputsNames(inputBlobNames) -> None\n",
      "     |      .   @brief Sets outputs names of the network input pseudo layer.\n",
      "     |      .            *\n",
      "     |      .            * Each net always has special own the network input pseudo layer with id=0.\n",
      "     |      .            * This layer stores the user blobs only and don't make any computations.\n",
      "     |      .            * In fact, this layer provides the only way to pass user data into the network.\n",
      "     |      .            * As any other layer, this layer can label its outputs and this function provides an easy way to do this.\n",
      "     |  \n",
      "     |  setParam(...)\n",
      "     |      setParam(layer, numParam, blob) -> None\n",
      "     |      .   @brief Sets the new value for the learned param of the layer.\n",
      "     |      .            *  @param layer name or id of the layer.\n",
      "     |      .            *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .            *  @param blob the new value.\n",
      "     |      .            *  @see Layer::blobs\n",
      "     |      .            *  @note If shape of the new blob differs from the previous shape,\n",
      "     |      .            *  then the following forward pass may fail.\n",
      "     |  \n",
      "     |  setPreferableBackend(...)\n",
      "     |      setPreferableBackend(backendId) -> None\n",
      "     |      .   * @brief Ask network to use specific computation backend where it supported.\n",
      "     |      .            * @param[in] backendId backend identifier.\n",
      "     |      .            * @see Backend\n",
      "     |      .            *\n",
      "     |      .            * If OpenCV is compiled with Intel's Inference Engine library, DNN_BACKEND_DEFAULT\n",
      "     |      .            * means DNN_BACKEND_INFERENCE_ENGINE. Otherwise it equals to DNN_BACKEND_OPENCV.\n",
      "     |  \n",
      "     |  setPreferableTarget(...)\n",
      "     |      setPreferableTarget(targetId) -> None\n",
      "     |      .   * @brief Ask network to make computations on specific target device.\n",
      "     |      .            * @param[in] targetId target identifier.\n",
      "     |      .            * @see Target\n",
      "     |      .            *\n",
      "     |      .            * List of supported combinations backend / target:\n",
      "     |      .            * |                        | DNN_BACKEND_OPENCV | DNN_BACKEND_INFERENCE_ENGINE | DNN_BACKEND_HALIDE |  DNN_BACKEND_CUDA |\n",
      "     |      .            * |------------------------|--------------------|------------------------------|--------------------|-------------------|\n",
      "     |      .            * | DNN_TARGET_CPU         |                  + |                            + |                  + |                   |\n",
      "     |      .            * | DNN_TARGET_OPENCL      |                  + |                            + |                  + |                   |\n",
      "     |      .            * | DNN_TARGET_OPENCL_FP16 |                  + |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_MYRIAD      |                    |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_FPGA        |                    |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_CUDA        |                    |                              |                    |                 + |\n",
      "     |      .            * | DNN_TARGET_CUDA_FP16   |                    |                              |                    |                 + |\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  readFromModelOptimizer(...)\n",
      "     |      readFromModelOptimizer(xml, bin) -> retval\n",
      "     |      .   @brief Create a network from Intel's Model Optimizer intermediate representation (IR).\n",
      "     |      .            *  @param[in] xml XML configuration file with network's topology.\n",
      "     |      .            *  @param[in] bin Binary file with trained weights.\n",
      "     |      .            *  Networks imported from Intel's Model Optimizer are launched in Intel's Inference Engine\n",
      "     |      .            *  backend.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      readFromModelOptimizer(bufferModelConfig, bufferWeights) -> retval\n",
      "     |      .   @brief Create a network from Intel's Model Optimizer in-memory buffers with intermediate representation (IR).\n",
      "     |      .            *  @param[in] bufferModelConfig buffer with model's configuration.\n",
      "     |      .            *  @param[in] bufferWeights buffer with model's trained weights.\n",
      "     |      .            *  @returns Net object.\n",
      "    \n",
      "    class dnn_SegmentationModel(dnn_Model)\n",
      "     |  Method resolution order:\n",
      "     |      dnn_SegmentationModel\n",
      "     |      dnn_Model\n",
      "     |      dnn_Net\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  segment(...)\n",
      "     |      segment(frame[, mask]) -> mask\n",
      "     |      .   @brief Given the @p input frame, create input blob, run net\n",
      "     |      .             *  @param[in]  frame  The input image.\n",
      "     |      .             *  @param[out] mask Allocated class prediction for each pixel\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from dnn_Model:\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(frame[, outs]) -> outs\n",
      "     |      .   @brief Given the @p input frame, create input blob, run net and return the output @p blobs.\n",
      "     |      .             *  @param[in]  frame  The input image.\n",
      "     |      .             *  @param[out] outs Allocated output blobs, which will store results of the computation.\n",
      "     |  \n",
      "     |  setInputCrop(...)\n",
      "     |      setInputCrop(crop) -> retval\n",
      "     |      .   @brief Set flag crop for frame.\n",
      "     |      .             *  @param[in] crop Flag which indicates whether image will be cropped after resize or not.\n",
      "     |  \n",
      "     |  setInputMean(...)\n",
      "     |      setInputMean(mean) -> retval\n",
      "     |      .   @brief Set mean value for frame.\n",
      "     |      .             *  @param[in] mean Scalar with mean values which are subtracted from channels.\n",
      "     |  \n",
      "     |  setInputParams(...)\n",
      "     |      setInputParams([, scale[, size[, mean[, swapRB[, crop]]]]]) -> None\n",
      "     |      .   @brief Set preprocessing parameters for frame.\n",
      "     |      .            *  @param[in] size New input size.\n",
      "     |      .            *  @param[in] mean Scalar with mean values which are subtracted from channels.\n",
      "     |      .            *  @param[in] scale Multiplier for frame values.\n",
      "     |      .            *  @param[in] swapRB Flag which indicates that swap first and last channels.\n",
      "     |      .            *  @param[in] crop Flag which indicates whether image will be cropped after resize or not.\n",
      "     |      .            *  blob(n, c, y, x) = scale * resize( frame(y, x, c) ) - mean(c) )\n",
      "     |  \n",
      "     |  setInputScale(...)\n",
      "     |      setInputScale(scale) -> retval\n",
      "     |      .   @brief Set scalefactor value for frame.\n",
      "     |      .             *  @param[in] scale Multiplier for frame values.\n",
      "     |  \n",
      "     |  setInputSize(...)\n",
      "     |      setInputSize(size) -> retval\n",
      "     |      .   @brief Set input size for frame.\n",
      "     |      .             *  @param[in] size New input size.\n",
      "     |      .             *  @note If shape of the new blob less than 0, then frame size not change.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      setInputSize(width, height) -> retval\n",
      "     |      .   @brief Set input size for frame.\n",
      "     |      .            *  @param[in] width New input width.\n",
      "     |      .            *  @param[in] height New input height.\n",
      "     |      .            *  @note If shape of the new blob less than 0,\n",
      "     |      .            *  then frame size not change.\n",
      "     |  \n",
      "     |  setInputSwapRB(...)\n",
      "     |      setInputSwapRB(swapRB) -> retval\n",
      "     |      .   @brief Set flag swapRB for frame.\n",
      "     |      .             *  @param[in] swapRB Flag which indicates that swap first and last channels.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from dnn_Net:\n",
      "     |  \n",
      "     |  connect(...)\n",
      "     |      connect(outPin, inpPin) -> None\n",
      "     |      .   @brief Connects output of the first layer to input of the second layer.\n",
      "     |      .            *  @param outPin descriptor of the first layer output.\n",
      "     |      .            *  @param inpPin descriptor of the second layer input.\n",
      "     |      .            *\n",
      "     |      .            * Descriptors have the following template <DFN>&lt;layer_name&gt;[.input_number]</DFN>:\n",
      "     |      .            * - the first part of the template <DFN>layer_name</DFN> is string name of the added layer.\n",
      "     |      .            *   If this part is empty then the network input pseudo layer will be used;\n",
      "     |      .            * - the second optional part of the template <DFN>input_number</DFN>\n",
      "     |      .            *   is either number of the layer input, either label one.\n",
      "     |      .            *   If this part is omitted then the first layer input will be used.\n",
      "     |      .            *\n",
      "     |      .            *  @see setNetInputs(), Layer::inputNameToIndex(), Layer::outputNameToIndex()\n",
      "     |  \n",
      "     |  dump(...)\n",
      "     |      dump() -> retval\n",
      "     |      .   @brief Dump net to String\n",
      "     |      .            *  @returns String with structure, hyperparameters, backend, target and fusion\n",
      "     |      .            *  Call method after setInput(). To see correct backend, target and fusion run after forward().\n",
      "     |  \n",
      "     |  dumpToFile(...)\n",
      "     |      dumpToFile(path) -> None\n",
      "     |      .   @brief Dump net structure, hyperparameters, backend, target and fusion to dot file\n",
      "     |      .            *  @param path   path to output file with .dot extension\n",
      "     |      .            *  @see dump()\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .   Returns true if there are no layers in the network.\n",
      "     |  \n",
      "     |  enableFusion(...)\n",
      "     |      enableFusion(fusion) -> None\n",
      "     |      .   @brief Enables or disables layer fusion in the network.\n",
      "     |      .            * @param fusion true to enable the fusion, false to disable. The fusion is enabled by default.\n",
      "     |  \n",
      "     |  forward(...)\n",
      "     |      forward([, outputName]) -> retval\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @return blob for first output of specified layer.\n",
      "     |      .            *  @details By default runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward([, outputBlobs[, outputName]]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputBlobs contains all output blobs for specified layer.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @details If @p outputName is empty, runs forward pass for the whole network.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      forward(outBlobNames[, outputBlobs]) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .            *  @param outputBlobs contains blobs for first outputs of specified layers.\n",
      "     |      .            *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  forwardAndRetrieve(...)\n",
      "     |      forwardAndRetrieve(outBlobNames) -> outputBlobs\n",
      "     |      .   @brief Runs forward pass to compute outputs of layers listed in @p outBlobNames.\n",
      "     |      .            *  @param outputBlobs contains all output blobs for each layer specified in @p outBlobNames.\n",
      "     |      .            *  @param outBlobNames names for layers which outputs are needed to get\n",
      "     |  \n",
      "     |  forwardAsync(...)\n",
      "     |      forwardAsync([, outputName]) -> retval\n",
      "     |      .   @brief Runs forward pass to compute output of layer with name @p outputName.\n",
      "     |      .            *  @param outputName name for layer which output is needed to get\n",
      "     |      .            *  @details By default runs forward pass for the whole network.\n",
      "     |      .            *\n",
      "     |      .            *  This is an asynchronous version of forward(const String&).\n",
      "     |      .            *  dnn::DNN_BACKEND_INFERENCE_ENGINE backend is required.\n",
      "     |  \n",
      "     |  getFLOPS(...)\n",
      "     |      getFLOPS(netInputShapes) -> retval\n",
      "     |      .   @brief Computes FLOP for whole loaded model with specified input shapes.\n",
      "     |      .            * @param netInputShapes vector of shapes for all net inputs.\n",
      "     |      .            * @returns computed FLOP.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShapes) -> retval\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getFLOPS(layerId, netInputShape) -> retval\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getLayer(...)\n",
      "     |      getLayer(layerId) -> retval\n",
      "     |      .   @brief Returns pointer to layer with specified id or name which the network use.\n",
      "     |  \n",
      "     |  getLayerId(...)\n",
      "     |      getLayerId(layer) -> retval\n",
      "     |      .   @brief Converts string name of the layer to the integer identifier.\n",
      "     |      .            *  @returns id of the layer, or -1 if the layer wasn't found.\n",
      "     |  \n",
      "     |  getLayerNames(...)\n",
      "     |      getLayerNames() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getLayerTypes(...)\n",
      "     |      getLayerTypes() -> layersTypes\n",
      "     |      .   @brief Returns list of types for layer used in model.\n",
      "     |      .            * @param layersTypes output parameter for returning types.\n",
      "     |  \n",
      "     |  getLayersCount(...)\n",
      "     |      getLayersCount(layerType) -> retval\n",
      "     |      .   @brief Returns count of layers of specified type.\n",
      "     |      .            * @param layerType type.\n",
      "     |      .            * @returns count of layers\n",
      "     |  \n",
      "     |  getLayersShapes(...)\n",
      "     |      getLayersShapes(netInputShapes) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @brief Returns input and output shapes for all layers in loaded model;\n",
      "     |      .            *  preliminary inferencing isn't necessary.\n",
      "     |      .            *  @param netInputShapes shapes for all input blobs in net input layer.\n",
      "     |      .            *  @param layersIds output parameter for layer IDs.\n",
      "     |      .            *  @param inLayersShapes output parameter for input layers shapes;\n",
      "     |      .            * order is the same as in layersIds\n",
      "     |      .            *  @param outLayersShapes output parameter for output layers shapes;\n",
      "     |      .            * order is the same as in layersIds\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getLayersShapes(netInputShape) -> layersIds, inLayersShapes, outLayersShapes\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getMemoryConsumption(...)\n",
      "     |      getMemoryConsumption(netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShapes) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      getMemoryConsumption(layerId, netInputShape) -> weights, blobs\n",
      "     |      .   @overload\n",
      "     |  \n",
      "     |  getParam(...)\n",
      "     |      getParam(layer[, numParam]) -> retval\n",
      "     |      .   @brief Returns parameter blob of the layer.\n",
      "     |      .            *  @param layer name or id of the layer.\n",
      "     |      .            *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .            *  @see Layer::blobs\n",
      "     |  \n",
      "     |  getPerfProfile(...)\n",
      "     |      getPerfProfile() -> retval, timings\n",
      "     |      .   @brief Returns overall time for inference and timings (in ticks) for layers.\n",
      "     |      .            * Indexes in returned vector correspond to layers ids. Some layers can be fused with others,\n",
      "     |      .            * in this case zero ticks count will be return for that skipped layers.\n",
      "     |      .            * @param timings vector for tick timings for all layers.\n",
      "     |      .            * @return overall ticks for model inference.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayers(...)\n",
      "     |      getUnconnectedOutLayers() -> retval\n",
      "     |      .   @brief Returns indexes of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  getUnconnectedOutLayersNames(...)\n",
      "     |      getUnconnectedOutLayersNames() -> retval\n",
      "     |      .   @brief Returns names of layers with unconnected outputs.\n",
      "     |  \n",
      "     |  setHalideScheduler(...)\n",
      "     |      setHalideScheduler(scheduler) -> None\n",
      "     |      .   * @brief Compile Halide layers.\n",
      "     |      .            * @param[in] scheduler Path to YAML file with scheduling directives.\n",
      "     |      .            * @see setPreferableBackend\n",
      "     |      .            *\n",
      "     |      .            * Schedule layers that support Halide backend. Then compile them for\n",
      "     |      .            * specific target. For layers that not represented in scheduling file\n",
      "     |      .            * or if no manual scheduling used at all, automatic scheduling will be applied.\n",
      "     |  \n",
      "     |  setInput(...)\n",
      "     |      setInput(blob[, name[, scalefactor[, mean]]]) -> None\n",
      "     |      .   @brief Sets the new input value for the network\n",
      "     |      .            *  @param blob        A new blob. Should have CV_32F or CV_8U depth.\n",
      "     |      .            *  @param name        A name of input layer.\n",
      "     |      .            *  @param scalefactor An optional normalization scale.\n",
      "     |      .            *  @param mean        An optional mean subtraction values.\n",
      "     |      .            *  @see connect(String, String) to know format of the descriptor.\n",
      "     |      .            *\n",
      "     |      .            *  If scale or mean values are specified, a final input blob is computed\n",
      "     |      .            *  as:\n",
      "     |      .            * \\f[input(n,c,h,w) = scalefactor \\times (blob(n,c,h,w) - mean_c)\\f]\n",
      "     |  \n",
      "     |  setInputShape(...)\n",
      "     |      setInputShape(inputName, shape) -> None\n",
      "     |      .   @brief Specify shape of network input.\n",
      "     |  \n",
      "     |  setInputsNames(...)\n",
      "     |      setInputsNames(inputBlobNames) -> None\n",
      "     |      .   @brief Sets outputs names of the network input pseudo layer.\n",
      "     |      .            *\n",
      "     |      .            * Each net always has special own the network input pseudo layer with id=0.\n",
      "     |      .            * This layer stores the user blobs only and don't make any computations.\n",
      "     |      .            * In fact, this layer provides the only way to pass user data into the network.\n",
      "     |      .            * As any other layer, this layer can label its outputs and this function provides an easy way to do this.\n",
      "     |  \n",
      "     |  setParam(...)\n",
      "     |      setParam(layer, numParam, blob) -> None\n",
      "     |      .   @brief Sets the new value for the learned param of the layer.\n",
      "     |      .            *  @param layer name or id of the layer.\n",
      "     |      .            *  @param numParam index of the layer parameter in the Layer::blobs array.\n",
      "     |      .            *  @param blob the new value.\n",
      "     |      .            *  @see Layer::blobs\n",
      "     |      .            *  @note If shape of the new blob differs from the previous shape,\n",
      "     |      .            *  then the following forward pass may fail.\n",
      "     |  \n",
      "     |  setPreferableBackend(...)\n",
      "     |      setPreferableBackend(backendId) -> None\n",
      "     |      .   * @brief Ask network to use specific computation backend where it supported.\n",
      "     |      .            * @param[in] backendId backend identifier.\n",
      "     |      .            * @see Backend\n",
      "     |      .            *\n",
      "     |      .            * If OpenCV is compiled with Intel's Inference Engine library, DNN_BACKEND_DEFAULT\n",
      "     |      .            * means DNN_BACKEND_INFERENCE_ENGINE. Otherwise it equals to DNN_BACKEND_OPENCV.\n",
      "     |  \n",
      "     |  setPreferableTarget(...)\n",
      "     |      setPreferableTarget(targetId) -> None\n",
      "     |      .   * @brief Ask network to make computations on specific target device.\n",
      "     |      .            * @param[in] targetId target identifier.\n",
      "     |      .            * @see Target\n",
      "     |      .            *\n",
      "     |      .            * List of supported combinations backend / target:\n",
      "     |      .            * |                        | DNN_BACKEND_OPENCV | DNN_BACKEND_INFERENCE_ENGINE | DNN_BACKEND_HALIDE |  DNN_BACKEND_CUDA |\n",
      "     |      .            * |------------------------|--------------------|------------------------------|--------------------|-------------------|\n",
      "     |      .            * | DNN_TARGET_CPU         |                  + |                            + |                  + |                   |\n",
      "     |      .            * | DNN_TARGET_OPENCL      |                  + |                            + |                  + |                   |\n",
      "     |      .            * | DNN_TARGET_OPENCL_FP16 |                  + |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_MYRIAD      |                    |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_FPGA        |                    |                            + |                    |                   |\n",
      "     |      .            * | DNN_TARGET_CUDA        |                    |                              |                    |                 + |\n",
      "     |      .            * | DNN_TARGET_CUDA_FP16   |                    |                              |                    |                 + |\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from dnn_Net:\n",
      "     |  \n",
      "     |  readFromModelOptimizer(...)\n",
      "     |      readFromModelOptimizer(xml, bin) -> retval\n",
      "     |      .   @brief Create a network from Intel's Model Optimizer intermediate representation (IR).\n",
      "     |      .            *  @param[in] xml XML configuration file with network's topology.\n",
      "     |      .            *  @param[in] bin Binary file with trained weights.\n",
      "     |      .            *  Networks imported from Intel's Model Optimizer are launched in Intel's Inference Engine\n",
      "     |      .            *  backend.\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      readFromModelOptimizer(bufferModelConfig, bufferWeights) -> retval\n",
      "     |      .   @brief Create a network from Intel's Model Optimizer in-memory buffers with intermediate representation (IR).\n",
      "     |      .            *  @param[in] bufferModelConfig buffer with model's configuration.\n",
      "     |      .            *  @param[in] bufferWeights buffer with model's trained weights.\n",
      "     |      .            *  @returns Net object.\n",
      "    \n",
      "    class error(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      error\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  code = None\n",
      "     |  \n",
      "     |  err = None\n",
      "     |  \n",
      "     |  file = None\n",
      "     |  \n",
      "     |  func = None\n",
      "     |  \n",
      "     |  line = None\n",
      "     |  \n",
      "     |  msg = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class flann_Index(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  build(...)\n",
      "     |      build(features, params[, distType]) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  getAlgorithm(...)\n",
      "     |      getAlgorithm() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getDistance(...)\n",
      "     |      getDistance() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  knnSearch(...)\n",
      "     |      knnSearch(query, knn[, indices[, dists[, params]]]) -> indices, dists\n",
      "     |      .\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(features, filename) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  radiusSearch(...)\n",
      "     |      radiusSearch(query, radius, maxResults[, indices[, dists[, params]]]) -> retval, indices, dists\n",
      "     |      .\n",
      "     |  \n",
      "     |  release(...)\n",
      "     |      release() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ml_ANN_MLP(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_ANN_MLP\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getAnnealCoolingRatio(...)\n",
      "     |      getAnnealCoolingRatio() -> retval\n",
      "     |      .   @see setAnnealCoolingRatio\n",
      "     |  \n",
      "     |  getAnnealFinalT(...)\n",
      "     |      getAnnealFinalT() -> retval\n",
      "     |      .   @see setAnnealFinalT\n",
      "     |  \n",
      "     |  getAnnealInitialT(...)\n",
      "     |      getAnnealInitialT() -> retval\n",
      "     |      .   @see setAnnealInitialT\n",
      "     |  \n",
      "     |  getAnnealItePerStep(...)\n",
      "     |      getAnnealItePerStep() -> retval\n",
      "     |      .   @see setAnnealItePerStep\n",
      "     |  \n",
      "     |  getBackpropMomentumScale(...)\n",
      "     |      getBackpropMomentumScale() -> retval\n",
      "     |      .   @see setBackpropMomentumScale\n",
      "     |  \n",
      "     |  getBackpropWeightScale(...)\n",
      "     |      getBackpropWeightScale() -> retval\n",
      "     |      .   @see setBackpropWeightScale\n",
      "     |  \n",
      "     |  getLayerSizes(...)\n",
      "     |      getLayerSizes() -> retval\n",
      "     |      .   Integer vector specifying the number of neurons in each layer including the input and output layers.\n",
      "     |      .       The very first element specifies the number of elements in the input layer.\n",
      "     |      .       The last element - number of elements in the output layer.\n",
      "     |      .   @sa setLayerSizes\n",
      "     |  \n",
      "     |  getRpropDW0(...)\n",
      "     |      getRpropDW0() -> retval\n",
      "     |      .   @see setRpropDW0\n",
      "     |  \n",
      "     |  getRpropDWMax(...)\n",
      "     |      getRpropDWMax() -> retval\n",
      "     |      .   @see setRpropDWMax\n",
      "     |  \n",
      "     |  getRpropDWMin(...)\n",
      "     |      getRpropDWMin() -> retval\n",
      "     |      .   @see setRpropDWMin\n",
      "     |  \n",
      "     |  getRpropDWMinus(...)\n",
      "     |      getRpropDWMinus() -> retval\n",
      "     |      .   @see setRpropDWMinus\n",
      "     |  \n",
      "     |  getRpropDWPlus(...)\n",
      "     |      getRpropDWPlus() -> retval\n",
      "     |      .   @see setRpropDWPlus\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .   @see setTermCriteria\n",
      "     |  \n",
      "     |  getTrainMethod(...)\n",
      "     |      getTrainMethod() -> retval\n",
      "     |      .   Returns current training method\n",
      "     |  \n",
      "     |  getWeights(...)\n",
      "     |      getWeights(layerIdx) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setActivationFunction(...)\n",
      "     |      setActivationFunction(type[, param1[, param2]]) -> None\n",
      "     |      .   Initialize the activation function for each neuron.\n",
      "     |      .       Currently the default and the only fully supported activation function is ANN_MLP::SIGMOID_SYM.\n",
      "     |      .       @param type The type of activation function. See ANN_MLP::ActivationFunctions.\n",
      "     |      .       @param param1 The first parameter of the activation function, \\f$\\alpha\\f$. Default value is 0.\n",
      "     |      .       @param param2 The second parameter of the activation function, \\f$\\beta\\f$. Default value is 0.\n",
      "     |  \n",
      "     |  setAnnealCoolingRatio(...)\n",
      "     |      setAnnealCoolingRatio(val) -> None\n",
      "     |      .   @copybrief getAnnealCoolingRatio @see getAnnealCoolingRatio\n",
      "     |  \n",
      "     |  setAnnealFinalT(...)\n",
      "     |      setAnnealFinalT(val) -> None\n",
      "     |      .   @copybrief getAnnealFinalT @see getAnnealFinalT\n",
      "     |  \n",
      "     |  setAnnealInitialT(...)\n",
      "     |      setAnnealInitialT(val) -> None\n",
      "     |      .   @copybrief getAnnealInitialT @see getAnnealInitialT\n",
      "     |  \n",
      "     |  setAnnealItePerStep(...)\n",
      "     |      setAnnealItePerStep(val) -> None\n",
      "     |      .   @copybrief getAnnealItePerStep @see getAnnealItePerStep\n",
      "     |  \n",
      "     |  setBackpropMomentumScale(...)\n",
      "     |      setBackpropMomentumScale(val) -> None\n",
      "     |      .   @copybrief getBackpropMomentumScale @see getBackpropMomentumScale\n",
      "     |  \n",
      "     |  setBackpropWeightScale(...)\n",
      "     |      setBackpropWeightScale(val) -> None\n",
      "     |      .   @copybrief getBackpropWeightScale @see getBackpropWeightScale\n",
      "     |  \n",
      "     |  setLayerSizes(...)\n",
      "     |      setLayerSizes(_layer_sizes) -> None\n",
      "     |      .   Integer vector specifying the number of neurons in each layer including the input and output layers.\n",
      "     |      .       The very first element specifies the number of elements in the input layer.\n",
      "     |      .       The last element - number of elements in the output layer. Default value is empty Mat.\n",
      "     |      .   @sa getLayerSizes\n",
      "     |  \n",
      "     |  setRpropDW0(...)\n",
      "     |      setRpropDW0(val) -> None\n",
      "     |      .   @copybrief getRpropDW0 @see getRpropDW0\n",
      "     |  \n",
      "     |  setRpropDWMax(...)\n",
      "     |      setRpropDWMax(val) -> None\n",
      "     |      .   @copybrief getRpropDWMax @see getRpropDWMax\n",
      "     |  \n",
      "     |  setRpropDWMin(...)\n",
      "     |      setRpropDWMin(val) -> None\n",
      "     |      .   @copybrief getRpropDWMin @see getRpropDWMin\n",
      "     |  \n",
      "     |  setRpropDWMinus(...)\n",
      "     |      setRpropDWMinus(val) -> None\n",
      "     |      .   @copybrief getRpropDWMinus @see getRpropDWMinus\n",
      "     |  \n",
      "     |  setRpropDWPlus(...)\n",
      "     |      setRpropDWPlus(val) -> None\n",
      "     |      .   @copybrief getRpropDWPlus @see getRpropDWPlus\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(val) -> None\n",
      "     |      .   @copybrief getTermCriteria @see getTermCriteria\n",
      "     |  \n",
      "     |  setTrainMethod(...)\n",
      "     |      setTrainMethod(method[, param1[, param2]]) -> None\n",
      "     |      .   Sets training method and common parameters.\n",
      "     |      .       @param method Default value is ANN_MLP::RPROP. See ANN_MLP::TrainingMethods.\n",
      "     |      .       @param param1 passed to setRpropDW0 for ANN_MLP::RPROP and to setBackpropWeightScale for ANN_MLP::BACKPROP and to initialT for ANN_MLP::ANNEAL.\n",
      "     |      .       @param param2 passed to setRpropDWMin for ANN_MLP::RPROP and to setBackpropMomentumScale for ANN_MLP::BACKPROP and to finalT for ANN_MLP::ANNEAL.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   @brief Creates empty model\n",
      "     |      .   \n",
      "     |      .       Use StatModel::train to train the model, Algorithm::load\\<ANN_MLP\\>(filename) to load the pre-trained model.\n",
      "     |      .       Note that the train method has optional flags: ANN_MLP::TrainFlags.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath) -> retval\n",
      "     |      .   @brief Loads and creates a serialized ANN from a file\n",
      "     |      .        *\n",
      "     |      .        * Use ANN::save to serialize and store an ANN to disk.\n",
      "     |      .        * Load the ANN from this file again, by calling this function with the path to the file.\n",
      "     |      .        *\n",
      "     |      .        * @param filepath path to serialized ANN\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .       @param data the training data\n",
      "     |      .       @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .           computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .           different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .           the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .           that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .       @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .       The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .       computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .       @param samples The input samples, floating-point matrix\n",
      "     |      .       @param results The optional output matrix of results.\n",
      "     |      .       @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .           created with TrainData::create.\n",
      "     |      .       @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .           new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param samples training samples\n",
      "     |      .       @param layout See ml::SampleTypes.\n",
      "     |      .       @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class ml_Boost(ml_DTrees)\n",
      "     |  Method resolution order:\n",
      "     |      ml_Boost\n",
      "     |      ml_DTrees\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getBoostType(...)\n",
      "     |      getBoostType() -> retval\n",
      "     |      .   @see setBoostType\n",
      "     |  \n",
      "     |  getWeakCount(...)\n",
      "     |      getWeakCount() -> retval\n",
      "     |      .   @see setWeakCount\n",
      "     |  \n",
      "     |  getWeightTrimRate(...)\n",
      "     |      getWeightTrimRate() -> retval\n",
      "     |      .   @see setWeightTrimRate\n",
      "     |  \n",
      "     |  setBoostType(...)\n",
      "     |      setBoostType(val) -> None\n",
      "     |      .   @copybrief getBoostType @see getBoostType\n",
      "     |  \n",
      "     |  setWeakCount(...)\n",
      "     |      setWeakCount(val) -> None\n",
      "     |      .   @copybrief getWeakCount @see getWeakCount\n",
      "     |  \n",
      "     |  setWeightTrimRate(...)\n",
      "     |      setWeightTrimRate(val) -> None\n",
      "     |      .   @copybrief getWeightTrimRate @see getWeightTrimRate\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   Creates the empty model.\n",
      "     |      .   Use StatModel::train to train the model, Algorithm::load\\<Boost\\>(filename) to load the pre-trained model.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized Boost from a file\n",
      "     |      .        *\n",
      "     |      .        * Use Boost::save to serialize and store an RTree to disk.\n",
      "     |      .        * Load the Boost from this file again, by calling this function with the path to the file.\n",
      "     |      .        * Optionally specify the node for the file containing the classifier\n",
      "     |      .        *\n",
      "     |      .        * @param filepath path to serialized Boost\n",
      "     |      .        * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_DTrees:\n",
      "     |  \n",
      "     |  getCVFolds(...)\n",
      "     |      getCVFolds() -> retval\n",
      "     |      .   @see setCVFolds\n",
      "     |  \n",
      "     |  getMaxCategories(...)\n",
      "     |      getMaxCategories() -> retval\n",
      "     |      .   @see setMaxCategories\n",
      "     |  \n",
      "     |  getMaxDepth(...)\n",
      "     |      getMaxDepth() -> retval\n",
      "     |      .   @see setMaxDepth\n",
      "     |  \n",
      "     |  getMinSampleCount(...)\n",
      "     |      getMinSampleCount() -> retval\n",
      "     |      .   @see setMinSampleCount\n",
      "     |  \n",
      "     |  getPriors(...)\n",
      "     |      getPriors() -> retval\n",
      "     |      .   @see setPriors\n",
      "     |  \n",
      "     |  getRegressionAccuracy(...)\n",
      "     |      getRegressionAccuracy() -> retval\n",
      "     |      .   @see setRegressionAccuracy\n",
      "     |  \n",
      "     |  getTruncatePrunedTree(...)\n",
      "     |      getTruncatePrunedTree() -> retval\n",
      "     |      .   @see setTruncatePrunedTree\n",
      "     |  \n",
      "     |  getUse1SERule(...)\n",
      "     |      getUse1SERule() -> retval\n",
      "     |      .   @see setUse1SERule\n",
      "     |  \n",
      "     |  getUseSurrogates(...)\n",
      "     |      getUseSurrogates() -> retval\n",
      "     |      .   @see setUseSurrogates\n",
      "     |  \n",
      "     |  setCVFolds(...)\n",
      "     |      setCVFolds(val) -> None\n",
      "     |      .   @copybrief getCVFolds @see getCVFolds\n",
      "     |  \n",
      "     |  setMaxCategories(...)\n",
      "     |      setMaxCategories(val) -> None\n",
      "     |      .   @copybrief getMaxCategories @see getMaxCategories\n",
      "     |  \n",
      "     |  setMaxDepth(...)\n",
      "     |      setMaxDepth(val) -> None\n",
      "     |      .   @copybrief getMaxDepth @see getMaxDepth\n",
      "     |  \n",
      "     |  setMinSampleCount(...)\n",
      "     |      setMinSampleCount(val) -> None\n",
      "     |      .   @copybrief getMinSampleCount @see getMinSampleCount\n",
      "     |  \n",
      "     |  setPriors(...)\n",
      "     |      setPriors(val) -> None\n",
      "     |      .   @copybrief getPriors @see getPriors\n",
      "     |  \n",
      "     |  setRegressionAccuracy(...)\n",
      "     |      setRegressionAccuracy(val) -> None\n",
      "     |      .   @copybrief getRegressionAccuracy @see getRegressionAccuracy\n",
      "     |  \n",
      "     |  setTruncatePrunedTree(...)\n",
      "     |      setTruncatePrunedTree(val) -> None\n",
      "     |      .   @copybrief getTruncatePrunedTree @see getTruncatePrunedTree\n",
      "     |  \n",
      "     |  setUse1SERule(...)\n",
      "     |      setUse1SERule(val) -> None\n",
      "     |      .   @copybrief getUse1SERule @see getUse1SERule\n",
      "     |  \n",
      "     |  setUseSurrogates(...)\n",
      "     |      setUseSurrogates(val) -> None\n",
      "     |      .   @copybrief getUseSurrogates @see getUseSurrogates\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .       @param data the training data\n",
      "     |      .       @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .           computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .           different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .           the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .           that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .       @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .       The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .       computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .       @param samples The input samples, floating-point matrix\n",
      "     |      .       @param results The optional output matrix of results.\n",
      "     |      .       @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .           created with TrainData::create.\n",
      "     |      .       @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .           new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param samples training samples\n",
      "     |      .       @param layout See ml::SampleTypes.\n",
      "     |      .       @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class ml_DTrees(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_DTrees\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getCVFolds(...)\n",
      "     |      getCVFolds() -> retval\n",
      "     |      .   @see setCVFolds\n",
      "     |  \n",
      "     |  getMaxCategories(...)\n",
      "     |      getMaxCategories() -> retval\n",
      "     |      .   @see setMaxCategories\n",
      "     |  \n",
      "     |  getMaxDepth(...)\n",
      "     |      getMaxDepth() -> retval\n",
      "     |      .   @see setMaxDepth\n",
      "     |  \n",
      "     |  getMinSampleCount(...)\n",
      "     |      getMinSampleCount() -> retval\n",
      "     |      .   @see setMinSampleCount\n",
      "     |  \n",
      "     |  getPriors(...)\n",
      "     |      getPriors() -> retval\n",
      "     |      .   @see setPriors\n",
      "     |  \n",
      "     |  getRegressionAccuracy(...)\n",
      "     |      getRegressionAccuracy() -> retval\n",
      "     |      .   @see setRegressionAccuracy\n",
      "     |  \n",
      "     |  getTruncatePrunedTree(...)\n",
      "     |      getTruncatePrunedTree() -> retval\n",
      "     |      .   @see setTruncatePrunedTree\n",
      "     |  \n",
      "     |  getUse1SERule(...)\n",
      "     |      getUse1SERule() -> retval\n",
      "     |      .   @see setUse1SERule\n",
      "     |  \n",
      "     |  getUseSurrogates(...)\n",
      "     |      getUseSurrogates() -> retval\n",
      "     |      .   @see setUseSurrogates\n",
      "     |  \n",
      "     |  setCVFolds(...)\n",
      "     |      setCVFolds(val) -> None\n",
      "     |      .   @copybrief getCVFolds @see getCVFolds\n",
      "     |  \n",
      "     |  setMaxCategories(...)\n",
      "     |      setMaxCategories(val) -> None\n",
      "     |      .   @copybrief getMaxCategories @see getMaxCategories\n",
      "     |  \n",
      "     |  setMaxDepth(...)\n",
      "     |      setMaxDepth(val) -> None\n",
      "     |      .   @copybrief getMaxDepth @see getMaxDepth\n",
      "     |  \n",
      "     |  setMinSampleCount(...)\n",
      "     |      setMinSampleCount(val) -> None\n",
      "     |      .   @copybrief getMinSampleCount @see getMinSampleCount\n",
      "     |  \n",
      "     |  setPriors(...)\n",
      "     |      setPriors(val) -> None\n",
      "     |      .   @copybrief getPriors @see getPriors\n",
      "     |  \n",
      "     |  setRegressionAccuracy(...)\n",
      "     |      setRegressionAccuracy(val) -> None\n",
      "     |      .   @copybrief getRegressionAccuracy @see getRegressionAccuracy\n",
      "     |  \n",
      "     |  setTruncatePrunedTree(...)\n",
      "     |      setTruncatePrunedTree(val) -> None\n",
      "     |      .   @copybrief getTruncatePrunedTree @see getTruncatePrunedTree\n",
      "     |  \n",
      "     |  setUse1SERule(...)\n",
      "     |      setUse1SERule(val) -> None\n",
      "     |      .   @copybrief getUse1SERule @see getUse1SERule\n",
      "     |  \n",
      "     |  setUseSurrogates(...)\n",
      "     |      setUseSurrogates(val) -> None\n",
      "     |      .   @copybrief getUseSurrogates @see getUseSurrogates\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   @brief Creates the empty model\n",
      "     |      .   \n",
      "     |      .       The static method creates empty decision tree with the specified parameters. It should be then\n",
      "     |      .       trained using train method (see StatModel::train). Alternatively, you can load the model from\n",
      "     |      .       file using Algorithm::load\\<DTrees\\>(filename).\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized DTrees from a file\n",
      "     |      .        *\n",
      "     |      .        * Use DTree::save to serialize and store an DTree to disk.\n",
      "     |      .        * Load the DTree from this file again, by calling this function with the path to the file.\n",
      "     |      .        * Optionally specify the node for the file containing the classifier\n",
      "     |      .        *\n",
      "     |      .        * @param filepath path to serialized DTree\n",
      "     |      .        * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .       @param data the training data\n",
      "     |      .       @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .           computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .           different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .           the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .           that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .       @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .       The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .       computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .       @param samples The input samples, floating-point matrix\n",
      "     |      .       @param results The optional output matrix of results.\n",
      "     |      .       @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .           created with TrainData::create.\n",
      "     |      .       @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .           new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param samples training samples\n",
      "     |      .       @param layout See ml::SampleTypes.\n",
      "     |      .       @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class ml_EM(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_EM\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getClustersNumber(...)\n",
      "     |      getClustersNumber() -> retval\n",
      "     |      .   @see setClustersNumber\n",
      "     |  \n",
      "     |  getCovarianceMatrixType(...)\n",
      "     |      getCovarianceMatrixType() -> retval\n",
      "     |      .   @see setCovarianceMatrixType\n",
      "     |  \n",
      "     |  getCovs(...)\n",
      "     |      getCovs([, covs]) -> covs\n",
      "     |      .   @brief Returns covariation matrices\n",
      "     |      .   \n",
      "     |      .       Returns vector of covariation matrices. Number of matrices is the number of gaussian mixtures,\n",
      "     |      .       each matrix is a square floating-point matrix NxN, where N is the space dimensionality.\n",
      "     |  \n",
      "     |  getMeans(...)\n",
      "     |      getMeans() -> retval\n",
      "     |      .   @brief Returns the cluster centers (means of the Gaussian mixture)\n",
      "     |      .   \n",
      "     |      .       Returns matrix with the number of rows equal to the number of mixtures and number of columns\n",
      "     |      .       equal to the space dimensionality.\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .   @see setTermCriteria\n",
      "     |  \n",
      "     |  getWeights(...)\n",
      "     |      getWeights() -> retval\n",
      "     |      .   @brief Returns weights of the mixtures\n",
      "     |      .   \n",
      "     |      .       Returns vector with the number of elements equal to the number of mixtures.\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Returns posterior probabilities for the provided samples\n",
      "     |      .   \n",
      "     |      .       @param samples The input samples, floating-point matrix\n",
      "     |      .       @param results The optional output \\f$ nSamples \\times nClusters\\f$ matrix of results. It contains\n",
      "     |      .       posterior probabilities for each sample from the input\n",
      "     |      .       @param flags This parameter will be ignored\n",
      "     |  \n",
      "     |  predict2(...)\n",
      "     |      predict2(sample[, probs]) -> retval, probs\n",
      "     |      .   @brief Returns a likelihood logarithm value and an index of the most probable mixture component\n",
      "     |      .       for the given sample.\n",
      "     |      .   \n",
      "     |      .       @param sample A sample for classification. It should be a one-channel matrix of\n",
      "     |      .           \\f$1 \\times dims\\f$ or \\f$dims \\times 1\\f$ size.\n",
      "     |      .       @param probs Optional output matrix that contains posterior probabilities of each component\n",
      "     |      .           given the sample. It has \\f$1 \\times nclusters\\f$ size and CV_64FC1 type.\n",
      "     |      .   \n",
      "     |      .       The method returns a two-element double vector. Zero element is a likelihood logarithm value for\n",
      "     |      .       the sample. First element is an index of the most probable mixture component for the given\n",
      "     |      .       sample.\n",
      "     |  \n",
      "     |  setClustersNumber(...)\n",
      "     |      setClustersNumber(val) -> None\n",
      "     |      .   @copybrief getClustersNumber @see getClustersNumber\n",
      "     |  \n",
      "     |  setCovarianceMatrixType(...)\n",
      "     |      setCovarianceMatrixType(val) -> None\n",
      "     |      .   @copybrief getCovarianceMatrixType @see getCovarianceMatrixType\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(val) -> None\n",
      "     |      .   @copybrief getTermCriteria @see getTermCriteria\n",
      "     |  \n",
      "     |  trainE(...)\n",
      "     |      trainE(samples, means0[, covs0[, weights0[, logLikelihoods[, labels[, probs]]]]]) -> retval, logLikelihoods, labels, probs\n",
      "     |      .   @brief Estimate the Gaussian mixture parameters from a samples set.\n",
      "     |      .   \n",
      "     |      .       This variation starts with Expectation step. You need to provide initial means \\f$a_k\\f$ of\n",
      "     |      .       mixture components. Optionally you can pass initial weights \\f$\\pi_k\\f$ and covariance matrices\n",
      "     |      .       \\f$S_k\\f$ of mixture components.\n",
      "     |      .   \n",
      "     |      .       @param samples Samples from which the Gaussian mixture model will be estimated. It should be a\n",
      "     |      .           one-channel matrix, each row of which is a sample. If the matrix does not have CV_64F type\n",
      "     |      .           it will be converted to the inner matrix of such type for the further computing.\n",
      "     |      .       @param means0 Initial means \\f$a_k\\f$ of mixture components. It is a one-channel matrix of\n",
      "     |      .           \\f$nclusters \\times dims\\f$ size. If the matrix does not have CV_64F type it will be\n",
      "     |      .           converted to the inner matrix of such type for the further computing.\n",
      "     |      .       @param covs0 The vector of initial covariance matrices \\f$S_k\\f$ of mixture components. Each of\n",
      "     |      .           covariance matrices is a one-channel matrix of \\f$dims \\times dims\\f$ size. If the matrices\n",
      "     |      .           do not have CV_64F type they will be converted to the inner matrices of such type for the\n",
      "     |      .           further computing.\n",
      "     |      .       @param weights0 Initial weights \\f$\\pi_k\\f$ of mixture components. It should be a one-channel\n",
      "     |      .           floating-point matrix with \\f$1 \\times nclusters\\f$ or \\f$nclusters \\times 1\\f$ size.\n",
      "     |      .       @param logLikelihoods The optional output matrix that contains a likelihood logarithm value for\n",
      "     |      .           each sample. It has \\f$nsamples \\times 1\\f$ size and CV_64FC1 type.\n",
      "     |      .       @param labels The optional output \"class label\" for each sample:\n",
      "     |      .           \\f$\\texttt{labels}_i=\\texttt{arg max}_k(p_{i,k}), i=1..N\\f$ (indices of the most probable\n",
      "     |      .           mixture component for each sample). It has \\f$nsamples \\times 1\\f$ size and CV_32SC1 type.\n",
      "     |      .       @param probs The optional output matrix that contains posterior probabilities of each Gaussian\n",
      "     |      .           mixture component given the each sample. It has \\f$nsamples \\times nclusters\\f$ size and\n",
      "     |      .           CV_64FC1 type.\n",
      "     |  \n",
      "     |  trainEM(...)\n",
      "     |      trainEM(samples[, logLikelihoods[, labels[, probs]]]) -> retval, logLikelihoods, labels, probs\n",
      "     |      .   @brief Estimate the Gaussian mixture parameters from a samples set.\n",
      "     |      .   \n",
      "     |      .       This variation starts with Expectation step. Initial values of the model parameters will be\n",
      "     |      .       estimated by the k-means algorithm.\n",
      "     |      .   \n",
      "     |      .       Unlike many of the ML models, %EM is an unsupervised learning algorithm and it does not take\n",
      "     |      .       responses (class labels or function values) as input. Instead, it computes the *Maximum\n",
      "     |      .       Likelihood Estimate* of the Gaussian mixture parameters from an input sample set, stores all the\n",
      "     |      .       parameters inside the structure: \\f$p_{i,k}\\f$ in probs, \\f$a_k\\f$ in means , \\f$S_k\\f$ in\n",
      "     |      .       covs[k], \\f$\\pi_k\\f$ in weights , and optionally computes the output \"class label\" for each\n",
      "     |      .       sample: \\f$\\texttt{labels}_i=\\texttt{arg max}_k(p_{i,k}), i=1..N\\f$ (indices of the most\n",
      "     |      .       probable mixture component for each sample).\n",
      "     |      .   \n",
      "     |      .       The trained model can be used further for prediction, just like any other classifier. The\n",
      "     |      .       trained model is similar to the NormalBayesClassifier.\n",
      "     |      .   \n",
      "     |      .       @param samples Samples from which the Gaussian mixture model will be estimated. It should be a\n",
      "     |      .           one-channel matrix, each row of which is a sample. If the matrix does not have CV_64F type\n",
      "     |      .           it will be converted to the inner matrix of such type for the further computing.\n",
      "     |      .       @param logLikelihoods The optional output matrix that contains a likelihood logarithm value for\n",
      "     |      .           each sample. It has \\f$nsamples \\times 1\\f$ size and CV_64FC1 type.\n",
      "     |      .       @param labels The optional output \"class label\" for each sample:\n",
      "     |      .           \\f$\\texttt{labels}_i=\\texttt{arg max}_k(p_{i,k}), i=1..N\\f$ (indices of the most probable\n",
      "     |      .           mixture component for each sample). It has \\f$nsamples \\times 1\\f$ size and CV_32SC1 type.\n",
      "     |      .       @param probs The optional output matrix that contains posterior probabilities of each Gaussian\n",
      "     |      .           mixture component given the each sample. It has \\f$nsamples \\times nclusters\\f$ size and\n",
      "     |      .           CV_64FC1 type.\n",
      "     |  \n",
      "     |  trainM(...)\n",
      "     |      trainM(samples, probs0[, logLikelihoods[, labels[, probs]]]) -> retval, logLikelihoods, labels, probs\n",
      "     |      .   @brief Estimate the Gaussian mixture parameters from a samples set.\n",
      "     |      .   \n",
      "     |      .       This variation starts with Maximization step. You need to provide initial probabilities\n",
      "     |      .       \\f$p_{i,k}\\f$ to use this option.\n",
      "     |      .   \n",
      "     |      .       @param samples Samples from which the Gaussian mixture model will be estimated. It should be a\n",
      "     |      .           one-channel matrix, each row of which is a sample. If the matrix does not have CV_64F type\n",
      "     |      .           it will be converted to the inner matrix of such type for the further computing.\n",
      "     |      .       @param probs0 the probabilities\n",
      "     |      .       @param logLikelihoods The optional output matrix that contains a likelihood logarithm value for\n",
      "     |      .           each sample. It has \\f$nsamples \\times 1\\f$ size and CV_64FC1 type.\n",
      "     |      .       @param labels The optional output \"class label\" for each sample:\n",
      "     |      .           \\f$\\texttt{labels}_i=\\texttt{arg max}_k(p_{i,k}), i=1..N\\f$ (indices of the most probable\n",
      "     |      .           mixture component for each sample). It has \\f$nsamples \\times 1\\f$ size and CV_32SC1 type.\n",
      "     |      .       @param probs The optional output matrix that contains posterior probabilities of each Gaussian\n",
      "     |      .           mixture component given the each sample. It has \\f$nsamples \\times nclusters\\f$ size and\n",
      "     |      .           CV_64FC1 type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   Creates empty %EM model.\n",
      "     |      .       The model should be trained then using StatModel::train(traindata, flags) method. Alternatively, you\n",
      "     |      .       can use one of the EM::train\\* methods or load it from file using Algorithm::load\\<EM\\>(filename).\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized EM from a file\n",
      "     |      .        *\n",
      "     |      .        * Use EM::save to serialize and store an EM to disk.\n",
      "     |      .        * Load the EM from this file again, by calling this function with the path to the file.\n",
      "     |      .        * Optionally specify the node for the file containing the classifier\n",
      "     |      .        *\n",
      "     |      .        * @param filepath path to serialized EM\n",
      "     |      .        * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .       @param data the training data\n",
      "     |      .       @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .           computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .           different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .           the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .           that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .       @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .       The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .       computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .           created with TrainData::create.\n",
      "     |      .       @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .           new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param samples training samples\n",
      "     |      .       @param layout See ml::SampleTypes.\n",
      "     |      .       @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class ml_KNearest(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_KNearest\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  findNearest(...)\n",
      "     |      findNearest(samples, k[, results[, neighborResponses[, dist]]]) -> retval, results, neighborResponses, dist\n",
      "     |      .   @brief Finds the neighbors and predicts responses for input vectors.\n",
      "     |      .   \n",
      "     |      .       @param samples Input samples stored by rows. It is a single-precision floating-point matrix of\n",
      "     |      .           `<number_of_samples> * k` size.\n",
      "     |      .       @param k Number of used nearest neighbors. Should be greater than 1.\n",
      "     |      .       @param results Vector with results of prediction (regression or classification) for each input\n",
      "     |      .           sample. It is a single-precision floating-point vector with `<number_of_samples>` elements.\n",
      "     |      .       @param neighborResponses Optional output values for corresponding neighbors. It is a single-\n",
      "     |      .           precision floating-point matrix of `<number_of_samples> * k` size.\n",
      "     |      .       @param dist Optional output distances from the input vectors to the corresponding neighbors. It\n",
      "     |      .           is a single-precision floating-point matrix of `<number_of_samples> * k` size.\n",
      "     |      .   \n",
      "     |      .       For each input vector (a row of the matrix samples), the method finds the k nearest neighbors.\n",
      "     |      .       In case of regression, the predicted result is a mean value of the particular vector's neighbor\n",
      "     |      .       responses. In case of classification, the class is determined by voting.\n",
      "     |      .   \n",
      "     |      .       For each input vector, the neighbors are sorted by their distances to the vector.\n",
      "     |      .   \n",
      "     |      .       In case of C++ interface you can use output pointers to empty matrices and the function will\n",
      "     |      .       allocate memory itself.\n",
      "     |      .   \n",
      "     |      .       If only a single input vector is passed, all output matrices are optional and the predicted\n",
      "     |      .       value is returned by the method.\n",
      "     |      .   \n",
      "     |      .       The function is parallelized with the TBB library.\n",
      "     |  \n",
      "     |  getAlgorithmType(...)\n",
      "     |      getAlgorithmType() -> retval\n",
      "     |      .   @see setAlgorithmType\n",
      "     |  \n",
      "     |  getDefaultK(...)\n",
      "     |      getDefaultK() -> retval\n",
      "     |      .   @see setDefaultK\n",
      "     |  \n",
      "     |  getEmax(...)\n",
      "     |      getEmax() -> retval\n",
      "     |      .   @see setEmax\n",
      "     |  \n",
      "     |  getIsClassifier(...)\n",
      "     |      getIsClassifier() -> retval\n",
      "     |      .   @see setIsClassifier\n",
      "     |  \n",
      "     |  setAlgorithmType(...)\n",
      "     |      setAlgorithmType(val) -> None\n",
      "     |      .   @copybrief getAlgorithmType @see getAlgorithmType\n",
      "     |  \n",
      "     |  setDefaultK(...)\n",
      "     |      setDefaultK(val) -> None\n",
      "     |      .   @copybrief getDefaultK @see getDefaultK\n",
      "     |  \n",
      "     |  setEmax(...)\n",
      "     |      setEmax(val) -> None\n",
      "     |      .   @copybrief getEmax @see getEmax\n",
      "     |  \n",
      "     |  setIsClassifier(...)\n",
      "     |      setIsClassifier(val) -> None\n",
      "     |      .   @copybrief getIsClassifier @see getIsClassifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   @brief Creates the empty model\n",
      "     |      .   \n",
      "     |      .       The static method creates empty %KNearest classifier. It should be then trained using StatModel::train method.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath) -> retval\n",
      "     |      .   @brief Loads and creates a serialized knearest from a file\n",
      "     |      .        *\n",
      "     |      .        * Use KNearest::save to serialize and store an KNearest to disk.\n",
      "     |      .        * Load the KNearest from this file again, by calling this function with the path to the file.\n",
      "     |      .        *\n",
      "     |      .        * @param filepath path to serialized KNearest\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .       @param data the training data\n",
      "     |      .       @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .           computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .           different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .           the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .           that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .       @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .       The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .       computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .       @param samples The input samples, floating-point matrix\n",
      "     |      .       @param results The optional output matrix of results.\n",
      "     |      .       @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .           created with TrainData::create.\n",
      "     |      .       @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .           new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param samples training samples\n",
      "     |      .       @param layout See ml::SampleTypes.\n",
      "     |      .       @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class ml_LogisticRegression(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_LogisticRegression\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getIterations(...)\n",
      "     |      getIterations() -> retval\n",
      "     |      .   @see setIterations\n",
      "     |  \n",
      "     |  getLearningRate(...)\n",
      "     |      getLearningRate() -> retval\n",
      "     |      .   @see setLearningRate\n",
      "     |  \n",
      "     |  getMiniBatchSize(...)\n",
      "     |      getMiniBatchSize() -> retval\n",
      "     |      .   @see setMiniBatchSize\n",
      "     |  \n",
      "     |  getRegularization(...)\n",
      "     |      getRegularization() -> retval\n",
      "     |      .   @see setRegularization\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .   @see setTermCriteria\n",
      "     |  \n",
      "     |  getTrainMethod(...)\n",
      "     |      getTrainMethod() -> retval\n",
      "     |      .   @see setTrainMethod\n",
      "     |  \n",
      "     |  get_learnt_thetas(...)\n",
      "     |      get_learnt_thetas() -> retval\n",
      "     |      .   @brief This function returns the trained parameters arranged across rows.\n",
      "     |      .   \n",
      "     |      .       For a two class classification problem, it returns a row matrix. It returns learnt parameters of\n",
      "     |      .       the Logistic Regression as a matrix of type CV_32F.\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts responses for input samples and returns a float type.\n",
      "     |      .   \n",
      "     |      .       @param samples The input data for the prediction algorithm. Matrix [m x n], where each row\n",
      "     |      .           contains variables (features) of one object being classified. Should have data type CV_32F.\n",
      "     |      .       @param results Predicted labels as a column matrix of type CV_32S.\n",
      "     |      .       @param flags Not used.\n",
      "     |  \n",
      "     |  setIterations(...)\n",
      "     |      setIterations(val) -> None\n",
      "     |      .   @copybrief getIterations @see getIterations\n",
      "     |  \n",
      "     |  setLearningRate(...)\n",
      "     |      setLearningRate(val) -> None\n",
      "     |      .   @copybrief getLearningRate @see getLearningRate\n",
      "     |  \n",
      "     |  setMiniBatchSize(...)\n",
      "     |      setMiniBatchSize(val) -> None\n",
      "     |      .   @copybrief getMiniBatchSize @see getMiniBatchSize\n",
      "     |  \n",
      "     |  setRegularization(...)\n",
      "     |      setRegularization(val) -> None\n",
      "     |      .   @copybrief getRegularization @see getRegularization\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(val) -> None\n",
      "     |      .   @copybrief getTermCriteria @see getTermCriteria\n",
      "     |  \n",
      "     |  setTrainMethod(...)\n",
      "     |      setTrainMethod(val) -> None\n",
      "     |      .   @copybrief getTrainMethod @see getTrainMethod\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   @brief Creates empty model.\n",
      "     |      .   \n",
      "     |      .       Creates Logistic Regression model with parameters given.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized LogisticRegression from a file\n",
      "     |      .        *\n",
      "     |      .        * Use LogisticRegression::save to serialize and store an LogisticRegression to disk.\n",
      "     |      .        * Load the LogisticRegression from this file again, by calling this function with the path to the file.\n",
      "     |      .        * Optionally specify the node for the file containing the classifier\n",
      "     |      .        *\n",
      "     |      .        * @param filepath path to serialized LogisticRegression\n",
      "     |      .        * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .       @param data the training data\n",
      "     |      .       @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .           computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .           different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .           the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .           that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .       @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .       The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .       computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .           created with TrainData::create.\n",
      "     |      .       @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .           new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param samples training samples\n",
      "     |      .       @param layout See ml::SampleTypes.\n",
      "     |      .       @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class ml_NormalBayesClassifier(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_NormalBayesClassifier\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  predictProb(...)\n",
      "     |      predictProb(inputs[, outputs[, outputProbs[, flags]]]) -> retval, outputs, outputProbs\n",
      "     |      .   @brief Predicts the response for sample(s).\n",
      "     |      .   \n",
      "     |      .       The method estimates the most probable classes for input vectors. Input vectors (one or more)\n",
      "     |      .       are stored as rows of the matrix inputs. In case of multiple input vectors, there should be one\n",
      "     |      .       output vector outputs. The predicted class for a single input vector is returned by the method.\n",
      "     |      .       The vector outputProbs contains the output probabilities corresponding to each element of\n",
      "     |      .       result.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   Creates empty model\n",
      "     |      .   Use StatModel::train to train the model after creation.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized NormalBayesClassifier from a file\n",
      "     |      .        *\n",
      "     |      .        * Use NormalBayesClassifier::save to serialize and store an NormalBayesClassifier to disk.\n",
      "     |      .        * Load the NormalBayesClassifier from this file again, by calling this function with the path to the file.\n",
      "     |      .        * Optionally specify the node for the file containing the classifier\n",
      "     |      .        *\n",
      "     |      .        * @param filepath path to serialized NormalBayesClassifier\n",
      "     |      .        * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .       @param data the training data\n",
      "     |      .       @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .           computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .           different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .           the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .           that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .       @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .       The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .       computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .       @param samples The input samples, floating-point matrix\n",
      "     |      .       @param results The optional output matrix of results.\n",
      "     |      .       @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .           created with TrainData::create.\n",
      "     |      .       @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .           new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param samples training samples\n",
      "     |      .       @param layout See ml::SampleTypes.\n",
      "     |      .       @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class ml_ParamGrid(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create([, minVal[, maxVal[, logstep]]]) -> retval\n",
      "     |      .   @brief Creates a ParamGrid Ptr that can be given to the %SVM::trainAuto method\n",
      "     |      .   \n",
      "     |      .       @param minVal minimum value of the parameter grid\n",
      "     |      .       @param maxVal maximum value of the parameter grid\n",
      "     |      .       @param logstep Logarithmic step for iterating the statmodel parameter\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  logStep\n",
      "     |      logStep\n",
      "     |  \n",
      "     |  maxVal\n",
      "     |      maxVal\n",
      "     |  \n",
      "     |  minVal\n",
      "     |      minVal\n",
      "    \n",
      "    class ml_RTrees(ml_DTrees)\n",
      "     |  Method resolution order:\n",
      "     |      ml_RTrees\n",
      "     |      ml_DTrees\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getActiveVarCount(...)\n",
      "     |      getActiveVarCount() -> retval\n",
      "     |      .   @see setActiveVarCount\n",
      "     |  \n",
      "     |  getCalculateVarImportance(...)\n",
      "     |      getCalculateVarImportance() -> retval\n",
      "     |      .   @see setCalculateVarImportance\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .   @see setTermCriteria\n",
      "     |  \n",
      "     |  getVarImportance(...)\n",
      "     |      getVarImportance() -> retval\n",
      "     |      .   Returns the variable importance array.\n",
      "     |      .       The method returns the variable importance vector, computed at the training stage when\n",
      "     |      .       CalculateVarImportance is set to true. If this flag was set to false, the empty matrix is\n",
      "     |      .       returned.\n",
      "     |  \n",
      "     |  getVotes(...)\n",
      "     |      getVotes(samples, flags[, results]) -> results\n",
      "     |      .   Returns the result of each individual tree in the forest.\n",
      "     |      .       In case the model is a regression problem, the method will return each of the trees'\n",
      "     |      .       results for each of the sample cases. If the model is a classifier, it will return\n",
      "     |      .       a Mat with samples + 1 rows, where the first row gives the class number and the\n",
      "     |      .       following rows return the votes each class had for each sample.\n",
      "     |      .           @param samples Array containing the samples for which votes will be calculated.\n",
      "     |      .           @param results Array where the result of the calculation will be written.\n",
      "     |      .           @param flags Flags for defining the type of RTrees.\n",
      "     |  \n",
      "     |  setActiveVarCount(...)\n",
      "     |      setActiveVarCount(val) -> None\n",
      "     |      .   @copybrief getActiveVarCount @see getActiveVarCount\n",
      "     |  \n",
      "     |  setCalculateVarImportance(...)\n",
      "     |      setCalculateVarImportance(val) -> None\n",
      "     |      .   @copybrief getCalculateVarImportance @see getCalculateVarImportance\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(val) -> None\n",
      "     |      .   @copybrief getTermCriteria @see getTermCriteria\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   Creates the empty model.\n",
      "     |      .       Use StatModel::train to train the model, StatModel::train to create and train the model,\n",
      "     |      .       Algorithm::load to load the pre-trained model.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized RTree from a file\n",
      "     |      .        *\n",
      "     |      .        * Use RTree::save to serialize and store an RTree to disk.\n",
      "     |      .        * Load the RTree from this file again, by calling this function with the path to the file.\n",
      "     |      .        * Optionally specify the node for the file containing the classifier\n",
      "     |      .        *\n",
      "     |      .        * @param filepath path to serialized RTree\n",
      "     |      .        * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_DTrees:\n",
      "     |  \n",
      "     |  getCVFolds(...)\n",
      "     |      getCVFolds() -> retval\n",
      "     |      .   @see setCVFolds\n",
      "     |  \n",
      "     |  getMaxCategories(...)\n",
      "     |      getMaxCategories() -> retval\n",
      "     |      .   @see setMaxCategories\n",
      "     |  \n",
      "     |  getMaxDepth(...)\n",
      "     |      getMaxDepth() -> retval\n",
      "     |      .   @see setMaxDepth\n",
      "     |  \n",
      "     |  getMinSampleCount(...)\n",
      "     |      getMinSampleCount() -> retval\n",
      "     |      .   @see setMinSampleCount\n",
      "     |  \n",
      "     |  getPriors(...)\n",
      "     |      getPriors() -> retval\n",
      "     |      .   @see setPriors\n",
      "     |  \n",
      "     |  getRegressionAccuracy(...)\n",
      "     |      getRegressionAccuracy() -> retval\n",
      "     |      .   @see setRegressionAccuracy\n",
      "     |  \n",
      "     |  getTruncatePrunedTree(...)\n",
      "     |      getTruncatePrunedTree() -> retval\n",
      "     |      .   @see setTruncatePrunedTree\n",
      "     |  \n",
      "     |  getUse1SERule(...)\n",
      "     |      getUse1SERule() -> retval\n",
      "     |      .   @see setUse1SERule\n",
      "     |  \n",
      "     |  getUseSurrogates(...)\n",
      "     |      getUseSurrogates() -> retval\n",
      "     |      .   @see setUseSurrogates\n",
      "     |  \n",
      "     |  setCVFolds(...)\n",
      "     |      setCVFolds(val) -> None\n",
      "     |      .   @copybrief getCVFolds @see getCVFolds\n",
      "     |  \n",
      "     |  setMaxCategories(...)\n",
      "     |      setMaxCategories(val) -> None\n",
      "     |      .   @copybrief getMaxCategories @see getMaxCategories\n",
      "     |  \n",
      "     |  setMaxDepth(...)\n",
      "     |      setMaxDepth(val) -> None\n",
      "     |      .   @copybrief getMaxDepth @see getMaxDepth\n",
      "     |  \n",
      "     |  setMinSampleCount(...)\n",
      "     |      setMinSampleCount(val) -> None\n",
      "     |      .   @copybrief getMinSampleCount @see getMinSampleCount\n",
      "     |  \n",
      "     |  setPriors(...)\n",
      "     |      setPriors(val) -> None\n",
      "     |      .   @copybrief getPriors @see getPriors\n",
      "     |  \n",
      "     |  setRegressionAccuracy(...)\n",
      "     |      setRegressionAccuracy(val) -> None\n",
      "     |      .   @copybrief getRegressionAccuracy @see getRegressionAccuracy\n",
      "     |  \n",
      "     |  setTruncatePrunedTree(...)\n",
      "     |      setTruncatePrunedTree(val) -> None\n",
      "     |      .   @copybrief getTruncatePrunedTree @see getTruncatePrunedTree\n",
      "     |  \n",
      "     |  setUse1SERule(...)\n",
      "     |      setUse1SERule(val) -> None\n",
      "     |      .   @copybrief getUse1SERule @see getUse1SERule\n",
      "     |  \n",
      "     |  setUseSurrogates(...)\n",
      "     |      setUseSurrogates(val) -> None\n",
      "     |      .   @copybrief getUseSurrogates @see getUseSurrogates\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .       @param data the training data\n",
      "     |      .       @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .           computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .           different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .           the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .           that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .       @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .       The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .       computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .       @param samples The input samples, floating-point matrix\n",
      "     |      .       @param results The optional output matrix of results.\n",
      "     |      .       @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .           created with TrainData::create.\n",
      "     |      .       @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .           new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param samples training samples\n",
      "     |      .       @param layout See ml::SampleTypes.\n",
      "     |      .       @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class ml_SVM(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_SVM\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getC(...)\n",
      "     |      getC() -> retval\n",
      "     |      .   @see setC\n",
      "     |  \n",
      "     |  getClassWeights(...)\n",
      "     |      getClassWeights() -> retval\n",
      "     |      .   @see setClassWeights\n",
      "     |  \n",
      "     |  getCoef0(...)\n",
      "     |      getCoef0() -> retval\n",
      "     |      .   @see setCoef0\n",
      "     |  \n",
      "     |  getDecisionFunction(...)\n",
      "     |      getDecisionFunction(i[, alpha[, svidx]]) -> retval, alpha, svidx\n",
      "     |      .   @brief Retrieves the decision function\n",
      "     |      .   \n",
      "     |      .       @param i the index of the decision function. If the problem solved is regression, 1-class or\n",
      "     |      .           2-class classification, then there will be just one decision function and the index should\n",
      "     |      .           always be 0. Otherwise, in the case of N-class classification, there will be \\f$N(N-1)/2\\f$\n",
      "     |      .           decision functions.\n",
      "     |      .       @param alpha the optional output vector for weights, corresponding to different support vectors.\n",
      "     |      .           In the case of linear %SVM all the alpha's will be 1's.\n",
      "     |      .       @param svidx the optional output vector of indices of support vectors within the matrix of\n",
      "     |      .           support vectors (which can be retrieved by SVM::getSupportVectors). In the case of linear\n",
      "     |      .           %SVM each decision function consists of a single \"compressed\" support vector.\n",
      "     |      .   \n",
      "     |      .       The method returns rho parameter of the decision function, a scalar subtracted from the weighted\n",
      "     |      .       sum of kernel responses.\n",
      "     |  \n",
      "     |  getDegree(...)\n",
      "     |      getDegree() -> retval\n",
      "     |      .   @see setDegree\n",
      "     |  \n",
      "     |  getGamma(...)\n",
      "     |      getGamma() -> retval\n",
      "     |      .   @see setGamma\n",
      "     |  \n",
      "     |  getKernelType(...)\n",
      "     |      getKernelType() -> retval\n",
      "     |      .   Type of a %SVM kernel.\n",
      "     |      .   See SVM::KernelTypes. Default value is SVM::RBF.\n",
      "     |  \n",
      "     |  getNu(...)\n",
      "     |      getNu() -> retval\n",
      "     |      .   @see setNu\n",
      "     |  \n",
      "     |  getP(...)\n",
      "     |      getP() -> retval\n",
      "     |      .   @see setP\n",
      "     |  \n",
      "     |  getSupportVectors(...)\n",
      "     |      getSupportVectors() -> retval\n",
      "     |      .   @brief Retrieves all the support vectors\n",
      "     |      .   \n",
      "     |      .       The method returns all the support vectors as a floating-point matrix, where support vectors are\n",
      "     |      .       stored as matrix rows.\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .   @see setTermCriteria\n",
      "     |  \n",
      "     |  getType(...)\n",
      "     |      getType() -> retval\n",
      "     |      .   @see setType\n",
      "     |  \n",
      "     |  getUncompressedSupportVectors(...)\n",
      "     |      getUncompressedSupportVectors() -> retval\n",
      "     |      .   @brief Retrieves all the uncompressed support vectors of a linear %SVM\n",
      "     |      .   \n",
      "     |      .       The method returns all the uncompressed support vectors of a linear %SVM that the compressed\n",
      "     |      .       support vector, used for prediction, was derived from. They are returned in a floating-point\n",
      "     |      .       matrix, where the support vectors are stored as matrix rows.\n",
      "     |  \n",
      "     |  setC(...)\n",
      "     |      setC(val) -> None\n",
      "     |      .   @copybrief getC @see getC\n",
      "     |  \n",
      "     |  setClassWeights(...)\n",
      "     |      setClassWeights(val) -> None\n",
      "     |      .   @copybrief getClassWeights @see getClassWeights\n",
      "     |  \n",
      "     |  setCoef0(...)\n",
      "     |      setCoef0(val) -> None\n",
      "     |      .   @copybrief getCoef0 @see getCoef0\n",
      "     |  \n",
      "     |  setDegree(...)\n",
      "     |      setDegree(val) -> None\n",
      "     |      .   @copybrief getDegree @see getDegree\n",
      "     |  \n",
      "     |  setGamma(...)\n",
      "     |      setGamma(val) -> None\n",
      "     |      .   @copybrief getGamma @see getGamma\n",
      "     |  \n",
      "     |  setKernel(...)\n",
      "     |      setKernel(kernelType) -> None\n",
      "     |      .   Initialize with one of predefined kernels.\n",
      "     |      .   See SVM::KernelTypes.\n",
      "     |  \n",
      "     |  setNu(...)\n",
      "     |      setNu(val) -> None\n",
      "     |      .   @copybrief getNu @see getNu\n",
      "     |  \n",
      "     |  setP(...)\n",
      "     |      setP(val) -> None\n",
      "     |      .   @copybrief getP @see getP\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(val) -> None\n",
      "     |      .   @copybrief getTermCriteria @see getTermCriteria\n",
      "     |  \n",
      "     |  setType(...)\n",
      "     |      setType(val) -> None\n",
      "     |      .   @copybrief getType @see getType\n",
      "     |  \n",
      "     |  trainAuto(...)\n",
      "     |      trainAuto(samples, layout, responses[, kFold[, Cgrid[, gammaGrid[, pGrid[, nuGrid[, coeffGrid[, degreeGrid[, balanced]]]]]]]]) -> retval\n",
      "     |      .   @brief Trains an %SVM with optimal parameters\n",
      "     |      .   \n",
      "     |      .       @param samples training samples\n",
      "     |      .       @param layout See ml::SampleTypes.\n",
      "     |      .       @param responses vector of responses associated with the training samples.\n",
      "     |      .       @param kFold Cross-validation parameter. The training set is divided into kFold subsets. One\n",
      "     |      .           subset is used to test the model, the others form the train set. So, the %SVM algorithm is\n",
      "     |      .       @param Cgrid grid for C\n",
      "     |      .       @param gammaGrid grid for gamma\n",
      "     |      .       @param pGrid grid for p\n",
      "     |      .       @param nuGrid grid for nu\n",
      "     |      .       @param coeffGrid grid for coeff\n",
      "     |      .       @param degreeGrid grid for degree\n",
      "     |      .       @param balanced If true and the problem is 2-class classification then the method creates more\n",
      "     |      .           balanced cross-validation subsets that is proportions between classes in subsets are close\n",
      "     |      .           to such proportion in the whole train dataset.\n",
      "     |      .   \n",
      "     |      .       The method trains the %SVM model automatically by choosing the optimal parameters C, gamma, p,\n",
      "     |      .       nu, coef0, degree. Parameters are considered optimal when the cross-validation\n",
      "     |      .       estimate of the test set error is minimal.\n",
      "     |      .   \n",
      "     |      .       This function only makes use of SVM::getDefaultGrid for parameter optimization and thus only\n",
      "     |      .       offers rudimentary parameter options.\n",
      "     |      .   \n",
      "     |      .       This function works for the classification (SVM::C_SVC or SVM::NU_SVC) as well as for the\n",
      "     |      .       regression (SVM::EPS_SVR or SVM::NU_SVR). If it is SVM::ONE_CLASS, no optimization is made and\n",
      "     |      .       the usual %SVM with parameters specified in params is executed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   Creates empty model.\n",
      "     |      .       Use StatModel::train to train the model. Since %SVM has several parameters, you may want to\n",
      "     |      .   find the best parameters for your problem, it can be done with SVM::trainAuto.\n",
      "     |  \n",
      "     |  getDefaultGridPtr(...)\n",
      "     |      getDefaultGridPtr(param_id) -> retval\n",
      "     |      .   @brief Generates a grid for %SVM parameters.\n",
      "     |      .   \n",
      "     |      .       @param param_id %SVM parameters IDs that must be one of the SVM::ParamTypes. The grid is\n",
      "     |      .       generated for the parameter with this ID.\n",
      "     |      .   \n",
      "     |      .       The function generates a grid pointer for the specified parameter of the %SVM algorithm.\n",
      "     |      .       The grid may be passed to the function SVM::trainAuto.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath) -> retval\n",
      "     |      .   @brief Loads and creates a serialized svm from a file\n",
      "     |      .        *\n",
      "     |      .        * Use SVM::save to serialize and store an SVM to disk.\n",
      "     |      .        * Load the SVM from this file again, by calling this function with the path to the file.\n",
      "     |      .        *\n",
      "     |      .        * @param filepath path to serialized svm\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .       @param data the training data\n",
      "     |      .       @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .           computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .           different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .           the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .           that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .       @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .       The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .       computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .       @param samples The input samples, floating-point matrix\n",
      "     |      .       @param results The optional output matrix of results.\n",
      "     |      .       @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .           created with TrainData::create.\n",
      "     |      .       @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .           new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param samples training samples\n",
      "     |      .       @param layout See ml::SampleTypes.\n",
      "     |      .       @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class ml_SVMSGD(ml_StatModel)\n",
      "     |  Method resolution order:\n",
      "     |      ml_SVMSGD\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getInitialStepSize(...)\n",
      "     |      getInitialStepSize() -> retval\n",
      "     |      .   @see setInitialStepSize\n",
      "     |  \n",
      "     |  getMarginRegularization(...)\n",
      "     |      getMarginRegularization() -> retval\n",
      "     |      .   @see setMarginRegularization\n",
      "     |  \n",
      "     |  getMarginType(...)\n",
      "     |      getMarginType() -> retval\n",
      "     |      .   @see setMarginType\n",
      "     |  \n",
      "     |  getShift(...)\n",
      "     |      getShift() -> retval\n",
      "     |      .   * @return the shift of the trained model (decision function f(x) = weights * x + shift).\n",
      "     |  \n",
      "     |  getStepDecreasingPower(...)\n",
      "     |      getStepDecreasingPower() -> retval\n",
      "     |      .   @see setStepDecreasingPower\n",
      "     |  \n",
      "     |  getSvmsgdType(...)\n",
      "     |      getSvmsgdType() -> retval\n",
      "     |      .   @see setSvmsgdType\n",
      "     |  \n",
      "     |  getTermCriteria(...)\n",
      "     |      getTermCriteria() -> retval\n",
      "     |      .   @see setTermCriteria\n",
      "     |  \n",
      "     |  getWeights(...)\n",
      "     |      getWeights() -> retval\n",
      "     |      .   * @return the weights of the trained model (decision function f(x) = weights * x + shift).\n",
      "     |  \n",
      "     |  setInitialStepSize(...)\n",
      "     |      setInitialStepSize(InitialStepSize) -> None\n",
      "     |      .   @copybrief getInitialStepSize @see getInitialStepSize\n",
      "     |  \n",
      "     |  setMarginRegularization(...)\n",
      "     |      setMarginRegularization(marginRegularization) -> None\n",
      "     |      .   @copybrief getMarginRegularization @see getMarginRegularization\n",
      "     |  \n",
      "     |  setMarginType(...)\n",
      "     |      setMarginType(marginType) -> None\n",
      "     |      .   @copybrief getMarginType @see getMarginType\n",
      "     |  \n",
      "     |  setOptimalParameters(...)\n",
      "     |      setOptimalParameters([, svmsgdType[, marginType]]) -> None\n",
      "     |      .   @brief Function sets optimal parameters values for chosen SVM SGD model.\n",
      "     |      .        * @param svmsgdType is the type of SVMSGD classifier.\n",
      "     |      .        * @param marginType is the type of margin constraint.\n",
      "     |  \n",
      "     |  setStepDecreasingPower(...)\n",
      "     |      setStepDecreasingPower(stepDecreasingPower) -> None\n",
      "     |      .   @copybrief getStepDecreasingPower @see getStepDecreasingPower\n",
      "     |  \n",
      "     |  setSvmsgdType(...)\n",
      "     |      setSvmsgdType(svmsgdType) -> None\n",
      "     |      .   @copybrief getSvmsgdType @see getSvmsgdType\n",
      "     |  \n",
      "     |  setTermCriteria(...)\n",
      "     |      setTermCriteria(val) -> None\n",
      "     |      .   @copybrief getTermCriteria @see getTermCriteria\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create() -> retval\n",
      "     |      .   @brief Creates empty model.\n",
      "     |      .        * Use StatModel::train to train the model. Since %SVMSGD has several parameters, you may want to\n",
      "     |      .        * find the best parameters for your problem or use setOptimalParameters() to set some default parameters.\n",
      "     |  \n",
      "     |  load(...)\n",
      "     |      load(filepath[, nodeName]) -> retval\n",
      "     |      .   @brief Loads and creates a serialized SVMSGD from a file\n",
      "     |      .        *\n",
      "     |      .        * Use SVMSGD::save to serialize and store an SVMSGD to disk.\n",
      "     |      .        * Load the SVMSGD from this file again, by calling this function with the path to the file.\n",
      "     |      .        * Optionally specify the node for the file containing the classifier\n",
      "     |      .        *\n",
      "     |      .        * @param filepath path to serialized SVMSGD\n",
      "     |      .        * @param nodeName name of node containing the classifier\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ml_StatModel:\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .       @param data the training data\n",
      "     |      .       @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .           computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .           different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .           the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .           that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .       @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .       The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .       computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .       @param samples The input samples, floating-point matrix\n",
      "     |      .       @param results The optional output matrix of results.\n",
      "     |      .       @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .           created with TrainData::create.\n",
      "     |      .       @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .           new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param samples training samples\n",
      "     |      .       @param layout See ml::SampleTypes.\n",
      "     |      .       @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class ml_StatModel(Algorithm)\n",
      "     |  Method resolution order:\n",
      "     |      ml_StatModel\n",
      "     |      Algorithm\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  calcError(...)\n",
      "     |      calcError(data, test[, resp]) -> retval, resp\n",
      "     |      .   @brief Computes error on the training or test dataset\n",
      "     |      .   \n",
      "     |      .       @param data the training data\n",
      "     |      .       @param test if true, the error is computed over the test subset of the data, otherwise it's\n",
      "     |      .           computed over the training subset of the data. Please note that if you loaded a completely\n",
      "     |      .           different dataset to evaluate already trained classifier, you will probably want not to set\n",
      "     |      .           the test subset at all with TrainData::setTrainTestSplitRatio and specify test=false, so\n",
      "     |      .           that the error is computed for the whole new set. Yes, this sounds a bit confusing.\n",
      "     |      .       @param resp the optional output responses.\n",
      "     |      .   \n",
      "     |      .       The method uses StatModel::predict to compute the error. For regression models the error is\n",
      "     |      .       computed as RMS, for classifiers - as a percent of missclassified samples (0%-100%).\n",
      "     |  \n",
      "     |  empty(...)\n",
      "     |      empty() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarCount(...)\n",
      "     |      getVarCount() -> retval\n",
      "     |      .   @brief Returns the number of variables in training samples\n",
      "     |  \n",
      "     |  isClassifier(...)\n",
      "     |      isClassifier() -> retval\n",
      "     |      .   @brief Returns true if the model is classifier\n",
      "     |  \n",
      "     |  isTrained(...)\n",
      "     |      isTrained() -> retval\n",
      "     |      .   @brief Returns true if the model is trained\n",
      "     |  \n",
      "     |  predict(...)\n",
      "     |      predict(samples[, results[, flags]]) -> retval, results\n",
      "     |      .   @brief Predicts response(s) for the provided sample(s)\n",
      "     |      .   \n",
      "     |      .       @param samples The input samples, floating-point matrix\n",
      "     |      .       @param results The optional output matrix of results.\n",
      "     |      .       @param flags The optional flags, model-dependent. See cv::ml::StatModel::Flags.\n",
      "     |  \n",
      "     |  train(...)\n",
      "     |      train(trainData[, flags]) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param trainData training data that can be loaded from file using TrainData::loadFromCSV or\n",
      "     |      .           created with TrainData::create.\n",
      "     |      .       @param flags optional flags, depending on the model. Some of the models can be updated with the\n",
      "     |      .           new training samples, not completely overwritten (such as NormalBayesClassifier or ANN_MLP).\n",
      "     |      \n",
      "     |      \n",
      "     |      \n",
      "     |      train(samples, layout, responses) -> retval\n",
      "     |      .   @brief Trains the statistical model\n",
      "     |      .   \n",
      "     |      .       @param samples training samples\n",
      "     |      .       @param layout See ml::SampleTypes.\n",
      "     |      .       @param responses vector of responses associated with the training samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Algorithm:\n",
      "     |  \n",
      "     |  clear(...)\n",
      "     |      clear() -> None\n",
      "     |      .   @brief Clears the algorithm state\n",
      "     |  \n",
      "     |  getDefaultName(...)\n",
      "     |      getDefaultName() -> retval\n",
      "     |      .   Returns the algorithm string identifier.\n",
      "     |      .   This string is used as top level xml/yml node tag when the object is saved to a file or string.\n",
      "     |  \n",
      "     |  read(...)\n",
      "     |      read(fn) -> None\n",
      "     |      .   @brief Reads algorithm parameters from a file storage\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(filename) -> None\n",
      "     |      .   Saves the algorithm to a file.\n",
      "     |      .   In order to make this method work, the derived class must implement Algorithm::write(FileStorage& fs).\n",
      "     |  \n",
      "     |  write(...)\n",
      "     |      write(fs[, name]) -> None\n",
      "     |      .   @brief simplified API for language bindings\n",
      "     |      .       * @overload\n",
      "    \n",
      "    class ml_TrainData(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  getCatCount(...)\n",
      "     |      getCatCount(vi) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCatMap(...)\n",
      "     |      getCatMap() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getCatOfs(...)\n",
      "     |      getCatOfs() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getClassLabels(...)\n",
      "     |      getClassLabels() -> retval\n",
      "     |      .   @brief Returns the vector of class labels\n",
      "     |      .   \n",
      "     |      .       The function returns vector of unique labels occurred in the responses.\n",
      "     |  \n",
      "     |  getDefaultSubstValues(...)\n",
      "     |      getDefaultSubstValues() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getLayout(...)\n",
      "     |      getLayout() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getMissing(...)\n",
      "     |      getMissing() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNAllVars(...)\n",
      "     |      getNAllVars() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNSamples(...)\n",
      "     |      getNSamples() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNTestSamples(...)\n",
      "     |      getNTestSamples() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNTrainSamples(...)\n",
      "     |      getNTrainSamples() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNVars(...)\n",
      "     |      getNVars() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getNames(...)\n",
      "     |      getNames(names) -> None\n",
      "     |      .   @brief Returns vector of symbolic names captured in loadFromCSV()\n",
      "     |  \n",
      "     |  getNormCatResponses(...)\n",
      "     |      getNormCatResponses() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getResponseType(...)\n",
      "     |      getResponseType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getResponses(...)\n",
      "     |      getResponses() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSample(...)\n",
      "     |      getSample(varIdx, sidx, buf) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSampleWeights(...)\n",
      "     |      getSampleWeights() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getSamples(...)\n",
      "     |      getSamples() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTestNormCatResponses(...)\n",
      "     |      getTestNormCatResponses() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTestResponses(...)\n",
      "     |      getTestResponses() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTestSampleIdx(...)\n",
      "     |      getTestSampleIdx() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTestSampleWeights(...)\n",
      "     |      getTestSampleWeights() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTestSamples(...)\n",
      "     |      getTestSamples() -> retval\n",
      "     |      .   @brief Returns matrix of test samples\n",
      "     |  \n",
      "     |  getTrainNormCatResponses(...)\n",
      "     |      getTrainNormCatResponses() -> retval\n",
      "     |      .   @brief Returns the vector of normalized categorical responses\n",
      "     |      .   \n",
      "     |      .       The function returns vector of responses. Each response is integer from `0` to `<number of\n",
      "     |      .       classes>-1`. The actual label value can be retrieved then from the class label vector, see\n",
      "     |      .       TrainData::getClassLabels.\n",
      "     |  \n",
      "     |  getTrainResponses(...)\n",
      "     |      getTrainResponses() -> retval\n",
      "     |      .   @brief Returns the vector of responses\n",
      "     |      .   \n",
      "     |      .       The function returns ordered or the original categorical responses. Usually it's used in\n",
      "     |      .       regression algorithms.\n",
      "     |  \n",
      "     |  getTrainSampleIdx(...)\n",
      "     |      getTrainSampleIdx() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTrainSampleWeights(...)\n",
      "     |      getTrainSampleWeights() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getTrainSamples(...)\n",
      "     |      getTrainSamples([, layout[, compressSamples[, compressVars]]]) -> retval\n",
      "     |      .   @brief Returns matrix of train samples\n",
      "     |      .   \n",
      "     |      .       @param layout The requested layout. If it's different from the initial one, the matrix is\n",
      "     |      .           transposed. See ml::SampleTypes.\n",
      "     |      .       @param compressSamples if true, the function returns only the training samples (specified by\n",
      "     |      .           sampleIdx)\n",
      "     |      .       @param compressVars if true, the function returns the shorter training samples, containing only\n",
      "     |      .           the active variables.\n",
      "     |      .   \n",
      "     |      .       In current implementation the function tries to avoid physical data copying and returns the\n",
      "     |      .       matrix stored inside TrainData (unless the transposition or compression is needed).\n",
      "     |  \n",
      "     |  getValues(...)\n",
      "     |      getValues(vi, sidx, values) -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarIdx(...)\n",
      "     |      getVarIdx() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarSymbolFlags(...)\n",
      "     |      getVarSymbolFlags() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  getVarType(...)\n",
      "     |      getVarType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  setTrainTestSplit(...)\n",
      "     |      setTrainTestSplit(count[, shuffle]) -> None\n",
      "     |      .   @brief Splits the training data into the training and test parts\n",
      "     |      .       @sa TrainData::setTrainTestSplitRatio\n",
      "     |  \n",
      "     |  setTrainTestSplitRatio(...)\n",
      "     |      setTrainTestSplitRatio(ratio[, shuffle]) -> None\n",
      "     |      .   @brief Splits the training data into the training and test parts\n",
      "     |      .   \n",
      "     |      .       The function selects a subset of specified relative size and then returns it as the training\n",
      "     |      .       set. If the function is not called, all the data is used for training. Please, note that for\n",
      "     |      .       each of TrainData::getTrain\\* there is corresponding TrainData::getTest\\*, so that the test\n",
      "     |      .       subset can be retrieved and processed as well.\n",
      "     |      .       @sa TrainData::setTrainTestSplit\n",
      "     |  \n",
      "     |  shuffleTrainTest(...)\n",
      "     |      shuffleTrainTest() -> None\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create(samples, layout, responses[, varIdx[, sampleIdx[, sampleWeights[, varType]]]]) -> retval\n",
      "     |      .   @brief Creates training data from in-memory arrays.\n",
      "     |      .   \n",
      "     |      .       @param samples matrix of samples. It should have CV_32F type.\n",
      "     |      .       @param layout see ml::SampleTypes.\n",
      "     |      .       @param responses matrix of responses. If the responses are scalar, they should be stored as a\n",
      "     |      .           single row or as a single column. The matrix should have type CV_32F or CV_32S (in the\n",
      "     |      .           former case the responses are considered as ordered by default; in the latter case - as\n",
      "     |      .           categorical)\n",
      "     |      .       @param varIdx vector specifying which variables to use for training. It can be an integer vector\n",
      "     |      .           (CV_32S) containing 0-based variable indices or byte vector (CV_8U) containing a mask of\n",
      "     |      .           active variables.\n",
      "     |      .       @param sampleIdx vector specifying which samples to use for training. It can be an integer\n",
      "     |      .           vector (CV_32S) containing 0-based sample indices or byte vector (CV_8U) containing a mask\n",
      "     |      .           of training samples.\n",
      "     |      .       @param sampleWeights optional vector with weights for each sample. It should have CV_32F type.\n",
      "     |      .       @param varType optional vector of type CV_8U and size `<number_of_variables_in_samples> +\n",
      "     |      .           <number_of_variables_in_responses>`, containing types of each input and output variable. See\n",
      "     |      .           ml::VariableTypes.\n",
      "     |  \n",
      "     |  getSubMatrix(...)\n",
      "     |      getSubMatrix(matrix, idx, layout) -> retval\n",
      "     |      .   @brief Extract from matrix rows/cols specified by passed indexes.\n",
      "     |      .       @param matrix input matrix (supported types: CV_32S, CV_32F, CV_64F)\n",
      "     |      .       @param idx 1D index vector\n",
      "     |      .       @param layout specifies to extract rows (cv::ml::ROW_SAMPLES) or to extract columns (cv::ml::COL_SAMPLES)\n",
      "     |  \n",
      "     |  getSubVector(...)\n",
      "     |      getSubVector(vec, idx) -> retval\n",
      "     |      .   @brief Extract from 1D vector elements specified by passed indexes.\n",
      "     |      .       @param vec input vector (supported types: CV_32S, CV_32F, CV_64F)\n",
      "     |      .       @param idx 1D index vector\n",
      "    \n",
      "    class ocl_Device(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  OpenCLVersion(...)\n",
      "     |      OpenCLVersion() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  OpenCL_C_Version(...)\n",
      "     |      OpenCL_C_Version() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  addressBits(...)\n",
      "     |      addressBits() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  available(...)\n",
      "     |      available() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  compilerAvailable(...)\n",
      "     |      compilerAvailable() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  deviceVersionMajor(...)\n",
      "     |      deviceVersionMajor() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  deviceVersionMinor(...)\n",
      "     |      deviceVersionMinor() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  doubleFPConfig(...)\n",
      "     |      doubleFPConfig() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  driverVersion(...)\n",
      "     |      driverVersion() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  endianLittle(...)\n",
      "     |      endianLittle() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  errorCorrectionSupport(...)\n",
      "     |      errorCorrectionSupport() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  executionCapabilities(...)\n",
      "     |      executionCapabilities() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  extensions(...)\n",
      "     |      extensions() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  globalMemCacheLineSize(...)\n",
      "     |      globalMemCacheLineSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  globalMemCacheSize(...)\n",
      "     |      globalMemCacheSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  globalMemCacheType(...)\n",
      "     |      globalMemCacheType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  globalMemSize(...)\n",
      "     |      globalMemSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  halfFPConfig(...)\n",
      "     |      halfFPConfig() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  hostUnifiedMemory(...)\n",
      "     |      hostUnifiedMemory() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  image2DMaxHeight(...)\n",
      "     |      image2DMaxHeight() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  image2DMaxWidth(...)\n",
      "     |      image2DMaxWidth() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  image3DMaxDepth(...)\n",
      "     |      image3DMaxDepth() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  image3DMaxHeight(...)\n",
      "     |      image3DMaxHeight() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  image3DMaxWidth(...)\n",
      "     |      image3DMaxWidth() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  imageFromBufferSupport(...)\n",
      "     |      imageFromBufferSupport() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  imageMaxArraySize(...)\n",
      "     |      imageMaxArraySize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  imageMaxBufferSize(...)\n",
      "     |      imageMaxBufferSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  imageSupport(...)\n",
      "     |      imageSupport() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  intelSubgroupsSupport(...)\n",
      "     |      intelSubgroupsSupport() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isAMD(...)\n",
      "     |      isAMD() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isExtensionSupported(...)\n",
      "     |      isExtensionSupported(extensionName) -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isIntel(...)\n",
      "     |      isIntel() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  isNVidia(...)\n",
      "     |      isNVidia() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  linkerAvailable(...)\n",
      "     |      linkerAvailable() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  localMemSize(...)\n",
      "     |      localMemSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  localMemType(...)\n",
      "     |      localMemType() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxClockFrequency(...)\n",
      "     |      maxClockFrequency() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxComputeUnits(...)\n",
      "     |      maxComputeUnits() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxConstantArgs(...)\n",
      "     |      maxConstantArgs() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxConstantBufferSize(...)\n",
      "     |      maxConstantBufferSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxMemAllocSize(...)\n",
      "     |      maxMemAllocSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxParameterSize(...)\n",
      "     |      maxParameterSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxReadImageArgs(...)\n",
      "     |      maxReadImageArgs() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxSamplers(...)\n",
      "     |      maxSamplers() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxWorkGroupSize(...)\n",
      "     |      maxWorkGroupSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxWorkItemDims(...)\n",
      "     |      maxWorkItemDims() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  maxWriteImageArgs(...)\n",
      "     |      maxWriteImageArgs() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  memBaseAddrAlign(...)\n",
      "     |      memBaseAddrAlign() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  name(...)\n",
      "     |      name() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthChar(...)\n",
      "     |      nativeVectorWidthChar() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthDouble(...)\n",
      "     |      nativeVectorWidthDouble() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthFloat(...)\n",
      "     |      nativeVectorWidthFloat() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthHalf(...)\n",
      "     |      nativeVectorWidthHalf() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthInt(...)\n",
      "     |      nativeVectorWidthInt() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthLong(...)\n",
      "     |      nativeVectorWidthLong() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  nativeVectorWidthShort(...)\n",
      "     |      nativeVectorWidthShort() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthChar(...)\n",
      "     |      preferredVectorWidthChar() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthDouble(...)\n",
      "     |      preferredVectorWidthDouble() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthFloat(...)\n",
      "     |      preferredVectorWidthFloat() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthHalf(...)\n",
      "     |      preferredVectorWidthHalf() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthInt(...)\n",
      "     |      preferredVectorWidthInt() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthLong(...)\n",
      "     |      preferredVectorWidthLong() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  preferredVectorWidthShort(...)\n",
      "     |      preferredVectorWidthShort() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  printfBufferSize(...)\n",
      "     |      printfBufferSize() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  profilingTimerResolution(...)\n",
      "     |      profilingTimerResolution() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  singleFPConfig(...)\n",
      "     |      singleFPConfig() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  vendorID(...)\n",
      "     |      vendorID() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  vendorName(...)\n",
      "     |      vendorName() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  version(...)\n",
      "     |      version() -> retval\n",
      "     |      .\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  getDefault(...)\n",
      "     |      getDefault() -> retval\n",
      "     |      .\n",
      "\n",
      "FUNCTIONS\n",
      "    AKAZE_create(...)\n",
      "        AKAZE_create([, descriptor_type[, descriptor_size[, descriptor_channels[, threshold[, nOctaves[, nOctaveLayers[, diffusivity]]]]]]]) -> retval\n",
      "        .   @brief The AKAZE constructor\n",
      "        .   \n",
      "        .       @param descriptor_type Type of the extracted descriptor: DESCRIPTOR_KAZE,\n",
      "        .       DESCRIPTOR_KAZE_UPRIGHT, DESCRIPTOR_MLDB or DESCRIPTOR_MLDB_UPRIGHT.\n",
      "        .       @param descriptor_size Size of the descriptor in bits. 0 -\\> Full size\n",
      "        .       @param descriptor_channels Number of channels in the descriptor (1, 2, 3)\n",
      "        .       @param threshold Detector response threshold to accept point\n",
      "        .       @param nOctaves Maximum octave evolution of the image\n",
      "        .       @param nOctaveLayers Default number of sublevels per scale level\n",
      "        .       @param diffusivity Diffusivity type. DIFF_PM_G1, DIFF_PM_G2, DIFF_WEICKERT or\n",
      "        .       DIFF_CHARBONNIER\n",
      "    \n",
      "    AgastFeatureDetector_create(...)\n",
      "        AgastFeatureDetector_create([, threshold[, nonmaxSuppression[, type]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    BFMatcher_create(...)\n",
      "        BFMatcher_create([, normType[, crossCheck]]) -> retval\n",
      "        .   @brief Brute-force matcher create method.\n",
      "        .       @param normType One of NORM_L1, NORM_L2, NORM_HAMMING, NORM_HAMMING2. L1 and L2 norms are\n",
      "        .       preferable choices for SIFT and SURF descriptors, NORM_HAMMING should be used with ORB, BRISK and\n",
      "        .       BRIEF, NORM_HAMMING2 should be used with ORB when WTA_K==3 or 4 (see ORB::ORB constructor\n",
      "        .       description).\n",
      "        .       @param crossCheck If it is false, this is will be default BFMatcher behaviour when it finds the k\n",
      "        .       nearest neighbors for each query descriptor. If crossCheck==true, then the knnMatch() method with\n",
      "        .       k=1 will only return pairs (i,j) such that for i-th query descriptor the j-th descriptor in the\n",
      "        .       matcher's collection is the nearest and vice versa, i.e. the BFMatcher will only return consistent\n",
      "        .       pairs. Such technique usually produces best results with minimal number of outliers when there are\n",
      "        .       enough matches. This is alternative to the ratio test, used by D. Lowe in SIFT paper.\n",
      "    \n",
      "    BRISK_create(...)\n",
      "        BRISK_create([, thresh[, octaves[, patternScale]]]) -> retval\n",
      "        .   @brief The BRISK constructor\n",
      "        .   \n",
      "        .       @param thresh AGAST detection threshold score.\n",
      "        .       @param octaves detection octaves. Use 0 to do single scale.\n",
      "        .       @param patternScale apply this scale to the pattern used for sampling the neighbourhood of a\n",
      "        .       keypoint.\n",
      "        \n",
      "        \n",
      "        \n",
      "        BRISK_create(radiusList, numberList[, dMax[, dMin[, indexChange]]]) -> retval\n",
      "        .   @brief The BRISK constructor for a custom pattern\n",
      "        .   \n",
      "        .       @param radiusList defines the radii (in pixels) where the samples around a keypoint are taken (for\n",
      "        .       keypoint scale 1).\n",
      "        .       @param numberList defines the number of sampling points on the sampling circle. Must be the same\n",
      "        .       size as radiusList..\n",
      "        .       @param dMax threshold for the short pairings used for descriptor formation (in pixels for keypoint\n",
      "        .       scale 1).\n",
      "        .       @param dMin threshold for the long pairings used for orientation determination (in pixels for\n",
      "        .       keypoint scale 1).\n",
      "        .   @param indexChange index remapping of the bits.\n",
      "        \n",
      "        \n",
      "        \n",
      "        BRISK_create(thresh, octaves, radiusList, numberList[, dMax[, dMin[, indexChange]]]) -> retval\n",
      "        .   @brief The BRISK constructor for a custom pattern, detection threshold and octaves\n",
      "        .   \n",
      "        .       @param thresh AGAST detection threshold score.\n",
      "        .       @param octaves detection octaves. Use 0 to do single scale.\n",
      "        .       @param radiusList defines the radii (in pixels) where the samples around a keypoint are taken (for\n",
      "        .       keypoint scale 1).\n",
      "        .       @param numberList defines the number of sampling points on the sampling circle. Must be the same\n",
      "        .       size as radiusList..\n",
      "        .       @param dMax threshold for the short pairings used for descriptor formation (in pixels for keypoint\n",
      "        .       scale 1).\n",
      "        .       @param dMin threshold for the long pairings used for orientation determination (in pixels for\n",
      "        .       keypoint scale 1).\n",
      "        .   @param indexChange index remapping of the bits.\n",
      "    \n",
      "    CamShift(...)\n",
      "        CamShift(probImage, window, criteria) -> retval, window\n",
      "        .   @brief Finds an object center, size, and orientation.\n",
      "        .   \n",
      "        .   @param probImage Back projection of the object histogram. See calcBackProject.\n",
      "        .   @param window Initial search window.\n",
      "        .   @param criteria Stop criteria for the underlying meanShift.\n",
      "        .   returns\n",
      "        .   (in old interfaces) Number of iterations CAMSHIFT took to converge\n",
      "        .   The function implements the CAMSHIFT object tracking algorithm @cite Bradski98 . First, it finds an\n",
      "        .   object center using meanShift and then adjusts the window size and finds the optimal rotation. The\n",
      "        .   function returns the rotated rectangle structure that includes the object position, size, and\n",
      "        .   orientation. The next position of the search window can be obtained with RotatedRect::boundingRect()\n",
      "        .   \n",
      "        .   See the OpenCV sample camshiftdemo.c that tracks colored objects.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   (Python) A sample explaining the camshift tracking algorithm can be found at\n",
      "        .       opencv_source_code/samples/python/camshift.py\n",
      "    \n",
      "    Canny(...)\n",
      "        Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]]) -> edges\n",
      "        .   @brief Finds edges in an image using the Canny algorithm @cite Canny86 .\n",
      "        .   \n",
      "        .   The function finds edges in the input image and marks them in the output map edges using the\n",
      "        .   Canny algorithm. The smallest value between threshold1 and threshold2 is used for edge linking. The\n",
      "        .   largest value is used to find initial segments of strong edges. See\n",
      "        .   <http://en.wikipedia.org/wiki/Canny_edge_detector>\n",
      "        .   \n",
      "        .   @param image 8-bit input image.\n",
      "        .   @param edges output edge map; single channels 8-bit image, which has the same size as image .\n",
      "        .   @param threshold1 first threshold for the hysteresis procedure.\n",
      "        .   @param threshold2 second threshold for the hysteresis procedure.\n",
      "        .   @param apertureSize aperture size for the Sobel operator.\n",
      "        .   @param L2gradient a flag, indicating whether a more accurate \\f$L_2\\f$ norm\n",
      "        .   \\f$=\\sqrt{(dI/dx)^2 + (dI/dy)^2}\\f$ should be used to calculate the image gradient magnitude (\n",
      "        .   L2gradient=true ), or whether the default \\f$L_1\\f$ norm \\f$=|dI/dx|+|dI/dy|\\f$ is enough (\n",
      "        .   L2gradient=false ).\n",
      "        \n",
      "        \n",
      "        \n",
      "        Canny(dx, dy, threshold1, threshold2[, edges[, L2gradient]]) -> edges\n",
      "        .   \\overload\n",
      "        .   \n",
      "        .   Finds edges in an image using the Canny algorithm with custom image gradient.\n",
      "        .   \n",
      "        .   @param dx 16-bit x derivative of input image (CV_16SC1 or CV_16SC3).\n",
      "        .   @param dy 16-bit y derivative of input image (same type as dx).\n",
      "        .   @param edges output edge map; single channels 8-bit image, which has the same size as image .\n",
      "        .   @param threshold1 first threshold for the hysteresis procedure.\n",
      "        .   @param threshold2 second threshold for the hysteresis procedure.\n",
      "        .   @param L2gradient a flag, indicating whether a more accurate \\f$L_2\\f$ norm\n",
      "        .   \\f$=\\sqrt{(dI/dx)^2 + (dI/dy)^2}\\f$ should be used to calculate the image gradient magnitude (\n",
      "        .   L2gradient=true ), or whether the default \\f$L_1\\f$ norm \\f$=|dI/dx|+|dI/dy|\\f$ is enough (\n",
      "        .   L2gradient=false ).\n",
      "    \n",
      "    CascadeClassifier_convert(...)\n",
      "        CascadeClassifier_convert(oldcascade, newcascade) -> retval\n",
      "        .\n",
      "    \n",
      "    DISOpticalFlow_create(...)\n",
      "        DISOpticalFlow_create([, preset]) -> retval\n",
      "        .   @brief Creates an instance of DISOpticalFlow\n",
      "        .   \n",
      "        .       @param preset one of PRESET_ULTRAFAST, PRESET_FAST and PRESET_MEDIUM\n",
      "    \n",
      "    DescriptorMatcher_create(...)\n",
      "        DescriptorMatcher_create(descriptorMatcherType) -> retval\n",
      "        .   @brief Creates a descriptor matcher of a given type with the default parameters (using default\n",
      "        .       constructor).\n",
      "        .   \n",
      "        .       @param descriptorMatcherType Descriptor matcher type. Now the following matcher types are\n",
      "        .       supported:\n",
      "        .       -   `BruteForce` (it uses L2 )\n",
      "        .       -   `BruteForce-L1`\n",
      "        .       -   `BruteForce-Hamming`\n",
      "        .       -   `BruteForce-Hamming(2)`\n",
      "        .       -   `FlannBased`\n",
      "        \n",
      "        \n",
      "        \n",
      "        DescriptorMatcher_create(matcherType) -> retval\n",
      "        .\n",
      "    \n",
      "    EMD(...)\n",
      "        EMD(signature1, signature2, distType[, cost[, lowerBound[, flow]]]) -> retval, lowerBound, flow\n",
      "        .   @brief Computes the \"minimal work\" distance between two weighted point configurations.\n",
      "        .   \n",
      "        .   The function computes the earth mover distance and/or a lower boundary of the distance between the\n",
      "        .   two weighted point configurations. One of the applications described in @cite RubnerSept98,\n",
      "        .   @cite Rubner2000 is multi-dimensional histogram comparison for image retrieval. EMD is a transportation\n",
      "        .   problem that is solved using some modification of a simplex algorithm, thus the complexity is\n",
      "        .   exponential in the worst case, though, on average it is much faster. In the case of a real metric\n",
      "        .   the lower boundary can be calculated even faster (using linear-time algorithm) and it can be used\n",
      "        .   to determine roughly whether the two signatures are far enough so that they cannot relate to the\n",
      "        .   same object.\n",
      "        .   \n",
      "        .   @param signature1 First signature, a \\f$\\texttt{size1}\\times \\texttt{dims}+1\\f$ floating-point matrix.\n",
      "        .   Each row stores the point weight followed by the point coordinates. The matrix is allowed to have\n",
      "        .   a single column (weights only) if the user-defined cost matrix is used. The weights must be\n",
      "        .   non-negative and have at least one non-zero value.\n",
      "        .   @param signature2 Second signature of the same format as signature1 , though the number of rows\n",
      "        .   may be different. The total weights may be different. In this case an extra \"dummy\" point is added\n",
      "        .   to either signature1 or signature2. The weights must be non-negative and have at least one non-zero\n",
      "        .   value.\n",
      "        .   @param distType Used metric. See #DistanceTypes.\n",
      "        .   @param cost User-defined \\f$\\texttt{size1}\\times \\texttt{size2}\\f$ cost matrix. Also, if a cost matrix\n",
      "        .   is used, lower boundary lowerBound cannot be calculated because it needs a metric function.\n",
      "        .   @param lowerBound Optional input/output parameter: lower boundary of a distance between the two\n",
      "        .   signatures that is a distance between mass centers. The lower boundary may not be calculated if\n",
      "        .   the user-defined cost matrix is used, the total weights of point configurations are not equal, or\n",
      "        .   if the signatures consist of weights only (the signature matrices have a single column). You\n",
      "        .   **must** initialize \\*lowerBound . If the calculated distance between mass centers is greater or\n",
      "        .   equal to \\*lowerBound (it means that the signatures are far enough), the function does not\n",
      "        .   calculate EMD. In any case \\*lowerBound is set to the calculated distance between mass centers on\n",
      "        .   return. Thus, if you want to calculate both distance between mass centers and EMD, \\*lowerBound\n",
      "        .   should be set to 0.\n",
      "        .   @param flow Resultant \\f$\\texttt{size1} \\times \\texttt{size2}\\f$ flow matrix: \\f$\\texttt{flow}_{i,j}\\f$ is\n",
      "        .   a flow from \\f$i\\f$ -th point of signature1 to \\f$j\\f$ -th point of signature2 .\n",
      "    \n",
      "    FarnebackOpticalFlow_create(...)\n",
      "        FarnebackOpticalFlow_create([, numLevels[, pyrScale[, fastPyramids[, winSize[, numIters[, polyN[, polySigma[, flags]]]]]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    FastFeatureDetector_create(...)\n",
      "        FastFeatureDetector_create([, threshold[, nonmaxSuppression[, type]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    FlannBasedMatcher_create(...)\n",
      "        FlannBasedMatcher_create() -> retval\n",
      "        .\n",
      "    \n",
      "    GFTTDetector_create(...)\n",
      "        GFTTDetector_create([, maxCorners[, qualityLevel[, minDistance[, blockSize[, useHarrisDetector[, k]]]]]]) -> retval\n",
      "        .   \n",
      "        \n",
      "        \n",
      "        \n",
      "        GFTTDetector_create(maxCorners, qualityLevel, minDistance, blockSize, gradiantSize[, useHarrisDetector[, k]]) -> retval\n",
      "        .\n",
      "    \n",
      "    GaussianBlur(...)\n",
      "        GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType]]]) -> dst\n",
      "        .   @brief Blurs an image using a Gaussian filter.\n",
      "        .   \n",
      "        .   The function convolves the source image with the specified Gaussian kernel. In-place filtering is\n",
      "        .   supported.\n",
      "        .   \n",
      "        .   @param src input image; the image can have any number of channels, which are processed\n",
      "        .   independently, but the depth should be CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
      "        .   @param dst output image of the same size and type as src.\n",
      "        .   @param ksize Gaussian kernel size. ksize.width and ksize.height can differ but they both must be\n",
      "        .   positive and odd. Or, they can be zero's and then they are computed from sigma.\n",
      "        .   @param sigmaX Gaussian kernel standard deviation in X direction.\n",
      "        .   @param sigmaY Gaussian kernel standard deviation in Y direction; if sigmaY is zero, it is set to be\n",
      "        .   equal to sigmaX, if both sigmas are zeros, they are computed from ksize.width and ksize.height,\n",
      "        .   respectively (see #getGaussianKernel for details); to fully control the result regardless of\n",
      "        .   possible future modifications of all this semantics, it is recommended to specify all of ksize,\n",
      "        .   sigmaX, and sigmaY.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes. #BORDER_WRAP is not supported.\n",
      "        .   \n",
      "        .   @sa  sepFilter2D, filter2D, blur, boxFilter, bilateralFilter, medianBlur\n",
      "    \n",
      "    HOGDescriptor_getDaimlerPeopleDetector(...)\n",
      "        HOGDescriptor_getDaimlerPeopleDetector() -> retval\n",
      "        .   @brief Returns coefficients of the classifier trained for people detection (for 48x96 windows).\n",
      "    \n",
      "    HOGDescriptor_getDefaultPeopleDetector(...)\n",
      "        HOGDescriptor_getDefaultPeopleDetector() -> retval\n",
      "        .   @brief Returns coefficients of the classifier trained for people detection (for 64x128 windows).\n",
      "    \n",
      "    HoughCircles(...)\n",
      "        HoughCircles(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) -> circles\n",
      "        .   @brief Finds circles in a grayscale image using the Hough transform.\n",
      "        .   \n",
      "        .   The function finds circles in a grayscale image using a modification of the Hough transform.\n",
      "        .   \n",
      "        .   Example: :\n",
      "        .   @include snippets/imgproc_HoughLinesCircles.cpp\n",
      "        .   \n",
      "        .   @note Usually the function detects the centers of circles well. However, it may fail to find correct\n",
      "        .   radii. You can assist to the function by specifying the radius range ( minRadius and maxRadius ) if\n",
      "        .   you know it. Or, in the case of #HOUGH_GRADIENT method you may set maxRadius to a negative number\n",
      "        .   to return centers only without radius search, and find the correct radius using an additional procedure.\n",
      "        .   \n",
      "        .   It also helps to smooth image a bit unless it's already soft. For example,\n",
      "        .   GaussianBlur() with 7x7 kernel and 1.5x1.5 sigma or similar blurring may help.\n",
      "        .   \n",
      "        .   @param image 8-bit, single-channel, grayscale input image.\n",
      "        .   @param circles Output vector of found circles. Each vector is encoded as  3 or 4 element\n",
      "        .   floating-point vector \\f$(x, y, radius)\\f$ or \\f$(x, y, radius, votes)\\f$ .\n",
      "        .   @param method Detection method, see #HoughModes. The available methods are #HOUGH_GRADIENT and #HOUGH_GRADIENT_ALT.\n",
      "        .   @param dp Inverse ratio of the accumulator resolution to the image resolution. For example, if\n",
      "        .   dp=1 , the accumulator has the same resolution as the input image. If dp=2 , the accumulator has\n",
      "        .   half as big width and height. For #HOUGH_GRADIENT_ALT the recommended value is dp=1.5,\n",
      "        .   unless some small very circles need to be detected.\n",
      "        .   @param minDist Minimum distance between the centers of the detected circles. If the parameter is\n",
      "        .   too small, multiple neighbor circles may be falsely detected in addition to a true one. If it is\n",
      "        .   too large, some circles may be missed.\n",
      "        .   @param param1 First method-specific parameter. In case of #HOUGH_GRADIENT and #HOUGH_GRADIENT_ALT,\n",
      "        .   it is the higher threshold of the two passed to the Canny edge detector (the lower one is twice smaller).\n",
      "        .   Note that #HOUGH_GRADIENT_ALT uses #Scharr algorithm to compute image derivatives, so the threshold value\n",
      "        .   shough normally be higher, such as 300 or normally exposed and contrasty images.\n",
      "        .   @param param2 Second method-specific parameter. In case of #HOUGH_GRADIENT, it is the\n",
      "        .   accumulator threshold for the circle centers at the detection stage. The smaller it is, the more\n",
      "        .   false circles may be detected. Circles, corresponding to the larger accumulator values, will be\n",
      "        .   returned first. In the case of #HOUGH_GRADIENT_ALT algorithm, this is the circle \"perfectness\" measure.\n",
      "        .   The closer it to 1, the better shaped circles algorithm selects. In most cases 0.9 should be fine.\n",
      "        .   If you want get better detection of small circles, you may decrease it to 0.85, 0.8 or even less.\n",
      "        .   But then also try to limit the search range [minRadius, maxRadius] to avoid many false circles.\n",
      "        .   @param minRadius Minimum circle radius.\n",
      "        .   @param maxRadius Maximum circle radius. If <= 0, uses the maximum image dimension. If < 0, #HOUGH_GRADIENT returns\n",
      "        .   centers without finding the radius. #HOUGH_GRADIENT_ALT always computes circle radiuses.\n",
      "        .   \n",
      "        .   @sa fitEllipse, minEnclosingCircle\n",
      "    \n",
      "    HoughLines(...)\n",
      "        HoughLines(image, rho, theta, threshold[, lines[, srn[, stn[, min_theta[, max_theta]]]]]) -> lines\n",
      "        .   @brief Finds lines in a binary image using the standard Hough transform.\n",
      "        .   \n",
      "        .   The function implements the standard or standard multi-scale Hough transform algorithm for line\n",
      "        .   detection. See <http://homepages.inf.ed.ac.uk/rbf/HIPR2/hough.htm> for a good explanation of Hough\n",
      "        .   transform.\n",
      "        .   \n",
      "        .   @param image 8-bit, single-channel binary source image. The image may be modified by the function.\n",
      "        .   @param lines Output vector of lines. Each line is represented by a 2 or 3 element vector\n",
      "        .   \\f$(\\rho, \\theta)\\f$ or \\f$(\\rho, \\theta, \\textrm{votes})\\f$ . \\f$\\rho\\f$ is the distance from the coordinate origin \\f$(0,0)\\f$ (top-left corner of\n",
      "        .   the image). \\f$\\theta\\f$ is the line rotation angle in radians (\n",
      "        .   \\f$0 \\sim \\textrm{vertical line}, \\pi/2 \\sim \\textrm{horizontal line}\\f$ ).\n",
      "        .   \\f$\\textrm{votes}\\f$ is the value of accumulator.\n",
      "        .   @param rho Distance resolution of the accumulator in pixels.\n",
      "        .   @param theta Angle resolution of the accumulator in radians.\n",
      "        .   @param threshold Accumulator threshold parameter. Only those lines are returned that get enough\n",
      "        .   votes ( \\f$>\\texttt{threshold}\\f$ ).\n",
      "        .   @param srn For the multi-scale Hough transform, it is a divisor for the distance resolution rho .\n",
      "        .   The coarse accumulator distance resolution is rho and the accurate accumulator resolution is\n",
      "        .   rho/srn . If both srn=0 and stn=0 , the classical Hough transform is used. Otherwise, both these\n",
      "        .   parameters should be positive.\n",
      "        .   @param stn For the multi-scale Hough transform, it is a divisor for the distance resolution theta.\n",
      "        .   @param min_theta For standard and multi-scale Hough transform, minimum angle to check for lines.\n",
      "        .   Must fall between 0 and max_theta.\n",
      "        .   @param max_theta For standard and multi-scale Hough transform, maximum angle to check for lines.\n",
      "        .   Must fall between min_theta and CV_PI.\n",
      "    \n",
      "    HoughLinesP(...)\n",
      "        HoughLinesP(image, rho, theta, threshold[, lines[, minLineLength[, maxLineGap]]]) -> lines\n",
      "        .   @brief Finds line segments in a binary image using the probabilistic Hough transform.\n",
      "        .   \n",
      "        .   The function implements the probabilistic Hough transform algorithm for line detection, described\n",
      "        .   in @cite Matas00\n",
      "        .   \n",
      "        .   See the line detection example below:\n",
      "        .   @include snippets/imgproc_HoughLinesP.cpp\n",
      "        .   This is a sample picture the function parameters have been tuned for:\n",
      "        .   \n",
      "        .   ![image](pics/building.jpg)\n",
      "        .   \n",
      "        .   And this is the output of the above program in case of the probabilistic Hough transform:\n",
      "        .   \n",
      "        .   ![image](pics/houghp.png)\n",
      "        .   \n",
      "        .   @param image 8-bit, single-channel binary source image. The image may be modified by the function.\n",
      "        .   @param lines Output vector of lines. Each line is represented by a 4-element vector\n",
      "        .   \\f$(x_1, y_1, x_2, y_2)\\f$ , where \\f$(x_1,y_1)\\f$ and \\f$(x_2, y_2)\\f$ are the ending points of each detected\n",
      "        .   line segment.\n",
      "        .   @param rho Distance resolution of the accumulator in pixels.\n",
      "        .   @param theta Angle resolution of the accumulator in radians.\n",
      "        .   @param threshold Accumulator threshold parameter. Only those lines are returned that get enough\n",
      "        .   votes ( \\f$>\\texttt{threshold}\\f$ ).\n",
      "        .   @param minLineLength Minimum line length. Line segments shorter than that are rejected.\n",
      "        .   @param maxLineGap Maximum allowed gap between points on the same line to link them.\n",
      "        .   \n",
      "        .   @sa LineSegmentDetector\n",
      "    \n",
      "    HoughLinesPointSet(...)\n",
      "        HoughLinesPointSet(_point, lines_max, threshold, min_rho, max_rho, rho_step, min_theta, max_theta, theta_step[, _lines]) -> _lines\n",
      "        .   @brief Finds lines in a set of points using the standard Hough transform.\n",
      "        .   \n",
      "        .   The function finds lines in a set of points using a modification of the Hough transform.\n",
      "        .   @include snippets/imgproc_HoughLinesPointSet.cpp\n",
      "        .   @param _point Input vector of points. Each vector must be encoded as a Point vector \\f$(x,y)\\f$. Type must be CV_32FC2 or CV_32SC2.\n",
      "        .   @param _lines Output vector of found lines. Each vector is encoded as a vector<Vec3d> \\f$(votes, rho, theta)\\f$.\n",
      "        .   The larger the value of 'votes', the higher the reliability of the Hough line.\n",
      "        .   @param lines_max Max count of hough lines.\n",
      "        .   @param threshold Accumulator threshold parameter. Only those lines are returned that get enough\n",
      "        .   votes ( \\f$>\\texttt{threshold}\\f$ )\n",
      "        .   @param min_rho Minimum Distance value of the accumulator in pixels.\n",
      "        .   @param max_rho Maximum Distance value of the accumulator in pixels.\n",
      "        .   @param rho_step Distance resolution of the accumulator in pixels.\n",
      "        .   @param min_theta Minimum angle value of the accumulator in radians.\n",
      "        .   @param max_theta Maximum angle value of the accumulator in radians.\n",
      "        .   @param theta_step Angle resolution of the accumulator in radians.\n",
      "    \n",
      "    HuMoments(...)\n",
      "        HuMoments(m[, hu]) -> hu\n",
      "        .   @overload\n",
      "    \n",
      "    KAZE_create(...)\n",
      "        KAZE_create([, extended[, upright[, threshold[, nOctaves[, nOctaveLayers[, diffusivity]]]]]]) -> retval\n",
      "        .   @brief The KAZE constructor\n",
      "        .   \n",
      "        .       @param extended Set to enable extraction of extended (128-byte) descriptor.\n",
      "        .       @param upright Set to enable use of upright descriptors (non rotation-invariant).\n",
      "        .       @param threshold Detector response threshold to accept point\n",
      "        .       @param nOctaves Maximum octave evolution of the image\n",
      "        .       @param nOctaveLayers Default number of sublevels per scale level\n",
      "        .       @param diffusivity Diffusivity type. DIFF_PM_G1, DIFF_PM_G2, DIFF_WEICKERT or\n",
      "        .       DIFF_CHARBONNIER\n",
      "    \n",
      "    KeyPoint_convert(...)\n",
      "        KeyPoint_convert(keypoints[, keypointIndexes]) -> points2f\n",
      "        .   This method converts vector of keypoints to vector of points or the reverse, where each keypoint is\n",
      "        .       assigned the same size and the same orientation.\n",
      "        .   \n",
      "        .       @param keypoints Keypoints obtained from any feature detection algorithm like SIFT/SURF/ORB\n",
      "        .       @param points2f Array of (x,y) coordinates of each keypoint\n",
      "        .       @param keypointIndexes Array of indexes of keypoints to be converted to points. (Acts like a mask to\n",
      "        .       convert only specified keypoints)\n",
      "        \n",
      "        \n",
      "        \n",
      "        KeyPoint_convert(points2f[, size[, response[, octave[, class_id]]]]) -> keypoints\n",
      "        .   @overload\n",
      "        .       @param points2f Array of (x,y) coordinates of each keypoint\n",
      "        .       @param keypoints Keypoints obtained from any feature detection algorithm like SIFT/SURF/ORB\n",
      "        .       @param size keypoint diameter\n",
      "        .       @param response keypoint detector response on the keypoint (that is, strength of the keypoint)\n",
      "        .       @param octave pyramid octave in which the keypoint has been detected\n",
      "        .       @param class_id object id\n",
      "    \n",
      "    KeyPoint_overlap(...)\n",
      "        KeyPoint_overlap(kp1, kp2) -> retval\n",
      "        .   This method computes overlap for pair of keypoints. Overlap is the ratio between area of keypoint\n",
      "        .       regions' intersection and area of keypoint regions' union (considering keypoint region as circle).\n",
      "        .       If they don't overlap, we get zero. If they coincide at same location with same size, we get 1.\n",
      "        .       @param kp1 First keypoint\n",
      "        .       @param kp2 Second keypoint\n",
      "    \n",
      "    LUT(...)\n",
      "        LUT(src, lut[, dst]) -> dst\n",
      "        .   @brief Performs a look-up table transform of an array.\n",
      "        .   \n",
      "        .   The function LUT fills the output array with values from the look-up table. Indices of the entries\n",
      "        .   are taken from the input array. That is, the function processes each element of src as follows:\n",
      "        .   \\f[\\texttt{dst} (I)  \\leftarrow \\texttt{lut(src(I) + d)}\\f]\n",
      "        .   where\n",
      "        .   \\f[d =  \\fork{0}{if \\(\\texttt{src}\\) has depth \\(\\texttt{CV_8U}\\)}{128}{if \\(\\texttt{src}\\) has depth \\(\\texttt{CV_8S}\\)}\\f]\n",
      "        .   @param src input array of 8-bit elements.\n",
      "        .   @param lut look-up table of 256 elements; in case of multi-channel input array, the table should\n",
      "        .   either have a single channel (in this case the same table is used for all channels) or the same\n",
      "        .   number of channels as in the input array.\n",
      "        .   @param dst output array of the same size and number of channels as src, and the same depth as lut.\n",
      "        .   @sa  convertScaleAbs, Mat::convertTo\n",
      "    \n",
      "    Laplacian(...)\n",
      "        Laplacian(src, ddepth[, dst[, ksize[, scale[, delta[, borderType]]]]]) -> dst\n",
      "        .   @brief Calculates the Laplacian of an image.\n",
      "        .   \n",
      "        .   The function calculates the Laplacian of the source image by adding up the second x and y\n",
      "        .   derivatives calculated using the Sobel operator:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} =  \\Delta \\texttt{src} =  \\frac{\\partial^2 \\texttt{src}}{\\partial x^2} +  \\frac{\\partial^2 \\texttt{src}}{\\partial y^2}\\f]\n",
      "        .   \n",
      "        .   This is done when `ksize > 1`. When `ksize == 1`, the Laplacian is computed by filtering the image\n",
      "        .   with the following \\f$3 \\times 3\\f$ aperture:\n",
      "        .   \n",
      "        .   \\f[\\vecthreethree {0}{1}{0}{1}{-4}{1}{0}{1}{0}\\f]\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image of the same size and the same number of channels as src .\n",
      "        .   @param ddepth Desired depth of the destination image.\n",
      "        .   @param ksize Aperture size used to compute the second-derivative filters. See #getDerivKernels for\n",
      "        .   details. The size must be positive and odd.\n",
      "        .   @param scale Optional scale factor for the computed Laplacian values. By default, no scaling is\n",
      "        .   applied. See #getDerivKernels for details.\n",
      "        .   @param delta Optional delta value that is added to the results prior to storing them in dst .\n",
      "        .   @param borderType Pixel extrapolation method, see #BorderTypes. #BORDER_WRAP is not supported.\n",
      "        .   @sa  Sobel, Scharr\n",
      "    \n",
      "    MSER_create(...)\n",
      "        MSER_create([, _delta[, _min_area[, _max_area[, _max_variation[, _min_diversity[, _max_evolution[, _area_threshold[, _min_margin[, _edge_blur_size]]]]]]]]]) -> retval\n",
      "        .   @brief Full constructor for %MSER detector\n",
      "        .   \n",
      "        .       @param _delta it compares \\f$(size_{i}-size_{i-delta})/size_{i-delta}\\f$\n",
      "        .       @param _min_area prune the area which smaller than minArea\n",
      "        .       @param _max_area prune the area which bigger than maxArea\n",
      "        .       @param _max_variation prune the area have similar size to its children\n",
      "        .       @param _min_diversity for color image, trace back to cut off mser with diversity less than min_diversity\n",
      "        .       @param _max_evolution  for color image, the evolution steps\n",
      "        .       @param _area_threshold for color image, the area threshold to cause re-initialize\n",
      "        .       @param _min_margin for color image, ignore too small margin\n",
      "        .       @param _edge_blur_size for color image, the aperture size for edge blur\n",
      "    \n",
      "    Mahalanobis(...)\n",
      "        Mahalanobis(v1, v2, icovar) -> retval\n",
      "        .   @brief Calculates the Mahalanobis distance between two vectors.\n",
      "        .   \n",
      "        .   The function cv::Mahalanobis calculates and returns the weighted distance between two vectors:\n",
      "        .   \\f[d( \\texttt{vec1} , \\texttt{vec2} )= \\sqrt{\\sum_{i,j}{\\texttt{icovar(i,j)}\\cdot(\\texttt{vec1}(I)-\\texttt{vec2}(I))\\cdot(\\texttt{vec1(j)}-\\texttt{vec2(j)})} }\\f]\n",
      "        .   The covariance matrix may be calculated using the #calcCovarMatrix function and then inverted using\n",
      "        .   the invert function (preferably using the #DECOMP_SVD method, as the most accurate).\n",
      "        .   @param v1 first 1D input vector.\n",
      "        .   @param v2 second 1D input vector.\n",
      "        .   @param icovar inverse covariance matrix.\n",
      "    \n",
      "    ORB_create(...)\n",
      "        ORB_create([, nfeatures[, scaleFactor[, nlevels[, edgeThreshold[, firstLevel[, WTA_K[, scoreType[, patchSize[, fastThreshold]]]]]]]]]) -> retval\n",
      "        .   @brief The ORB constructor\n",
      "        .   \n",
      "        .       @param nfeatures The maximum number of features to retain.\n",
      "        .       @param scaleFactor Pyramid decimation ratio, greater than 1. scaleFactor==2 means the classical\n",
      "        .       pyramid, where each next level has 4x less pixels than the previous, but such a big scale factor\n",
      "        .       will degrade feature matching scores dramatically. On the other hand, too close to 1 scale factor\n",
      "        .       will mean that to cover certain scale range you will need more pyramid levels and so the speed\n",
      "        .       will suffer.\n",
      "        .       @param nlevels The number of pyramid levels. The smallest level will have linear size equal to\n",
      "        .       input_image_linear_size/pow(scaleFactor, nlevels - firstLevel).\n",
      "        .       @param edgeThreshold This is size of the border where the features are not detected. It should\n",
      "        .       roughly match the patchSize parameter.\n",
      "        .       @param firstLevel The level of pyramid to put source image to. Previous layers are filled\n",
      "        .       with upscaled source image.\n",
      "        .       @param WTA_K The number of points that produce each element of the oriented BRIEF descriptor. The\n",
      "        .       default value 2 means the BRIEF where we take a random point pair and compare their brightnesses,\n",
      "        .       so we get 0/1 response. Other possible values are 3 and 4. For example, 3 means that we take 3\n",
      "        .       random points (of course, those point coordinates are random, but they are generated from the\n",
      "        .       pre-defined seed, so each element of BRIEF descriptor is computed deterministically from the pixel\n",
      "        .       rectangle), find point of maximum brightness and output index of the winner (0, 1 or 2). Such\n",
      "        .       output will occupy 2 bits, and therefore it will need a special variant of Hamming distance,\n",
      "        .       denoted as NORM_HAMMING2 (2 bits per bin). When WTA_K=4, we take 4 random points to compute each\n",
      "        .       bin (that will also occupy 2 bits with possible values 0, 1, 2 or 3).\n",
      "        .       @param scoreType The default HARRIS_SCORE means that Harris algorithm is used to rank features\n",
      "        .       (the score is written to KeyPoint::score and is used to retain best nfeatures features);\n",
      "        .       FAST_SCORE is alternative value of the parameter that produces slightly less stable keypoints,\n",
      "        .       but it is a little faster to compute.\n",
      "        .       @param patchSize size of the patch used by the oriented BRIEF descriptor. Of course, on smaller\n",
      "        .       pyramid layers the perceived image area covered by a feature will be larger.\n",
      "        .       @param fastThreshold the fast threshold\n",
      "    \n",
      "    PCABackProject(...)\n",
      "        PCABackProject(data, mean, eigenvectors[, result]) -> result\n",
      "        .   wrap PCA::backProject\n",
      "    \n",
      "    PCACompute(...)\n",
      "        PCACompute(data, mean[, eigenvectors[, maxComponents]]) -> mean, eigenvectors\n",
      "        .   wrap PCA::operator()\n",
      "        \n",
      "        \n",
      "        \n",
      "        PCACompute(data, mean, retainedVariance[, eigenvectors]) -> mean, eigenvectors\n",
      "        .   wrap PCA::operator()\n",
      "    \n",
      "    PCACompute2(...)\n",
      "        PCACompute2(data, mean[, eigenvectors[, eigenvalues[, maxComponents]]]) -> mean, eigenvectors, eigenvalues\n",
      "        .   wrap PCA::operator() and add eigenvalues output parameter\n",
      "        \n",
      "        \n",
      "        \n",
      "        PCACompute2(data, mean, retainedVariance[, eigenvectors[, eigenvalues]]) -> mean, eigenvectors, eigenvalues\n",
      "        .   wrap PCA::operator() and add eigenvalues output parameter\n",
      "    \n",
      "    PCAProject(...)\n",
      "        PCAProject(data, mean, eigenvectors[, result]) -> result\n",
      "        .   wrap PCA::project\n",
      "    \n",
      "    PSNR(...)\n",
      "        PSNR(src1, src2[, R]) -> retval\n",
      "        .   @brief Computes the Peak Signal-to-Noise Ratio (PSNR) image quality metric.\n",
      "        .   \n",
      "        .   This function calculates the Peak Signal-to-Noise Ratio (PSNR) image quality metric in decibels (dB),\n",
      "        .   between two input arrays src1 and src2. The arrays must have the same type.\n",
      "        .   \n",
      "        .   The PSNR is calculated as follows:\n",
      "        .   \n",
      "        .   \\f[\n",
      "        .   \\texttt{PSNR} = 10 \\cdot \\log_{10}{\\left( \\frac{R^2}{MSE} \\right) }\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   where R is the maximum integer value of depth (e.g. 255 in the case of CV_8U data)\n",
      "        .   and MSE is the mean squared error between the two arrays.\n",
      "        .   \n",
      "        .   @param src1 first input array.\n",
      "        .   @param src2 second input array of the same size as src1.\n",
      "        .   @param R the maximum pixel value (255 by default)\n",
      "    \n",
      "    RQDecomp3x3(...)\n",
      "        RQDecomp3x3(src[, mtxR[, mtxQ[, Qx[, Qy[, Qz]]]]]) -> retval, mtxR, mtxQ, Qx, Qy, Qz\n",
      "        .   @brief Computes an RQ decomposition of 3x3 matrices.\n",
      "        .   \n",
      "        .   @param src 3x3 input matrix.\n",
      "        .   @param mtxR Output 3x3 upper-triangular matrix.\n",
      "        .   @param mtxQ Output 3x3 orthogonal matrix.\n",
      "        .   @param Qx Optional output 3x3 rotation matrix around x-axis.\n",
      "        .   @param Qy Optional output 3x3 rotation matrix around y-axis.\n",
      "        .   @param Qz Optional output 3x3 rotation matrix around z-axis.\n",
      "        .   \n",
      "        .   The function computes a RQ decomposition using the given rotations. This function is used in\n",
      "        .   decomposeProjectionMatrix to decompose the left 3x3 submatrix of a projection matrix into a camera\n",
      "        .   and a rotation matrix.\n",
      "        .   \n",
      "        .   It optionally returns three rotation matrices, one for each axis, and the three Euler angles in\n",
      "        .   degrees (as the return value) that could be used in OpenGL. Note, there is always more than one\n",
      "        .   sequence of rotations about the three principal axes that results in the same orientation of an\n",
      "        .   object, e.g. see @cite Slabaugh . Returned tree rotation matrices and corresponding three Euler angles\n",
      "        .   are only one of the possible solutions.\n",
      "    \n",
      "    Rodrigues(...)\n",
      "        Rodrigues(src[, dst[, jacobian]]) -> dst, jacobian\n",
      "        .   @brief Converts a rotation matrix to a rotation vector or vice versa.\n",
      "        .   \n",
      "        .   @param src Input rotation vector (3x1 or 1x3) or rotation matrix (3x3).\n",
      "        .   @param dst Output rotation matrix (3x3) or rotation vector (3x1 or 1x3), respectively.\n",
      "        .   @param jacobian Optional output Jacobian matrix, 3x9 or 9x3, which is a matrix of partial\n",
      "        .   derivatives of the output array components with respect to the input array components.\n",
      "        .   \n",
      "        .   \\f[\\begin{array}{l} \\theta \\leftarrow norm(r) \\\\ r  \\leftarrow r/ \\theta \\\\ R =  \\cos(\\theta) I + (1- \\cos{\\theta} ) r r^T +  \\sin(\\theta) \\vecthreethree{0}{-r_z}{r_y}{r_z}{0}{-r_x}{-r_y}{r_x}{0} \\end{array}\\f]\n",
      "        .   \n",
      "        .   Inverse transformation can be also done easily, since\n",
      "        .   \n",
      "        .   \\f[\\sin ( \\theta ) \\vecthreethree{0}{-r_z}{r_y}{r_z}{0}{-r_x}{-r_y}{r_x}{0} = \\frac{R - R^T}{2}\\f]\n",
      "        .   \n",
      "        .   A rotation vector is a convenient and most compact representation of a rotation matrix (since any\n",
      "        .   rotation matrix has just 3 degrees of freedom). The representation is used in the global 3D geometry\n",
      "        .   optimization procedures like @ref calibrateCamera, @ref stereoCalibrate, or @ref solvePnP .\n",
      "        .   \n",
      "        .   @note More information about the computation of the derivative of a 3D rotation matrix with respect to its exponential coordinate\n",
      "        .   can be found in:\n",
      "        .       - A Compact Formula for the Derivative of a 3-D Rotation in Exponential Coordinates, Guillermo Gallego, Anthony J. Yezzi @cite Gallego2014ACF\n",
      "        .   \n",
      "        .   @note Useful information on SE(3) and Lie Groups can be found in:\n",
      "        .       - A tutorial on SE(3) transformation parameterizations and on-manifold optimization, Jose-Luis Blanco @cite blanco2010tutorial\n",
      "        .       - Lie Groups for 2D and 3D Transformation, Ethan Eade @cite Eade17\n",
      "        .       - A micro Lie theory for state estimation in robotics, Joan Sol&#224;, J&#233;r&#233;mie Deray, Dinesh Atchuthan @cite Sol2018AML\n",
      "    \n",
      "    SIFT_create(...)\n",
      "        SIFT_create([, nfeatures[, nOctaveLayers[, contrastThreshold[, edgeThreshold[, sigma]]]]]) -> retval\n",
      "        .   @param nfeatures The number of best features to retain. The features are ranked by their scores\n",
      "        .       (measured in SIFT algorithm as the local contrast)\n",
      "        .   \n",
      "        .       @param nOctaveLayers The number of layers in each octave. 3 is the value used in D. Lowe paper. The\n",
      "        .       number of octaves is computed automatically from the image resolution.\n",
      "        .   \n",
      "        .       @param contrastThreshold The contrast threshold used to filter out weak features in semi-uniform\n",
      "        .       (low-contrast) regions. The larger the threshold, the less features are produced by the detector.\n",
      "        .   \n",
      "        .       @note The contrast threshold will be divided by nOctaveLayers when the filtering is applied. When\n",
      "        .       nOctaveLayers is set to default and if you want to use the value used in D. Lowe paper, 0.03, set\n",
      "        .       this argument to 0.09.\n",
      "        .   \n",
      "        .       @param edgeThreshold The threshold used to filter out edge-like features. Note that the its meaning\n",
      "        .       is different from the contrastThreshold, i.e. the larger the edgeThreshold, the less features are\n",
      "        .       filtered out (more features are retained).\n",
      "        .   \n",
      "        .       @param sigma The sigma of the Gaussian applied to the input image at the octave \\#0. If your image\n",
      "        .       is captured with a weak camera with soft lenses, you might want to reduce the number.\n",
      "    \n",
      "    SVBackSubst(...)\n",
      "        SVBackSubst(w, u, vt, rhs[, dst]) -> dst\n",
      "        .   wrap SVD::backSubst\n",
      "    \n",
      "    SVDecomp(...)\n",
      "        SVDecomp(src[, w[, u[, vt[, flags]]]]) -> w, u, vt\n",
      "        .   wrap SVD::compute\n",
      "    \n",
      "    Scharr(...)\n",
      "        Scharr(src, ddepth, dx, dy[, dst[, scale[, delta[, borderType]]]]) -> dst\n",
      "        .   @brief Calculates the first x- or y- image derivative using Scharr operator.\n",
      "        .   \n",
      "        .   The function computes the first x- or y- spatial image derivative using the Scharr operator. The\n",
      "        .   call\n",
      "        .   \n",
      "        .   \\f[\\texttt{Scharr(src, dst, ddepth, dx, dy, scale, delta, borderType)}\\f]\n",
      "        .   \n",
      "        .   is equivalent to\n",
      "        .   \n",
      "        .   \\f[\\texttt{Sobel(src, dst, ddepth, dx, dy, FILTER_SCHARR, scale, delta, borderType)} .\\f]\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image of the same size and the same number of channels as src.\n",
      "        .   @param ddepth output image depth, see @ref filter_depths \"combinations\"\n",
      "        .   @param dx order of the derivative x.\n",
      "        .   @param dy order of the derivative y.\n",
      "        .   @param scale optional scale factor for the computed derivative values; by default, no scaling is\n",
      "        .   applied (see #getDerivKernels for details).\n",
      "        .   @param delta optional delta value that is added to the results prior to storing them in dst.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes. #BORDER_WRAP is not supported.\n",
      "        .   @sa  cartToPolar\n",
      "    \n",
      "    SimpleBlobDetector_create(...)\n",
      "        SimpleBlobDetector_create([, parameters]) -> retval\n",
      "        .\n",
      "    \n",
      "    Sobel(...)\n",
      "        Sobel(src, ddepth, dx, dy[, dst[, ksize[, scale[, delta[, borderType]]]]]) -> dst\n",
      "        .   @brief Calculates the first, second, third, or mixed image derivatives using an extended Sobel operator.\n",
      "        .   \n",
      "        .   In all cases except one, the \\f$\\texttt{ksize} \\times \\texttt{ksize}\\f$ separable kernel is used to\n",
      "        .   calculate the derivative. When \\f$\\texttt{ksize = 1}\\f$, the \\f$3 \\times 1\\f$ or \\f$1 \\times 3\\f$\n",
      "        .   kernel is used (that is, no Gaussian smoothing is done). `ksize = 1` can only be used for the first\n",
      "        .   or the second x- or y- derivatives.\n",
      "        .   \n",
      "        .   There is also the special value `ksize = #FILTER_SCHARR (-1)` that corresponds to the \\f$3\\times3\\f$ Scharr\n",
      "        .   filter that may give more accurate results than the \\f$3\\times3\\f$ Sobel. The Scharr aperture is\n",
      "        .   \n",
      "        .   \\f[\\vecthreethree{-3}{0}{3}{-10}{0}{10}{-3}{0}{3}\\f]\n",
      "        .   \n",
      "        .   for the x-derivative, or transposed for the y-derivative.\n",
      "        .   \n",
      "        .   The function calculates an image derivative by convolving the image with the appropriate kernel:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} =  \\frac{\\partial^{xorder+yorder} \\texttt{src}}{\\partial x^{xorder} \\partial y^{yorder}}\\f]\n",
      "        .   \n",
      "        .   The Sobel operators combine Gaussian smoothing and differentiation, so the result is more or less\n",
      "        .   resistant to the noise. Most often, the function is called with ( xorder = 1, yorder = 0, ksize = 3)\n",
      "        .   or ( xorder = 0, yorder = 1, ksize = 3) to calculate the first x- or y- image derivative. The first\n",
      "        .   case corresponds to a kernel of:\n",
      "        .   \n",
      "        .   \\f[\\vecthreethree{-1}{0}{1}{-2}{0}{2}{-1}{0}{1}\\f]\n",
      "        .   \n",
      "        .   The second case corresponds to a kernel of:\n",
      "        .   \n",
      "        .   \\f[\\vecthreethree{-1}{-2}{-1}{0}{0}{0}{1}{2}{1}\\f]\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image of the same size and the same number of channels as src .\n",
      "        .   @param ddepth output image depth, see @ref filter_depths \"combinations\"; in the case of\n",
      "        .       8-bit input images it will result in truncated derivatives.\n",
      "        .   @param dx order of the derivative x.\n",
      "        .   @param dy order of the derivative y.\n",
      "        .   @param ksize size of the extended Sobel kernel; it must be 1, 3, 5, or 7.\n",
      "        .   @param scale optional scale factor for the computed derivative values; by default, no scaling is\n",
      "        .   applied (see #getDerivKernels for details).\n",
      "        .   @param delta optional delta value that is added to the results prior to storing them in dst.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes. #BORDER_WRAP is not supported.\n",
      "        .   @sa  Scharr, Laplacian, sepFilter2D, filter2D, GaussianBlur, cartToPolar\n",
      "    \n",
      "    SparsePyrLKOpticalFlow_create(...)\n",
      "        SparsePyrLKOpticalFlow_create([, winSize[, maxLevel[, crit[, flags[, minEigThreshold]]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    StereoBM_create(...)\n",
      "        StereoBM_create([, numDisparities[, blockSize]]) -> retval\n",
      "        .   @brief Creates StereoBM object\n",
      "        .   \n",
      "        .       @param numDisparities the disparity search range. For each pixel algorithm will find the best\n",
      "        .       disparity from 0 (default minimum disparity) to numDisparities. The search range can then be\n",
      "        .       shifted by changing the minimum disparity.\n",
      "        .       @param blockSize the linear size of the blocks compared by the algorithm. The size should be odd\n",
      "        .       (as the block is centered at the current pixel). Larger block size implies smoother, though less\n",
      "        .       accurate disparity map. Smaller block size gives more detailed disparity map, but there is higher\n",
      "        .       chance for algorithm to find a wrong correspondence.\n",
      "        .   \n",
      "        .       The function create StereoBM object. You can then call StereoBM::compute() to compute disparity for\n",
      "        .       a specific stereo pair.\n",
      "    \n",
      "    StereoSGBM_create(...)\n",
      "        StereoSGBM_create([, minDisparity[, numDisparities[, blockSize[, P1[, P2[, disp12MaxDiff[, preFilterCap[, uniquenessRatio[, speckleWindowSize[, speckleRange[, mode]]]]]]]]]]]) -> retval\n",
      "        .   @brief Creates StereoSGBM object\n",
      "        .   \n",
      "        .       @param minDisparity Minimum possible disparity value. Normally, it is zero but sometimes\n",
      "        .       rectification algorithms can shift images, so this parameter needs to be adjusted accordingly.\n",
      "        .       @param numDisparities Maximum disparity minus minimum disparity. The value is always greater than\n",
      "        .       zero. In the current implementation, this parameter must be divisible by 16.\n",
      "        .       @param blockSize Matched block size. It must be an odd number \\>=1 . Normally, it should be\n",
      "        .       somewhere in the 3..11 range.\n",
      "        .       @param P1 The first parameter controlling the disparity smoothness. See below.\n",
      "        .       @param P2 The second parameter controlling the disparity smoothness. The larger the values are,\n",
      "        .       the smoother the disparity is. P1 is the penalty on the disparity change by plus or minus 1\n",
      "        .       between neighbor pixels. P2 is the penalty on the disparity change by more than 1 between neighbor\n",
      "        .       pixels. The algorithm requires P2 \\> P1 . See stereo_match.cpp sample where some reasonably good\n",
      "        .       P1 and P2 values are shown (like 8\\*number_of_image_channels\\*blockSize\\*blockSize and\n",
      "        .       32\\*number_of_image_channels\\*blockSize\\*blockSize , respectively).\n",
      "        .       @param disp12MaxDiff Maximum allowed difference (in integer pixel units) in the left-right\n",
      "        .       disparity check. Set it to a non-positive value to disable the check.\n",
      "        .       @param preFilterCap Truncation value for the prefiltered image pixels. The algorithm first\n",
      "        .       computes x-derivative at each pixel and clips its value by [-preFilterCap, preFilterCap] interval.\n",
      "        .       The result values are passed to the Birchfield-Tomasi pixel cost function.\n",
      "        .       @param uniquenessRatio Margin in percentage by which the best (minimum) computed cost function\n",
      "        .       value should \"win\" the second best value to consider the found match correct. Normally, a value\n",
      "        .       within the 5-15 range is good enough.\n",
      "        .       @param speckleWindowSize Maximum size of smooth disparity regions to consider their noise speckles\n",
      "        .       and invalidate. Set it to 0 to disable speckle filtering. Otherwise, set it somewhere in the\n",
      "        .       50-200 range.\n",
      "        .       @param speckleRange Maximum disparity variation within each connected component. If you do speckle\n",
      "        .       filtering, set the parameter to a positive value, it will be implicitly multiplied by 16.\n",
      "        .       Normally, 1 or 2 is good enough.\n",
      "        .       @param mode Set it to StereoSGBM::MODE_HH to run the full-scale two-pass dynamic programming\n",
      "        .       algorithm. It will consume O(W\\*H\\*numDisparities) bytes, which is large for 640x480 stereo and\n",
      "        .       huge for HD-size pictures. By default, it is set to false .\n",
      "        .   \n",
      "        .       The first constructor initializes StereoSGBM with all the default parameters. So, you only have to\n",
      "        .       set StereoSGBM::numDisparities at minimum. The second constructor enables you to set each parameter\n",
      "        .       to a custom value.\n",
      "    \n",
      "    Stitcher_create(...)\n",
      "        Stitcher_create([, mode]) -> retval\n",
      "        .   @brief Creates a Stitcher configured in one of the stitching modes.\n",
      "        .   \n",
      "        .       @param mode Scenario for stitcher operation. This is usually determined by source of images\n",
      "        .       to stitch and their transformation. Default parameters will be chosen for operation in given\n",
      "        .       scenario.\n",
      "        .       @return Stitcher class instance.\n",
      "    \n",
      "    UMat_context(...)\n",
      "        UMat_context() -> retval\n",
      "        .\n",
      "    \n",
      "    UMat_queue(...)\n",
      "        UMat_queue() -> retval\n",
      "        .\n",
      "    \n",
      "    VariationalRefinement_create(...)\n",
      "        VariationalRefinement_create() -> retval\n",
      "        .   @brief Creates an instance of VariationalRefinement\n",
      "    \n",
      "    VideoWriter_fourcc(...)\n",
      "        VideoWriter_fourcc(c1, c2, c3, c4) -> retval\n",
      "        .   @brief Concatenates 4 chars to a fourcc code\n",
      "        .   \n",
      "        .       @return a fourcc code\n",
      "        .   \n",
      "        .       This static method constructs the fourcc code of the codec to be used in the constructor\n",
      "        .       VideoWriter::VideoWriter or VideoWriter::open.\n",
      "    \n",
      "    absdiff(...)\n",
      "        absdiff(src1, src2[, dst]) -> dst\n",
      "        .   @brief Calculates the per-element absolute difference between two arrays or between an array and a scalar.\n",
      "        .   \n",
      "        .   The function cv::absdiff calculates:\n",
      "        .   *   Absolute difference between two arrays when they have the same\n",
      "        .       size and type:\n",
      "        .       \\f[\\texttt{dst}(I) =  \\texttt{saturate} (| \\texttt{src1}(I) -  \\texttt{src2}(I)|)\\f]\n",
      "        .   *   Absolute difference between an array and a scalar when the second\n",
      "        .       array is constructed from Scalar or has as many elements as the\n",
      "        .       number of channels in `src1`:\n",
      "        .       \\f[\\texttt{dst}(I) =  \\texttt{saturate} (| \\texttt{src1}(I) -  \\texttt{src2} |)\\f]\n",
      "        .   *   Absolute difference between a scalar and an array when the first\n",
      "        .       array is constructed from Scalar or has as many elements as the\n",
      "        .       number of channels in `src2`:\n",
      "        .       \\f[\\texttt{dst}(I) =  \\texttt{saturate} (| \\texttt{src1} -  \\texttt{src2}(I) |)\\f]\n",
      "        .       where I is a multi-dimensional index of array elements. In case of\n",
      "        .       multi-channel arrays, each channel is processed independently.\n",
      "        .   @note Saturation is not applied when the arrays have the depth CV_32S.\n",
      "        .   You may even get a negative value in the case of overflow.\n",
      "        .   @param src1 first input array or a scalar.\n",
      "        .   @param src2 second input array or a scalar.\n",
      "        .   @param dst output array that has the same size and type as input arrays.\n",
      "        .   @sa cv::abs(const Mat&)\n",
      "    \n",
      "    accumulate(...)\n",
      "        accumulate(src, dst[, mask]) -> dst\n",
      "        .   @brief Adds an image to the accumulator image.\n",
      "        .   \n",
      "        .   The function adds src or some of its elements to dst :\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y)  \\leftarrow \\texttt{dst} (x,y) +  \\texttt{src} (x,y)  \\quad \\text{if} \\quad \\texttt{mask} (x,y)  \\ne 0\\f]\n",
      "        .   \n",
      "        .   The function supports multi-channel images. Each channel is processed independently.\n",
      "        .   \n",
      "        .   The function cv::accumulate can be used, for example, to collect statistics of a scene background\n",
      "        .   viewed by a still camera and for the further foreground-background segmentation.\n",
      "        .   \n",
      "        .   @param src Input image of type CV_8UC(n), CV_16UC(n), CV_32FC(n) or CV_64FC(n), where n is a positive integer.\n",
      "        .   @param dst %Accumulator image with the same number of channels as input image, and a depth of CV_32F or CV_64F.\n",
      "        .   @param mask Optional operation mask.\n",
      "        .   \n",
      "        .   @sa  accumulateSquare, accumulateProduct, accumulateWeighted\n",
      "    \n",
      "    accumulateProduct(...)\n",
      "        accumulateProduct(src1, src2, dst[, mask]) -> dst\n",
      "        .   @brief Adds the per-element product of two input images to the accumulator image.\n",
      "        .   \n",
      "        .   The function adds the product of two images or their selected regions to the accumulator dst :\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y)  \\leftarrow \\texttt{dst} (x,y) +  \\texttt{src1} (x,y)  \\cdot \\texttt{src2} (x,y)  \\quad \\text{if} \\quad \\texttt{mask} (x,y)  \\ne 0\\f]\n",
      "        .   \n",
      "        .   The function supports multi-channel images. Each channel is processed independently.\n",
      "        .   \n",
      "        .   @param src1 First input image, 1- or 3-channel, 8-bit or 32-bit floating point.\n",
      "        .   @param src2 Second input image of the same type and the same size as src1 .\n",
      "        .   @param dst %Accumulator image with the same number of channels as input images, 32-bit or 64-bit\n",
      "        .   floating-point.\n",
      "        .   @param mask Optional operation mask.\n",
      "        .   \n",
      "        .   @sa  accumulate, accumulateSquare, accumulateWeighted\n",
      "    \n",
      "    accumulateSquare(...)\n",
      "        accumulateSquare(src, dst[, mask]) -> dst\n",
      "        .   @brief Adds the square of a source image to the accumulator image.\n",
      "        .   \n",
      "        .   The function adds the input image src or its selected region, raised to a power of 2, to the\n",
      "        .   accumulator dst :\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y)  \\leftarrow \\texttt{dst} (x,y) +  \\texttt{src} (x,y)^2  \\quad \\text{if} \\quad \\texttt{mask} (x,y)  \\ne 0\\f]\n",
      "        .   \n",
      "        .   The function supports multi-channel images. Each channel is processed independently.\n",
      "        .   \n",
      "        .   @param src Input image as 1- or 3-channel, 8-bit or 32-bit floating point.\n",
      "        .   @param dst %Accumulator image with the same number of channels as input image, 32-bit or 64-bit\n",
      "        .   floating-point.\n",
      "        .   @param mask Optional operation mask.\n",
      "        .   \n",
      "        .   @sa  accumulateSquare, accumulateProduct, accumulateWeighted\n",
      "    \n",
      "    accumulateWeighted(...)\n",
      "        accumulateWeighted(src, dst, alpha[, mask]) -> dst\n",
      "        .   @brief Updates a running average.\n",
      "        .   \n",
      "        .   The function calculates the weighted sum of the input image src and the accumulator dst so that dst\n",
      "        .   becomes a running average of a frame sequence:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y)  \\leftarrow (1- \\texttt{alpha} )  \\cdot \\texttt{dst} (x,y) +  \\texttt{alpha} \\cdot \\texttt{src} (x,y)  \\quad \\text{if} \\quad \\texttt{mask} (x,y)  \\ne 0\\f]\n",
      "        .   \n",
      "        .   That is, alpha regulates the update speed (how fast the accumulator \"forgets\" about earlier images).\n",
      "        .   The function supports multi-channel images. Each channel is processed independently.\n",
      "        .   \n",
      "        .   @param src Input image as 1- or 3-channel, 8-bit or 32-bit floating point.\n",
      "        .   @param dst %Accumulator image with the same number of channels as input image, 32-bit or 64-bit\n",
      "        .   floating-point.\n",
      "        .   @param alpha Weight of the input image.\n",
      "        .   @param mask Optional operation mask.\n",
      "        .   \n",
      "        .   @sa  accumulate, accumulateSquare, accumulateProduct\n",
      "    \n",
      "    adaptiveThreshold(...)\n",
      "        adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst]) -> dst\n",
      "        .   @brief Applies an adaptive threshold to an array.\n",
      "        .   \n",
      "        .   The function transforms a grayscale image to a binary image according to the formulae:\n",
      "        .   -   **THRESH_BINARY**\n",
      "        .       \\f[dst(x,y) =  \\fork{\\texttt{maxValue}}{if \\(src(x,y) > T(x,y)\\)}{0}{otherwise}\\f]\n",
      "        .   -   **THRESH_BINARY_INV**\n",
      "        .       \\f[dst(x,y) =  \\fork{0}{if \\(src(x,y) > T(x,y)\\)}{\\texttt{maxValue}}{otherwise}\\f]\n",
      "        .   where \\f$T(x,y)\\f$ is a threshold calculated individually for each pixel (see adaptiveMethod parameter).\n",
      "        .   \n",
      "        .   The function can process the image in-place.\n",
      "        .   \n",
      "        .   @param src Source 8-bit single-channel image.\n",
      "        .   @param dst Destination image of the same size and the same type as src.\n",
      "        .   @param maxValue Non-zero value assigned to the pixels for which the condition is satisfied\n",
      "        .   @param adaptiveMethod Adaptive thresholding algorithm to use, see #AdaptiveThresholdTypes.\n",
      "        .   The #BORDER_REPLICATE | #BORDER_ISOLATED is used to process boundaries.\n",
      "        .   @param thresholdType Thresholding type that must be either #THRESH_BINARY or #THRESH_BINARY_INV,\n",
      "        .   see #ThresholdTypes.\n",
      "        .   @param blockSize Size of a pixel neighborhood that is used to calculate a threshold value for the\n",
      "        .   pixel: 3, 5, 7, and so on.\n",
      "        .   @param C Constant subtracted from the mean or weighted mean (see the details below). Normally, it\n",
      "        .   is positive but may be zero or negative as well.\n",
      "        .   \n",
      "        .   @sa  threshold, blur, GaussianBlur\n",
      "    \n",
      "    add(...)\n",
      "        add(src1, src2[, dst[, mask[, dtype]]]) -> dst\n",
      "        .   @brief Calculates the per-element sum of two arrays or an array and a scalar.\n",
      "        .   \n",
      "        .   The function add calculates:\n",
      "        .   - Sum of two arrays when both input arrays have the same size and the same number of channels:\n",
      "        .   \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src1}(I) +  \\texttt{src2}(I)) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   - Sum of an array and a scalar when src2 is constructed from Scalar or has the same number of\n",
      "        .   elements as `src1.channels()`:\n",
      "        .   \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src1}(I) +  \\texttt{src2} ) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   - Sum of a scalar and an array when src1 is constructed from Scalar or has the same number of\n",
      "        .   elements as `src2.channels()`:\n",
      "        .   \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src1} +  \\texttt{src2}(I) ) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   where `I` is a multi-dimensional index of array elements. In case of multi-channel arrays, each\n",
      "        .   channel is processed independently.\n",
      "        .   \n",
      "        .   The first function in the list above can be replaced with matrix expressions:\n",
      "        .   @code{.cpp}\n",
      "        .       dst = src1 + src2;\n",
      "        .       dst += src1; // equivalent to add(dst, src1, dst);\n",
      "        .   @endcode\n",
      "        .   The input arrays and the output array can all have the same or different depths. For example, you\n",
      "        .   can add a 16-bit unsigned array to a 8-bit signed array and store the sum as a 32-bit\n",
      "        .   floating-point array. Depth of the output array is determined by the dtype parameter. In the second\n",
      "        .   and third cases above, as well as in the first case, when src1.depth() == src2.depth(), dtype can\n",
      "        .   be set to the default -1. In this case, the output array will have the same depth as the input\n",
      "        .   array, be it src1, src2 or both.\n",
      "        .   @note Saturation is not applied when the output array has the depth CV_32S. You may even get\n",
      "        .   result of an incorrect sign in the case of overflow.\n",
      "        .   @param src1 first input array or a scalar.\n",
      "        .   @param src2 second input array or a scalar.\n",
      "        .   @param dst output array that has the same size and number of channels as the input array(s); the\n",
      "        .   depth is defined by dtype or src1/src2.\n",
      "        .   @param mask optional operation mask - 8-bit single channel array, that specifies elements of the\n",
      "        .   output array to be changed.\n",
      "        .   @param dtype optional depth of the output array (see the discussion below).\n",
      "        .   @sa subtract, addWeighted, scaleAdd, Mat::convertTo\n",
      "    \n",
      "    addText(...)\n",
      "        addText(img, text, org, nameFont[, pointSize[, color[, weight[, style[, spacing]]]]]) -> None\n",
      "        .   @brief Draws a text on the image.\n",
      "        .   \n",
      "        .   @param img 8-bit 3-channel image where the text should be drawn.\n",
      "        .   @param text Text to write on an image.\n",
      "        .   @param org Point(x,y) where the text should start on an image.\n",
      "        .   @param nameFont Name of the font. The name should match the name of a system font (such as\n",
      "        .   *Times*). If the font is not found, a default one is used.\n",
      "        .   @param pointSize Size of the font. If not specified, equal zero or negative, the point size of the\n",
      "        .   font is set to a system-dependent default value. Generally, this is 12 points.\n",
      "        .   @param color Color of the font in BGRA where A = 255 is fully transparent.\n",
      "        .   @param weight Font weight. Available operation flags are : cv::QtFontWeights You can also specify a positive integer for better control.\n",
      "        .   @param style Font style. Available operation flags are : cv::QtFontStyles\n",
      "        .   @param spacing Spacing between characters. It can be negative or positive.\n",
      "    \n",
      "    addWeighted(...)\n",
      "        addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]]) -> dst\n",
      "        .   @brief Calculates the weighted sum of two arrays.\n",
      "        .   \n",
      "        .   The function addWeighted calculates the weighted sum of two arrays as follows:\n",
      "        .   \\f[\\texttt{dst} (I)= \\texttt{saturate} ( \\texttt{src1} (I)* \\texttt{alpha} +  \\texttt{src2} (I)* \\texttt{beta} +  \\texttt{gamma} )\\f]\n",
      "        .   where I is a multi-dimensional index of array elements. In case of multi-channel arrays, each\n",
      "        .   channel is processed independently.\n",
      "        .   The function can be replaced with a matrix expression:\n",
      "        .   @code{.cpp}\n",
      "        .       dst = src1*alpha + src2*beta + gamma;\n",
      "        .   @endcode\n",
      "        .   @note Saturation is not applied when the output array has the depth CV_32S. You may even get\n",
      "        .   result of an incorrect sign in the case of overflow.\n",
      "        .   @param src1 first input array.\n",
      "        .   @param alpha weight of the first array elements.\n",
      "        .   @param src2 second input array of the same size and channel number as src1.\n",
      "        .   @param beta weight of the second array elements.\n",
      "        .   @param gamma scalar added to each sum.\n",
      "        .   @param dst output array that has the same size and number of channels as the input arrays.\n",
      "        .   @param dtype optional depth of the output array; when both input arrays have the same depth, dtype\n",
      "        .   can be set to -1, which will be equivalent to src1.depth().\n",
      "        .   @sa  add, subtract, scaleAdd, Mat::convertTo\n",
      "    \n",
      "    applyColorMap(...)\n",
      "        applyColorMap(src, colormap[, dst]) -> dst\n",
      "        .   @brief Applies a GNU Octave/MATLAB equivalent colormap on a given image.\n",
      "        .   \n",
      "        .   @param src The source image, grayscale or colored of type CV_8UC1 or CV_8UC3.\n",
      "        .   @param dst The result is the colormapped source image. Note: Mat::create is called on dst.\n",
      "        .   @param colormap The colormap to apply, see #ColormapTypes\n",
      "        \n",
      "        \n",
      "        \n",
      "        applyColorMap(src, userColor[, dst]) -> dst\n",
      "        .   @brief Applies a user colormap on a given image.\n",
      "        .   \n",
      "        .   @param src The source image, grayscale or colored of type CV_8UC1 or CV_8UC3.\n",
      "        .   @param dst The result is the colormapped source image. Note: Mat::create is called on dst.\n",
      "        .   @param userColor The colormap to apply of type CV_8UC1 or CV_8UC3 and size 256\n",
      "    \n",
      "    approxPolyDP(...)\n",
      "        approxPolyDP(curve, epsilon, closed[, approxCurve]) -> approxCurve\n",
      "        .   @brief Approximates a polygonal curve(s) with the specified precision.\n",
      "        .   \n",
      "        .   The function cv::approxPolyDP approximates a curve or a polygon with another curve/polygon with less\n",
      "        .   vertices so that the distance between them is less or equal to the specified precision. It uses the\n",
      "        .   Douglas-Peucker algorithm <http://en.wikipedia.org/wiki/Ramer-Douglas-Peucker_algorithm>\n",
      "        .   \n",
      "        .   @param curve Input vector of a 2D point stored in std::vector or Mat\n",
      "        .   @param approxCurve Result of the approximation. The type should match the type of the input curve.\n",
      "        .   @param epsilon Parameter specifying the approximation accuracy. This is the maximum distance\n",
      "        .   between the original curve and its approximation.\n",
      "        .   @param closed If true, the approximated curve is closed (its first and last vertices are\n",
      "        .   connected). Otherwise, it is not closed.\n",
      "    \n",
      "    arcLength(...)\n",
      "        arcLength(curve, closed) -> retval\n",
      "        .   @brief Calculates a contour perimeter or a curve length.\n",
      "        .   \n",
      "        .   The function computes a curve length or a closed contour perimeter.\n",
      "        .   \n",
      "        .   @param curve Input vector of 2D points, stored in std::vector or Mat.\n",
      "        .   @param closed Flag indicating whether the curve is closed or not.\n",
      "    \n",
      "    arrowedLine(...)\n",
      "        arrowedLine(img, pt1, pt2, color[, thickness[, line_type[, shift[, tipLength]]]]) -> img\n",
      "        .   @brief Draws a arrow segment pointing from the first point to the second one.\n",
      "        .   \n",
      "        .   The function cv::arrowedLine draws an arrow between pt1 and pt2 points in the image. See also #line.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param pt1 The point the arrow starts from.\n",
      "        .   @param pt2 The point the arrow points to.\n",
      "        .   @param color Line color.\n",
      "        .   @param thickness Line thickness.\n",
      "        .   @param line_type Type of the line. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the point coordinates.\n",
      "        .   @param tipLength The length of the arrow tip in relation to the arrow length\n",
      "    \n",
      "    batchDistance(...)\n",
      "        batchDistance(src1, src2, dtype[, dist[, nidx[, normType[, K[, mask[, update[, crosscheck]]]]]]]) -> dist, nidx\n",
      "        .   @brief naive nearest neighbor finder\n",
      "        .   \n",
      "        .   see http://en.wikipedia.org/wiki/Nearest_neighbor_search\n",
      "        .   @todo document\n",
      "    \n",
      "    bilateralFilter(...)\n",
      "        bilateralFilter(src, d, sigmaColor, sigmaSpace[, dst[, borderType]]) -> dst\n",
      "        .   @brief Applies the bilateral filter to an image.\n",
      "        .   \n",
      "        .   The function applies bilateral filtering to the input image, as described in\n",
      "        .   http://www.dai.ed.ac.uk/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html\n",
      "        .   bilateralFilter can reduce unwanted noise very well while keeping edges fairly sharp. However, it is\n",
      "        .   very slow compared to most filters.\n",
      "        .   \n",
      "        .   _Sigma values_: For simplicity, you can set the 2 sigma values to be the same. If they are small (\\<\n",
      "        .   10), the filter will not have much effect, whereas if they are large (\\> 150), they will have a very\n",
      "        .   strong effect, making the image look \"cartoonish\".\n",
      "        .   \n",
      "        .   _Filter size_: Large filters (d \\> 5) are very slow, so it is recommended to use d=5 for real-time\n",
      "        .   applications, and perhaps d=9 for offline applications that need heavy noise filtering.\n",
      "        .   \n",
      "        .   This filter does not work inplace.\n",
      "        .   @param src Source 8-bit or floating-point, 1-channel or 3-channel image.\n",
      "        .   @param dst Destination image of the same size and type as src .\n",
      "        .   @param d Diameter of each pixel neighborhood that is used during filtering. If it is non-positive,\n",
      "        .   it is computed from sigmaSpace.\n",
      "        .   @param sigmaColor Filter sigma in the color space. A larger value of the parameter means that\n",
      "        .   farther colors within the pixel neighborhood (see sigmaSpace) will be mixed together, resulting\n",
      "        .   in larger areas of semi-equal color.\n",
      "        .   @param sigmaSpace Filter sigma in the coordinate space. A larger value of the parameter means that\n",
      "        .   farther pixels will influence each other as long as their colors are close enough (see sigmaColor\n",
      "        .   ). When d\\>0, it specifies the neighborhood size regardless of sigmaSpace. Otherwise, d is\n",
      "        .   proportional to sigmaSpace.\n",
      "        .   @param borderType border mode used to extrapolate pixels outside of the image, see #BorderTypes\n",
      "    \n",
      "    bitwise_and(...)\n",
      "        bitwise_and(src1, src2[, dst[, mask]]) -> dst\n",
      "        .   @brief computes bitwise conjunction of the two arrays (dst = src1 & src2)\n",
      "        .   Calculates the per-element bit-wise conjunction of two arrays or an\n",
      "        .   array and a scalar.\n",
      "        .   \n",
      "        .   The function cv::bitwise_and calculates the per-element bit-wise logical conjunction for:\n",
      "        .   *   Two arrays when src1 and src2 have the same size:\n",
      "        .       \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\wedge \\texttt{src2} (I) \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   *   An array and a scalar when src2 is constructed from Scalar or has\n",
      "        .       the same number of elements as `src1.channels()`:\n",
      "        .       \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\wedge \\texttt{src2} \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   *   A scalar and an array when src1 is constructed from Scalar or has\n",
      "        .       the same number of elements as `src2.channels()`:\n",
      "        .       \\f[\\texttt{dst} (I) =  \\texttt{src1}  \\wedge \\texttt{src2} (I) \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   In case of floating-point arrays, their machine-specific bit\n",
      "        .   representations (usually IEEE754-compliant) are used for the operation.\n",
      "        .   In case of multi-channel arrays, each channel is processed\n",
      "        .   independently. In the second and third cases above, the scalar is first\n",
      "        .   converted to the array type.\n",
      "        .   @param src1 first input array or a scalar.\n",
      "        .   @param src2 second input array or a scalar.\n",
      "        .   @param dst output array that has the same size and type as the input\n",
      "        .   arrays.\n",
      "        .   @param mask optional operation mask, 8-bit single channel array, that\n",
      "        .   specifies elements of the output array to be changed.\n",
      "    \n",
      "    bitwise_not(...)\n",
      "        bitwise_not(src[, dst[, mask]]) -> dst\n",
      "        .   @brief  Inverts every bit of an array.\n",
      "        .   \n",
      "        .   The function cv::bitwise_not calculates per-element bit-wise inversion of the input\n",
      "        .   array:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\neg \\texttt{src} (I)\\f]\n",
      "        .   In case of a floating-point input array, its machine-specific bit\n",
      "        .   representation (usually IEEE754-compliant) is used for the operation. In\n",
      "        .   case of multi-channel arrays, each channel is processed independently.\n",
      "        .   @param src input array.\n",
      "        .   @param dst output array that has the same size and type as the input\n",
      "        .   array.\n",
      "        .   @param mask optional operation mask, 8-bit single channel array, that\n",
      "        .   specifies elements of the output array to be changed.\n",
      "    \n",
      "    bitwise_or(...)\n",
      "        bitwise_or(src1, src2[, dst[, mask]]) -> dst\n",
      "        .   @brief Calculates the per-element bit-wise disjunction of two arrays or an\n",
      "        .   array and a scalar.\n",
      "        .   \n",
      "        .   The function cv::bitwise_or calculates the per-element bit-wise logical disjunction for:\n",
      "        .   *   Two arrays when src1 and src2 have the same size:\n",
      "        .       \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\vee \\texttt{src2} (I) \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   *   An array and a scalar when src2 is constructed from Scalar or has\n",
      "        .       the same number of elements as `src1.channels()`:\n",
      "        .       \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\vee \\texttt{src2} \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   *   A scalar and an array when src1 is constructed from Scalar or has\n",
      "        .       the same number of elements as `src2.channels()`:\n",
      "        .       \\f[\\texttt{dst} (I) =  \\texttt{src1}  \\vee \\texttt{src2} (I) \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   In case of floating-point arrays, their machine-specific bit\n",
      "        .   representations (usually IEEE754-compliant) are used for the operation.\n",
      "        .   In case of multi-channel arrays, each channel is processed\n",
      "        .   independently. In the second and third cases above, the scalar is first\n",
      "        .   converted to the array type.\n",
      "        .   @param src1 first input array or a scalar.\n",
      "        .   @param src2 second input array or a scalar.\n",
      "        .   @param dst output array that has the same size and type as the input\n",
      "        .   arrays.\n",
      "        .   @param mask optional operation mask, 8-bit single channel array, that\n",
      "        .   specifies elements of the output array to be changed.\n",
      "    \n",
      "    bitwise_xor(...)\n",
      "        bitwise_xor(src1, src2[, dst[, mask]]) -> dst\n",
      "        .   @brief Calculates the per-element bit-wise \"exclusive or\" operation on two\n",
      "        .   arrays or an array and a scalar.\n",
      "        .   \n",
      "        .   The function cv::bitwise_xor calculates the per-element bit-wise logical \"exclusive-or\"\n",
      "        .   operation for:\n",
      "        .   *   Two arrays when src1 and src2 have the same size:\n",
      "        .       \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\oplus \\texttt{src2} (I) \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   *   An array and a scalar when src2 is constructed from Scalar or has\n",
      "        .       the same number of elements as `src1.channels()`:\n",
      "        .       \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\oplus \\texttt{src2} \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   *   A scalar and an array when src1 is constructed from Scalar or has\n",
      "        .       the same number of elements as `src2.channels()`:\n",
      "        .       \\f[\\texttt{dst} (I) =  \\texttt{src1}  \\oplus \\texttt{src2} (I) \\quad \\texttt{if mask} (I) \\ne0\\f]\n",
      "        .   In case of floating-point arrays, their machine-specific bit\n",
      "        .   representations (usually IEEE754-compliant) are used for the operation.\n",
      "        .   In case of multi-channel arrays, each channel is processed\n",
      "        .   independently. In the 2nd and 3rd cases above, the scalar is first\n",
      "        .   converted to the array type.\n",
      "        .   @param src1 first input array or a scalar.\n",
      "        .   @param src2 second input array or a scalar.\n",
      "        .   @param dst output array that has the same size and type as the input\n",
      "        .   arrays.\n",
      "        .   @param mask optional operation mask, 8-bit single channel array, that\n",
      "        .   specifies elements of the output array to be changed.\n",
      "    \n",
      "    blur(...)\n",
      "        blur(src, ksize[, dst[, anchor[, borderType]]]) -> dst\n",
      "        .   @brief Blurs an image using the normalized box filter.\n",
      "        .   \n",
      "        .   The function smooths an image using the kernel:\n",
      "        .   \n",
      "        .   \\f[\\texttt{K} =  \\frac{1}{\\texttt{ksize.width*ksize.height}} \\begin{bmatrix} 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ \\hdotsfor{6} \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   The call `blur(src, dst, ksize, anchor, borderType)` is equivalent to `boxFilter(src, dst, src.type(), ksize,\n",
      "        .   anchor, true, borderType)`.\n",
      "        .   \n",
      "        .   @param src input image; it can have any number of channels, which are processed independently, but\n",
      "        .   the depth should be CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
      "        .   @param dst output image of the same size and type as src.\n",
      "        .   @param ksize blurring kernel size.\n",
      "        .   @param anchor anchor point; default value Point(-1,-1) means that the anchor is at the kernel\n",
      "        .   center.\n",
      "        .   @param borderType border mode used to extrapolate pixels outside of the image, see #BorderTypes. #BORDER_WRAP is not supported.\n",
      "        .   @sa  boxFilter, bilateralFilter, GaussianBlur, medianBlur\n",
      "    \n",
      "    borderInterpolate(...)\n",
      "        borderInterpolate(p, len, borderType) -> retval\n",
      "        .   @brief Computes the source location of an extrapolated pixel.\n",
      "        .   \n",
      "        .   The function computes and returns the coordinate of a donor pixel corresponding to the specified\n",
      "        .   extrapolated pixel when using the specified extrapolation border mode. For example, if you use\n",
      "        .   cv::BORDER_WRAP mode in the horizontal direction, cv::BORDER_REFLECT_101 in the vertical direction and\n",
      "        .   want to compute value of the \"virtual\" pixel Point(-5, 100) in a floating-point image img , it\n",
      "        .   looks like:\n",
      "        .   @code{.cpp}\n",
      "        .       float val = img.at<float>(borderInterpolate(100, img.rows, cv::BORDER_REFLECT_101),\n",
      "        .                                 borderInterpolate(-5, img.cols, cv::BORDER_WRAP));\n",
      "        .   @endcode\n",
      "        .   Normally, the function is not called directly. It is used inside filtering functions and also in\n",
      "        .   copyMakeBorder.\n",
      "        .   @param p 0-based coordinate of the extrapolated pixel along one of the axes, likely \\<0 or \\>= len\n",
      "        .   @param len Length of the array along the corresponding axis.\n",
      "        .   @param borderType Border type, one of the #BorderTypes, except for #BORDER_TRANSPARENT and\n",
      "        .   #BORDER_ISOLATED . When borderType==#BORDER_CONSTANT , the function always returns -1, regardless\n",
      "        .   of p and len.\n",
      "        .   \n",
      "        .   @sa copyMakeBorder\n",
      "    \n",
      "    boundingRect(...)\n",
      "        boundingRect(array) -> retval\n",
      "        .   @brief Calculates the up-right bounding rectangle of a point set or non-zero pixels of gray-scale image.\n",
      "        .   \n",
      "        .   The function calculates and returns the minimal up-right bounding rectangle for the specified point set or\n",
      "        .   non-zero pixels of gray-scale image.\n",
      "        .   \n",
      "        .   @param array Input gray-scale image or 2D point set, stored in std::vector or Mat.\n",
      "    \n",
      "    boxFilter(...)\n",
      "        boxFilter(src, ddepth, ksize[, dst[, anchor[, normalize[, borderType]]]]) -> dst\n",
      "        .   @brief Blurs an image using the box filter.\n",
      "        .   \n",
      "        .   The function smooths an image using the kernel:\n",
      "        .   \n",
      "        .   \\f[\\texttt{K} =  \\alpha \\begin{bmatrix} 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ \\hdotsfor{6} \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \n",
      "        .   \\f[\\alpha = \\begin{cases} \\frac{1}{\\texttt{ksize.width*ksize.height}} & \\texttt{when } \\texttt{normalize=true}  \\\\1 & \\texttt{otherwise}\\end{cases}\\f]\n",
      "        .   \n",
      "        .   Unnormalized box filter is useful for computing various integral characteristics over each pixel\n",
      "        .   neighborhood, such as covariance matrices of image derivatives (used in dense optical flow\n",
      "        .   algorithms, and so on). If you need to compute pixel sums over variable-size windows, use #integral.\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image of the same size and type as src.\n",
      "        .   @param ddepth the output image depth (-1 to use src.depth()).\n",
      "        .   @param ksize blurring kernel size.\n",
      "        .   @param anchor anchor point; default value Point(-1,-1) means that the anchor is at the kernel\n",
      "        .   center.\n",
      "        .   @param normalize flag, specifying whether the kernel is normalized by its area or not.\n",
      "        .   @param borderType border mode used to extrapolate pixels outside of the image, see #BorderTypes. #BORDER_WRAP is not supported.\n",
      "        .   @sa  blur, bilateralFilter, GaussianBlur, medianBlur, integral\n",
      "    \n",
      "    boxPoints(...)\n",
      "        boxPoints(box[, points]) -> points\n",
      "        .   @brief Finds the four vertices of a rotated rect. Useful to draw the rotated rectangle.\n",
      "        .   \n",
      "        .   The function finds the four vertices of a rotated rectangle. This function is useful to draw the\n",
      "        .   rectangle. In C++, instead of using this function, you can directly use RotatedRect::points method. Please\n",
      "        .   visit the @ref tutorial_bounding_rotated_ellipses \"tutorial on Creating Bounding rotated boxes and ellipses for contours\" for more information.\n",
      "        .   \n",
      "        .   @param box The input rotated rectangle. It may be the output of\n",
      "        .   @param points The output array of four vertices of rectangles.\n",
      "    \n",
      "    buildOpticalFlowPyramid(...)\n",
      "        buildOpticalFlowPyramid(img, winSize, maxLevel[, pyramid[, withDerivatives[, pyrBorder[, derivBorder[, tryReuseInputImage]]]]]) -> retval, pyramid\n",
      "        .   @brief Constructs the image pyramid which can be passed to calcOpticalFlowPyrLK.\n",
      "        .   \n",
      "        .   @param img 8-bit input image.\n",
      "        .   @param pyramid output pyramid.\n",
      "        .   @param winSize window size of optical flow algorithm. Must be not less than winSize argument of\n",
      "        .   calcOpticalFlowPyrLK. It is needed to calculate required padding for pyramid levels.\n",
      "        .   @param maxLevel 0-based maximal pyramid level number.\n",
      "        .   @param withDerivatives set to precompute gradients for the every pyramid level. If pyramid is\n",
      "        .   constructed without the gradients then calcOpticalFlowPyrLK will calculate them internally.\n",
      "        .   @param pyrBorder the border mode for pyramid layers.\n",
      "        .   @param derivBorder the border mode for gradients.\n",
      "        .   @param tryReuseInputImage put ROI of input image into the pyramid if possible. You can pass false\n",
      "        .   to force data copying.\n",
      "        .   @return number of levels in constructed pyramid. Can be less than maxLevel.\n",
      "    \n",
      "    calcBackProject(...)\n",
      "        calcBackProject(images, channels, hist, ranges, scale[, dst]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    calcCovarMatrix(...)\n",
      "        calcCovarMatrix(samples, mean, flags[, covar[, ctype]]) -> covar, mean\n",
      "        .   @overload\n",
      "        .   @note use #COVAR_ROWS or #COVAR_COLS flag\n",
      "        .   @param samples samples stored as rows/columns of a single matrix.\n",
      "        .   @param covar output covariance matrix of the type ctype and square size.\n",
      "        .   @param mean input or output (depending on the flags) array as the average value of the input vectors.\n",
      "        .   @param flags operation flags as a combination of #CovarFlags\n",
      "        .   @param ctype type of the matrixl; it equals 'CV_64F' by default.\n",
      "    \n",
      "    calcHist(...)\n",
      "        calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]]) -> hist\n",
      "        .   @overload\n",
      "    \n",
      "    calcOpticalFlowFarneback(...)\n",
      "        calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags) -> flow\n",
      "        .   @brief Computes a dense optical flow using the Gunnar Farneback's algorithm.\n",
      "        .   \n",
      "        .   @param prev first 8-bit single-channel input image.\n",
      "        .   @param next second input image of the same size and the same type as prev.\n",
      "        .   @param flow computed flow image that has the same size as prev and type CV_32FC2.\n",
      "        .   @param pyr_scale parameter, specifying the image scale (\\<1) to build pyramids for each image;\n",
      "        .   pyr_scale=0.5 means a classical pyramid, where each next layer is twice smaller than the previous\n",
      "        .   one.\n",
      "        .   @param levels number of pyramid layers including the initial image; levels=1 means that no extra\n",
      "        .   layers are created and only the original images are used.\n",
      "        .   @param winsize averaging window size; larger values increase the algorithm robustness to image\n",
      "        .   noise and give more chances for fast motion detection, but yield more blurred motion field.\n",
      "        .   @param iterations number of iterations the algorithm does at each pyramid level.\n",
      "        .   @param poly_n size of the pixel neighborhood used to find polynomial expansion in each pixel;\n",
      "        .   larger values mean that the image will be approximated with smoother surfaces, yielding more\n",
      "        .   robust algorithm and more blurred motion field, typically poly_n =5 or 7.\n",
      "        .   @param poly_sigma standard deviation of the Gaussian that is used to smooth derivatives used as a\n",
      "        .   basis for the polynomial expansion; for poly_n=5, you can set poly_sigma=1.1, for poly_n=7, a\n",
      "        .   good value would be poly_sigma=1.5.\n",
      "        .   @param flags operation flags that can be a combination of the following:\n",
      "        .    -   **OPTFLOW_USE_INITIAL_FLOW** uses the input flow as an initial flow approximation.\n",
      "        .    -   **OPTFLOW_FARNEBACK_GAUSSIAN** uses the Gaussian \\f$\\texttt{winsize}\\times\\texttt{winsize}\\f$\n",
      "        .        filter instead of a box filter of the same size for optical flow estimation; usually, this\n",
      "        .        option gives z more accurate flow than with a box filter, at the cost of lower speed;\n",
      "        .        normally, winsize for a Gaussian window should be set to a larger value to achieve the same\n",
      "        .        level of robustness.\n",
      "        .   \n",
      "        .   The function finds an optical flow for each prev pixel using the @cite Farneback2003 algorithm so that\n",
      "        .   \n",
      "        .   \\f[\\texttt{prev} (y,x)  \\sim \\texttt{next} ( y + \\texttt{flow} (y,x)[1],  x + \\texttt{flow} (y,x)[0])\\f]\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   -   An example using the optical flow algorithm described by Gunnar Farneback can be found at\n",
      "        .       opencv_source_code/samples/cpp/fback.cpp\n",
      "        .   -   (Python) An example using the optical flow algorithm described by Gunnar Farneback can be\n",
      "        .       found at opencv_source_code/samples/python/opt_flow.py\n",
      "    \n",
      "    calcOpticalFlowPyrLK(...)\n",
      "        calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, nextPts[, status[, err[, winSize[, maxLevel[, criteria[, flags[, minEigThreshold]]]]]]]) -> nextPts, status, err\n",
      "        .   @brief Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with\n",
      "        .   pyramids.\n",
      "        .   \n",
      "        .   @param prevImg first 8-bit input image or pyramid constructed by buildOpticalFlowPyramid.\n",
      "        .   @param nextImg second input image or pyramid of the same size and the same type as prevImg.\n",
      "        .   @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be\n",
      "        .   single-precision floating-point numbers.\n",
      "        .   @param nextPts output vector of 2D points (with single-precision floating-point coordinates)\n",
      "        .   containing the calculated new positions of input features in the second image; when\n",
      "        .   OPTFLOW_USE_INITIAL_FLOW flag is passed, the vector must have the same size as in the input.\n",
      "        .   @param status output status vector (of unsigned chars); each element of the vector is set to 1 if\n",
      "        .   the flow for the corresponding features has been found, otherwise, it is set to 0.\n",
      "        .   @param err output vector of errors; each element of the vector is set to an error for the\n",
      "        .   corresponding feature, type of the error measure can be set in flags parameter; if the flow wasn't\n",
      "        .   found then the error is not defined (use the status parameter to find such cases).\n",
      "        .   @param winSize size of the search window at each pyramid level.\n",
      "        .   @param maxLevel 0-based maximal pyramid level number; if set to 0, pyramids are not used (single\n",
      "        .   level), if set to 1, two levels are used, and so on; if pyramids are passed to input then\n",
      "        .   algorithm will use as many levels as pyramids have but no more than maxLevel.\n",
      "        .   @param criteria parameter, specifying the termination criteria of the iterative search algorithm\n",
      "        .   (after the specified maximum number of iterations criteria.maxCount or when the search window\n",
      "        .   moves by less than criteria.epsilon.\n",
      "        .   @param flags operation flags:\n",
      "        .    -   **OPTFLOW_USE_INITIAL_FLOW** uses initial estimations, stored in nextPts; if the flag is\n",
      "        .        not set, then prevPts is copied to nextPts and is considered the initial estimate.\n",
      "        .    -   **OPTFLOW_LK_GET_MIN_EIGENVALS** use minimum eigen values as an error measure (see\n",
      "        .        minEigThreshold description); if the flag is not set, then L1 distance between patches\n",
      "        .        around the original and a moved point, divided by number of pixels in a window, is used as a\n",
      "        .        error measure.\n",
      "        .   @param minEigThreshold the algorithm calculates the minimum eigen value of a 2x2 normal matrix of\n",
      "        .   optical flow equations (this matrix is called a spatial gradient matrix in @cite Bouguet00), divided\n",
      "        .   by number of pixels in a window; if this value is less than minEigThreshold, then a corresponding\n",
      "        .   feature is filtered out and its flow is not processed, so it allows to remove bad points and get a\n",
      "        .   performance boost.\n",
      "        .   \n",
      "        .   The function implements a sparse iterative version of the Lucas-Kanade optical flow in pyramids. See\n",
      "        .   @cite Bouguet00 . The function is parallelized with the TBB library.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   -   An example using the Lucas-Kanade optical flow algorithm can be found at\n",
      "        .       opencv_source_code/samples/cpp/lkdemo.cpp\n",
      "        .   -   (Python) An example using the Lucas-Kanade optical flow algorithm can be found at\n",
      "        .       opencv_source_code/samples/python/lk_track.py\n",
      "        .   -   (Python) An example using the Lucas-Kanade tracker for homography matching can be found at\n",
      "        .       opencv_source_code/samples/python/lk_homography.py\n",
      "    \n",
      "    calibrateCamera(...)\n",
      "        calibrateCamera(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs\n",
      "        .   @overload\n",
      "    \n",
      "    calibrateCameraExtended(...)\n",
      "        calibrateCameraExtended(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, perViewErrors[, flags[, criteria]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors\n",
      "        .   @brief Finds the camera intrinsic and extrinsic parameters from several views of a calibration\n",
      "        .   pattern.\n",
      "        .   \n",
      "        .   @param objectPoints In the new interface it is a vector of vectors of calibration pattern points in\n",
      "        .   the calibration pattern coordinate space (e.g. std::vector<std::vector<cv::Vec3f>>). The outer\n",
      "        .   vector contains as many elements as the number of pattern views. If the same calibration pattern\n",
      "        .   is shown in each view and it is fully visible, all the vectors will be the same. Although, it is\n",
      "        .   possible to use partially occluded patterns or even different patterns in different views. Then,\n",
      "        .   the vectors will be different. Although the points are 3D, they all lie in the calibration pattern's\n",
      "        .   XY coordinate plane (thus 0 in the Z-coordinate), if the used calibration pattern is a planar rig.\n",
      "        .   In the old interface all the vectors of object points from different views are concatenated\n",
      "        .   together.\n",
      "        .   @param imagePoints In the new interface it is a vector of vectors of the projections of calibration\n",
      "        .   pattern points (e.g. std::vector<std::vector<cv::Vec2f>>). imagePoints.size() and\n",
      "        .   objectPoints.size(), and imagePoints[i].size() and objectPoints[i].size() for each i, must be equal,\n",
      "        .   respectively. In the old interface all the vectors of object points from different views are\n",
      "        .   concatenated together.\n",
      "        .   @param imageSize Size of the image used only to initialize the intrinsic camera matrix.\n",
      "        .   @param cameraMatrix Input/output 3x3 floating-point camera matrix\n",
      "        .   \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ . If CV\\_CALIB\\_USE\\_INTRINSIC\\_GUESS\n",
      "        .   and/or CALIB_FIX_ASPECT_RATIO are specified, some or all of fx, fy, cx, cy must be\n",
      "        .   initialized before calling the function.\n",
      "        .   @param distCoeffs Input/output vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements.\n",
      "        .   @param rvecs Output vector of rotation vectors (@ref Rodrigues ) estimated for each pattern view\n",
      "        .   (e.g. std::vector<cv::Mat>>). That is, each i-th rotation vector together with the corresponding\n",
      "        .   i-th translation vector (see the next output parameter description) brings the calibration pattern\n",
      "        .   from the object coordinate space (in which object points are specified) to the camera coordinate\n",
      "        .   space. In more technical terms, the tuple of the i-th rotation and translation vector performs\n",
      "        .   a change of basis from object coordinate space to camera coordinate space. Due to its duality, this\n",
      "        .   tuple is equivalent to the position of the calibration pattern with respect to the camera coordinate\n",
      "        .   space.\n",
      "        .   @param tvecs Output vector of translation vectors estimated for each pattern view, see parameter\n",
      "        .   describtion above.\n",
      "        .   @param stdDeviationsIntrinsics Output vector of standard deviations estimated for intrinsic\n",
      "        .   parameters. Order of deviations values:\n",
      "        .   \\f$(f_x, f_y, c_x, c_y, k_1, k_2, p_1, p_2, k_3, k_4, k_5, k_6 , s_1, s_2, s_3,\n",
      "        .    s_4, \\tau_x, \\tau_y)\\f$ If one of parameters is not estimated, it's deviation is equals to zero.\n",
      "        .   @param stdDeviationsExtrinsics Output vector of standard deviations estimated for extrinsic\n",
      "        .   parameters. Order of deviations values: \\f$(R_0, T_0, \\dotsc , R_{M - 1}, T_{M - 1})\\f$ where M is\n",
      "        .   the number of pattern views. \\f$R_i, T_i\\f$ are concatenated 1x3 vectors.\n",
      "        .    @param perViewErrors Output vector of the RMS re-projection error estimated for each pattern view.\n",
      "        .   @param flags Different flags that may be zero or a combination of the following values:\n",
      "        .   -   **CALIB_USE_INTRINSIC_GUESS** cameraMatrix contains valid initial values of\n",
      "        .   fx, fy, cx, cy that are optimized further. Otherwise, (cx, cy) is initially set to the image\n",
      "        .   center ( imageSize is used), and focal distances are computed in a least-squares fashion.\n",
      "        .   Note, that if intrinsic parameters are known, there is no need to use this function just to\n",
      "        .   estimate extrinsic parameters. Use solvePnP instead.\n",
      "        .   -   **CALIB_FIX_PRINCIPAL_POINT** The principal point is not changed during the global\n",
      "        .   optimization. It stays at the center or at a different location specified when\n",
      "        .   CALIB_USE_INTRINSIC_GUESS is set too.\n",
      "        .   -   **CALIB_FIX_ASPECT_RATIO** The functions consider only fy as a free parameter. The\n",
      "        .   ratio fx/fy stays the same as in the input cameraMatrix . When\n",
      "        .   CALIB_USE_INTRINSIC_GUESS is not set, the actual input values of fx and fy are\n",
      "        .   ignored, only their ratio is computed and used further.\n",
      "        .   -   **CALIB_ZERO_TANGENT_DIST** Tangential distortion coefficients \\f$(p_1, p_2)\\f$ are set\n",
      "        .   to zeros and stay zero.\n",
      "        .   -   **CALIB_FIX_K1,...,CALIB_FIX_K6** The corresponding radial distortion\n",
      "        .   coefficient is not changed during the optimization. If CALIB_USE_INTRINSIC_GUESS is\n",
      "        .   set, the coefficient from the supplied distCoeffs matrix is used. Otherwise, it is set to 0.\n",
      "        .   -   **CALIB_RATIONAL_MODEL** Coefficients k4, k5, and k6 are enabled. To provide the\n",
      "        .   backward compatibility, this extra flag should be explicitly specified to make the\n",
      "        .   calibration function use the rational model and return 8 coefficients. If the flag is not\n",
      "        .   set, the function computes and returns only 5 distortion coefficients.\n",
      "        .   -   **CALIB_THIN_PRISM_MODEL** Coefficients s1, s2, s3 and s4 are enabled. To provide the\n",
      "        .   backward compatibility, this extra flag should be explicitly specified to make the\n",
      "        .   calibration function use the thin prism model and return 12 coefficients. If the flag is not\n",
      "        .   set, the function computes and returns only 5 distortion coefficients.\n",
      "        .   -   **CALIB_FIX_S1_S2_S3_S4** The thin prism distortion coefficients are not changed during\n",
      "        .   the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the\n",
      "        .   supplied distCoeffs matrix is used. Otherwise, it is set to 0.\n",
      "        .   -   **CALIB_TILTED_MODEL** Coefficients tauX and tauY are enabled. To provide the\n",
      "        .   backward compatibility, this extra flag should be explicitly specified to make the\n",
      "        .   calibration function use the tilted sensor model and return 14 coefficients. If the flag is not\n",
      "        .   set, the function computes and returns only 5 distortion coefficients.\n",
      "        .   -   **CALIB_FIX_TAUX_TAUY** The coefficients of the tilted sensor model are not changed during\n",
      "        .   the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the\n",
      "        .   supplied distCoeffs matrix is used. Otherwise, it is set to 0.\n",
      "        .   @param criteria Termination criteria for the iterative optimization algorithm.\n",
      "        .   \n",
      "        .   @return the overall RMS re-projection error.\n",
      "        .   \n",
      "        .   The function estimates the intrinsic camera parameters and extrinsic parameters for each of the\n",
      "        .   views. The algorithm is based on @cite Zhang2000 and @cite BouguetMCT . The coordinates of 3D object\n",
      "        .   points and their corresponding 2D projections in each view must be specified. That may be achieved\n",
      "        .   by using an object with known geometry and easily detectable feature points. Such an object is\n",
      "        .   called a calibration rig or calibration pattern, and OpenCV has built-in support for a chessboard as\n",
      "        .   a calibration rig (see @ref findChessboardCorners). Currently, initialization of intrinsic\n",
      "        .   parameters (when CALIB_USE_INTRINSIC_GUESS is not set) is only implemented for planar calibration\n",
      "        .   patterns (where Z-coordinates of the object points must be all zeros). 3D calibration rigs can also\n",
      "        .   be used as long as initial cameraMatrix is provided.\n",
      "        .   \n",
      "        .   The algorithm performs the following steps:\n",
      "        .   \n",
      "        .   -   Compute the initial intrinsic parameters (the option only available for planar calibration\n",
      "        .       patterns) or read them from the input parameters. The distortion coefficients are all set to\n",
      "        .       zeros initially unless some of CALIB_FIX_K? are specified.\n",
      "        .   \n",
      "        .   -   Estimate the initial camera pose as if the intrinsic parameters have been already known. This is\n",
      "        .       done using solvePnP .\n",
      "        .   \n",
      "        .   -   Run the global Levenberg-Marquardt optimization algorithm to minimize the reprojection error,\n",
      "        .       that is, the total sum of squared distances between the observed feature points imagePoints and\n",
      "        .       the projected (using the current estimates for camera parameters and the poses) object points\n",
      "        .       objectPoints. See projectPoints for details.\n",
      "        .   \n",
      "        .   @note\n",
      "        .       If you use a non-square (i.e. non-N-by-N) grid and @ref findChessboardCorners for calibration,\n",
      "        .       and @ref calibrateCamera returns bad values (zero distortion coefficients, \\f$c_x\\f$ and\n",
      "        .       \\f$c_y\\f$ very far from the image center, and/or large differences between \\f$f_x\\f$ and\n",
      "        .       \\f$f_y\\f$ (ratios of 10:1 or more)), then you are probably using patternSize=cvSize(rows,cols)\n",
      "        .       instead of using patternSize=cvSize(cols,rows) in @ref findChessboardCorners.\n",
      "        .   \n",
      "        .   @sa\n",
      "        .      calibrateCameraRO, findChessboardCorners, solvePnP, initCameraMatrix2D, stereoCalibrate,\n",
      "        .      undistort\n",
      "    \n",
      "    calibrateCameraRO(...)\n",
      "        calibrateCameraRO(objectPoints, imagePoints, imageSize, iFixedPoint, cameraMatrix, distCoeffs[, rvecs[, tvecs[, newObjPoints[, flags[, criteria]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, newObjPoints\n",
      "        .   @overload\n",
      "    \n",
      "    calibrateCameraROExtended(...)\n",
      "        calibrateCameraROExtended(objectPoints, imagePoints, imageSize, iFixedPoint, cameraMatrix, distCoeffs[, rvecs[, tvecs[, newObjPoints[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, stdDeviationsObjPoints[, perViewErrors[, flags[, criteria]]]]]]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs, newObjPoints, stdDeviationsIntrinsics, stdDeviationsExtrinsics, stdDeviationsObjPoints, perViewErrors\n",
      "        .   @brief Finds the camera intrinsic and extrinsic parameters from several views of a calibration pattern.\n",
      "        .   \n",
      "        .   This function is an extension of calibrateCamera() with the method of releasing object which was\n",
      "        .   proposed in @cite strobl2011iccv. In many common cases with inaccurate, unmeasured, roughly planar\n",
      "        .   targets (calibration plates), this method can dramatically improve the precision of the estimated\n",
      "        .   camera parameters. Both the object-releasing method and standard method are supported by this\n",
      "        .   function. Use the parameter **iFixedPoint** for method selection. In the internal implementation,\n",
      "        .   calibrateCamera() is a wrapper for this function.\n",
      "        .   \n",
      "        .   @param objectPoints Vector of vectors of calibration pattern points in the calibration pattern\n",
      "        .   coordinate space. See calibrateCamera() for details. If the method of releasing object to be used,\n",
      "        .   the identical calibration board must be used in each view and it must be fully visible, and all\n",
      "        .   objectPoints[i] must be the same and all points should be roughly close to a plane. **The calibration\n",
      "        .   target has to be rigid, or at least static if the camera (rather than the calibration target) is\n",
      "        .   shifted for grabbing images.**\n",
      "        .   @param imagePoints Vector of vectors of the projections of calibration pattern points. See\n",
      "        .   calibrateCamera() for details.\n",
      "        .   @param imageSize Size of the image used only to initialize the intrinsic camera matrix.\n",
      "        .   @param iFixedPoint The index of the 3D object point in objectPoints[0] to be fixed. It also acts as\n",
      "        .   a switch for calibration method selection. If object-releasing method to be used, pass in the\n",
      "        .   parameter in the range of [1, objectPoints[0].size()-2], otherwise a value out of this range will\n",
      "        .   make standard calibration method selected. Usually the top-right corner point of the calibration\n",
      "        .   board grid is recommended to be fixed when object-releasing method being utilized. According to\n",
      "        .   \\cite strobl2011iccv, two other points are also fixed. In this implementation, objectPoints[0].front\n",
      "        .   and objectPoints[0].back.z are used. With object-releasing method, accurate rvecs, tvecs and\n",
      "        .   newObjPoints are only possible if coordinates of these three fixed points are accurate enough.\n",
      "        .   @param cameraMatrix Output 3x3 floating-point camera matrix. See calibrateCamera() for details.\n",
      "        .   @param distCoeffs Output vector of distortion coefficients. See calibrateCamera() for details.\n",
      "        .   @param rvecs Output vector of rotation vectors estimated for each pattern view. See calibrateCamera()\n",
      "        .   for details.\n",
      "        .   @param tvecs Output vector of translation vectors estimated for each pattern view.\n",
      "        .   @param newObjPoints The updated output vector of calibration pattern points. The coordinates might\n",
      "        .   be scaled based on three fixed points. The returned coordinates are accurate only if the above\n",
      "        .   mentioned three fixed points are accurate. If not needed, noArray() can be passed in. This parameter\n",
      "        .   is ignored with standard calibration method.\n",
      "        .   @param stdDeviationsIntrinsics Output vector of standard deviations estimated for intrinsic parameters.\n",
      "        .   See calibrateCamera() for details.\n",
      "        .   @param stdDeviationsExtrinsics Output vector of standard deviations estimated for extrinsic parameters.\n",
      "        .   See calibrateCamera() for details.\n",
      "        .   @param stdDeviationsObjPoints Output vector of standard deviations estimated for refined coordinates\n",
      "        .   of calibration pattern points. It has the same size and order as objectPoints[0] vector. This\n",
      "        .   parameter is ignored with standard calibration method.\n",
      "        .    @param perViewErrors Output vector of the RMS re-projection error estimated for each pattern view.\n",
      "        .   @param flags Different flags that may be zero or a combination of some predefined values. See\n",
      "        .   calibrateCamera() for details. If the method of releasing object is used, the calibration time may\n",
      "        .   be much longer. CALIB_USE_QR or CALIB_USE_LU could be used for faster calibration with potentially\n",
      "        .   less precise and less stable in some rare cases.\n",
      "        .   @param criteria Termination criteria for the iterative optimization algorithm.\n",
      "        .   \n",
      "        .   @return the overall RMS re-projection error.\n",
      "        .   \n",
      "        .   The function estimates the intrinsic camera parameters and extrinsic parameters for each of the\n",
      "        .   views. The algorithm is based on @cite Zhang2000, @cite BouguetMCT and @cite strobl2011iccv. See\n",
      "        .   calibrateCamera() for other detailed explanations.\n",
      "        .   @sa\n",
      "        .      calibrateCamera, findChessboardCorners, solvePnP, initCameraMatrix2D, stereoCalibrate, undistort\n",
      "    \n",
      "    calibrateHandEye(...)\n",
      "        calibrateHandEye(R_gripper2base, t_gripper2base, R_target2cam, t_target2cam[, R_cam2gripper[, t_cam2gripper[, method]]]) -> R_cam2gripper, t_cam2gripper\n",
      "        .   @brief Computes Hand-Eye calibration: \\f$_{}^{g}\\textrm{T}_c\\f$\n",
      "        .   \n",
      "        .   @param[in] R_gripper2base Rotation part extracted from the homogeneous matrix that transforms a point\n",
      "        .   expressed in the gripper frame to the robot base frame (\\f$_{}^{b}\\textrm{T}_g\\f$).\n",
      "        .   This is a vector (`vector<Mat>`) that contains the rotation matrices for all the transformations\n",
      "        .   from gripper frame to robot base frame.\n",
      "        .   @param[in] t_gripper2base Translation part extracted from the homogeneous matrix that transforms a point\n",
      "        .   expressed in the gripper frame to the robot base frame (\\f$_{}^{b}\\textrm{T}_g\\f$).\n",
      "        .   This is a vector (`vector<Mat>`) that contains the translation vectors for all the transformations\n",
      "        .   from gripper frame to robot base frame.\n",
      "        .   @param[in] R_target2cam Rotation part extracted from the homogeneous matrix that transforms a point\n",
      "        .   expressed in the target frame to the camera frame (\\f$_{}^{c}\\textrm{T}_t\\f$).\n",
      "        .   This is a vector (`vector<Mat>`) that contains the rotation matrices for all the transformations\n",
      "        .   from calibration target frame to camera frame.\n",
      "        .   @param[in] t_target2cam Rotation part extracted from the homogeneous matrix that transforms a point\n",
      "        .   expressed in the target frame to the camera frame (\\f$_{}^{c}\\textrm{T}_t\\f$).\n",
      "        .   This is a vector (`vector<Mat>`) that contains the translation vectors for all the transformations\n",
      "        .   from calibration target frame to camera frame.\n",
      "        .   @param[out] R_cam2gripper Estimated rotation part extracted from the homogeneous matrix that transforms a point\n",
      "        .   expressed in the camera frame to the gripper frame (\\f$_{}^{g}\\textrm{T}_c\\f$).\n",
      "        .   @param[out] t_cam2gripper Estimated translation part extracted from the homogeneous matrix that transforms a point\n",
      "        .   expressed in the camera frame to the gripper frame (\\f$_{}^{g}\\textrm{T}_c\\f$).\n",
      "        .   @param[in] method One of the implemented Hand-Eye calibration method, see cv::HandEyeCalibrationMethod\n",
      "        .   \n",
      "        .   The function performs the Hand-Eye calibration using various methods. One approach consists in estimating the\n",
      "        .   rotation then the translation (separable solutions) and the following methods are implemented:\n",
      "        .     - R. Tsai, R. Lenz A New Technique for Fully Autonomous and Efficient 3D Robotics Hand/EyeCalibration \\cite Tsai89\n",
      "        .     - F. Park, B. Martin Robot Sensor Calibration: Solving AX = XB on the Euclidean Group \\cite Park94\n",
      "        .     - R. Horaud, F. Dornaika Hand-Eye Calibration \\cite Horaud95\n",
      "        .   \n",
      "        .   Another approach consists in estimating simultaneously the rotation and the translation (simultaneous solutions),\n",
      "        .   with the following implemented method:\n",
      "        .     - N. Andreff, R. Horaud, B. Espiau On-line Hand-Eye Calibration \\cite Andreff99\n",
      "        .     - K. Daniilidis Hand-Eye Calibration Using Dual Quaternions \\cite Daniilidis98\n",
      "        .   \n",
      "        .   The following picture describes the Hand-Eye calibration problem where the transformation between a camera (\"eye\")\n",
      "        .   mounted on a robot gripper (\"hand\") has to be estimated.\n",
      "        .   \n",
      "        .   ![](pics/hand-eye_figure.png)\n",
      "        .   \n",
      "        .   The calibration procedure is the following:\n",
      "        .     - a static calibration pattern is used to estimate the transformation between the target frame\n",
      "        .     and the camera frame\n",
      "        .     - the robot gripper is moved in order to acquire several poses\n",
      "        .     - for each pose, the homogeneous transformation between the gripper frame and the robot base frame is recorded using for\n",
      "        .     instance the robot kinematics\n",
      "        .   \\f[\n",
      "        .       \\begin{bmatrix}\n",
      "        .       X_b\\\\\n",
      "        .       Y_b\\\\\n",
      "        .       Z_b\\\\\n",
      "        .       1\n",
      "        .       \\end{bmatrix}\n",
      "        .       =\n",
      "        .       \\begin{bmatrix}\n",
      "        .       _{}^{b}\\textrm{R}_g & _{}^{b}\\textrm{t}_g \\\\\n",
      "        .       0_{1 \\times 3} & 1\n",
      "        .       \\end{bmatrix}\n",
      "        .       \\begin{bmatrix}\n",
      "        .       X_g\\\\\n",
      "        .       Y_g\\\\\n",
      "        .       Z_g\\\\\n",
      "        .       1\n",
      "        .       \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .     - for each pose, the homogeneous transformation between the calibration target frame and the camera frame is recorded using\n",
      "        .     for instance a pose estimation method (PnP) from 2D-3D point correspondences\n",
      "        .   \\f[\n",
      "        .       \\begin{bmatrix}\n",
      "        .       X_c\\\\\n",
      "        .       Y_c\\\\\n",
      "        .       Z_c\\\\\n",
      "        .       1\n",
      "        .       \\end{bmatrix}\n",
      "        .       =\n",
      "        .       \\begin{bmatrix}\n",
      "        .       _{}^{c}\\textrm{R}_t & _{}^{c}\\textrm{t}_t \\\\\n",
      "        .       0_{1 \\times 3} & 1\n",
      "        .       \\end{bmatrix}\n",
      "        .       \\begin{bmatrix}\n",
      "        .       X_t\\\\\n",
      "        .       Y_t\\\\\n",
      "        .       Z_t\\\\\n",
      "        .       1\n",
      "        .       \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   The Hand-Eye calibration procedure returns the following homogeneous transformation\n",
      "        .   \\f[\n",
      "        .       \\begin{bmatrix}\n",
      "        .       X_g\\\\\n",
      "        .       Y_g\\\\\n",
      "        .       Z_g\\\\\n",
      "        .       1\n",
      "        .       \\end{bmatrix}\n",
      "        .       =\n",
      "        .       \\begin{bmatrix}\n",
      "        .       _{}^{g}\\textrm{R}_c & _{}^{g}\\textrm{t}_c \\\\\n",
      "        .       0_{1 \\times 3} & 1\n",
      "        .       \\end{bmatrix}\n",
      "        .       \\begin{bmatrix}\n",
      "        .       X_c\\\\\n",
      "        .       Y_c\\\\\n",
      "        .       Z_c\\\\\n",
      "        .       1\n",
      "        .       \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   This problem is also known as solving the \\f$\\mathbf{A}\\mathbf{X}=\\mathbf{X}\\mathbf{B}\\f$ equation:\n",
      "        .   \\f[\n",
      "        .       \\begin{align*}\n",
      "        .       ^{b}{\\textrm{T}_g}^{(1)} \\hspace{0.2em} ^{g}\\textrm{T}_c \\hspace{0.2em} ^{c}{\\textrm{T}_t}^{(1)} &=\n",
      "        .       \\hspace{0.1em} ^{b}{\\textrm{T}_g}^{(2)} \\hspace{0.2em} ^{g}\\textrm{T}_c \\hspace{0.2em} ^{c}{\\textrm{T}_t}^{(2)} \\\\\n",
      "        .   \n",
      "        .       (^{b}{\\textrm{T}_g}^{(2)})^{-1} \\hspace{0.2em} ^{b}{\\textrm{T}_g}^{(1)} \\hspace{0.2em} ^{g}\\textrm{T}_c &=\n",
      "        .       \\hspace{0.1em} ^{g}\\textrm{T}_c \\hspace{0.2em} ^{c}{\\textrm{T}_t}^{(2)} (^{c}{\\textrm{T}_t}^{(1)})^{-1} \\\\\n",
      "        .   \n",
      "        .       \\textrm{A}_i \\textrm{X} &= \\textrm{X} \\textrm{B}_i \\\\\n",
      "        .       \\end{align*}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   \\note\n",
      "        .   Additional information can be found on this [website](http://campar.in.tum.de/Chair/HandEyeCalibration).\n",
      "        .   \\note\n",
      "        .   A minimum of 2 motions with non parallel rotation axes are necessary to determine the hand-eye transformation.\n",
      "        .   So at least 3 different poses are required, but it is strongly recommended to use many more poses.\n",
      "    \n",
      "    calibrationMatrixValues(...)\n",
      "        calibrationMatrixValues(cameraMatrix, imageSize, apertureWidth, apertureHeight) -> fovx, fovy, focalLength, principalPoint, aspectRatio\n",
      "        .   @brief Computes useful camera characteristics from the camera matrix.\n",
      "        .   \n",
      "        .   @param cameraMatrix Input camera matrix that can be estimated by calibrateCamera or\n",
      "        .   stereoCalibrate .\n",
      "        .   @param imageSize Input image size in pixels.\n",
      "        .   @param apertureWidth Physical width in mm of the sensor.\n",
      "        .   @param apertureHeight Physical height in mm of the sensor.\n",
      "        .   @param fovx Output field of view in degrees along the horizontal sensor axis.\n",
      "        .   @param fovy Output field of view in degrees along the vertical sensor axis.\n",
      "        .   @param focalLength Focal length of the lens in mm.\n",
      "        .   @param principalPoint Principal point in mm.\n",
      "        .   @param aspectRatio \\f$f_y/f_x\\f$\n",
      "        .   \n",
      "        .   The function computes various useful camera characteristics from the previously estimated camera\n",
      "        .   matrix.\n",
      "        .   \n",
      "        .   @note\n",
      "        .      Do keep in mind that the unity measure 'mm' stands for whatever unit of measure one chooses for\n",
      "        .       the chessboard pitch (it can thus be any value).\n",
      "    \n",
      "    cartToPolar(...)\n",
      "        cartToPolar(x, y[, magnitude[, angle[, angleInDegrees]]]) -> magnitude, angle\n",
      "        .   @brief Calculates the magnitude and angle of 2D vectors.\n",
      "        .   \n",
      "        .   The function cv::cartToPolar calculates either the magnitude, angle, or both\n",
      "        .   for every 2D vector (x(I),y(I)):\n",
      "        .   \\f[\\begin{array}{l} \\texttt{magnitude} (I)= \\sqrt{\\texttt{x}(I)^2+\\texttt{y}(I)^2} , \\\\ \\texttt{angle} (I)= \\texttt{atan2} ( \\texttt{y} (I), \\texttt{x} (I))[ \\cdot180 / \\pi ] \\end{array}\\f]\n",
      "        .   \n",
      "        .   The angles are calculated with accuracy about 0.3 degrees. For the point\n",
      "        .   (0,0), the angle is set to 0.\n",
      "        .   @param x array of x-coordinates; this must be a single-precision or\n",
      "        .   double-precision floating-point array.\n",
      "        .   @param y array of y-coordinates, that must have the same size and same type as x.\n",
      "        .   @param magnitude output array of magnitudes of the same size and type as x.\n",
      "        .   @param angle output array of angles that has the same size and type as\n",
      "        .   x; the angles are measured in radians (from 0 to 2\\*Pi) or in degrees (0 to 360 degrees).\n",
      "        .   @param angleInDegrees a flag, indicating whether the angles are measured\n",
      "        .   in radians (which is by default), or in degrees.\n",
      "        .   @sa Sobel, Scharr\n",
      "    \n",
      "    checkChessboard(...)\n",
      "        checkChessboard(img, size) -> retval\n",
      "        .\n",
      "    \n",
      "    checkHardwareSupport(...)\n",
      "        checkHardwareSupport(feature) -> retval\n",
      "        .   @brief Returns true if the specified feature is supported by the host hardware.\n",
      "        .   \n",
      "        .   The function returns true if the host hardware supports the specified feature. When user calls\n",
      "        .   setUseOptimized(false), the subsequent calls to checkHardwareSupport() will return false until\n",
      "        .   setUseOptimized(true) is called. This way user can dynamically switch on and off the optimized code\n",
      "        .   in OpenCV.\n",
      "        .   @param feature The feature of interest, one of cv::CpuFeatures\n",
      "    \n",
      "    checkRange(...)\n",
      "        checkRange(a[, quiet[, minVal[, maxVal]]]) -> retval, pos\n",
      "        .   @brief Checks every element of an input array for invalid values.\n",
      "        .   \n",
      "        .   The function cv::checkRange checks that every array element is neither NaN nor infinite. When minVal \\>\n",
      "        .   -DBL_MAX and maxVal \\< DBL_MAX, the function also checks that each value is between minVal and\n",
      "        .   maxVal. In case of multi-channel arrays, each channel is processed independently. If some values\n",
      "        .   are out of range, position of the first outlier is stored in pos (when pos != NULL). Then, the\n",
      "        .   function either returns false (when quiet=true) or throws an exception.\n",
      "        .   @param a input array.\n",
      "        .   @param quiet a flag, indicating whether the functions quietly return false when the array elements\n",
      "        .   are out of range or they throw an exception.\n",
      "        .   @param pos optional output parameter, when not NULL, must be a pointer to array of src.dims\n",
      "        .   elements.\n",
      "        .   @param minVal inclusive lower boundary of valid values range.\n",
      "        .   @param maxVal exclusive upper boundary of valid values range.\n",
      "    \n",
      "    circle(...)\n",
      "        circle(img, center, radius, color[, thickness[, lineType[, shift]]]) -> img\n",
      "        .   @brief Draws a circle.\n",
      "        .   \n",
      "        .   The function cv::circle draws a simple or filled circle with a given center and radius.\n",
      "        .   @param img Image where the circle is drawn.\n",
      "        .   @param center Center of the circle.\n",
      "        .   @param radius Radius of the circle.\n",
      "        .   @param color Circle color.\n",
      "        .   @param thickness Thickness of the circle outline, if positive. Negative values, like #FILLED,\n",
      "        .   mean that a filled circle is to be drawn.\n",
      "        .   @param lineType Type of the circle boundary. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the coordinates of the center and in the radius value.\n",
      "    \n",
      "    clipLine(...)\n",
      "        clipLine(imgRect, pt1, pt2) -> retval, pt1, pt2\n",
      "        .   @overload\n",
      "        .   @param imgRect Image rectangle.\n",
      "        .   @param pt1 First line point.\n",
      "        .   @param pt2 Second line point.\n",
      "    \n",
      "    colorChange(...)\n",
      "        colorChange(src, mask[, dst[, red_mul[, green_mul[, blue_mul]]]]) -> dst\n",
      "        .   @brief Given an original color image, two differently colored versions of this image can be mixed\n",
      "        .   seamlessly.\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param mask Input 8-bit 1 or 3-channel image.\n",
      "        .   @param dst Output image with the same size and type as src .\n",
      "        .   @param red_mul R-channel multiply factor.\n",
      "        .   @param green_mul G-channel multiply factor.\n",
      "        .   @param blue_mul B-channel multiply factor.\n",
      "        .   \n",
      "        .   Multiplication factor is between .5 to 2.5.\n",
      "    \n",
      "    compare(...)\n",
      "        compare(src1, src2, cmpop[, dst]) -> dst\n",
      "        .   @brief Performs the per-element comparison of two arrays or an array and scalar value.\n",
      "        .   \n",
      "        .   The function compares:\n",
      "        .   *   Elements of two arrays when src1 and src2 have the same size:\n",
      "        .       \\f[\\texttt{dst} (I) =  \\texttt{src1} (I)  \\,\\texttt{cmpop}\\, \\texttt{src2} (I)\\f]\n",
      "        .   *   Elements of src1 with a scalar src2 when src2 is constructed from\n",
      "        .       Scalar or has a single element:\n",
      "        .       \\f[\\texttt{dst} (I) =  \\texttt{src1}(I) \\,\\texttt{cmpop}\\,  \\texttt{src2}\\f]\n",
      "        .   *   src1 with elements of src2 when src1 is constructed from Scalar or\n",
      "        .       has a single element:\n",
      "        .       \\f[\\texttt{dst} (I) =  \\texttt{src1}  \\,\\texttt{cmpop}\\, \\texttt{src2} (I)\\f]\n",
      "        .   When the comparison result is true, the corresponding element of output\n",
      "        .   array is set to 255. The comparison operations can be replaced with the\n",
      "        .   equivalent matrix expressions:\n",
      "        .   @code{.cpp}\n",
      "        .       Mat dst1 = src1 >= src2;\n",
      "        .       Mat dst2 = src1 < 8;\n",
      "        .       ...\n",
      "        .   @endcode\n",
      "        .   @param src1 first input array or a scalar; when it is an array, it must have a single channel.\n",
      "        .   @param src2 second input array or a scalar; when it is an array, it must have a single channel.\n",
      "        .   @param dst output array of type ref CV_8U that has the same size and the same number of channels as\n",
      "        .       the input arrays.\n",
      "        .   @param cmpop a flag, that specifies correspondence between the arrays (cv::CmpTypes)\n",
      "        .   @sa checkRange, min, max, threshold\n",
      "    \n",
      "    compareHist(...)\n",
      "        compareHist(H1, H2, method) -> retval\n",
      "        .   @brief Compares two histograms.\n",
      "        .   \n",
      "        .   The function cv::compareHist compares two dense or two sparse histograms using the specified method.\n",
      "        .   \n",
      "        .   The function returns \\f$d(H_1, H_2)\\f$ .\n",
      "        .   \n",
      "        .   While the function works well with 1-, 2-, 3-dimensional dense histograms, it may not be suitable\n",
      "        .   for high-dimensional sparse histograms. In such histograms, because of aliasing and sampling\n",
      "        .   problems, the coordinates of non-zero histogram bins can slightly shift. To compare such histograms\n",
      "        .   or more general sparse configurations of weighted points, consider using the #EMD function.\n",
      "        .   \n",
      "        .   @param H1 First compared histogram.\n",
      "        .   @param H2 Second compared histogram of the same size as H1 .\n",
      "        .   @param method Comparison method, see #HistCompMethods\n",
      "    \n",
      "    completeSymm(...)\n",
      "        completeSymm(m[, lowerToUpper]) -> m\n",
      "        .   @brief Copies the lower or the upper half of a square matrix to its another half.\n",
      "        .   \n",
      "        .   The function cv::completeSymm copies the lower or the upper half of a square matrix to\n",
      "        .   its another half. The matrix diagonal remains unchanged:\n",
      "        .    - \\f$\\texttt{m}_{ij}=\\texttt{m}_{ji}\\f$ for \\f$i > j\\f$ if\n",
      "        .       lowerToUpper=false\n",
      "        .    - \\f$\\texttt{m}_{ij}=\\texttt{m}_{ji}\\f$ for \\f$i < j\\f$ if\n",
      "        .       lowerToUpper=true\n",
      "        .   \n",
      "        .   @param m input-output floating-point square matrix.\n",
      "        .   @param lowerToUpper operation flag; if true, the lower half is copied to\n",
      "        .   the upper half. Otherwise, the upper half is copied to the lower half.\n",
      "        .   @sa flip, transpose\n",
      "    \n",
      "    composeRT(...)\n",
      "        composeRT(rvec1, tvec1, rvec2, tvec2[, rvec3[, tvec3[, dr3dr1[, dr3dt1[, dr3dr2[, dr3dt2[, dt3dr1[, dt3dt1[, dt3dr2[, dt3dt2]]]]]]]]]]) -> rvec3, tvec3, dr3dr1, dr3dt1, dr3dr2, dr3dt2, dt3dr1, dt3dt1, dt3dr2, dt3dt2\n",
      "        .   @brief Combines two rotation-and-shift transformations.\n",
      "        .   \n",
      "        .   @param rvec1 First rotation vector.\n",
      "        .   @param tvec1 First translation vector.\n",
      "        .   @param rvec2 Second rotation vector.\n",
      "        .   @param tvec2 Second translation vector.\n",
      "        .   @param rvec3 Output rotation vector of the superposition.\n",
      "        .   @param tvec3 Output translation vector of the superposition.\n",
      "        .   @param dr3dr1 Optional output derivative of rvec3 with regard to rvec1\n",
      "        .   @param dr3dt1 Optional output derivative of rvec3 with regard to tvec1\n",
      "        .   @param dr3dr2 Optional output derivative of rvec3 with regard to rvec2\n",
      "        .   @param dr3dt2 Optional output derivative of rvec3 with regard to tvec2\n",
      "        .   @param dt3dr1 Optional output derivative of tvec3 with regard to rvec1\n",
      "        .   @param dt3dt1 Optional output derivative of tvec3 with regard to tvec1\n",
      "        .   @param dt3dr2 Optional output derivative of tvec3 with regard to rvec2\n",
      "        .   @param dt3dt2 Optional output derivative of tvec3 with regard to tvec2\n",
      "        .   \n",
      "        .   The functions compute:\n",
      "        .   \n",
      "        .   \\f[\\begin{array}{l} \\texttt{rvec3} =  \\mathrm{rodrigues} ^{-1} \\left ( \\mathrm{rodrigues} ( \\texttt{rvec2} )  \\cdot \\mathrm{rodrigues} ( \\texttt{rvec1} ) \\right )  \\\\ \\texttt{tvec3} =  \\mathrm{rodrigues} ( \\texttt{rvec2} )  \\cdot \\texttt{tvec1} +  \\texttt{tvec2} \\end{array} ,\\f]\n",
      "        .   \n",
      "        .   where \\f$\\mathrm{rodrigues}\\f$ denotes a rotation vector to a rotation matrix transformation, and\n",
      "        .   \\f$\\mathrm{rodrigues}^{-1}\\f$ denotes the inverse transformation. See Rodrigues for details.\n",
      "        .   \n",
      "        .   Also, the functions can compute the derivatives of the output vectors with regards to the input\n",
      "        .   vectors (see matMulDeriv ). The functions are used inside stereoCalibrate but can also be used in\n",
      "        .   your own code where Levenberg-Marquardt or another gradient-based solver is used to optimize a\n",
      "        .   function that contains a matrix multiplication.\n",
      "    \n",
      "    computeCorrespondEpilines(...)\n",
      "        computeCorrespondEpilines(points, whichImage, F[, lines]) -> lines\n",
      "        .   @brief For points in an image of a stereo pair, computes the corresponding epilines in the other image.\n",
      "        .   \n",
      "        .   @param points Input points. \\f$N \\times 1\\f$ or \\f$1 \\times N\\f$ matrix of type CV_32FC2 or\n",
      "        .   vector\\<Point2f\\> .\n",
      "        .   @param whichImage Index of the image (1 or 2) that contains the points .\n",
      "        .   @param F Fundamental matrix that can be estimated using findFundamentalMat or stereoRectify .\n",
      "        .   @param lines Output vector of the epipolar lines corresponding to the points in the other image.\n",
      "        .   Each line \\f$ax + by + c=0\\f$ is encoded by 3 numbers \\f$(a, b, c)\\f$ .\n",
      "        .   \n",
      "        .   For every point in one of the two images of a stereo pair, the function finds the equation of the\n",
      "        .   corresponding epipolar line in the other image.\n",
      "        .   \n",
      "        .   From the fundamental matrix definition (see findFundamentalMat ), line \\f$l^{(2)}_i\\f$ in the second\n",
      "        .   image for the point \\f$p^{(1)}_i\\f$ in the first image (when whichImage=1 ) is computed as:\n",
      "        .   \n",
      "        .   \\f[l^{(2)}_i = F p^{(1)}_i\\f]\n",
      "        .   \n",
      "        .   And vice versa, when whichImage=2, \\f$l^{(1)}_i\\f$ is computed from \\f$p^{(2)}_i\\f$ as:\n",
      "        .   \n",
      "        .   \\f[l^{(1)}_i = F^T p^{(2)}_i\\f]\n",
      "        .   \n",
      "        .   Line coefficients are defined up to a scale. They are normalized so that \\f$a_i^2+b_i^2=1\\f$ .\n",
      "    \n",
      "    computeECC(...)\n",
      "        computeECC(templateImage, inputImage[, inputMask]) -> retval\n",
      "        .   @brief Computes the Enhanced Correlation Coefficient value between two images @cite EP08 .\n",
      "        .   \n",
      "        .   @param templateImage single-channel template image; CV_8U or CV_32F array.\n",
      "        .   @param inputImage single-channel input image to be warped to provide an image similar to\n",
      "        .    templateImage, same type as templateImage.\n",
      "        .   @param inputMask An optional mask to indicate valid values of inputImage.\n",
      "        .   \n",
      "        .   @sa\n",
      "        .   findTransformECC\n",
      "    \n",
      "    connectedComponents(...)\n",
      "        connectedComponents(image[, labels[, connectivity[, ltype]]]) -> retval, labels\n",
      "        .   @overload\n",
      "        .   \n",
      "        .   @param image the 8-bit single-channel image to be labeled\n",
      "        .   @param labels destination labeled image\n",
      "        .   @param connectivity 8 or 4 for 8-way or 4-way connectivity respectively\n",
      "        .   @param ltype output image label type. Currently CV_32S and CV_16U are supported.\n",
      "    \n",
      "    connectedComponentsWithAlgorithm(...)\n",
      "        connectedComponentsWithAlgorithm(image, connectivity, ltype, ccltype[, labels]) -> retval, labels\n",
      "        .   @brief computes the connected components labeled image of boolean image\n",
      "        .   \n",
      "        .   image with 4 or 8 way connectivity - returns N, the total number of labels [0, N-1] where 0\n",
      "        .   represents the background label. ltype specifies the output label image type, an important\n",
      "        .   consideration based on the total number of labels or alternatively the total number of pixels in\n",
      "        .   the source image. ccltype specifies the connected components labeling algorithm to use, currently\n",
      "        .   Grana (BBDT) and Wu's (SAUF) algorithms are supported, see the #ConnectedComponentsAlgorithmsTypes\n",
      "        .   for details. Note that SAUF algorithm forces a row major ordering of labels while BBDT does not.\n",
      "        .   This function uses parallel version of both Grana and Wu's algorithms if at least one allowed\n",
      "        .   parallel framework is enabled and if the rows of the image are at least twice the number returned by #getNumberOfCPUs.\n",
      "        .   \n",
      "        .   @param image the 8-bit single-channel image to be labeled\n",
      "        .   @param labels destination labeled image\n",
      "        .   @param connectivity 8 or 4 for 8-way or 4-way connectivity respectively\n",
      "        .   @param ltype output image label type. Currently CV_32S and CV_16U are supported.\n",
      "        .   @param ccltype connected components algorithm type (see the #ConnectedComponentsAlgorithmsTypes).\n",
      "    \n",
      "    connectedComponentsWithStats(...)\n",
      "        connectedComponentsWithStats(image[, labels[, stats[, centroids[, connectivity[, ltype]]]]]) -> retval, labels, stats, centroids\n",
      "        .   @overload\n",
      "        .   @param image the 8-bit single-channel image to be labeled\n",
      "        .   @param labels destination labeled image\n",
      "        .   @param stats statistics output for each label, including the background label.\n",
      "        .   Statistics are accessed via stats(label, COLUMN) where COLUMN is one of\n",
      "        .   #ConnectedComponentsTypes, selecting the statistic. The data type is CV_32S.\n",
      "        .   @param centroids centroid output for each label, including the background label. Centroids are\n",
      "        .   accessed via centroids(label, 0) for x and centroids(label, 1) for y. The data type CV_64F.\n",
      "        .   @param connectivity 8 or 4 for 8-way or 4-way connectivity respectively\n",
      "        .   @param ltype output image label type. Currently CV_32S and CV_16U are supported.\n",
      "    \n",
      "    connectedComponentsWithStatsWithAlgorithm(...)\n",
      "        connectedComponentsWithStatsWithAlgorithm(image, connectivity, ltype, ccltype[, labels[, stats[, centroids]]]) -> retval, labels, stats, centroids\n",
      "        .   @brief computes the connected components labeled image of boolean image and also produces a statistics output for each label\n",
      "        .   \n",
      "        .   image with 4 or 8 way connectivity - returns N, the total number of labels [0, N-1] where 0\n",
      "        .   represents the background label. ltype specifies the output label image type, an important\n",
      "        .   consideration based on the total number of labels or alternatively the total number of pixels in\n",
      "        .   the source image. ccltype specifies the connected components labeling algorithm to use, currently\n",
      "        .   Grana's (BBDT) and Wu's (SAUF) algorithms are supported, see the #ConnectedComponentsAlgorithmsTypes\n",
      "        .   for details. Note that SAUF algorithm forces a row major ordering of labels while BBDT does not.\n",
      "        .   This function uses parallel version of both Grana and Wu's algorithms (statistics included) if at least one allowed\n",
      "        .   parallel framework is enabled and if the rows of the image are at least twice the number returned by #getNumberOfCPUs.\n",
      "        .   \n",
      "        .   @param image the 8-bit single-channel image to be labeled\n",
      "        .   @param labels destination labeled image\n",
      "        .   @param stats statistics output for each label, including the background label.\n",
      "        .   Statistics are accessed via stats(label, COLUMN) where COLUMN is one of\n",
      "        .   #ConnectedComponentsTypes, selecting the statistic. The data type is CV_32S.\n",
      "        .   @param centroids centroid output for each label, including the background label. Centroids are\n",
      "        .   accessed via centroids(label, 0) for x and centroids(label, 1) for y. The data type CV_64F.\n",
      "        .   @param connectivity 8 or 4 for 8-way or 4-way connectivity respectively\n",
      "        .   @param ltype output image label type. Currently CV_32S and CV_16U are supported.\n",
      "        .   @param ccltype connected components algorithm type (see #ConnectedComponentsAlgorithmsTypes).\n",
      "    \n",
      "    contourArea(...)\n",
      "        contourArea(contour[, oriented]) -> retval\n",
      "        .   @brief Calculates a contour area.\n",
      "        .   \n",
      "        .   The function computes a contour area. Similarly to moments , the area is computed using the Green\n",
      "        .   formula. Thus, the returned area and the number of non-zero pixels, if you draw the contour using\n",
      "        .   #drawContours or #fillPoly , can be different. Also, the function will most certainly give a wrong\n",
      "        .   results for contours with self-intersections.\n",
      "        .   \n",
      "        .   Example:\n",
      "        .   @code\n",
      "        .       vector<Point> contour;\n",
      "        .       contour.push_back(Point2f(0, 0));\n",
      "        .       contour.push_back(Point2f(10, 0));\n",
      "        .       contour.push_back(Point2f(10, 10));\n",
      "        .       contour.push_back(Point2f(5, 4));\n",
      "        .   \n",
      "        .       double area0 = contourArea(contour);\n",
      "        .       vector<Point> approx;\n",
      "        .       approxPolyDP(contour, approx, 5, true);\n",
      "        .       double area1 = contourArea(approx);\n",
      "        .   \n",
      "        .       cout << \"area0 =\" << area0 << endl <<\n",
      "        .               \"area1 =\" << area1 << endl <<\n",
      "        .               \"approx poly vertices\" << approx.size() << endl;\n",
      "        .   @endcode\n",
      "        .   @param contour Input vector of 2D points (contour vertices), stored in std::vector or Mat.\n",
      "        .   @param oriented Oriented area flag. If it is true, the function returns a signed area value,\n",
      "        .   depending on the contour orientation (clockwise or counter-clockwise). Using this feature you can\n",
      "        .   determine orientation of a contour by taking the sign of an area. By default, the parameter is\n",
      "        .   false, which means that the absolute value is returned.\n",
      "    \n",
      "    convertFp16(...)\n",
      "        convertFp16(src[, dst]) -> dst\n",
      "        .   @brief Converts an array to half precision floating number.\n",
      "        .   \n",
      "        .   This function converts FP32 (single precision floating point) from/to FP16 (half precision floating point). CV_16S format is used to represent FP16 data.\n",
      "        .   There are two use modes (src -> dst): CV_32F -> CV_16S and CV_16S -> CV_32F. The input array has to have type of CV_32F or\n",
      "        .   CV_16S to represent the bit depth. If the input array is neither of them, the function will raise an error.\n",
      "        .   The format of half precision floating point is defined in IEEE 754-2008.\n",
      "        .   \n",
      "        .   @param src input array.\n",
      "        .   @param dst output array.\n",
      "    \n",
      "    convertMaps(...)\n",
      "        convertMaps(map1, map2, dstmap1type[, dstmap1[, dstmap2[, nninterpolation]]]) -> dstmap1, dstmap2\n",
      "        .   @brief Converts image transformation maps from one representation to another.\n",
      "        .   \n",
      "        .   The function converts a pair of maps for remap from one representation to another. The following\n",
      "        .   options ( (map1.type(), map2.type()) \\f$\\rightarrow\\f$ (dstmap1.type(), dstmap2.type()) ) are\n",
      "        .   supported:\n",
      "        .   \n",
      "        .   - \\f$\\texttt{(CV_32FC1, CV_32FC1)} \\rightarrow \\texttt{(CV_16SC2, CV_16UC1)}\\f$. This is the\n",
      "        .   most frequently used conversion operation, in which the original floating-point maps (see remap )\n",
      "        .   are converted to a more compact and much faster fixed-point representation. The first output array\n",
      "        .   contains the rounded coordinates and the second array (created only when nninterpolation=false )\n",
      "        .   contains indices in the interpolation tables.\n",
      "        .   \n",
      "        .   - \\f$\\texttt{(CV_32FC2)} \\rightarrow \\texttt{(CV_16SC2, CV_16UC1)}\\f$. The same as above but\n",
      "        .   the original maps are stored in one 2-channel matrix.\n",
      "        .   \n",
      "        .   - Reverse conversion. Obviously, the reconstructed floating-point maps will not be exactly the same\n",
      "        .   as the originals.\n",
      "        .   \n",
      "        .   @param map1 The first input map of type CV_16SC2, CV_32FC1, or CV_32FC2 .\n",
      "        .   @param map2 The second input map of type CV_16UC1, CV_32FC1, or none (empty matrix),\n",
      "        .   respectively.\n",
      "        .   @param dstmap1 The first output map that has the type dstmap1type and the same size as src .\n",
      "        .   @param dstmap2 The second output map.\n",
      "        .   @param dstmap1type Type of the first output map that should be CV_16SC2, CV_32FC1, or\n",
      "        .   CV_32FC2 .\n",
      "        .   @param nninterpolation Flag indicating whether the fixed-point maps are used for the\n",
      "        .   nearest-neighbor or for a more complex interpolation.\n",
      "        .   \n",
      "        .   @sa  remap, undistort, initUndistortRectifyMap\n",
      "    \n",
      "    convertPointsFromHomogeneous(...)\n",
      "        convertPointsFromHomogeneous(src[, dst]) -> dst\n",
      "        .   @brief Converts points from homogeneous to Euclidean space.\n",
      "        .   \n",
      "        .   @param src Input vector of N-dimensional points.\n",
      "        .   @param dst Output vector of N-1-dimensional points.\n",
      "        .   \n",
      "        .   The function converts points homogeneous to Euclidean space using perspective projection. That is,\n",
      "        .   each point (x1, x2, ... x(n-1), xn) is converted to (x1/xn, x2/xn, ..., x(n-1)/xn). When xn=0, the\n",
      "        .   output point coordinates will be (0,0,0,...).\n",
      "    \n",
      "    convertPointsToHomogeneous(...)\n",
      "        convertPointsToHomogeneous(src[, dst]) -> dst\n",
      "        .   @brief Converts points from Euclidean to homogeneous space.\n",
      "        .   \n",
      "        .   @param src Input vector of N-dimensional points.\n",
      "        .   @param dst Output vector of N+1-dimensional points.\n",
      "        .   \n",
      "        .   The function converts points from Euclidean to homogeneous space by appending 1's to the tuple of\n",
      "        .   point coordinates. That is, each point (x1, x2, ..., xn) is converted to (x1, x2, ..., xn, 1).\n",
      "    \n",
      "    convertScaleAbs(...)\n",
      "        convertScaleAbs(src[, dst[, alpha[, beta]]]) -> dst\n",
      "        .   @brief Scales, calculates absolute values, and converts the result to 8-bit.\n",
      "        .   \n",
      "        .   On each element of the input array, the function convertScaleAbs\n",
      "        .   performs three operations sequentially: scaling, taking an absolute\n",
      "        .   value, conversion to an unsigned 8-bit type:\n",
      "        .   \\f[\\texttt{dst} (I)= \\texttt{saturate\\_cast<uchar>} (| \\texttt{src} (I)* \\texttt{alpha} +  \\texttt{beta} |)\\f]\n",
      "        .   In case of multi-channel arrays, the function processes each channel\n",
      "        .   independently. When the output is not 8-bit, the operation can be\n",
      "        .   emulated by calling the Mat::convertTo method (or by using matrix\n",
      "        .   expressions) and then by calculating an absolute value of the result.\n",
      "        .   For example:\n",
      "        .   @code{.cpp}\n",
      "        .       Mat_<float> A(30,30);\n",
      "        .       randu(A, Scalar(-100), Scalar(100));\n",
      "        .       Mat_<float> B = A*5 + 3;\n",
      "        .       B = abs(B);\n",
      "        .       // Mat_<float> B = abs(A*5+3) will also do the job,\n",
      "        .       // but it will allocate a temporary matrix\n",
      "        .   @endcode\n",
      "        .   @param src input array.\n",
      "        .   @param dst output array.\n",
      "        .   @param alpha optional scale factor.\n",
      "        .   @param beta optional delta added to the scaled values.\n",
      "        .   @sa  Mat::convertTo, cv::abs(const Mat&)\n",
      "    \n",
      "    convexHull(...)\n",
      "        convexHull(points[, hull[, clockwise[, returnPoints]]]) -> hull\n",
      "        .   @brief Finds the convex hull of a point set.\n",
      "        .   \n",
      "        .   The function cv::convexHull finds the convex hull of a 2D point set using the Sklansky's algorithm @cite Sklansky82\n",
      "        .   that has *O(N logN)* complexity in the current implementation.\n",
      "        .   \n",
      "        .   @param points Input 2D point set, stored in std::vector or Mat.\n",
      "        .   @param hull Output convex hull. It is either an integer vector of indices or vector of points. In\n",
      "        .   the first case, the hull elements are 0-based indices of the convex hull points in the original\n",
      "        .   array (since the set of convex hull points is a subset of the original point set). In the second\n",
      "        .   case, hull elements are the convex hull points themselves.\n",
      "        .   @param clockwise Orientation flag. If it is true, the output convex hull is oriented clockwise.\n",
      "        .   Otherwise, it is oriented counter-clockwise. The assumed coordinate system has its X axis pointing\n",
      "        .   to the right, and its Y axis pointing upwards.\n",
      "        .   @param returnPoints Operation flag. In case of a matrix, when the flag is true, the function\n",
      "        .   returns convex hull points. Otherwise, it returns indices of the convex hull points. When the\n",
      "        .   output array is std::vector, the flag is ignored, and the output depends on the type of the\n",
      "        .   vector: std::vector\\<int\\> implies returnPoints=false, std::vector\\<Point\\> implies\n",
      "        .   returnPoints=true.\n",
      "        .   \n",
      "        .   @note `points` and `hull` should be different arrays, inplace processing isn't supported.\n",
      "        .   \n",
      "        .   Check @ref tutorial_hull \"the corresponding tutorial\" for more details.\n",
      "        .   \n",
      "        .   useful links:\n",
      "        .   \n",
      "        .   https://www.learnopencv.com/convex-hull-using-opencv-in-python-and-c/\n",
      "    \n",
      "    convexityDefects(...)\n",
      "        convexityDefects(contour, convexhull[, convexityDefects]) -> convexityDefects\n",
      "        .   @brief Finds the convexity defects of a contour.\n",
      "        .   \n",
      "        .   The figure below displays convexity defects of a hand contour:\n",
      "        .   \n",
      "        .   ![image](pics/defects.png)\n",
      "        .   \n",
      "        .   @param contour Input contour.\n",
      "        .   @param convexhull Convex hull obtained using convexHull that should contain indices of the contour\n",
      "        .   points that make the hull.\n",
      "        .   @param convexityDefects The output vector of convexity defects. In C++ and the new Python/Java\n",
      "        .   interface each convexity defect is represented as 4-element integer vector (a.k.a. #Vec4i):\n",
      "        .   (start_index, end_index, farthest_pt_index, fixpt_depth), where indices are 0-based indices\n",
      "        .   in the original contour of the convexity defect beginning, end and the farthest point, and\n",
      "        .   fixpt_depth is fixed-point approximation (with 8 fractional bits) of the distance between the\n",
      "        .   farthest contour point and the hull. That is, to get the floating-point value of the depth will be\n",
      "        .   fixpt_depth/256.0.\n",
      "    \n",
      "    copyMakeBorder(...)\n",
      "        copyMakeBorder(src, top, bottom, left, right, borderType[, dst[, value]]) -> dst\n",
      "        .   @brief Forms a border around an image.\n",
      "        .   \n",
      "        .   The function copies the source image into the middle of the destination image. The areas to the\n",
      "        .   left, to the right, above and below the copied source image will be filled with extrapolated\n",
      "        .   pixels. This is not what filtering functions based on it do (they extrapolate pixels on-fly), but\n",
      "        .   what other more complex functions, including your own, may do to simplify image boundary handling.\n",
      "        .   \n",
      "        .   The function supports the mode when src is already in the middle of dst . In this case, the\n",
      "        .   function does not copy src itself but simply constructs the border, for example:\n",
      "        .   \n",
      "        .   @code{.cpp}\n",
      "        .       // let border be the same in all directions\n",
      "        .       int border=2;\n",
      "        .       // constructs a larger image to fit both the image and the border\n",
      "        .       Mat gray_buf(rgb.rows + border*2, rgb.cols + border*2, rgb.depth());\n",
      "        .       // select the middle part of it w/o copying data\n",
      "        .       Mat gray(gray_canvas, Rect(border, border, rgb.cols, rgb.rows));\n",
      "        .       // convert image from RGB to grayscale\n",
      "        .       cvtColor(rgb, gray, COLOR_RGB2GRAY);\n",
      "        .       // form a border in-place\n",
      "        .       copyMakeBorder(gray, gray_buf, border, border,\n",
      "        .                      border, border, BORDER_REPLICATE);\n",
      "        .       // now do some custom filtering ...\n",
      "        .       ...\n",
      "        .   @endcode\n",
      "        .   @note When the source image is a part (ROI) of a bigger image, the function will try to use the\n",
      "        .   pixels outside of the ROI to form a border. To disable this feature and always do extrapolation, as\n",
      "        .   if src was not a ROI, use borderType | #BORDER_ISOLATED.\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image of the same type as src and the size Size(src.cols+left+right,\n",
      "        .   src.rows+top+bottom) .\n",
      "        .   @param top the top pixels\n",
      "        .   @param bottom the bottom pixels\n",
      "        .   @param left the left pixels\n",
      "        .   @param right Parameter specifying how many pixels in each direction from the source image rectangle\n",
      "        .   to extrapolate. For example, top=1, bottom=1, left=1, right=1 mean that 1 pixel-wide border needs\n",
      "        .   to be built.\n",
      "        .   @param borderType Border type. See borderInterpolate for details.\n",
      "        .   @param value Border value if borderType==BORDER_CONSTANT .\n",
      "        .   \n",
      "        .   @sa  borderInterpolate\n",
      "    \n",
      "    copyTo(...)\n",
      "        copyTo(src, mask[, dst]) -> dst\n",
      "        .   @brief  This is an overloaded member function, provided for convenience (python)\n",
      "        .   Copies the matrix to another one.\n",
      "        .   When the operation mask is specified, if the Mat::create call shown above reallocates the matrix, the newly allocated matrix is initialized with all zeros before copying the data.\n",
      "        .   @param src source matrix.\n",
      "        .   @param dst Destination matrix. If it does not have a proper size or type before the operation, it is\n",
      "        .   reallocated.\n",
      "        .   @param mask Operation mask of the same size as \\*this. Its non-zero elements indicate which matrix\n",
      "        .   elements need to be copied. The mask has to be of type CV_8U and can have 1 or multiple channels.\n",
      "    \n",
      "    cornerEigenValsAndVecs(...)\n",
      "        cornerEigenValsAndVecs(src, blockSize, ksize[, dst[, borderType]]) -> dst\n",
      "        .   @brief Calculates eigenvalues and eigenvectors of image blocks for corner detection.\n",
      "        .   \n",
      "        .   For every pixel \\f$p\\f$ , the function cornerEigenValsAndVecs considers a blockSize \\f$\\times\\f$ blockSize\n",
      "        .   neighborhood \\f$S(p)\\f$ . It calculates the covariation matrix of derivatives over the neighborhood as:\n",
      "        .   \n",
      "        .   \\f[M =  \\begin{bmatrix} \\sum _{S(p)}(dI/dx)^2 &  \\sum _{S(p)}dI/dx dI/dy  \\\\ \\sum _{S(p)}dI/dx dI/dy &  \\sum _{S(p)}(dI/dy)^2 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   where the derivatives are computed using the Sobel operator.\n",
      "        .   \n",
      "        .   After that, it finds eigenvectors and eigenvalues of \\f$M\\f$ and stores them in the destination image as\n",
      "        .   \\f$(\\lambda_1, \\lambda_2, x_1, y_1, x_2, y_2)\\f$ where\n",
      "        .   \n",
      "        .   -   \\f$\\lambda_1, \\lambda_2\\f$ are the non-sorted eigenvalues of \\f$M\\f$\n",
      "        .   -   \\f$x_1, y_1\\f$ are the eigenvectors corresponding to \\f$\\lambda_1\\f$\n",
      "        .   -   \\f$x_2, y_2\\f$ are the eigenvectors corresponding to \\f$\\lambda_2\\f$\n",
      "        .   \n",
      "        .   The output of the function can be used for robust edge or corner detection.\n",
      "        .   \n",
      "        .   @param src Input single-channel 8-bit or floating-point image.\n",
      "        .   @param dst Image to store the results. It has the same size as src and the type CV_32FC(6) .\n",
      "        .   @param blockSize Neighborhood size (see details below).\n",
      "        .   @param ksize Aperture parameter for the Sobel operator.\n",
      "        .   @param borderType Pixel extrapolation method. See #BorderTypes. #BORDER_WRAP is not supported.\n",
      "        .   \n",
      "        .   @sa  cornerMinEigenVal, cornerHarris, preCornerDetect\n",
      "    \n",
      "    cornerHarris(...)\n",
      "        cornerHarris(src, blockSize, ksize, k[, dst[, borderType]]) -> dst\n",
      "        .   @brief Harris corner detector.\n",
      "        .   \n",
      "        .   The function runs the Harris corner detector on the image. Similarly to cornerMinEigenVal and\n",
      "        .   cornerEigenValsAndVecs , for each pixel \\f$(x, y)\\f$ it calculates a \\f$2\\times2\\f$ gradient covariance\n",
      "        .   matrix \\f$M^{(x,y)}\\f$ over a \\f$\\texttt{blockSize} \\times \\texttt{blockSize}\\f$ neighborhood. Then, it\n",
      "        .   computes the following characteristic:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\mathrm{det} M^{(x,y)} - k  \\cdot \\left ( \\mathrm{tr} M^{(x,y)} \\right )^2\\f]\n",
      "        .   \n",
      "        .   Corners in the image can be found as the local maxima of this response map.\n",
      "        .   \n",
      "        .   @param src Input single-channel 8-bit or floating-point image.\n",
      "        .   @param dst Image to store the Harris detector responses. It has the type CV_32FC1 and the same\n",
      "        .   size as src .\n",
      "        .   @param blockSize Neighborhood size (see the details on #cornerEigenValsAndVecs ).\n",
      "        .   @param ksize Aperture parameter for the Sobel operator.\n",
      "        .   @param k Harris detector free parameter. See the formula above.\n",
      "        .   @param borderType Pixel extrapolation method. See #BorderTypes. #BORDER_WRAP is not supported.\n",
      "    \n",
      "    cornerMinEigenVal(...)\n",
      "        cornerMinEigenVal(src, blockSize[, dst[, ksize[, borderType]]]) -> dst\n",
      "        .   @brief Calculates the minimal eigenvalue of gradient matrices for corner detection.\n",
      "        .   \n",
      "        .   The function is similar to cornerEigenValsAndVecs but it calculates and stores only the minimal\n",
      "        .   eigenvalue of the covariance matrix of derivatives, that is, \\f$\\min(\\lambda_1, \\lambda_2)\\f$ in terms\n",
      "        .   of the formulae in the cornerEigenValsAndVecs description.\n",
      "        .   \n",
      "        .   @param src Input single-channel 8-bit or floating-point image.\n",
      "        .   @param dst Image to store the minimal eigenvalues. It has the type CV_32FC1 and the same size as\n",
      "        .   src .\n",
      "        .   @param blockSize Neighborhood size (see the details on #cornerEigenValsAndVecs ).\n",
      "        .   @param ksize Aperture parameter for the Sobel operator.\n",
      "        .   @param borderType Pixel extrapolation method. See #BorderTypes. #BORDER_WRAP is not supported.\n",
      "    \n",
      "    cornerSubPix(...)\n",
      "        cornerSubPix(image, corners, winSize, zeroZone, criteria) -> corners\n",
      "        .   @brief Refines the corner locations.\n",
      "        .   \n",
      "        .   The function iterates to find the sub-pixel accurate location of corners or radial saddle points, as\n",
      "        .   shown on the figure below.\n",
      "        .   \n",
      "        .   ![image](pics/cornersubpix.png)\n",
      "        .   \n",
      "        .   Sub-pixel accurate corner locator is based on the observation that every vector from the center \\f$q\\f$\n",
      "        .   to a point \\f$p\\f$ located within a neighborhood of \\f$q\\f$ is orthogonal to the image gradient at \\f$p\\f$\n",
      "        .   subject to image and measurement noise. Consider the expression:\n",
      "        .   \n",
      "        .   \\f[\\epsilon _i = {DI_{p_i}}^T  \\cdot (q - p_i)\\f]\n",
      "        .   \n",
      "        .   where \\f${DI_{p_i}}\\f$ is an image gradient at one of the points \\f$p_i\\f$ in a neighborhood of \\f$q\\f$ . The\n",
      "        .   value of \\f$q\\f$ is to be found so that \\f$\\epsilon_i\\f$ is minimized. A system of equations may be set up\n",
      "        .   with \\f$\\epsilon_i\\f$ set to zero:\n",
      "        .   \n",
      "        .   \\f[\\sum _i(DI_{p_i}  \\cdot {DI_{p_i}}^T) \\cdot q -  \\sum _i(DI_{p_i}  \\cdot {DI_{p_i}}^T  \\cdot p_i)\\f]\n",
      "        .   \n",
      "        .   where the gradients are summed within a neighborhood (\"search window\") of \\f$q\\f$ . Calling the first\n",
      "        .   gradient term \\f$G\\f$ and the second gradient term \\f$b\\f$ gives:\n",
      "        .   \n",
      "        .   \\f[q = G^{-1}  \\cdot b\\f]\n",
      "        .   \n",
      "        .   The algorithm sets the center of the neighborhood window at this new center \\f$q\\f$ and then iterates\n",
      "        .   until the center stays within a set threshold.\n",
      "        .   \n",
      "        .   @param image Input single-channel, 8-bit or float image.\n",
      "        .   @param corners Initial coordinates of the input corners and refined coordinates provided for\n",
      "        .   output.\n",
      "        .   @param winSize Half of the side length of the search window. For example, if winSize=Size(5,5) ,\n",
      "        .   then a \\f$(5*2+1) \\times (5*2+1) = 11 \\times 11\\f$ search window is used.\n",
      "        .   @param zeroZone Half of the size of the dead region in the middle of the search zone over which\n",
      "        .   the summation in the formula below is not done. It is used sometimes to avoid possible\n",
      "        .   singularities of the autocorrelation matrix. The value of (-1,-1) indicates that there is no such\n",
      "        .   a size.\n",
      "        .   @param criteria Criteria for termination of the iterative process of corner refinement. That is,\n",
      "        .   the process of corner position refinement stops either after criteria.maxCount iterations or when\n",
      "        .   the corner position moves by less than criteria.epsilon on some iteration.\n",
      "    \n",
      "    correctMatches(...)\n",
      "        correctMatches(F, points1, points2[, newPoints1[, newPoints2]]) -> newPoints1, newPoints2\n",
      "        .   @brief Refines coordinates of corresponding points.\n",
      "        .   \n",
      "        .   @param F 3x3 fundamental matrix.\n",
      "        .   @param points1 1xN array containing the first set of points.\n",
      "        .   @param points2 1xN array containing the second set of points.\n",
      "        .   @param newPoints1 The optimized points1.\n",
      "        .   @param newPoints2 The optimized points2.\n",
      "        .   \n",
      "        .   The function implements the Optimal Triangulation Method (see Multiple View Geometry for details).\n",
      "        .   For each given point correspondence points1[i] \\<-\\> points2[i], and a fundamental matrix F, it\n",
      "        .   computes the corrected correspondences newPoints1[i] \\<-\\> newPoints2[i] that minimize the geometric\n",
      "        .   error \\f$d(points1[i], newPoints1[i])^2 + d(points2[i],newPoints2[i])^2\\f$ (where \\f$d(a,b)\\f$ is the\n",
      "        .   geometric distance between points \\f$a\\f$ and \\f$b\\f$ ) subject to the epipolar constraint\n",
      "        .   \\f$newPoints2^T * F * newPoints1 = 0\\f$ .\n",
      "    \n",
      "    countNonZero(...)\n",
      "        countNonZero(src) -> retval\n",
      "        .   @brief Counts non-zero array elements.\n",
      "        .   \n",
      "        .   The function returns the number of non-zero elements in src :\n",
      "        .   \\f[\\sum _{I: \\; \\texttt{src} (I) \\ne0 } 1\\f]\n",
      "        .   @param src single-channel array.\n",
      "        .   @sa  mean, meanStdDev, norm, minMaxLoc, calcCovarMatrix\n",
      "    \n",
      "    createAlignMTB(...)\n",
      "        createAlignMTB([, max_bits[, exclude_range[, cut]]]) -> retval\n",
      "        .   @brief Creates AlignMTB object\n",
      "        .   \n",
      "        .   @param max_bits logarithm to the base 2 of maximal shift in each dimension. Values of 5 and 6 are\n",
      "        .   usually good enough (31 and 63 pixels shift respectively).\n",
      "        .   @param exclude_range range for exclusion bitmap that is constructed to suppress noise around the\n",
      "        .   median value.\n",
      "        .   @param cut if true cuts images, otherwise fills the new regions with zeros.\n",
      "    \n",
      "    createBackgroundSubtractorKNN(...)\n",
      "        createBackgroundSubtractorKNN([, history[, dist2Threshold[, detectShadows]]]) -> retval\n",
      "        .   @brief Creates KNN Background Subtractor\n",
      "        .   \n",
      "        .   @param history Length of the history.\n",
      "        .   @param dist2Threshold Threshold on the squared distance between the pixel and the sample to decide\n",
      "        .   whether a pixel is close to that sample. This parameter does not affect the background update.\n",
      "        .   @param detectShadows If true, the algorithm will detect shadows and mark them. It decreases the\n",
      "        .   speed a bit, so if you do not need this feature, set the parameter to false.\n",
      "    \n",
      "    createBackgroundSubtractorMOG2(...)\n",
      "        createBackgroundSubtractorMOG2([, history[, varThreshold[, detectShadows]]]) -> retval\n",
      "        .   @brief Creates MOG2 Background Subtractor\n",
      "        .   \n",
      "        .   @param history Length of the history.\n",
      "        .   @param varThreshold Threshold on the squared Mahalanobis distance between the pixel and the model\n",
      "        .   to decide whether a pixel is well described by the background model. This parameter does not\n",
      "        .   affect the background update.\n",
      "        .   @param detectShadows If true, the algorithm will detect shadows and mark them. It decreases the\n",
      "        .   speed a bit, so if you do not need this feature, set the parameter to false.\n",
      "    \n",
      "    createButton(...)\n",
      "        createButton(buttonName, onChange [, userData, buttonType, initialButtonState]) -> None\n",
      "    \n",
      "    createCLAHE(...)\n",
      "        createCLAHE([, clipLimit[, tileGridSize]]) -> retval\n",
      "        .   @brief Creates a smart pointer to a cv::CLAHE class and initializes it.\n",
      "        .   \n",
      "        .   @param clipLimit Threshold for contrast limiting.\n",
      "        .   @param tileGridSize Size of grid for histogram equalization. Input image will be divided into\n",
      "        .   equally sized rectangular tiles. tileGridSize defines the number of tiles in row and column.\n",
      "    \n",
      "    createCalibrateDebevec(...)\n",
      "        createCalibrateDebevec([, samples[, lambda[, random]]]) -> retval\n",
      "        .   @brief Creates CalibrateDebevec object\n",
      "        .   \n",
      "        .   @param samples number of pixel locations to use\n",
      "        .   @param lambda smoothness term weight. Greater values produce smoother results, but can alter the\n",
      "        .   response.\n",
      "        .   @param random if true sample pixel locations are chosen at random, otherwise they form a\n",
      "        .   rectangular grid.\n",
      "    \n",
      "    createCalibrateRobertson(...)\n",
      "        createCalibrateRobertson([, max_iter[, threshold]]) -> retval\n",
      "        .   @brief Creates CalibrateRobertson object\n",
      "        .   \n",
      "        .   @param max_iter maximal number of Gauss-Seidel solver iterations.\n",
      "        .   @param threshold target difference between results of two successive steps of the minimization.\n",
      "    \n",
      "    createGeneralizedHoughBallard(...)\n",
      "        createGeneralizedHoughBallard() -> retval\n",
      "        .   @brief Creates a smart pointer to a cv::GeneralizedHoughBallard class and initializes it.\n",
      "    \n",
      "    createGeneralizedHoughGuil(...)\n",
      "        createGeneralizedHoughGuil() -> retval\n",
      "        .   @brief Creates a smart pointer to a cv::GeneralizedHoughGuil class and initializes it.\n",
      "    \n",
      "    createHanningWindow(...)\n",
      "        createHanningWindow(winSize, type[, dst]) -> dst\n",
      "        .   @brief This function computes a Hanning window coefficients in two dimensions.\n",
      "        .   \n",
      "        .   See (http://en.wikipedia.org/wiki/Hann_function) and (http://en.wikipedia.org/wiki/Window_function)\n",
      "        .   for more information.\n",
      "        .   \n",
      "        .   An example is shown below:\n",
      "        .   @code\n",
      "        .       // create hanning window of size 100x100 and type CV_32F\n",
      "        .       Mat hann;\n",
      "        .       createHanningWindow(hann, Size(100, 100), CV_32F);\n",
      "        .   @endcode\n",
      "        .   @param dst Destination array to place Hann coefficients in\n",
      "        .   @param winSize The window size specifications (both width and height must be > 1)\n",
      "        .   @param type Created array type\n",
      "    \n",
      "    createLineSegmentDetector(...)\n",
      "        createLineSegmentDetector([, _refine[, _scale[, _sigma_scale[, _quant[, _ang_th[, _log_eps[, _density_th[, _n_bins]]]]]]]]) -> retval\n",
      "        .   @brief Creates a smart pointer to a LineSegmentDetector object and initializes it.\n",
      "        .   \n",
      "        .   The LineSegmentDetector algorithm is defined using the standard values. Only advanced users may want\n",
      "        .   to edit those, as to tailor it for their own application.\n",
      "        .   \n",
      "        .   @param _refine The way found lines will be refined, see #LineSegmentDetectorModes\n",
      "        .   @param _scale The scale of the image that will be used to find the lines. Range (0..1].\n",
      "        .   @param _sigma_scale Sigma for Gaussian filter. It is computed as sigma = _sigma_scale/_scale.\n",
      "        .   @param _quant Bound to the quantization error on the gradient norm.\n",
      "        .   @param _ang_th Gradient angle tolerance in degrees.\n",
      "        .   @param _log_eps Detection threshold: -log10(NFA) \\> log_eps. Used only when advance refinement\n",
      "        .   is chosen.\n",
      "        .   @param _density_th Minimal density of aligned region points in the enclosing rectangle.\n",
      "        .   @param _n_bins Number of bins in pseudo-ordering of gradient modulus.\n",
      "        .   \n",
      "        .   @note Implementation has been removed due original code license conflict\n",
      "    \n",
      "    createMergeDebevec(...)\n",
      "        createMergeDebevec() -> retval\n",
      "        .   @brief Creates MergeDebevec object\n",
      "    \n",
      "    createMergeMertens(...)\n",
      "        createMergeMertens([, contrast_weight[, saturation_weight[, exposure_weight]]]) -> retval\n",
      "        .   @brief Creates MergeMertens object\n",
      "        .   \n",
      "        .   @param contrast_weight contrast measure weight. See MergeMertens.\n",
      "        .   @param saturation_weight saturation measure weight\n",
      "        .   @param exposure_weight well-exposedness measure weight\n",
      "    \n",
      "    createMergeRobertson(...)\n",
      "        createMergeRobertson() -> retval\n",
      "        .   @brief Creates MergeRobertson object\n",
      "    \n",
      "    createTonemap(...)\n",
      "        createTonemap([, gamma]) -> retval\n",
      "        .   @brief Creates simple linear mapper with gamma correction\n",
      "        .   \n",
      "        .   @param gamma positive value for gamma correction. Gamma value of 1.0 implies no correction, gamma\n",
      "        .   equal to 2.2f is suitable for most displays.\n",
      "        .   Generally gamma \\> 1 brightens the image and gamma \\< 1 darkens it.\n",
      "    \n",
      "    createTonemapDrago(...)\n",
      "        createTonemapDrago([, gamma[, saturation[, bias]]]) -> retval\n",
      "        .   @brief Creates TonemapDrago object\n",
      "        .   \n",
      "        .   @param gamma gamma value for gamma correction. See createTonemap\n",
      "        .   @param saturation positive saturation enhancement value. 1.0 preserves saturation, values greater\n",
      "        .   than 1 increase saturation and values less than 1 decrease it.\n",
      "        .   @param bias value for bias function in [0, 1] range. Values from 0.7 to 0.9 usually give best\n",
      "        .   results, default value is 0.85.\n",
      "    \n",
      "    createTonemapMantiuk(...)\n",
      "        createTonemapMantiuk([, gamma[, scale[, saturation]]]) -> retval\n",
      "        .   @brief Creates TonemapMantiuk object\n",
      "        .   \n",
      "        .   @param gamma gamma value for gamma correction. See createTonemap\n",
      "        .   @param scale contrast scale factor. HVS response is multiplied by this parameter, thus compressing\n",
      "        .   dynamic range. Values from 0.6 to 0.9 produce best results.\n",
      "        .   @param saturation saturation enhancement value. See createTonemapDrago\n",
      "    \n",
      "    createTonemapReinhard(...)\n",
      "        createTonemapReinhard([, gamma[, intensity[, light_adapt[, color_adapt]]]]) -> retval\n",
      "        .   @brief Creates TonemapReinhard object\n",
      "        .   \n",
      "        .   @param gamma gamma value for gamma correction. See createTonemap\n",
      "        .   @param intensity result intensity in [-8, 8] range. Greater intensity produces brighter results.\n",
      "        .   @param light_adapt light adaptation in [0, 1] range. If 1 adaptation is based only on pixel\n",
      "        .   value, if 0 it's global, otherwise it's a weighted mean of this two cases.\n",
      "        .   @param color_adapt chromatic adaptation in [0, 1] range. If 1 channels are treated independently,\n",
      "        .   if 0 adaptation level is the same for each channel.\n",
      "    \n",
      "    createTrackbar(...)\n",
      "        createTrackbar(trackbarName, windowName, value, count, onChange) -> None\n",
      "    \n",
      "    cubeRoot(...)\n",
      "        cubeRoot(val) -> retval\n",
      "        .   @brief Computes the cube root of an argument.\n",
      "        .   \n",
      "        .    The function cubeRoot computes \\f$\\sqrt[3]{\\texttt{val}}\\f$. Negative arguments are handled correctly.\n",
      "        .    NaN and Inf are not handled. The accuracy approaches the maximum possible accuracy for\n",
      "        .    single-precision data.\n",
      "        .    @param val A function argument.\n",
      "    \n",
      "    cvtColor(...)\n",
      "        cvtColor(src, code[, dst[, dstCn]]) -> dst\n",
      "        .   @brief Converts an image from one color space to another.\n",
      "        .   \n",
      "        .   The function converts an input image from one color space to another. In case of a transformation\n",
      "        .   to-from RGB color space, the order of the channels should be specified explicitly (RGB or BGR). Note\n",
      "        .   that the default color format in OpenCV is often referred to as RGB but it is actually BGR (the\n",
      "        .   bytes are reversed). So the first byte in a standard (24-bit) color image will be an 8-bit Blue\n",
      "        .   component, the second byte will be Green, and the third byte will be Red. The fourth, fifth, and\n",
      "        .   sixth bytes would then be the second pixel (Blue, then Green, then Red), and so on.\n",
      "        .   \n",
      "        .   The conventional ranges for R, G, and B channel values are:\n",
      "        .   -   0 to 255 for CV_8U images\n",
      "        .   -   0 to 65535 for CV_16U images\n",
      "        .   -   0 to 1 for CV_32F images\n",
      "        .   \n",
      "        .   In case of linear transformations, the range does not matter. But in case of a non-linear\n",
      "        .   transformation, an input RGB image should be normalized to the proper value range to get the correct\n",
      "        .   results, for example, for RGB \\f$\\rightarrow\\f$ L\\*u\\*v\\* transformation. For example, if you have a\n",
      "        .   32-bit floating-point image directly converted from an 8-bit image without any scaling, then it will\n",
      "        .   have the 0..255 value range instead of 0..1 assumed by the function. So, before calling #cvtColor ,\n",
      "        .   you need first to scale the image down:\n",
      "        .   @code\n",
      "        .       img *= 1./255;\n",
      "        .       cvtColor(img, img, COLOR_BGR2Luv);\n",
      "        .   @endcode\n",
      "        .   If you use #cvtColor with 8-bit images, the conversion will have some information lost. For many\n",
      "        .   applications, this will not be noticeable but it is recommended to use 32-bit images in applications\n",
      "        .   that need the full range of colors or that convert an image before an operation and then convert\n",
      "        .   back.\n",
      "        .   \n",
      "        .   If conversion adds the alpha channel, its value will set to the maximum of corresponding channel\n",
      "        .   range: 255 for CV_8U, 65535 for CV_16U, 1 for CV_32F.\n",
      "        .   \n",
      "        .   @param src input image: 8-bit unsigned, 16-bit unsigned ( CV_16UC... ), or single-precision\n",
      "        .   floating-point.\n",
      "        .   @param dst output image of the same size and depth as src.\n",
      "        .   @param code color space conversion code (see #ColorConversionCodes).\n",
      "        .   @param dstCn number of channels in the destination image; if the parameter is 0, the number of the\n",
      "        .   channels is derived automatically from src and code.\n",
      "        .   \n",
      "        .   @see @ref imgproc_color_conversions\n",
      "    \n",
      "    cvtColorTwoPlane(...)\n",
      "        cvtColorTwoPlane(src1, src2, code[, dst]) -> dst\n",
      "        .   @brief Converts an image from one color space to another where the source image is\n",
      "        .   stored in two planes.\n",
      "        .   \n",
      "        .   This function only supports YUV420 to RGB conversion as of now.\n",
      "        .   \n",
      "        .   @param src1: 8-bit image (#CV_8U) of the Y plane.\n",
      "        .   @param src2: image containing interleaved U/V plane.\n",
      "        .   @param dst: output image.\n",
      "        .   @param code: Specifies the type of conversion. It can take any of the following values:\n",
      "        .   - #COLOR_YUV2BGR_NV12\n",
      "        .   - #COLOR_YUV2RGB_NV12\n",
      "        .   - #COLOR_YUV2BGRA_NV12\n",
      "        .   - #COLOR_YUV2RGBA_NV12\n",
      "        .   - #COLOR_YUV2BGR_NV21\n",
      "        .   - #COLOR_YUV2RGB_NV21\n",
      "        .   - #COLOR_YUV2BGRA_NV21\n",
      "        .   - #COLOR_YUV2RGBA_NV21\n",
      "    \n",
      "    dct(...)\n",
      "        dct(src[, dst[, flags]]) -> dst\n",
      "        .   @brief Performs a forward or inverse discrete Cosine transform of 1D or 2D array.\n",
      "        .   \n",
      "        .   The function cv::dct performs a forward or inverse discrete Cosine transform (DCT) of a 1D or 2D\n",
      "        .   floating-point array:\n",
      "        .   -   Forward Cosine transform of a 1D vector of N elements:\n",
      "        .       \\f[Y = C^{(N)}  \\cdot X\\f]\n",
      "        .       where\n",
      "        .       \\f[C^{(N)}_{jk}= \\sqrt{\\alpha_j/N} \\cos \\left ( \\frac{\\pi(2k+1)j}{2N} \\right )\\f]\n",
      "        .       and\n",
      "        .       \\f$\\alpha_0=1\\f$, \\f$\\alpha_j=2\\f$ for *j \\> 0*.\n",
      "        .   -   Inverse Cosine transform of a 1D vector of N elements:\n",
      "        .       \\f[X =  \\left (C^{(N)} \\right )^{-1}  \\cdot Y =  \\left (C^{(N)} \\right )^T  \\cdot Y\\f]\n",
      "        .       (since \\f$C^{(N)}\\f$ is an orthogonal matrix, \\f$C^{(N)} \\cdot \\left(C^{(N)}\\right)^T = I\\f$ )\n",
      "        .   -   Forward 2D Cosine transform of M x N matrix:\n",
      "        .       \\f[Y = C^{(N)}  \\cdot X  \\cdot \\left (C^{(N)} \\right )^T\\f]\n",
      "        .   -   Inverse 2D Cosine transform of M x N matrix:\n",
      "        .       \\f[X =  \\left (C^{(N)} \\right )^T  \\cdot X  \\cdot C^{(N)}\\f]\n",
      "        .   \n",
      "        .   The function chooses the mode of operation by looking at the flags and size of the input array:\n",
      "        .   -   If (flags & #DCT_INVERSE) == 0 , the function does a forward 1D or 2D transform. Otherwise, it\n",
      "        .       is an inverse 1D or 2D transform.\n",
      "        .   -   If (flags & #DCT_ROWS) != 0 , the function performs a 1D transform of each row.\n",
      "        .   -   If the array is a single column or a single row, the function performs a 1D transform.\n",
      "        .   -   If none of the above is true, the function performs a 2D transform.\n",
      "        .   \n",
      "        .   @note Currently dct supports even-size arrays (2, 4, 6 ...). For data analysis and approximation, you\n",
      "        .   can pad the array when necessary.\n",
      "        .   Also, the function performance depends very much, and not monotonically, on the array size (see\n",
      "        .   getOptimalDFTSize ). In the current implementation DCT of a vector of size N is calculated via DFT\n",
      "        .   of a vector of size N/2 . Thus, the optimal DCT size N1 \\>= N can be calculated as:\n",
      "        .   @code\n",
      "        .       size_t getOptimalDCTSize(size_t N) { return 2*getOptimalDFTSize((N+1)/2); }\n",
      "        .       N1 = getOptimalDCTSize(N);\n",
      "        .   @endcode\n",
      "        .   @param src input floating-point array.\n",
      "        .   @param dst output array of the same size and type as src .\n",
      "        .   @param flags transformation flags as a combination of cv::DftFlags (DCT_*)\n",
      "        .   @sa dft , getOptimalDFTSize , idct\n",
      "    \n",
      "    decolor(...)\n",
      "        decolor(src[, grayscale[, color_boost]]) -> grayscale, color_boost\n",
      "        .   @brief Transforms a color image to a grayscale image. It is a basic tool in digital printing, stylized\n",
      "        .   black-and-white photograph rendering, and in many single channel image processing applications\n",
      "        .   @cite CL12 .\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param grayscale Output 8-bit 1-channel image.\n",
      "        .   @param color_boost Output 8-bit 3-channel image.\n",
      "        .   \n",
      "        .   This function is to be applied on color images.\n",
      "    \n",
      "    decomposeEssentialMat(...)\n",
      "        decomposeEssentialMat(E[, R1[, R2[, t]]]) -> R1, R2, t\n",
      "        .   @brief Decompose an essential matrix to possible rotations and translation.\n",
      "        .   \n",
      "        .   @param E The input essential matrix.\n",
      "        .   @param R1 One possible rotation matrix.\n",
      "        .   @param R2 Another possible rotation matrix.\n",
      "        .   @param t One possible translation.\n",
      "        .   \n",
      "        .   This function decomposes the essential matrix E using svd decomposition @cite HartleyZ00. In\n",
      "        .   general, four possible poses exist for the decomposition of E. They are \\f$[R_1, t]\\f$,\n",
      "        .   \\f$[R_1, -t]\\f$, \\f$[R_2, t]\\f$, \\f$[R_2, -t]\\f$.\n",
      "        .   \n",
      "        .   If E gives the epipolar constraint \\f$[p_2; 1]^T A^{-T} E A^{-1} [p_1; 1] = 0\\f$ between the image\n",
      "        .   points \\f$p_1\\f$ in the first image and \\f$p_2\\f$ in second image, then any of the tuples\n",
      "        .   \\f$[R_1, t]\\f$, \\f$[R_1, -t]\\f$, \\f$[R_2, t]\\f$, \\f$[R_2, -t]\\f$ is a change of basis from the first\n",
      "        .   camera's coordinate system to the second camera's coordinate system. However, by decomposing E, one\n",
      "        .   can only get the direction of the translation. For this reason, the translation t is returned with\n",
      "        .   unit length.\n",
      "    \n",
      "    decomposeHomographyMat(...)\n",
      "        decomposeHomographyMat(H, K[, rotations[, translations[, normals]]]) -> retval, rotations, translations, normals\n",
      "        .   @brief Decompose a homography matrix to rotation(s), translation(s) and plane normal(s).\n",
      "        .   \n",
      "        .   @param H The input homography matrix between two images.\n",
      "        .   @param K The input intrinsic camera calibration matrix.\n",
      "        .   @param rotations Array of rotation matrices.\n",
      "        .   @param translations Array of translation matrices.\n",
      "        .   @param normals Array of plane normal matrices.\n",
      "        .   \n",
      "        .   This function extracts relative camera motion between two views of a planar object and returns up to\n",
      "        .   four mathematical solution tuples of rotation, translation, and plane normal. The decomposition of\n",
      "        .   the homography matrix H is described in detail in @cite Malis.\n",
      "        .   \n",
      "        .   If the homography H, induced by the plane, gives the constraint\n",
      "        .   \\f[s_i \\vecthree{x'_i}{y'_i}{1} \\sim H \\vecthree{x_i}{y_i}{1}\\f] on the source image points\n",
      "        .   \\f$p_i\\f$ and the destination image points \\f$p'_i\\f$, then the tuple of rotations[k] and\n",
      "        .   translations[k] is a change of basis from the source camera's coordinate system to the destination\n",
      "        .   camera's coordinate system. However, by decomposing H, one can only get the translation normalized\n",
      "        .   by the (typically unknown) depth of the scene, i.e. its direction but with normalized length.\n",
      "        .   \n",
      "        .   If point correspondences are available, at least two solutions may further be invalidated, by\n",
      "        .   applying positive depth constraint, i.e. all points must be in front of the camera.\n",
      "    \n",
      "    decomposeProjectionMatrix(...)\n",
      "        decomposeProjectionMatrix(projMatrix[, cameraMatrix[, rotMatrix[, transVect[, rotMatrixX[, rotMatrixY[, rotMatrixZ[, eulerAngles]]]]]]]) -> cameraMatrix, rotMatrix, transVect, rotMatrixX, rotMatrixY, rotMatrixZ, eulerAngles\n",
      "        .   @brief Decomposes a projection matrix into a rotation matrix and a camera matrix.\n",
      "        .   \n",
      "        .   @param projMatrix 3x4 input projection matrix P.\n",
      "        .   @param cameraMatrix Output 3x3 camera matrix K.\n",
      "        .   @param rotMatrix Output 3x3 external rotation matrix R.\n",
      "        .   @param transVect Output 4x1 translation vector T.\n",
      "        .   @param rotMatrixX Optional 3x3 rotation matrix around x-axis.\n",
      "        .   @param rotMatrixY Optional 3x3 rotation matrix around y-axis.\n",
      "        .   @param rotMatrixZ Optional 3x3 rotation matrix around z-axis.\n",
      "        .   @param eulerAngles Optional three-element vector containing three Euler angles of rotation in\n",
      "        .   degrees.\n",
      "        .   \n",
      "        .   The function computes a decomposition of a projection matrix into a calibration and a rotation\n",
      "        .   matrix and the position of a camera.\n",
      "        .   \n",
      "        .   It optionally returns three rotation matrices, one for each axis, and three Euler angles that could\n",
      "        .   be used in OpenGL. Note, there is always more than one sequence of rotations about the three\n",
      "        .   principal axes that results in the same orientation of an object, e.g. see @cite Slabaugh . Returned\n",
      "        .   tree rotation matrices and corresponding three Euler angles are only one of the possible solutions.\n",
      "        .   \n",
      "        .   The function is based on RQDecomp3x3 .\n",
      "    \n",
      "    demosaicing(...)\n",
      "        demosaicing(src, code[, dst[, dstCn]]) -> dst\n",
      "        .   @brief main function for all demosaicing processes\n",
      "        .   \n",
      "        .   @param src input image: 8-bit unsigned or 16-bit unsigned.\n",
      "        .   @param dst output image of the same size and depth as src.\n",
      "        .   @param code Color space conversion code (see the description below).\n",
      "        .   @param dstCn number of channels in the destination image; if the parameter is 0, the number of the\n",
      "        .   channels is derived automatically from src and code.\n",
      "        .   \n",
      "        .   The function can do the following transformations:\n",
      "        .   \n",
      "        .   -   Demosaicing using bilinear interpolation\n",
      "        .   \n",
      "        .       #COLOR_BayerBG2BGR , #COLOR_BayerGB2BGR , #COLOR_BayerRG2BGR , #COLOR_BayerGR2BGR\n",
      "        .   \n",
      "        .       #COLOR_BayerBG2GRAY , #COLOR_BayerGB2GRAY , #COLOR_BayerRG2GRAY , #COLOR_BayerGR2GRAY\n",
      "        .   \n",
      "        .   -   Demosaicing using Variable Number of Gradients.\n",
      "        .   \n",
      "        .       #COLOR_BayerBG2BGR_VNG , #COLOR_BayerGB2BGR_VNG , #COLOR_BayerRG2BGR_VNG , #COLOR_BayerGR2BGR_VNG\n",
      "        .   \n",
      "        .   -   Edge-Aware Demosaicing.\n",
      "        .   \n",
      "        .       #COLOR_BayerBG2BGR_EA , #COLOR_BayerGB2BGR_EA , #COLOR_BayerRG2BGR_EA , #COLOR_BayerGR2BGR_EA\n",
      "        .   \n",
      "        .   -   Demosaicing with alpha channel\n",
      "        .   \n",
      "        .       #COLOR_BayerBG2BGRA , #COLOR_BayerGB2BGRA , #COLOR_BayerRG2BGRA , #COLOR_BayerGR2BGRA\n",
      "        .   \n",
      "        .   @sa cvtColor\n",
      "    \n",
      "    denoise_TVL1(...)\n",
      "        denoise_TVL1(observations, result[, lambda[, niters]]) -> None\n",
      "        .   @brief Primal-dual algorithm is an algorithm for solving special types of variational problems (that is,\n",
      "        .   finding a function to minimize some functional). As the image denoising, in particular, may be seen\n",
      "        .   as the variational problem, primal-dual algorithm then can be used to perform denoising and this is\n",
      "        .   exactly what is implemented.\n",
      "        .   \n",
      "        .   It should be noted, that this implementation was taken from the July 2013 blog entry\n",
      "        .   @cite MA13 , which also contained (slightly more general) ready-to-use source code on Python.\n",
      "        .   Subsequently, that code was rewritten on C++ with the usage of openCV by Vadim Pisarevsky at the end\n",
      "        .   of July 2013 and finally it was slightly adapted by later authors.\n",
      "        .   \n",
      "        .   Although the thorough discussion and justification of the algorithm involved may be found in\n",
      "        .   @cite ChambolleEtAl, it might make sense to skim over it here, following @cite MA13 . To begin\n",
      "        .   with, we consider the 1-byte gray-level images as the functions from the rectangular domain of\n",
      "        .   pixels (it may be seen as set\n",
      "        .   \\f$\\left\\{(x,y)\\in\\mathbb{N}\\times\\mathbb{N}\\mid 1\\leq x\\leq n,\\;1\\leq y\\leq m\\right\\}\\f$ for some\n",
      "        .   \\f$m,\\;n\\in\\mathbb{N}\\f$) into \\f$\\{0,1,\\dots,255\\}\\f$. We shall denote the noised images as \\f$f_i\\f$ and with\n",
      "        .   this view, given some image \\f$x\\f$ of the same size, we may measure how bad it is by the formula\n",
      "        .   \n",
      "        .   \\f[\\left\\|\\left\\|\\nabla x\\right\\|\\right\\| + \\lambda\\sum_i\\left\\|\\left\\|x-f_i\\right\\|\\right\\|\\f]\n",
      "        .   \n",
      "        .   \\f$\\|\\|\\cdot\\|\\|\\f$ here denotes \\f$L_2\\f$-norm and as you see, the first addend states that we want our\n",
      "        .   image to be smooth (ideally, having zero gradient, thus being constant) and the second states that\n",
      "        .   we want our result to be close to the observations we've got. If we treat \\f$x\\f$ as a function, this is\n",
      "        .   exactly the functional what we seek to minimize and here the Primal-Dual algorithm comes into play.\n",
      "        .   \n",
      "        .   @param observations This array should contain one or more noised versions of the image that is to\n",
      "        .   be restored.\n",
      "        .   @param result Here the denoised image will be stored. There is no need to do pre-allocation of\n",
      "        .   storage space, as it will be automatically allocated, if necessary.\n",
      "        .   @param lambda Corresponds to \\f$\\lambda\\f$ in the formulas above. As it is enlarged, the smooth\n",
      "        .   (blurred) images are treated more favorably than detailed (but maybe more noised) ones. Roughly\n",
      "        .   speaking, as it becomes smaller, the result will be more blur but more sever outliers will be\n",
      "        .   removed.\n",
      "        .   @param niters Number of iterations that the algorithm will run. Of course, as more iterations as\n",
      "        .   better, but it is hard to quantitatively refine this statement, so just use the default and\n",
      "        .   increase it if the results are poor.\n",
      "    \n",
      "    destroyAllWindows(...)\n",
      "        destroyAllWindows() -> None\n",
      "        .   @brief Destroys all of the HighGUI windows.\n",
      "        .   \n",
      "        .   The function destroyAllWindows destroys all of the opened HighGUI windows.\n",
      "    \n",
      "    destroyWindow(...)\n",
      "        destroyWindow(winname) -> None\n",
      "        .   @brief Destroys the specified window.\n",
      "        .   \n",
      "        .   The function destroyWindow destroys the window with the given name.\n",
      "        .   \n",
      "        .   @param winname Name of the window to be destroyed.\n",
      "    \n",
      "    detailEnhance(...)\n",
      "        detailEnhance(src[, dst[, sigma_s[, sigma_r]]]) -> dst\n",
      "        .   @brief This filter enhances the details of a particular image.\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param dst Output image with the same size and type as src.\n",
      "        .   @param sigma_s %Range between 0 to 200.\n",
      "        .   @param sigma_r %Range between 0 to 1.\n",
      "    \n",
      "    determinant(...)\n",
      "        determinant(mtx) -> retval\n",
      "        .   @brief Returns the determinant of a square floating-point matrix.\n",
      "        .   \n",
      "        .   The function cv::determinant calculates and returns the determinant of the\n",
      "        .   specified matrix. For small matrices ( mtx.cols=mtx.rows\\<=3 ), the\n",
      "        .   direct method is used. For larger matrices, the function uses LU\n",
      "        .   factorization with partial pivoting.\n",
      "        .   \n",
      "        .   For symmetric positively-determined matrices, it is also possible to use\n",
      "        .   eigen decomposition to calculate the determinant.\n",
      "        .   @param mtx input matrix that must have CV_32FC1 or CV_64FC1 type and\n",
      "        .   square size.\n",
      "        .   @sa trace, invert, solve, eigen, @ref MatrixExpressions\n",
      "    \n",
      "    dft(...)\n",
      "        dft(src[, dst[, flags[, nonzeroRows]]]) -> dst\n",
      "        .   @brief Performs a forward or inverse Discrete Fourier transform of a 1D or 2D floating-point array.\n",
      "        .   \n",
      "        .   The function cv::dft performs one of the following:\n",
      "        .   -   Forward the Fourier transform of a 1D vector of N elements:\n",
      "        .       \\f[Y = F^{(N)}  \\cdot X,\\f]\n",
      "        .       where \\f$F^{(N)}_{jk}=\\exp(-2\\pi i j k/N)\\f$ and \\f$i=\\sqrt{-1}\\f$\n",
      "        .   -   Inverse the Fourier transform of a 1D vector of N elements:\n",
      "        .       \\f[\\begin{array}{l} X'=  \\left (F^{(N)} \\right )^{-1}  \\cdot Y =  \\left (F^{(N)} \\right )^*  \\cdot y  \\\\ X = (1/N)  \\cdot X, \\end{array}\\f]\n",
      "        .       where \\f$F^*=\\left(\\textrm{Re}(F^{(N)})-\\textrm{Im}(F^{(N)})\\right)^T\\f$\n",
      "        .   -   Forward the 2D Fourier transform of a M x N matrix:\n",
      "        .       \\f[Y = F^{(M)}  \\cdot X  \\cdot F^{(N)}\\f]\n",
      "        .   -   Inverse the 2D Fourier transform of a M x N matrix:\n",
      "        .       \\f[\\begin{array}{l} X'=  \\left (F^{(M)} \\right )^*  \\cdot Y  \\cdot \\left (F^{(N)} \\right )^* \\\\ X =  \\frac{1}{M \\cdot N} \\cdot X' \\end{array}\\f]\n",
      "        .   \n",
      "        .   In case of real (single-channel) data, the output spectrum of the forward Fourier transform or input\n",
      "        .   spectrum of the inverse Fourier transform can be represented in a packed format called *CCS*\n",
      "        .   (complex-conjugate-symmetrical). It was borrowed from IPL (Intel\\* Image Processing Library). Here\n",
      "        .   is how 2D *CCS* spectrum looks:\n",
      "        .   \\f[\\begin{bmatrix} Re Y_{0,0} & Re Y_{0,1} & Im Y_{0,1} & Re Y_{0,2} & Im Y_{0,2} &  \\cdots & Re Y_{0,N/2-1} & Im Y_{0,N/2-1} & Re Y_{0,N/2}  \\\\ Re Y_{1,0} & Re Y_{1,1} & Im Y_{1,1} & Re Y_{1,2} & Im Y_{1,2} &  \\cdots & Re Y_{1,N/2-1} & Im Y_{1,N/2-1} & Re Y_{1,N/2}  \\\\ Im Y_{1,0} & Re Y_{2,1} & Im Y_{2,1} & Re Y_{2,2} & Im Y_{2,2} &  \\cdots & Re Y_{2,N/2-1} & Im Y_{2,N/2-1} & Im Y_{1,N/2}  \\\\ \\hdotsfor{9} \\\\ Re Y_{M/2-1,0} &  Re Y_{M-3,1}  & Im Y_{M-3,1} &  \\hdotsfor{3} & Re Y_{M-3,N/2-1} & Im Y_{M-3,N/2-1}& Re Y_{M/2-1,N/2}  \\\\ Im Y_{M/2-1,0} &  Re Y_{M-2,1}  & Im Y_{M-2,1} &  \\hdotsfor{3} & Re Y_{M-2,N/2-1} & Im Y_{M-2,N/2-1}& Im Y_{M/2-1,N/2}  \\\\ Re Y_{M/2,0}  &  Re Y_{M-1,1} &  Im Y_{M-1,1} &  \\hdotsfor{3} & Re Y_{M-1,N/2-1} & Im Y_{M-1,N/2-1}& Re Y_{M/2,N/2} \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   In case of 1D transform of a real vector, the output looks like the first row of the matrix above.\n",
      "        .   \n",
      "        .   So, the function chooses an operation mode depending on the flags and size of the input array:\n",
      "        .   -   If #DFT_ROWS is set or the input array has a single row or single column, the function\n",
      "        .       performs a 1D forward or inverse transform of each row of a matrix when #DFT_ROWS is set.\n",
      "        .       Otherwise, it performs a 2D transform.\n",
      "        .   -   If the input array is real and #DFT_INVERSE is not set, the function performs a forward 1D or\n",
      "        .       2D transform:\n",
      "        .       -   When #DFT_COMPLEX_OUTPUT is set, the output is a complex matrix of the same size as\n",
      "        .           input.\n",
      "        .       -   When #DFT_COMPLEX_OUTPUT is not set, the output is a real matrix of the same size as\n",
      "        .           input. In case of 2D transform, it uses the packed format as shown above. In case of a\n",
      "        .           single 1D transform, it looks like the first row of the matrix above. In case of\n",
      "        .           multiple 1D transforms (when using the #DFT_ROWS flag), each row of the output matrix\n",
      "        .           looks like the first row of the matrix above.\n",
      "        .   -   If the input array is complex and either #DFT_INVERSE or #DFT_REAL_OUTPUT are not set, the\n",
      "        .       output is a complex array of the same size as input. The function performs a forward or\n",
      "        .       inverse 1D or 2D transform of the whole input array or each row of the input array\n",
      "        .       independently, depending on the flags DFT_INVERSE and DFT_ROWS.\n",
      "        .   -   When #DFT_INVERSE is set and the input array is real, or it is complex but #DFT_REAL_OUTPUT\n",
      "        .       is set, the output is a real array of the same size as input. The function performs a 1D or 2D\n",
      "        .       inverse transformation of the whole input array or each individual row, depending on the flags\n",
      "        .       #DFT_INVERSE and #DFT_ROWS.\n",
      "        .   \n",
      "        .   If #DFT_SCALE is set, the scaling is done after the transformation.\n",
      "        .   \n",
      "        .   Unlike dct , the function supports arrays of arbitrary size. But only those arrays are processed\n",
      "        .   efficiently, whose sizes can be factorized in a product of small prime numbers (2, 3, and 5 in the\n",
      "        .   current implementation). Such an efficient DFT size can be calculated using the getOptimalDFTSize\n",
      "        .   method.\n",
      "        .   \n",
      "        .   The sample below illustrates how to calculate a DFT-based convolution of two 2D real arrays:\n",
      "        .   @code\n",
      "        .       void convolveDFT(InputArray A, InputArray B, OutputArray C)\n",
      "        .       {\n",
      "        .           // reallocate the output array if needed\n",
      "        .           C.create(abs(A.rows - B.rows)+1, abs(A.cols - B.cols)+1, A.type());\n",
      "        .           Size dftSize;\n",
      "        .           // calculate the size of DFT transform\n",
      "        .           dftSize.width = getOptimalDFTSize(A.cols + B.cols - 1);\n",
      "        .           dftSize.height = getOptimalDFTSize(A.rows + B.rows - 1);\n",
      "        .   \n",
      "        .           // allocate temporary buffers and initialize them with 0's\n",
      "        .           Mat tempA(dftSize, A.type(), Scalar::all(0));\n",
      "        .           Mat tempB(dftSize, B.type(), Scalar::all(0));\n",
      "        .   \n",
      "        .           // copy A and B to the top-left corners of tempA and tempB, respectively\n",
      "        .           Mat roiA(tempA, Rect(0,0,A.cols,A.rows));\n",
      "        .           A.copyTo(roiA);\n",
      "        .           Mat roiB(tempB, Rect(0,0,B.cols,B.rows));\n",
      "        .           B.copyTo(roiB);\n",
      "        .   \n",
      "        .           // now transform the padded A & B in-place;\n",
      "        .           // use \"nonzeroRows\" hint for faster processing\n",
      "        .           dft(tempA, tempA, 0, A.rows);\n",
      "        .           dft(tempB, tempB, 0, B.rows);\n",
      "        .   \n",
      "        .           // multiply the spectrums;\n",
      "        .           // the function handles packed spectrum representations well\n",
      "        .           mulSpectrums(tempA, tempB, tempA);\n",
      "        .   \n",
      "        .           // transform the product back from the frequency domain.\n",
      "        .           // Even though all the result rows will be non-zero,\n",
      "        .           // you need only the first C.rows of them, and thus you\n",
      "        .           // pass nonzeroRows == C.rows\n",
      "        .           dft(tempA, tempA, DFT_INVERSE + DFT_SCALE, C.rows);\n",
      "        .   \n",
      "        .           // now copy the result back to C.\n",
      "        .           tempA(Rect(0, 0, C.cols, C.rows)).copyTo(C);\n",
      "        .   \n",
      "        .           // all the temporary buffers will be deallocated automatically\n",
      "        .       }\n",
      "        .   @endcode\n",
      "        .   To optimize this sample, consider the following approaches:\n",
      "        .   -   Since nonzeroRows != 0 is passed to the forward transform calls and since A and B are copied to\n",
      "        .       the top-left corners of tempA and tempB, respectively, it is not necessary to clear the whole\n",
      "        .       tempA and tempB. It is only necessary to clear the tempA.cols - A.cols ( tempB.cols - B.cols)\n",
      "        .       rightmost columns of the matrices.\n",
      "        .   -   This DFT-based convolution does not have to be applied to the whole big arrays, especially if B\n",
      "        .       is significantly smaller than A or vice versa. Instead, you can calculate convolution by parts.\n",
      "        .       To do this, you need to split the output array C into multiple tiles. For each tile, estimate\n",
      "        .       which parts of A and B are required to calculate convolution in this tile. If the tiles in C are\n",
      "        .       too small, the speed will decrease a lot because of repeated work. In the ultimate case, when\n",
      "        .       each tile in C is a single pixel, the algorithm becomes equivalent to the naive convolution\n",
      "        .       algorithm. If the tiles are too big, the temporary arrays tempA and tempB become too big and\n",
      "        .       there is also a slowdown because of bad cache locality. So, there is an optimal tile size\n",
      "        .       somewhere in the middle.\n",
      "        .   -   If different tiles in C can be calculated in parallel and, thus, the convolution is done by\n",
      "        .       parts, the loop can be threaded.\n",
      "        .   \n",
      "        .   All of the above improvements have been implemented in #matchTemplate and #filter2D . Therefore, by\n",
      "        .   using them, you can get the performance even better than with the above theoretically optimal\n",
      "        .   implementation. Though, those two functions actually calculate cross-correlation, not convolution,\n",
      "        .   so you need to \"flip\" the second convolution operand B vertically and horizontally using flip .\n",
      "        .   @note\n",
      "        .   -   An example using the discrete fourier transform can be found at\n",
      "        .       opencv_source_code/samples/cpp/dft.cpp\n",
      "        .   -   (Python) An example using the dft functionality to perform Wiener deconvolution can be found\n",
      "        .       at opencv_source/samples/python/deconvolution.py\n",
      "        .   -   (Python) An example rearranging the quadrants of a Fourier image can be found at\n",
      "        .       opencv_source/samples/python/dft.py\n",
      "        .   @param src input array that could be real or complex.\n",
      "        .   @param dst output array whose size and type depends on the flags .\n",
      "        .   @param flags transformation flags, representing a combination of the #DftFlags\n",
      "        .   @param nonzeroRows when the parameter is not zero, the function assumes that only the first\n",
      "        .   nonzeroRows rows of the input array (#DFT_INVERSE is not set) or only the first nonzeroRows of the\n",
      "        .   output array (#DFT_INVERSE is set) contain non-zeros, thus, the function can handle the rest of the\n",
      "        .   rows more efficiently and save some time; this technique is very useful for calculating array\n",
      "        .   cross-correlation or convolution using DFT.\n",
      "        .   @sa dct , getOptimalDFTSize , mulSpectrums, filter2D , matchTemplate , flip , cartToPolar ,\n",
      "        .   magnitude , phase\n",
      "    \n",
      "    dilate(...)\n",
      "        dilate(src, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
      "        .   @brief Dilates an image by using a specific structuring element.\n",
      "        .   \n",
      "        .   The function dilates the source image using the specified structuring element that determines the\n",
      "        .   shape of a pixel neighborhood over which the maximum is taken:\n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\max _{(x',y'):  \\, \\texttt{element} (x',y') \\ne0 } \\texttt{src} (x+x',y+y')\\f]\n",
      "        .   \n",
      "        .   The function supports the in-place mode. Dilation can be applied several ( iterations ) times. In\n",
      "        .   case of multi-channel images, each channel is processed independently.\n",
      "        .   \n",
      "        .   @param src input image; the number of channels can be arbitrary, but the depth should be one of\n",
      "        .   CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
      "        .   @param dst output image of the same size and type as src.\n",
      "        .   @param kernel structuring element used for dilation; if elemenat=Mat(), a 3 x 3 rectangular\n",
      "        .   structuring element is used. Kernel can be created using #getStructuringElement\n",
      "        .   @param anchor position of the anchor within the element; default value (-1, -1) means that the\n",
      "        .   anchor is at the element center.\n",
      "        .   @param iterations number of times dilation is applied.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes. #BORDER_WRAP is not suported.\n",
      "        .   @param borderValue border value in case of a constant border\n",
      "        .   @sa  erode, morphologyEx, getStructuringElement\n",
      "    \n",
      "    displayOverlay(...)\n",
      "        displayOverlay(winname, text[, delayms]) -> None\n",
      "        .   @brief Displays a text on a window image as an overlay for a specified duration.\n",
      "        .   \n",
      "        .   The function displayOverlay displays useful information/tips on top of the window for a certain\n",
      "        .   amount of time *delayms*. The function does not modify the image, displayed in the window, that is,\n",
      "        .   after the specified delay the original content of the window is restored.\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   @param text Overlay text to write on a window image.\n",
      "        .   @param delayms The period (in milliseconds), during which the overlay text is displayed. If this\n",
      "        .   function is called before the previous overlay text timed out, the timer is restarted and the text\n",
      "        .   is updated. If this value is zero, the text never disappears.\n",
      "    \n",
      "    displayStatusBar(...)\n",
      "        displayStatusBar(winname, text[, delayms]) -> None\n",
      "        .   @brief Displays a text on the window statusbar during the specified period of time.\n",
      "        .   \n",
      "        .   The function displayStatusBar displays useful information/tips on top of the window for a certain\n",
      "        .   amount of time *delayms* . This information is displayed on the window statusbar (the window must be\n",
      "        .   created with the CV_GUI_EXPANDED flags).\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   @param text Text to write on the window statusbar.\n",
      "        .   @param delayms Duration (in milliseconds) to display the text. If this function is called before\n",
      "        .   the previous text timed out, the timer is restarted and the text is updated. If this value is\n",
      "        .   zero, the text never disappears.\n",
      "    \n",
      "    distanceTransform(...)\n",
      "        distanceTransform(src, distanceType, maskSize[, dst[, dstType]]) -> dst\n",
      "        .   @overload\n",
      "        .   @param src 8-bit, single-channel (binary) source image.\n",
      "        .   @param dst Output image with calculated distances. It is a 8-bit or 32-bit floating-point,\n",
      "        .   single-channel image of the same size as src .\n",
      "        .   @param distanceType Type of distance, see #DistanceTypes\n",
      "        .   @param maskSize Size of the distance transform mask, see #DistanceTransformMasks. In case of the\n",
      "        .   #DIST_L1 or #DIST_C distance type, the parameter is forced to 3 because a \\f$3\\times 3\\f$ mask gives\n",
      "        .   the same result as \\f$5\\times 5\\f$ or any larger aperture.\n",
      "        .   @param dstType Type of output image. It can be CV_8U or CV_32F. Type CV_8U can be used only for\n",
      "        .   the first variant of the function and distanceType == #DIST_L1.\n",
      "    \n",
      "    distanceTransformWithLabels(...)\n",
      "        distanceTransformWithLabels(src, distanceType, maskSize[, dst[, labels[, labelType]]]) -> dst, labels\n",
      "        .   @brief Calculates the distance to the closest zero pixel for each pixel of the source image.\n",
      "        .   \n",
      "        .   The function cv::distanceTransform calculates the approximate or precise distance from every binary\n",
      "        .   image pixel to the nearest zero pixel. For zero image pixels, the distance will obviously be zero.\n",
      "        .   \n",
      "        .   When maskSize == #DIST_MASK_PRECISE and distanceType == #DIST_L2 , the function runs the\n",
      "        .   algorithm described in @cite Felzenszwalb04 . This algorithm is parallelized with the TBB library.\n",
      "        .   \n",
      "        .   In other cases, the algorithm @cite Borgefors86 is used. This means that for a pixel the function\n",
      "        .   finds the shortest path to the nearest zero pixel consisting of basic shifts: horizontal, vertical,\n",
      "        .   diagonal, or knight's move (the latest is available for a \\f$5\\times 5\\f$ mask). The overall\n",
      "        .   distance is calculated as a sum of these basic distances. Since the distance function should be\n",
      "        .   symmetric, all of the horizontal and vertical shifts must have the same cost (denoted as a ), all\n",
      "        .   the diagonal shifts must have the same cost (denoted as `b`), and all knight's moves must have the\n",
      "        .   same cost (denoted as `c`). For the #DIST_C and #DIST_L1 types, the distance is calculated\n",
      "        .   precisely, whereas for #DIST_L2 (Euclidean distance) the distance can be calculated only with a\n",
      "        .   relative error (a \\f$5\\times 5\\f$ mask gives more accurate results). For `a`,`b`, and `c`, OpenCV\n",
      "        .   uses the values suggested in the original paper:\n",
      "        .   - DIST_L1: `a = 1, b = 2`\n",
      "        .   - DIST_L2:\n",
      "        .       - `3 x 3`: `a=0.955, b=1.3693`\n",
      "        .       - `5 x 5`: `a=1, b=1.4, c=2.1969`\n",
      "        .   - DIST_C: `a = 1, b = 1`\n",
      "        .   \n",
      "        .   Typically, for a fast, coarse distance estimation #DIST_L2, a \\f$3\\times 3\\f$ mask is used. For a\n",
      "        .   more accurate distance estimation #DIST_L2, a \\f$5\\times 5\\f$ mask or the precise algorithm is used.\n",
      "        .   Note that both the precise and the approximate algorithms are linear on the number of pixels.\n",
      "        .   \n",
      "        .   This variant of the function does not only compute the minimum distance for each pixel \\f$(x, y)\\f$\n",
      "        .   but also identifies the nearest connected component consisting of zero pixels\n",
      "        .   (labelType==#DIST_LABEL_CCOMP) or the nearest zero pixel (labelType==#DIST_LABEL_PIXEL). Index of the\n",
      "        .   component/pixel is stored in `labels(x, y)`. When labelType==#DIST_LABEL_CCOMP, the function\n",
      "        .   automatically finds connected components of zero pixels in the input image and marks them with\n",
      "        .   distinct labels. When labelType==#DIST_LABEL_CCOMP, the function scans through the input image and\n",
      "        .   marks all the zero pixels with distinct labels.\n",
      "        .   \n",
      "        .   In this mode, the complexity is still linear. That is, the function provides a very fast way to\n",
      "        .   compute the Voronoi diagram for a binary image. Currently, the second variant can use only the\n",
      "        .   approximate distance transform algorithm, i.e. maskSize=#DIST_MASK_PRECISE is not supported\n",
      "        .   yet.\n",
      "        .   \n",
      "        .   @param src 8-bit, single-channel (binary) source image.\n",
      "        .   @param dst Output image with calculated distances. It is a 8-bit or 32-bit floating-point,\n",
      "        .   single-channel image of the same size as src.\n",
      "        .   @param labels Output 2D array of labels (the discrete Voronoi diagram). It has the type\n",
      "        .   CV_32SC1 and the same size as src.\n",
      "        .   @param distanceType Type of distance, see #DistanceTypes\n",
      "        .   @param maskSize Size of the distance transform mask, see #DistanceTransformMasks.\n",
      "        .   #DIST_MASK_PRECISE is not supported by this variant. In case of the #DIST_L1 or #DIST_C distance type,\n",
      "        .   the parameter is forced to 3 because a \\f$3\\times 3\\f$ mask gives the same result as \\f$5\\times\n",
      "        .   5\\f$ or any larger aperture.\n",
      "        .   @param labelType Type of the label array to build, see #DistanceTransformLabelTypes.\n",
      "    \n",
      "    divide(...)\n",
      "        divide(src1, src2[, dst[, scale[, dtype]]]) -> dst\n",
      "        .   @brief Performs per-element division of two arrays or a scalar by an array.\n",
      "        .   \n",
      "        .   The function cv::divide divides one array by another:\n",
      "        .   \\f[\\texttt{dst(I) = saturate(src1(I)*scale/src2(I))}\\f]\n",
      "        .   or a scalar by an array when there is no src1 :\n",
      "        .   \\f[\\texttt{dst(I) = saturate(scale/src2(I))}\\f]\n",
      "        .   \n",
      "        .   Different channels of multi-channel arrays are processed independently.\n",
      "        .   \n",
      "        .   For integer types when src2(I) is zero, dst(I) will also be zero.\n",
      "        .   \n",
      "        .   @note In case of floating point data there is no special defined behavior for zero src2(I) values.\n",
      "        .   Regular floating-point division is used.\n",
      "        .   Expect correct IEEE-754 behaviour for floating-point data (with NaN, Inf result values).\n",
      "        .   \n",
      "        .   @note Saturation is not applied when the output array has the depth CV_32S. You may even get\n",
      "        .   result of an incorrect sign in the case of overflow.\n",
      "        .   @param src1 first input array.\n",
      "        .   @param src2 second input array of the same size and type as src1.\n",
      "        .   @param scale scalar factor.\n",
      "        .   @param dst output array of the same size and type as src2.\n",
      "        .   @param dtype optional depth of the output array; if -1, dst will have depth src2.depth(), but in\n",
      "        .   case of an array-by-array division, you can only pass -1 when src1.depth()==src2.depth().\n",
      "        .   @sa  multiply, add, subtract\n",
      "        \n",
      "        \n",
      "        \n",
      "        divide(scale, src2[, dst[, dtype]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    dnn_registerLayer(...)\n",
      "        registerLayer(type, class) -> None\n",
      "    \n",
      "    dnn_unregisterLayer(...)\n",
      "        unregisterLayer(type) -> None\n",
      "    \n",
      "    drawChessboardCorners(...)\n",
      "        drawChessboardCorners(image, patternSize, corners, patternWasFound) -> image\n",
      "        .   @brief Renders the detected chessboard corners.\n",
      "        .   \n",
      "        .   @param image Destination image. It must be an 8-bit color image.\n",
      "        .   @param patternSize Number of inner corners per a chessboard row and column\n",
      "        .   (patternSize = cv::Size(points_per_row,points_per_column)).\n",
      "        .   @param corners Array of detected corners, the output of findChessboardCorners.\n",
      "        .   @param patternWasFound Parameter indicating whether the complete board was found or not. The\n",
      "        .   return value of findChessboardCorners should be passed here.\n",
      "        .   \n",
      "        .   The function draws individual chessboard corners detected either as red circles if the board was not\n",
      "        .   found, or as colored corners connected with lines if the board was found.\n",
      "    \n",
      "    drawContours(...)\n",
      "        drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]]) -> image\n",
      "        .   @brief Draws contours outlines or filled contours.\n",
      "        .   \n",
      "        .   The function draws contour outlines in the image if \\f$\\texttt{thickness} \\ge 0\\f$ or fills the area\n",
      "        .   bounded by the contours if \\f$\\texttt{thickness}<0\\f$ . The example below shows how to retrieve\n",
      "        .   connected components from the binary image and label them: :\n",
      "        .   @include snippets/imgproc_drawContours.cpp\n",
      "        .   \n",
      "        .   @param image Destination image.\n",
      "        .   @param contours All the input contours. Each contour is stored as a point vector.\n",
      "        .   @param contourIdx Parameter indicating a contour to draw. If it is negative, all the contours are drawn.\n",
      "        .   @param color Color of the contours.\n",
      "        .   @param thickness Thickness of lines the contours are drawn with. If it is negative (for example,\n",
      "        .   thickness=#FILLED ), the contour interiors are drawn.\n",
      "        .   @param lineType Line connectivity. See #LineTypes\n",
      "        .   @param hierarchy Optional information about hierarchy. It is only needed if you want to draw only\n",
      "        .   some of the contours (see maxLevel ).\n",
      "        .   @param maxLevel Maximal level for drawn contours. If it is 0, only the specified contour is drawn.\n",
      "        .   If it is 1, the function draws the contour(s) and all the nested contours. If it is 2, the function\n",
      "        .   draws the contours, all the nested contours, all the nested-to-nested contours, and so on. This\n",
      "        .   parameter is only taken into account when there is hierarchy available.\n",
      "        .   @param offset Optional contour shift parameter. Shift all the drawn contours by the specified\n",
      "        .   \\f$\\texttt{offset}=(dx,dy)\\f$ .\n",
      "        .   @note When thickness=#FILLED, the function is designed to handle connected components with holes correctly\n",
      "        .   even when no hierarchy date is provided. This is done by analyzing all the outlines together\n",
      "        .   using even-odd rule. This may give incorrect results if you have a joint collection of separately retrieved\n",
      "        .   contours. In order to solve this problem, you need to call #drawContours separately for each sub-group\n",
      "        .   of contours, or iterate over the collection using contourIdx parameter.\n",
      "    \n",
      "    drawFrameAxes(...)\n",
      "        drawFrameAxes(image, cameraMatrix, distCoeffs, rvec, tvec, length[, thickness]) -> image\n",
      "        .   @brief Draw axes of the world/object coordinate system from pose estimation. @sa solvePnP\n",
      "        .   \n",
      "        .   @param image Input/output image. It must have 1 or 3 channels. The number of channels is not altered.\n",
      "        .   @param cameraMatrix Input 3x3 floating-point matrix of camera intrinsic parameters.\n",
      "        .   \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is empty, the zero distortion coefficients are assumed.\n",
      "        .   @param rvec Rotation vector (see @ref Rodrigues ) that, together with tvec, brings points from\n",
      "        .   the model coordinate system to the camera coordinate system.\n",
      "        .   @param tvec Translation vector.\n",
      "        .   @param length Length of the painted axes in the same unit than tvec (usually in meters).\n",
      "        .   @param thickness Line thickness of the painted axes.\n",
      "        .   \n",
      "        .   This function draws the axes of the world/object coordinate system w.r.t. to the camera frame.\n",
      "        .   OX is drawn in red, OY in green and OZ in blue.\n",
      "    \n",
      "    drawKeypoints(...)\n",
      "        drawKeypoints(image, keypoints, outImage[, color[, flags]]) -> outImage\n",
      "        .   @brief Draws keypoints.\n",
      "        .   \n",
      "        .   @param image Source image.\n",
      "        .   @param keypoints Keypoints from the source image.\n",
      "        .   @param outImage Output image. Its content depends on the flags value defining what is drawn in the\n",
      "        .   output image. See possible flags bit values below.\n",
      "        .   @param color Color of keypoints.\n",
      "        .   @param flags Flags setting drawing features. Possible flags bit values are defined by\n",
      "        .   DrawMatchesFlags. See details above in drawMatches .\n",
      "        .   \n",
      "        .   @note\n",
      "        .   For Python API, flags are modified as cv.DRAW_MATCHES_FLAGS_DEFAULT,\n",
      "        .   cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, cv.DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG,\n",
      "        .   cv.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS\n",
      "    \n",
      "    drawMarker(...)\n",
      "        drawMarker(img, position, color[, markerType[, markerSize[, thickness[, line_type]]]]) -> img\n",
      "        .   @brief Draws a marker on a predefined position in an image.\n",
      "        .   \n",
      "        .   The function cv::drawMarker draws a marker on a given position in the image. For the moment several\n",
      "        .   marker types are supported, see #MarkerTypes for more information.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param position The point where the crosshair is positioned.\n",
      "        .   @param color Line color.\n",
      "        .   @param markerType The specific type of marker you want to use, see #MarkerTypes\n",
      "        .   @param thickness Line thickness.\n",
      "        .   @param line_type Type of the line, See #LineTypes\n",
      "        .   @param markerSize The length of the marker axis [default = 20 pixels]\n",
      "    \n",
      "    drawMatches(...)\n",
      "        drawMatches(img1, keypoints1, img2, keypoints2, matches1to2, outImg[, matchColor[, singlePointColor[, matchesMask[, flags]]]]) -> outImg\n",
      "        .   @brief Draws the found matches of keypoints from two images.\n",
      "        .   \n",
      "        .   @param img1 First source image.\n",
      "        .   @param keypoints1 Keypoints from the first source image.\n",
      "        .   @param img2 Second source image.\n",
      "        .   @param keypoints2 Keypoints from the second source image.\n",
      "        .   @param matches1to2 Matches from the first image to the second one, which means that keypoints1[i]\n",
      "        .   has a corresponding point in keypoints2[matches[i]] .\n",
      "        .   @param outImg Output image. Its content depends on the flags value defining what is drawn in the\n",
      "        .   output image. See possible flags bit values below.\n",
      "        .   @param matchColor Color of matches (lines and connected keypoints). If matchColor==Scalar::all(-1)\n",
      "        .   , the color is generated randomly.\n",
      "        .   @param singlePointColor Color of single keypoints (circles), which means that keypoints do not\n",
      "        .   have the matches. If singlePointColor==Scalar::all(-1) , the color is generated randomly.\n",
      "        .   @param matchesMask Mask determining which matches are drawn. If the mask is empty, all matches are\n",
      "        .   drawn.\n",
      "        .   @param flags Flags setting drawing features. Possible flags bit values are defined by\n",
      "        .   DrawMatchesFlags.\n",
      "        .   \n",
      "        .   This function draws matches of keypoints from two images in the output image. Match is a line\n",
      "        .   connecting two keypoints (circles). See cv::DrawMatchesFlags.\n",
      "    \n",
      "    drawMatchesKnn(...)\n",
      "        drawMatchesKnn(img1, keypoints1, img2, keypoints2, matches1to2, outImg[, matchColor[, singlePointColor[, matchesMask[, flags]]]]) -> outImg\n",
      "        .   @overload\n",
      "    \n",
      "    edgePreservingFilter(...)\n",
      "        edgePreservingFilter(src[, dst[, flags[, sigma_s[, sigma_r]]]]) -> dst\n",
      "        .   @brief Filtering is the fundamental operation in image and video processing. Edge-preserving smoothing\n",
      "        .   filters are used in many different applications @cite EM11 .\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param dst Output 8-bit 3-channel image.\n",
      "        .   @param flags Edge preserving filters: cv::RECURS_FILTER or cv::NORMCONV_FILTER\n",
      "        .   @param sigma_s %Range between 0 to 200.\n",
      "        .   @param sigma_r %Range between 0 to 1.\n",
      "    \n",
      "    eigen(...)\n",
      "        eigen(src[, eigenvalues[, eigenvectors]]) -> retval, eigenvalues, eigenvectors\n",
      "        .   @brief Calculates eigenvalues and eigenvectors of a symmetric matrix.\n",
      "        .   \n",
      "        .   The function cv::eigen calculates just eigenvalues, or eigenvalues and eigenvectors of the symmetric\n",
      "        .   matrix src:\n",
      "        .   @code\n",
      "        .       src*eigenvectors.row(i).t() = eigenvalues.at<srcType>(i)*eigenvectors.row(i).t()\n",
      "        .   @endcode\n",
      "        .   \n",
      "        .   @note Use cv::eigenNonSymmetric for calculation of real eigenvalues and eigenvectors of non-symmetric matrix.\n",
      "        .   \n",
      "        .   @param src input matrix that must have CV_32FC1 or CV_64FC1 type, square size and be symmetrical\n",
      "        .   (src ^T^ == src).\n",
      "        .   @param eigenvalues output vector of eigenvalues of the same type as src; the eigenvalues are stored\n",
      "        .   in the descending order.\n",
      "        .   @param eigenvectors output matrix of eigenvectors; it has the same size and type as src; the\n",
      "        .   eigenvectors are stored as subsequent matrix rows, in the same order as the corresponding\n",
      "        .   eigenvalues.\n",
      "        .   @sa eigenNonSymmetric, completeSymm , PCA\n",
      "    \n",
      "    eigenNonSymmetric(...)\n",
      "        eigenNonSymmetric(src[, eigenvalues[, eigenvectors]]) -> eigenvalues, eigenvectors\n",
      "        .   @brief Calculates eigenvalues and eigenvectors of a non-symmetric matrix (real eigenvalues only).\n",
      "        .   \n",
      "        .   @note Assumes real eigenvalues.\n",
      "        .   \n",
      "        .   The function calculates eigenvalues and eigenvectors (optional) of the square matrix src:\n",
      "        .   @code\n",
      "        .       src*eigenvectors.row(i).t() = eigenvalues.at<srcType>(i)*eigenvectors.row(i).t()\n",
      "        .   @endcode\n",
      "        .   \n",
      "        .   @param src input matrix (CV_32FC1 or CV_64FC1 type).\n",
      "        .   @param eigenvalues output vector of eigenvalues (type is the same type as src).\n",
      "        .   @param eigenvectors output matrix of eigenvectors (type is the same type as src). The eigenvectors are stored as subsequent matrix rows, in the same order as the corresponding eigenvalues.\n",
      "        .   @sa eigen\n",
      "    \n",
      "    ellipse(...)\n",
      "        ellipse(img, center, axes, angle, startAngle, endAngle, color[, thickness[, lineType[, shift]]]) -> img\n",
      "        .   @brief Draws a simple or thick elliptic arc or fills an ellipse sector.\n",
      "        .   \n",
      "        .   The function cv::ellipse with more parameters draws an ellipse outline, a filled ellipse, an elliptic\n",
      "        .   arc, or a filled ellipse sector. The drawing code uses general parametric form.\n",
      "        .   A piecewise-linear curve is used to approximate the elliptic arc\n",
      "        .   boundary. If you need more control of the ellipse rendering, you can retrieve the curve using\n",
      "        .   #ellipse2Poly and then render it with #polylines or fill it with #fillPoly. If you use the first\n",
      "        .   variant of the function and want to draw the whole ellipse, not an arc, pass `startAngle=0` and\n",
      "        .   `endAngle=360`. If `startAngle` is greater than `endAngle`, they are swapped. The figure below explains\n",
      "        .   the meaning of the parameters to draw the blue arc.\n",
      "        .   \n",
      "        .   ![Parameters of Elliptic Arc](pics/ellipse.svg)\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param center Center of the ellipse.\n",
      "        .   @param axes Half of the size of the ellipse main axes.\n",
      "        .   @param angle Ellipse rotation angle in degrees.\n",
      "        .   @param startAngle Starting angle of the elliptic arc in degrees.\n",
      "        .   @param endAngle Ending angle of the elliptic arc in degrees.\n",
      "        .   @param color Ellipse color.\n",
      "        .   @param thickness Thickness of the ellipse arc outline, if positive. Otherwise, this indicates that\n",
      "        .   a filled ellipse sector is to be drawn.\n",
      "        .   @param lineType Type of the ellipse boundary. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the coordinates of the center and values of axes.\n",
      "        \n",
      "        \n",
      "        \n",
      "        ellipse(img, box, color[, thickness[, lineType]]) -> img\n",
      "        .   @overload\n",
      "        .   @param img Image.\n",
      "        .   @param box Alternative ellipse representation via RotatedRect. This means that the function draws\n",
      "        .   an ellipse inscribed in the rotated rectangle.\n",
      "        .   @param color Ellipse color.\n",
      "        .   @param thickness Thickness of the ellipse arc outline, if positive. Otherwise, this indicates that\n",
      "        .   a filled ellipse sector is to be drawn.\n",
      "        .   @param lineType Type of the ellipse boundary. See #LineTypes\n",
      "    \n",
      "    ellipse2Poly(...)\n",
      "        ellipse2Poly(center, axes, angle, arcStart, arcEnd, delta) -> pts\n",
      "        .   @brief Approximates an elliptic arc with a polyline.\n",
      "        .   \n",
      "        .   The function ellipse2Poly computes the vertices of a polyline that approximates the specified\n",
      "        .   elliptic arc. It is used by #ellipse. If `arcStart` is greater than `arcEnd`, they are swapped.\n",
      "        .   \n",
      "        .   @param center Center of the arc.\n",
      "        .   @param axes Half of the size of the ellipse main axes. See #ellipse for details.\n",
      "        .   @param angle Rotation angle of the ellipse in degrees. See #ellipse for details.\n",
      "        .   @param arcStart Starting angle of the elliptic arc in degrees.\n",
      "        .   @param arcEnd Ending angle of the elliptic arc in degrees.\n",
      "        .   @param delta Angle between the subsequent polyline vertices. It defines the approximation\n",
      "        .   accuracy.\n",
      "        .   @param pts Output vector of polyline vertices.\n",
      "    \n",
      "    equalizeHist(...)\n",
      "        equalizeHist(src[, dst]) -> dst\n",
      "        .   @brief Equalizes the histogram of a grayscale image.\n",
      "        .   \n",
      "        .   The function equalizes the histogram of the input image using the following algorithm:\n",
      "        .   \n",
      "        .   - Calculate the histogram \\f$H\\f$ for src .\n",
      "        .   - Normalize the histogram so that the sum of histogram bins is 255.\n",
      "        .   - Compute the integral of the histogram:\n",
      "        .   \\f[H'_i =  \\sum _{0  \\le j < i} H(j)\\f]\n",
      "        .   - Transform the image using \\f$H'\\f$ as a look-up table: \\f$\\texttt{dst}(x,y) = H'(\\texttt{src}(x,y))\\f$\n",
      "        .   \n",
      "        .   The algorithm normalizes the brightness and increases the contrast of the image.\n",
      "        .   \n",
      "        .   @param src Source 8-bit single channel image.\n",
      "        .   @param dst Destination image of the same size and type as src .\n",
      "    \n",
      "    erode(...)\n",
      "        erode(src, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
      "        .   @brief Erodes an image by using a specific structuring element.\n",
      "        .   \n",
      "        .   The function erodes the source image using the specified structuring element that determines the\n",
      "        .   shape of a pixel neighborhood over which the minimum is taken:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\min _{(x',y'):  \\, \\texttt{element} (x',y') \\ne0 } \\texttt{src} (x+x',y+y')\\f]\n",
      "        .   \n",
      "        .   The function supports the in-place mode. Erosion can be applied several ( iterations ) times. In\n",
      "        .   case of multi-channel images, each channel is processed independently.\n",
      "        .   \n",
      "        .   @param src input image; the number of channels can be arbitrary, but the depth should be one of\n",
      "        .   CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
      "        .   @param dst output image of the same size and type as src.\n",
      "        .   @param kernel structuring element used for erosion; if `element=Mat()`, a `3 x 3` rectangular\n",
      "        .   structuring element is used. Kernel can be created using #getStructuringElement.\n",
      "        .   @param anchor position of the anchor within the element; default value (-1, -1) means that the\n",
      "        .   anchor is at the element center.\n",
      "        .   @param iterations number of times erosion is applied.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes. #BORDER_WRAP is not supported.\n",
      "        .   @param borderValue border value in case of a constant border\n",
      "        .   @sa  dilate, morphologyEx, getStructuringElement\n",
      "    \n",
      "    estimateAffine2D(...)\n",
      "        estimateAffine2D(from, to[, inliers[, method[, ransacReprojThreshold[, maxIters[, confidence[, refineIters]]]]]]) -> retval, inliers\n",
      "        .   @brief Computes an optimal affine transformation between two 2D point sets.\n",
      "        .   \n",
      "        .   It computes\n",
      "        .   \\f[\n",
      "        .   \\begin{bmatrix}\n",
      "        .   x\\\\\n",
      "        .   y\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   =\n",
      "        .   \\begin{bmatrix}\n",
      "        .   a_{11} & a_{12}\\\\\n",
      "        .   a_{21} & a_{22}\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X\\\\\n",
      "        .   Y\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   +\n",
      "        .   \\begin{bmatrix}\n",
      "        .   b_1\\\\\n",
      "        .   b_2\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   @param from First input 2D point set containing \\f$(X,Y)\\f$.\n",
      "        .   @param to Second input 2D point set containing \\f$(x,y)\\f$.\n",
      "        .   @param inliers Output vector indicating which points are inliers (1-inlier, 0-outlier).\n",
      "        .   @param method Robust method used to compute transformation. The following methods are possible:\n",
      "        .   -   cv::RANSAC - RANSAC-based robust method\n",
      "        .   -   cv::LMEDS - Least-Median robust method\n",
      "        .   RANSAC is the default method.\n",
      "        .   @param ransacReprojThreshold Maximum reprojection error in the RANSAC algorithm to consider\n",
      "        .   a point as an inlier. Applies only to RANSAC.\n",
      "        .   @param maxIters The maximum number of robust method iterations.\n",
      "        .   @param confidence Confidence level, between 0 and 1, for the estimated transformation. Anything\n",
      "        .   between 0.95 and 0.99 is usually good enough. Values too close to 1 can slow down the estimation\n",
      "        .   significantly. Values lower than 0.8-0.9 can result in an incorrectly estimated transformation.\n",
      "        .   @param refineIters Maximum number of iterations of refining algorithm (Levenberg-Marquardt).\n",
      "        .   Passing 0 will disable refining, so the output matrix will be output of robust method.\n",
      "        .   \n",
      "        .   @return Output 2D affine transformation matrix \\f$2 \\times 3\\f$ or empty matrix if transformation\n",
      "        .   could not be estimated. The returned matrix has the following form:\n",
      "        .   \\f[\n",
      "        .   \\begin{bmatrix}\n",
      "        .   a_{11} & a_{12} & b_1\\\\\n",
      "        .   a_{21} & a_{22} & b_2\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   The function estimates an optimal 2D affine transformation between two 2D point sets using the\n",
      "        .   selected robust algorithm.\n",
      "        .   \n",
      "        .   The computed transformation is then refined further (using only inliers) with the\n",
      "        .   Levenberg-Marquardt method to reduce the re-projection error even more.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   The RANSAC method can handle practically any ratio of outliers but needs a threshold to\n",
      "        .   distinguish inliers from outliers. The method LMeDS does not need any threshold but it works\n",
      "        .   correctly only when there are more than 50% of inliers.\n",
      "        .   \n",
      "        .   @sa estimateAffinePartial2D, getAffineTransform\n",
      "    \n",
      "    estimateAffine3D(...)\n",
      "        estimateAffine3D(src, dst[, out[, inliers[, ransacThreshold[, confidence]]]]) -> retval, out, inliers\n",
      "        .   @brief Computes an optimal affine transformation between two 3D point sets.\n",
      "        .   \n",
      "        .   It computes\n",
      "        .   \\f[\n",
      "        .   \\begin{bmatrix}\n",
      "        .   x\\\\\n",
      "        .   y\\\\\n",
      "        .   z\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   =\n",
      "        .   \\begin{bmatrix}\n",
      "        .   a_{11} & a_{12} & a_{13}\\\\\n",
      "        .   a_{21} & a_{22} & a_{23}\\\\\n",
      "        .   a_{31} & a_{32} & a_{33}\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\begin{bmatrix}\n",
      "        .   X\\\\\n",
      "        .   Y\\\\\n",
      "        .   Z\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   +\n",
      "        .   \\begin{bmatrix}\n",
      "        .   b_1\\\\\n",
      "        .   b_2\\\\\n",
      "        .   b_3\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   @param src First input 3D point set containing \\f$(X,Y,Z)\\f$.\n",
      "        .   @param dst Second input 3D point set containing \\f$(x,y,z)\\f$.\n",
      "        .   @param out Output 3D affine transformation matrix \\f$3 \\times 4\\f$ of the form\n",
      "        .   \\f[\n",
      "        .   \\begin{bmatrix}\n",
      "        .   a_{11} & a_{12} & a_{13} & b_1\\\\\n",
      "        .   a_{21} & a_{22} & a_{23} & b_2\\\\\n",
      "        .   a_{31} & a_{32} & a_{33} & b_3\\\\\n",
      "        .   \\end{bmatrix}\n",
      "        .   \\f]\n",
      "        .   @param inliers Output vector indicating which points are inliers (1-inlier, 0-outlier).\n",
      "        .   @param ransacThreshold Maximum reprojection error in the RANSAC algorithm to consider a point as\n",
      "        .   an inlier.\n",
      "        .   @param confidence Confidence level, between 0 and 1, for the estimated transformation. Anything\n",
      "        .   between 0.95 and 0.99 is usually good enough. Values too close to 1 can slow down the estimation\n",
      "        .   significantly. Values lower than 0.8-0.9 can result in an incorrectly estimated transformation.\n",
      "        .   \n",
      "        .   The function estimates an optimal 3D affine transformation between two 3D point sets using the\n",
      "        .   RANSAC algorithm.\n",
      "    \n",
      "    estimateAffinePartial2D(...)\n",
      "        estimateAffinePartial2D(from, to[, inliers[, method[, ransacReprojThreshold[, maxIters[, confidence[, refineIters]]]]]]) -> retval, inliers\n",
      "        .   @brief Computes an optimal limited affine transformation with 4 degrees of freedom between\n",
      "        .   two 2D point sets.\n",
      "        .   \n",
      "        .   @param from First input 2D point set.\n",
      "        .   @param to Second input 2D point set.\n",
      "        .   @param inliers Output vector indicating which points are inliers.\n",
      "        .   @param method Robust method used to compute transformation. The following methods are possible:\n",
      "        .   -   cv::RANSAC - RANSAC-based robust method\n",
      "        .   -   cv::LMEDS - Least-Median robust method\n",
      "        .   RANSAC is the default method.\n",
      "        .   @param ransacReprojThreshold Maximum reprojection error in the RANSAC algorithm to consider\n",
      "        .   a point as an inlier. Applies only to RANSAC.\n",
      "        .   @param maxIters The maximum number of robust method iterations.\n",
      "        .   @param confidence Confidence level, between 0 and 1, for the estimated transformation. Anything\n",
      "        .   between 0.95 and 0.99 is usually good enough. Values too close to 1 can slow down the estimation\n",
      "        .   significantly. Values lower than 0.8-0.9 can result in an incorrectly estimated transformation.\n",
      "        .   @param refineIters Maximum number of iterations of refining algorithm (Levenberg-Marquardt).\n",
      "        .   Passing 0 will disable refining, so the output matrix will be output of robust method.\n",
      "        .   \n",
      "        .   @return Output 2D affine transformation (4 degrees of freedom) matrix \\f$2 \\times 3\\f$ or\n",
      "        .   empty matrix if transformation could not be estimated.\n",
      "        .   \n",
      "        .   The function estimates an optimal 2D affine transformation with 4 degrees of freedom limited to\n",
      "        .   combinations of translation, rotation, and uniform scaling. Uses the selected algorithm for robust\n",
      "        .   estimation.\n",
      "        .   \n",
      "        .   The computed transformation is then refined further (using only inliers) with the\n",
      "        .   Levenberg-Marquardt method to reduce the re-projection error even more.\n",
      "        .   \n",
      "        .   Estimated transformation matrix is:\n",
      "        .   \\f[ \\begin{bmatrix} \\cos(\\theta) \\cdot s & -\\sin(\\theta) \\cdot s & t_x \\\\\n",
      "        .                   \\sin(\\theta) \\cdot s & \\cos(\\theta) \\cdot s & t_y\n",
      "        .   \\end{bmatrix} \\f]\n",
      "        .   Where \\f$ \\theta \\f$ is the rotation angle, \\f$ s \\f$ the scaling factor and \\f$ t_x, t_y \\f$ are\n",
      "        .   translations in \\f$ x, y \\f$ axes respectively.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   The RANSAC method can handle practically any ratio of outliers but need a threshold to\n",
      "        .   distinguish inliers from outliers. The method LMeDS does not need any threshold but it works\n",
      "        .   correctly only when there are more than 50% of inliers.\n",
      "        .   \n",
      "        .   @sa estimateAffine2D, getAffineTransform\n",
      "    \n",
      "    estimateChessboardSharpness(...)\n",
      "        estimateChessboardSharpness(image, patternSize, corners[, rise_distance[, vertical[, sharpness]]]) -> retval, sharpness\n",
      "        .   @brief Estimates the sharpness of a detected chessboard.\n",
      "        .   \n",
      "        .   Image sharpness, as well as brightness, are a critical parameter for accuracte\n",
      "        .   camera calibration. For accessing these parameters for filtering out\n",
      "        .   problematic calibraiton images, this method calculates edge profiles by traveling from\n",
      "        .   black to white chessboard cell centers. Based on this, the number of pixels is\n",
      "        .   calculated required to transit from black to white. This width of the\n",
      "        .   transition area is a good indication of how sharp the chessboard is imaged\n",
      "        .   and should be below ~3.0 pixels.\n",
      "        .   \n",
      "        .   @param image Gray image used to find chessboard corners\n",
      "        .   @param patternSize Size of a found chessboard pattern\n",
      "        .   @param corners Corners found by findChessboardCorners(SB)\n",
      "        .   @param rise_distance Rise distance 0.8 means 10% ... 90% of the final signal strength\n",
      "        .   @param vertical By default edge responses for horizontal lines are calculated\n",
      "        .   @param sharpness Optional output array with a sharpness value for calculated edge responses (see description)\n",
      "        .   \n",
      "        .   The optional sharpness array is of type CV_32FC1 and has for each calculated\n",
      "        .   profile one row with the following five entries:\n",
      "        .   * 0 = x coordinate of the underlying edge in the image\n",
      "        .   * 1 = y coordinate of the underlying edge in the image\n",
      "        .   * 2 = width of the transition area (sharpness)\n",
      "        .   * 3 = signal strength in the black cell (min brightness)\n",
      "        .   * 4 = signal strength in the white cell (max brightness)\n",
      "        .   \n",
      "        .   @return Scalar(average sharpness, average min brightness, average max brightness,0)\n",
      "    \n",
      "    estimateTranslation3D(...)\n",
      "        estimateTranslation3D(src, dst[, out[, inliers[, ransacThreshold[, confidence]]]]) -> retval, out, inliers\n",
      "        .   @brief Computes an optimal translation between two 3D point sets.\n",
      "        .    *\n",
      "        .    * It computes\n",
      "        .    * \\f[\n",
      "        .    * \\begin{bmatrix}\n",
      "        .    * x\\\\\n",
      "        .    * y\\\\\n",
      "        .    * z\\\\\n",
      "        .    * \\end{bmatrix}\n",
      "        .    * =\n",
      "        .    * \\begin{bmatrix}\n",
      "        .    * X\\\\\n",
      "        .    * Y\\\\\n",
      "        .    * Z\\\\\n",
      "        .    * \\end{bmatrix}\n",
      "        .    * +\n",
      "        .    * \\begin{bmatrix}\n",
      "        .    * b_1\\\\\n",
      "        .    * b_2\\\\\n",
      "        .    * b_3\\\\\n",
      "        .    * \\end{bmatrix}\n",
      "        .    * \\f]\n",
      "        .    *\n",
      "        .    * @param src First input 3D point set containing \\f$(X,Y,Z)\\f$.\n",
      "        .    * @param dst Second input 3D point set containing \\f$(x,y,z)\\f$.\n",
      "        .    * @param out Output 3D translation vector \\f$3 \\times 1\\f$ of the form\n",
      "        .    * \\f[\n",
      "        .    * \\begin{bmatrix}\n",
      "        .    * b_1 \\\\\n",
      "        .    * b_2 \\\\\n",
      "        .    * b_3 \\\\\n",
      "        .    * \\end{bmatrix}\n",
      "        .    * \\f]\n",
      "        .    * @param inliers Output vector indicating which points are inliers (1-inlier, 0-outlier).\n",
      "        .    * @param ransacThreshold Maximum reprojection error in the RANSAC algorithm to consider a point as\n",
      "        .    * an inlier.\n",
      "        .    * @param confidence Confidence level, between 0 and 1, for the estimated transformation. Anything\n",
      "        .    * between 0.95 and 0.99 is usually good enough. Values too close to 1 can slow down the estimation\n",
      "        .    * significantly. Values lower than 0.8-0.9 can result in an incorrectly estimated transformation.\n",
      "        .    *\n",
      "        .    * The function estimates an optimal 3D translation between two 3D point sets using the\n",
      "        .    * RANSAC algorithm.\n",
      "        .   *\n",
      "    \n",
      "    exp(...)\n",
      "        exp(src[, dst]) -> dst\n",
      "        .   @brief Calculates the exponent of every array element.\n",
      "        .   \n",
      "        .   The function cv::exp calculates the exponent of every element of the input\n",
      "        .   array:\n",
      "        .   \\f[\\texttt{dst} [I] = e^{ src(I) }\\f]\n",
      "        .   \n",
      "        .   The maximum relative error is about 7e-6 for single-precision input and\n",
      "        .   less than 1e-10 for double-precision input. Currently, the function\n",
      "        .   converts denormalized values to zeros on output. Special values (NaN,\n",
      "        .   Inf) are not handled.\n",
      "        .   @param src input array.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "        .   @sa log , cartToPolar , polarToCart , phase , pow , sqrt , magnitude\n",
      "    \n",
      "    extractChannel(...)\n",
      "        extractChannel(src, coi[, dst]) -> dst\n",
      "        .   @brief Extracts a single channel from src (coi is 0-based index)\n",
      "        .   @param src input array\n",
      "        .   @param dst output array\n",
      "        .   @param coi index of channel to extract\n",
      "        .   @sa mixChannels, split\n",
      "    \n",
      "    fastAtan2(...)\n",
      "        fastAtan2(y, x) -> retval\n",
      "        .   @brief Calculates the angle of a 2D vector in degrees.\n",
      "        .   \n",
      "        .    The function fastAtan2 calculates the full-range angle of an input 2D vector. The angle is measured\n",
      "        .    in degrees and varies from 0 to 360 degrees. The accuracy is about 0.3 degrees.\n",
      "        .    @param x x-coordinate of the vector.\n",
      "        .    @param y y-coordinate of the vector.\n",
      "    \n",
      "    fastNlMeansDenoising(...)\n",
      "        fastNlMeansDenoising(src[, dst[, h[, templateWindowSize[, searchWindowSize]]]]) -> dst\n",
      "        .   @brief Perform image denoising using Non-local Means Denoising algorithm\n",
      "        .   <http://www.ipol.im/pub/algo/bcm_non_local_means_denoising/> with several computational\n",
      "        .   optimizations. Noise expected to be a gaussian white noise\n",
      "        .   \n",
      "        .   @param src Input 8-bit 1-channel, 2-channel, 3-channel or 4-channel image.\n",
      "        .   @param dst Output image with the same size and type as src .\n",
      "        .   @param templateWindowSize Size in pixels of the template patch that is used to compute weights.\n",
      "        .   Should be odd. Recommended value 7 pixels\n",
      "        .   @param searchWindowSize Size in pixels of the window that is used to compute weighted average for\n",
      "        .   given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater\n",
      "        .   denoising time. Recommended value 21 pixels\n",
      "        .   @param h Parameter regulating filter strength. Big h value perfectly removes noise but also\n",
      "        .   removes image details, smaller h value preserves details but also preserves some noise\n",
      "        .   \n",
      "        .   This function expected to be applied to grayscale images. For colored images look at\n",
      "        .   fastNlMeansDenoisingColored. Advanced usage of this functions can be manual denoising of colored\n",
      "        .   image in different colorspaces. Such approach is used in fastNlMeansDenoisingColored by converting\n",
      "        .   image to CIELAB colorspace and then separately denoise L and AB components with different h\n",
      "        .   parameter.\n",
      "        \n",
      "        \n",
      "        \n",
      "        fastNlMeansDenoising(src, h[, dst[, templateWindowSize[, searchWindowSize[, normType]]]]) -> dst\n",
      "        .   @brief Perform image denoising using Non-local Means Denoising algorithm\n",
      "        .   <http://www.ipol.im/pub/algo/bcm_non_local_means_denoising/> with several computational\n",
      "        .   optimizations. Noise expected to be a gaussian white noise\n",
      "        .   \n",
      "        .   @param src Input 8-bit or 16-bit (only with NORM_L1) 1-channel,\n",
      "        .   2-channel, 3-channel or 4-channel image.\n",
      "        .   @param dst Output image with the same size and type as src .\n",
      "        .   @param templateWindowSize Size in pixels of the template patch that is used to compute weights.\n",
      "        .   Should be odd. Recommended value 7 pixels\n",
      "        .   @param searchWindowSize Size in pixels of the window that is used to compute weighted average for\n",
      "        .   given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater\n",
      "        .   denoising time. Recommended value 21 pixels\n",
      "        .   @param h Array of parameters regulating filter strength, either one\n",
      "        .   parameter applied to all channels or one per channel in dst. Big h value\n",
      "        .   perfectly removes noise but also removes image details, smaller h\n",
      "        .   value preserves details but also preserves some noise\n",
      "        .   @param normType Type of norm used for weight calculation. Can be either NORM_L2 or NORM_L1\n",
      "        .   \n",
      "        .   This function expected to be applied to grayscale images. For colored images look at\n",
      "        .   fastNlMeansDenoisingColored. Advanced usage of this functions can be manual denoising of colored\n",
      "        .   image in different colorspaces. Such approach is used in fastNlMeansDenoisingColored by converting\n",
      "        .   image to CIELAB colorspace and then separately denoise L and AB components with different h\n",
      "        .   parameter.\n",
      "    \n",
      "    fastNlMeansDenoisingColored(...)\n",
      "        fastNlMeansDenoisingColored(src[, dst[, h[, hColor[, templateWindowSize[, searchWindowSize]]]]]) -> dst\n",
      "        .   @brief Modification of fastNlMeansDenoising function for colored images\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param dst Output image with the same size and type as src .\n",
      "        .   @param templateWindowSize Size in pixels of the template patch that is used to compute weights.\n",
      "        .   Should be odd. Recommended value 7 pixels\n",
      "        .   @param searchWindowSize Size in pixels of the window that is used to compute weighted average for\n",
      "        .   given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater\n",
      "        .   denoising time. Recommended value 21 pixels\n",
      "        .   @param h Parameter regulating filter strength for luminance component. Bigger h value perfectly\n",
      "        .   removes noise but also removes image details, smaller h value preserves details but also preserves\n",
      "        .   some noise\n",
      "        .   @param hColor The same as h but for color components. For most images value equals 10\n",
      "        .   will be enough to remove colored noise and do not distort colors\n",
      "        .   \n",
      "        .   The function converts image to CIELAB colorspace and then separately denoise L and AB components\n",
      "        .   with given h parameters using fastNlMeansDenoising function.\n",
      "    \n",
      "    fastNlMeansDenoisingColoredMulti(...)\n",
      "        fastNlMeansDenoisingColoredMulti(srcImgs, imgToDenoiseIndex, temporalWindowSize[, dst[, h[, hColor[, templateWindowSize[, searchWindowSize]]]]]) -> dst\n",
      "        .   @brief Modification of fastNlMeansDenoisingMulti function for colored images sequences\n",
      "        .   \n",
      "        .   @param srcImgs Input 8-bit 3-channel images sequence. All images should have the same type and\n",
      "        .   size.\n",
      "        .   @param imgToDenoiseIndex Target image to denoise index in srcImgs sequence\n",
      "        .   @param temporalWindowSize Number of surrounding images to use for target image denoising. Should\n",
      "        .   be odd. Images from imgToDenoiseIndex - temporalWindowSize / 2 to\n",
      "        .   imgToDenoiseIndex - temporalWindowSize / 2 from srcImgs will be used to denoise\n",
      "        .   srcImgs[imgToDenoiseIndex] image.\n",
      "        .   @param dst Output image with the same size and type as srcImgs images.\n",
      "        .   @param templateWindowSize Size in pixels of the template patch that is used to compute weights.\n",
      "        .   Should be odd. Recommended value 7 pixels\n",
      "        .   @param searchWindowSize Size in pixels of the window that is used to compute weighted average for\n",
      "        .   given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater\n",
      "        .   denoising time. Recommended value 21 pixels\n",
      "        .   @param h Parameter regulating filter strength for luminance component. Bigger h value perfectly\n",
      "        .   removes noise but also removes image details, smaller h value preserves details but also preserves\n",
      "        .   some noise.\n",
      "        .   @param hColor The same as h but for color components.\n",
      "        .   \n",
      "        .   The function converts images to CIELAB colorspace and then separately denoise L and AB components\n",
      "        .   with given h parameters using fastNlMeansDenoisingMulti function.\n",
      "    \n",
      "    fastNlMeansDenoisingMulti(...)\n",
      "        fastNlMeansDenoisingMulti(srcImgs, imgToDenoiseIndex, temporalWindowSize[, dst[, h[, templateWindowSize[, searchWindowSize]]]]) -> dst\n",
      "        .   @brief Modification of fastNlMeansDenoising function for images sequence where consecutive images have been\n",
      "        .   captured in small period of time. For example video. This version of the function is for grayscale\n",
      "        .   images or for manual manipulation with colorspaces. For more details see\n",
      "        .   <http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.131.6394>\n",
      "        .   \n",
      "        .   @param srcImgs Input 8-bit 1-channel, 2-channel, 3-channel or\n",
      "        .   4-channel images sequence. All images should have the same type and\n",
      "        .   size.\n",
      "        .   @param imgToDenoiseIndex Target image to denoise index in srcImgs sequence\n",
      "        .   @param temporalWindowSize Number of surrounding images to use for target image denoising. Should\n",
      "        .   be odd. Images from imgToDenoiseIndex - temporalWindowSize / 2 to\n",
      "        .   imgToDenoiseIndex - temporalWindowSize / 2 from srcImgs will be used to denoise\n",
      "        .   srcImgs[imgToDenoiseIndex] image.\n",
      "        .   @param dst Output image with the same size and type as srcImgs images.\n",
      "        .   @param templateWindowSize Size in pixels of the template patch that is used to compute weights.\n",
      "        .   Should be odd. Recommended value 7 pixels\n",
      "        .   @param searchWindowSize Size in pixels of the window that is used to compute weighted average for\n",
      "        .   given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater\n",
      "        .   denoising time. Recommended value 21 pixels\n",
      "        .   @param h Parameter regulating filter strength. Bigger h value\n",
      "        .   perfectly removes noise but also removes image details, smaller h\n",
      "        .   value preserves details but also preserves some noise\n",
      "        \n",
      "        \n",
      "        \n",
      "        fastNlMeansDenoisingMulti(srcImgs, imgToDenoiseIndex, temporalWindowSize, h[, dst[, templateWindowSize[, searchWindowSize[, normType]]]]) -> dst\n",
      "        .   @brief Modification of fastNlMeansDenoising function for images sequence where consecutive images have been\n",
      "        .   captured in small period of time. For example video. This version of the function is for grayscale\n",
      "        .   images or for manual manipulation with colorspaces. For more details see\n",
      "        .   <http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.131.6394>\n",
      "        .   \n",
      "        .   @param srcImgs Input 8-bit or 16-bit (only with NORM_L1) 1-channel,\n",
      "        .   2-channel, 3-channel or 4-channel images sequence. All images should\n",
      "        .   have the same type and size.\n",
      "        .   @param imgToDenoiseIndex Target image to denoise index in srcImgs sequence\n",
      "        .   @param temporalWindowSize Number of surrounding images to use for target image denoising. Should\n",
      "        .   be odd. Images from imgToDenoiseIndex - temporalWindowSize / 2 to\n",
      "        .   imgToDenoiseIndex - temporalWindowSize / 2 from srcImgs will be used to denoise\n",
      "        .   srcImgs[imgToDenoiseIndex] image.\n",
      "        .   @param dst Output image with the same size and type as srcImgs images.\n",
      "        .   @param templateWindowSize Size in pixels of the template patch that is used to compute weights.\n",
      "        .   Should be odd. Recommended value 7 pixels\n",
      "        .   @param searchWindowSize Size in pixels of the window that is used to compute weighted average for\n",
      "        .   given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater\n",
      "        .   denoising time. Recommended value 21 pixels\n",
      "        .   @param h Array of parameters regulating filter strength, either one\n",
      "        .   parameter applied to all channels or one per channel in dst. Big h value\n",
      "        .   perfectly removes noise but also removes image details, smaller h\n",
      "        .   value preserves details but also preserves some noise\n",
      "        .   @param normType Type of norm used for weight calculation. Can be either NORM_L2 or NORM_L1\n",
      "    \n",
      "    fillConvexPoly(...)\n",
      "        fillConvexPoly(img, points, color[, lineType[, shift]]) -> img\n",
      "        .   @brief Fills a convex polygon.\n",
      "        .   \n",
      "        .   The function cv::fillConvexPoly draws a filled convex polygon. This function is much faster than the\n",
      "        .   function #fillPoly . It can fill not only convex polygons but any monotonic polygon without\n",
      "        .   self-intersections, that is, a polygon whose contour intersects every horizontal line (scan line)\n",
      "        .   twice at the most (though, its top-most and/or the bottom edge could be horizontal).\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param points Polygon vertices.\n",
      "        .   @param color Polygon color.\n",
      "        .   @param lineType Type of the polygon boundaries. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the vertex coordinates.\n",
      "    \n",
      "    fillPoly(...)\n",
      "        fillPoly(img, pts, color[, lineType[, shift[, offset]]]) -> img\n",
      "        .   @brief Fills the area bounded by one or more polygons.\n",
      "        .   \n",
      "        .   The function cv::fillPoly fills an area bounded by several polygonal contours. The function can fill\n",
      "        .   complex areas, for example, areas with holes, contours with self-intersections (some of their\n",
      "        .   parts), and so forth.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param pts Array of polygons where each polygon is represented as an array of points.\n",
      "        .   @param color Polygon color.\n",
      "        .   @param lineType Type of the polygon boundaries. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the vertex coordinates.\n",
      "        .   @param offset Optional offset of all points of the contours.\n",
      "    \n",
      "    filter2D(...)\n",
      "        filter2D(src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]]) -> dst\n",
      "        .   @brief Convolves an image with the kernel.\n",
      "        .   \n",
      "        .   The function applies an arbitrary linear filter to an image. In-place operation is supported. When\n",
      "        .   the aperture is partially outside the image, the function interpolates outlier pixel values\n",
      "        .   according to the specified border mode.\n",
      "        .   \n",
      "        .   The function does actually compute correlation, not the convolution:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\sum _{ \\substack{0\\leq x' < \\texttt{kernel.cols}\\\\{0\\leq y' < \\texttt{kernel.rows}}}}  \\texttt{kernel} (x',y')* \\texttt{src} (x+x'- \\texttt{anchor.x} ,y+y'- \\texttt{anchor.y} )\\f]\n",
      "        .   \n",
      "        .   That is, the kernel is not mirrored around the anchor point. If you need a real convolution, flip\n",
      "        .   the kernel using #flip and set the new anchor to `(kernel.cols - anchor.x - 1, kernel.rows -\n",
      "        .   anchor.y - 1)`.\n",
      "        .   \n",
      "        .   The function uses the DFT-based algorithm in case of sufficiently large kernels (~`11 x 11` or\n",
      "        .   larger) and the direct algorithm for small kernels.\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image of the same size and the same number of channels as src.\n",
      "        .   @param ddepth desired depth of the destination image, see @ref filter_depths \"combinations\"\n",
      "        .   @param kernel convolution kernel (or rather a correlation kernel), a single-channel floating point\n",
      "        .   matrix; if you want to apply different kernels to different channels, split the image into\n",
      "        .   separate color planes using split and process them individually.\n",
      "        .   @param anchor anchor of the kernel that indicates the relative position of a filtered point within\n",
      "        .   the kernel; the anchor should lie within the kernel; default value (-1,-1) means that the anchor\n",
      "        .   is at the kernel center.\n",
      "        .   @param delta optional value added to the filtered pixels before storing them in dst.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes. #BORDER_WRAP is not supported.\n",
      "        .   @sa  sepFilter2D, dft, matchTemplate\n",
      "    \n",
      "    filterHomographyDecompByVisibleRefpoints(...)\n",
      "        filterHomographyDecompByVisibleRefpoints(rotations, normals, beforePoints, afterPoints[, possibleSolutions[, pointsMask]]) -> possibleSolutions\n",
      "        .   @brief Filters homography decompositions based on additional information.\n",
      "        .   \n",
      "        .   @param rotations Vector of rotation matrices.\n",
      "        .   @param normals Vector of plane normal matrices.\n",
      "        .   @param beforePoints Vector of (rectified) visible reference points before the homography is applied\n",
      "        .   @param afterPoints Vector of (rectified) visible reference points after the homography is applied\n",
      "        .   @param possibleSolutions Vector of int indices representing the viable solution set after filtering\n",
      "        .   @param pointsMask optional Mat/Vector of 8u type representing the mask for the inliers as given by the findHomography function\n",
      "        .   \n",
      "        .   This function is intended to filter the output of the decomposeHomographyMat based on additional\n",
      "        .   information as described in @cite Malis . The summary of the method: the decomposeHomographyMat function\n",
      "        .   returns 2 unique solutions and their \"opposites\" for a total of 4 solutions. If we have access to the\n",
      "        .   sets of points visible in the camera frame before and after the homography transformation is applied,\n",
      "        .   we can determine which are the true potential solutions and which are the opposites by verifying which\n",
      "        .   homographies are consistent with all visible reference points being in front of the camera. The inputs\n",
      "        .   are left unchanged; the filtered solution set is returned as indices into the existing one.\n",
      "    \n",
      "    filterSpeckles(...)\n",
      "        filterSpeckles(img, newVal, maxSpeckleSize, maxDiff[, buf]) -> img, buf\n",
      "        .   @brief Filters off small noise blobs (speckles) in the disparity map\n",
      "        .   \n",
      "        .   @param img The input 16-bit signed disparity image\n",
      "        .   @param newVal The disparity value used to paint-off the speckles\n",
      "        .   @param maxSpeckleSize The maximum speckle size to consider it a speckle. Larger blobs are not\n",
      "        .   affected by the algorithm\n",
      "        .   @param maxDiff Maximum difference between neighbor disparity pixels to put them into the same\n",
      "        .   blob. Note that since StereoBM, StereoSGBM and may be other algorithms return a fixed-point\n",
      "        .   disparity map, where disparity values are multiplied by 16, this scale factor should be taken into\n",
      "        .   account when specifying this parameter value.\n",
      "        .   @param buf The optional temporary buffer to avoid memory allocation within the function.\n",
      "    \n",
      "    find4QuadCornerSubpix(...)\n",
      "        find4QuadCornerSubpix(img, corners, region_size) -> retval, corners\n",
      "        .\n",
      "    \n",
      "    findChessboardCorners(...)\n",
      "        findChessboardCorners(image, patternSize[, corners[, flags]]) -> retval, corners\n",
      "        .   @brief Finds the positions of internal corners of the chessboard.\n",
      "        .   \n",
      "        .   @param image Source chessboard view. It must be an 8-bit grayscale or color image.\n",
      "        .   @param patternSize Number of inner corners per a chessboard row and column\n",
      "        .   ( patternSize = cv::Size(points_per_row,points_per_colum) = cv::Size(columns,rows) ).\n",
      "        .   @param corners Output array of detected corners.\n",
      "        .   @param flags Various operation flags that can be zero or a combination of the following values:\n",
      "        .   -   **CALIB_CB_ADAPTIVE_THRESH** Use adaptive thresholding to convert the image to black\n",
      "        .   and white, rather than a fixed threshold level (computed from the average image brightness).\n",
      "        .   -   **CALIB_CB_NORMALIZE_IMAGE** Normalize the image gamma with equalizeHist before\n",
      "        .   applying fixed or adaptive thresholding.\n",
      "        .   -   **CALIB_CB_FILTER_QUADS** Use additional criteria (like contour area, perimeter,\n",
      "        .   square-like shape) to filter out false quads extracted at the contour retrieval stage.\n",
      "        .   -   **CALIB_CB_FAST_CHECK** Run a fast check on the image that looks for chessboard corners,\n",
      "        .   and shortcut the call if none is found. This can drastically speed up the call in the\n",
      "        .   degenerate condition when no chessboard is observed.\n",
      "        .   \n",
      "        .   The function attempts to determine whether the input image is a view of the chessboard pattern and\n",
      "        .   locate the internal chessboard corners. The function returns a non-zero value if all of the corners\n",
      "        .   are found and they are placed in a certain order (row by row, left to right in every row).\n",
      "        .   Otherwise, if the function fails to find all the corners or reorder them, it returns 0. For example,\n",
      "        .   a regular chessboard has 8 x 8 squares and 7 x 7 internal corners, that is, points where the black\n",
      "        .   squares touch each other. The detected coordinates are approximate, and to determine their positions\n",
      "        .   more accurately, the function calls cornerSubPix. You also may use the function cornerSubPix with\n",
      "        .   different parameters if returned coordinates are not accurate enough.\n",
      "        .   \n",
      "        .   Sample usage of detecting and drawing chessboard corners: :\n",
      "        .   @code\n",
      "        .       Size patternsize(8,6); //interior number of corners\n",
      "        .       Mat gray = ....; //source image\n",
      "        .       vector<Point2f> corners; //this will be filled by the detected corners\n",
      "        .   \n",
      "        .       //CALIB_CB_FAST_CHECK saves a lot of time on images\n",
      "        .       //that do not contain any chessboard corners\n",
      "        .       bool patternfound = findChessboardCorners(gray, patternsize, corners,\n",
      "        .               CALIB_CB_ADAPTIVE_THRESH + CALIB_CB_NORMALIZE_IMAGE\n",
      "        .               + CALIB_CB_FAST_CHECK);\n",
      "        .   \n",
      "        .       if(patternfound)\n",
      "        .         cornerSubPix(gray, corners, Size(11, 11), Size(-1, -1),\n",
      "        .           TermCriteria(CV_TERMCRIT_EPS + CV_TERMCRIT_ITER, 30, 0.1));\n",
      "        .   \n",
      "        .       drawChessboardCorners(img, patternsize, Mat(corners), patternfound);\n",
      "        .   @endcode\n",
      "        .   @note The function requires white space (like a square-thick border, the wider the better) around\n",
      "        .   the board to make the detection more robust in various environments. Otherwise, if there is no\n",
      "        .   border and the background is dark, the outer black squares cannot be segmented properly and so the\n",
      "        .   square grouping and ordering algorithm fails.\n",
      "    \n",
      "    findChessboardCornersSB(...)\n",
      "        findChessboardCornersSB(image, patternSize[, corners[, flags]]) -> retval, corners\n",
      "        .   @overload\n",
      "    \n",
      "    findChessboardCornersSBWithMeta(...)\n",
      "        findChessboardCornersSBWithMeta(image, patternSize, flags[, corners[, meta]]) -> retval, corners, meta\n",
      "        .   @brief Finds the positions of internal corners of the chessboard using a sector based approach.\n",
      "        .   \n",
      "        .   @param image Source chessboard view. It must be an 8-bit grayscale or color image.\n",
      "        .   @param patternSize Number of inner corners per a chessboard row and column\n",
      "        .   ( patternSize = cv::Size(points_per_row,points_per_colum) = cv::Size(columns,rows) ).\n",
      "        .   @param corners Output array of detected corners.\n",
      "        .   @param flags Various operation flags that can be zero or a combination of the following values:\n",
      "        .   -   **CALIB_CB_NORMALIZE_IMAGE** Normalize the image gamma with equalizeHist before detection.\n",
      "        .   -   **CALIB_CB_EXHAUSTIVE** Run an exhaustive search to improve detection rate.\n",
      "        .   -   **CALIB_CB_ACCURACY** Up sample input image to improve sub-pixel accuracy due to aliasing effects.\n",
      "        .   -   **CALIB_CB_LARGER** The detected pattern is allowed to be larger than patternSize (see description).\n",
      "        .   -   **CALIB_CB_MARKER** The detected pattern must have a marker (see description).\n",
      "        .   This should be used if an accurate camera calibration is required.\n",
      "        .   @param meta Optional output arrray of detected corners (CV_8UC1 and size = cv::Size(columns,rows)).\n",
      "        .   Each entry stands for one corner of the pattern and can have one of the following values:\n",
      "        .   -   0 = no meta data attached\n",
      "        .   -   1 = left-top corner of a black cell\n",
      "        .   -   2 = left-top corner of a white cell\n",
      "        .   -   3 = left-top corner of a black cell with a white marker dot\n",
      "        .   -   4 = left-top corner of a white cell with a black marker dot (pattern origin in case of markers otherwise first corner)\n",
      "        .   \n",
      "        .   The function is analog to findchessboardCorners but uses a localized radon\n",
      "        .   transformation approximated by box filters being more robust to all sort of\n",
      "        .   noise, faster on larger images and is able to directly return the sub-pixel\n",
      "        .   position of the internal chessboard corners. The Method is based on the paper\n",
      "        .   @cite duda2018 \"Accurate Detection and Localization of Checkerboard Corners for\n",
      "        .   Calibration\" demonstrating that the returned sub-pixel positions are more\n",
      "        .   accurate than the one returned by cornerSubPix allowing a precise camera\n",
      "        .   calibration for demanding applications.\n",
      "        .   \n",
      "        .   In the case, the flags **CALIB_CB_LARGER** or **CALIB_CB_MARKER** are given,\n",
      "        .   the result can be recovered from the optional meta array. Both flags are\n",
      "        .   helpful to use calibration patterns exceeding the field of view of the camera.\n",
      "        .   These oversized patterns allow more accurate calibrations as corners can be\n",
      "        .   utilized, which are as close as possible to the image borders.  For a\n",
      "        .   consistent coordinate system across all images, the optional marker (see image\n",
      "        .   below) can be used to move the origin of the board to the location where the\n",
      "        .   black circle is located.\n",
      "        .   \n",
      "        .   @note The function requires a white boarder with roughly the same width as one\n",
      "        .   of the checkerboard fields around the whole board to improve the detection in\n",
      "        .   various environments. In addition, because of the localized radon\n",
      "        .   transformation it is beneficial to use round corners for the field corners\n",
      "        .   which are located on the outside of the board. The following figure illustrates\n",
      "        .   a sample checkerboard optimized for the detection. However, any other checkerboard\n",
      "        .   can be used as well.\n",
      "        .   ![Checkerboard](pics/checkerboard_radon.png)\n",
      "    \n",
      "    findCirclesGrid(...)\n",
      "        findCirclesGrid(image, patternSize, flags, blobDetector, parameters[, centers]) -> retval, centers\n",
      "        .   @brief Finds centers in the grid of circles.\n",
      "        .   \n",
      "        .   @param image grid view of input circles; it must be an 8-bit grayscale or color image.\n",
      "        .   @param patternSize number of circles per row and column\n",
      "        .   ( patternSize = Size(points_per_row, points_per_colum) ).\n",
      "        .   @param centers output array of detected centers.\n",
      "        .   @param flags various operation flags that can be one of the following values:\n",
      "        .   -   **CALIB_CB_SYMMETRIC_GRID** uses symmetric pattern of circles.\n",
      "        .   -   **CALIB_CB_ASYMMETRIC_GRID** uses asymmetric pattern of circles.\n",
      "        .   -   **CALIB_CB_CLUSTERING** uses a special algorithm for grid detection. It is more robust to\n",
      "        .   perspective distortions but much more sensitive to background clutter.\n",
      "        .   @param blobDetector feature detector that finds blobs like dark circles on light background.\n",
      "        .   @param parameters struct for finding circles in a grid pattern.\n",
      "        .   \n",
      "        .   The function attempts to determine whether the input image contains a grid of circles. If it is, the\n",
      "        .   function locates centers of the circles. The function returns a non-zero value if all of the centers\n",
      "        .   have been found and they have been placed in a certain order (row by row, left to right in every\n",
      "        .   row). Otherwise, if the function fails to find all the corners or reorder them, it returns 0.\n",
      "        .   \n",
      "        .   Sample usage of detecting and drawing the centers of circles: :\n",
      "        .   @code\n",
      "        .       Size patternsize(7,7); //number of centers\n",
      "        .       Mat gray = ....; //source image\n",
      "        .       vector<Point2f> centers; //this will be filled by the detected centers\n",
      "        .   \n",
      "        .       bool patternfound = findCirclesGrid(gray, patternsize, centers);\n",
      "        .   \n",
      "        .       drawChessboardCorners(img, patternsize, Mat(centers), patternfound);\n",
      "        .   @endcode\n",
      "        .   @note The function requires white space (like a square-thick border, the wider the better) around\n",
      "        .   the board to make the detection more robust in various environments.\n",
      "        \n",
      "        \n",
      "        \n",
      "        findCirclesGrid(image, patternSize[, centers[, flags[, blobDetector]]]) -> retval, centers\n",
      "        .   @overload\n",
      "    \n",
      "    findContours(...)\n",
      "        findContours(image, mode, method[, contours[, hierarchy[, offset]]]) -> contours, hierarchy\n",
      "        .   @brief Finds contours in a binary image.\n",
      "        .   \n",
      "        .   The function retrieves contours from the binary image using the algorithm @cite Suzuki85 . The contours\n",
      "        .   are a useful tool for shape analysis and object detection and recognition. See squares.cpp in the\n",
      "        .   OpenCV sample directory.\n",
      "        .   @note Since opencv 3.2 source image is not modified by this function.\n",
      "        .   \n",
      "        .   @param image Source, an 8-bit single-channel image. Non-zero pixels are treated as 1's. Zero\n",
      "        .   pixels remain 0's, so the image is treated as binary . You can use #compare, #inRange, #threshold ,\n",
      "        .   #adaptiveThreshold, #Canny, and others to create a binary image out of a grayscale or color one.\n",
      "        .   If mode equals to #RETR_CCOMP or #RETR_FLOODFILL, the input can also be a 32-bit integer image of labels (CV_32SC1).\n",
      "        .   @param contours Detected contours. Each contour is stored as a vector of points (e.g.\n",
      "        .   std::vector<std::vector<cv::Point> >).\n",
      "        .   @param hierarchy Optional output vector (e.g. std::vector<cv::Vec4i>), containing information about the image topology. It has\n",
      "        .   as many elements as the number of contours. For each i-th contour contours[i], the elements\n",
      "        .   hierarchy[i][0] , hierarchy[i][1] , hierarchy[i][2] , and hierarchy[i][3] are set to 0-based indices\n",
      "        .   in contours of the next and previous contours at the same hierarchical level, the first child\n",
      "        .   contour and the parent contour, respectively. If for the contour i there are no next, previous,\n",
      "        .   parent, or nested contours, the corresponding elements of hierarchy[i] will be negative.\n",
      "        .   @param mode Contour retrieval mode, see #RetrievalModes\n",
      "        .   @param method Contour approximation method, see #ContourApproximationModes\n",
      "        .   @param offset Optional offset by which every contour point is shifted. This is useful if the\n",
      "        .   contours are extracted from the image ROI and then they should be analyzed in the whole image\n",
      "        .   context.\n",
      "    \n",
      "    findEssentialMat(...)\n",
      "        findEssentialMat(points1, points2, cameraMatrix[, method[, prob[, threshold[, mask]]]]) -> retval, mask\n",
      "        .   @brief Calculates an essential matrix from the corresponding points in two images.\n",
      "        .   \n",
      "        .   @param points1 Array of N (N \\>= 5) 2D points from the first image. The point coordinates should\n",
      "        .   be floating-point (single or double precision).\n",
      "        .   @param points2 Array of the second image points of the same size and format as points1 .\n",
      "        .   @param cameraMatrix Camera matrix \\f$K = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   Note that this function assumes that points1 and points2 are feature points from cameras with the\n",
      "        .   same camera matrix. If this assumption does not hold for your use case, use\n",
      "        .   `undistortPoints()` with `P = cv::NoArray()` for both cameras to transform image points\n",
      "        .   to normalized image coordinates, which are valid for the identity camera matrix. When\n",
      "        .   passing these coordinates, pass the identity matrix for this parameter.\n",
      "        .   @param method Method for computing an essential matrix.\n",
      "        .   -   **RANSAC** for the RANSAC algorithm.\n",
      "        .   -   **LMEDS** for the LMedS algorithm.\n",
      "        .   @param prob Parameter used for the RANSAC or LMedS methods only. It specifies a desirable level of\n",
      "        .   confidence (probability) that the estimated matrix is correct.\n",
      "        .   @param threshold Parameter used for RANSAC. It is the maximum distance from a point to an epipolar\n",
      "        .   line in pixels, beyond which the point is considered an outlier and is not used for computing the\n",
      "        .   final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the\n",
      "        .   point localization, image resolution, and the image noise.\n",
      "        .   @param mask Output array of N elements, every element of which is set to 0 for outliers and to 1\n",
      "        .   for the other points. The array is computed only in the RANSAC and LMedS methods.\n",
      "        .   \n",
      "        .   This function estimates essential matrix based on the five-point algorithm solver in @cite Nister03 .\n",
      "        .   @cite SteweniusCFS is also a related. The epipolar geometry is described by the following equation:\n",
      "        .   \n",
      "        .   \\f[[p_2; 1]^T K^{-T} E K^{-1} [p_1; 1] = 0\\f]\n",
      "        .   \n",
      "        .   where \\f$E\\f$ is an essential matrix, \\f$p_1\\f$ and \\f$p_2\\f$ are corresponding points in the first and the\n",
      "        .   second images, respectively. The result of this function may be passed further to\n",
      "        .   decomposeEssentialMat or recoverPose to recover the relative pose between cameras.\n",
      "        \n",
      "        \n",
      "        \n",
      "        findEssentialMat(points1, points2[, focal[, pp[, method[, prob[, threshold[, mask]]]]]]) -> retval, mask\n",
      "        .   @overload\n",
      "        .   @param points1 Array of N (N \\>= 5) 2D points from the first image. The point coordinates should\n",
      "        .   be floating-point (single or double precision).\n",
      "        .   @param points2 Array of the second image points of the same size and format as points1 .\n",
      "        .   @param focal focal length of the camera. Note that this function assumes that points1 and points2\n",
      "        .   are feature points from cameras with same focal length and principal point.\n",
      "        .   @param pp principal point of the camera.\n",
      "        .   @param method Method for computing a fundamental matrix.\n",
      "        .   -   **RANSAC** for the RANSAC algorithm.\n",
      "        .   -   **LMEDS** for the LMedS algorithm.\n",
      "        .   @param threshold Parameter used for RANSAC. It is the maximum distance from a point to an epipolar\n",
      "        .   line in pixels, beyond which the point is considered an outlier and is not used for computing the\n",
      "        .   final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the\n",
      "        .   point localization, image resolution, and the image noise.\n",
      "        .   @param prob Parameter used for the RANSAC or LMedS methods only. It specifies a desirable level of\n",
      "        .   confidence (probability) that the estimated matrix is correct.\n",
      "        .   @param mask Output array of N elements, every element of which is set to 0 for outliers and to 1\n",
      "        .   for the other points. The array is computed only in the RANSAC and LMedS methods.\n",
      "        .   \n",
      "        .   This function differs from the one above that it computes camera matrix from focal length and\n",
      "        .   principal point:\n",
      "        .   \n",
      "        .   \\f[K =\n",
      "        .   \\begin{bmatrix}\n",
      "        .   f & 0 & x_{pp}  \\\\\n",
      "        .   0 & f & y_{pp}  \\\\\n",
      "        .   0 & 0 & 1\n",
      "        .   \\end{bmatrix}\\f]\n",
      "    \n",
      "    findFundamentalMat(...)\n",
      "        findFundamentalMat(points1, points2, method, ransacReprojThreshold, confidence, maxIters[, mask]) -> retval, mask\n",
      "        .   @brief Calculates a fundamental matrix from the corresponding points in two images.\n",
      "        .   \n",
      "        .   @param points1 Array of N points from the first image. The point coordinates should be\n",
      "        .   floating-point (single or double precision).\n",
      "        .   @param points2 Array of the second image points of the same size and format as points1 .\n",
      "        .   @param method Method for computing a fundamental matrix.\n",
      "        .   -   **CV_FM_7POINT** for a 7-point algorithm. \\f$N = 7\\f$\n",
      "        .   -   **CV_FM_8POINT** for an 8-point algorithm. \\f$N \\ge 8\\f$\n",
      "        .   -   **CV_FM_RANSAC** for the RANSAC algorithm. \\f$N \\ge 8\\f$\n",
      "        .   -   **CV_FM_LMEDS** for the LMedS algorithm. \\f$N \\ge 8\\f$\n",
      "        .   @param ransacReprojThreshold Parameter used only for RANSAC. It is the maximum distance from a point to an epipolar\n",
      "        .   line in pixels, beyond which the point is considered an outlier and is not used for computing the\n",
      "        .   final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the\n",
      "        .   point localization, image resolution, and the image noise.\n",
      "        .   @param confidence Parameter used for the RANSAC and LMedS methods only. It specifies a desirable level\n",
      "        .   of confidence (probability) that the estimated matrix is correct.\n",
      "        .   @param mask\n",
      "        .   @param maxIters The maximum number of robust method iterations.\n",
      "        .   \n",
      "        .   The epipolar geometry is described by the following equation:\n",
      "        .   \n",
      "        .   \\f[[p_2; 1]^T F [p_1; 1] = 0\\f]\n",
      "        .   \n",
      "        .   where \\f$F\\f$ is a fundamental matrix, \\f$p_1\\f$ and \\f$p_2\\f$ are corresponding points in the first and the\n",
      "        .   second images, respectively.\n",
      "        .   \n",
      "        .   The function calculates the fundamental matrix using one of four methods listed above and returns\n",
      "        .   the found fundamental matrix. Normally just one matrix is found. But in case of the 7-point\n",
      "        .   algorithm, the function may return up to 3 solutions ( \\f$9 \\times 3\\f$ matrix that stores all 3\n",
      "        .   matrices sequentially).\n",
      "        .   \n",
      "        .   The calculated fundamental matrix may be passed further to computeCorrespondEpilines that finds the\n",
      "        .   epipolar lines corresponding to the specified points. It can also be passed to\n",
      "        .   stereoRectifyUncalibrated to compute the rectification transformation. :\n",
      "        .   @code\n",
      "        .       // Example. Estimation of fundamental matrix using the RANSAC algorithm\n",
      "        .       int point_count = 100;\n",
      "        .       vector<Point2f> points1(point_count);\n",
      "        .       vector<Point2f> points2(point_count);\n",
      "        .   \n",
      "        .       // initialize the points here ...\n",
      "        .       for( int i = 0; i < point_count; i++ )\n",
      "        .       {\n",
      "        .           points1[i] = ...;\n",
      "        .           points2[i] = ...;\n",
      "        .       }\n",
      "        .   \n",
      "        .       Mat fundamental_matrix =\n",
      "        .        findFundamentalMat(points1, points2, FM_RANSAC, 3, 0.99);\n",
      "        .   @endcode\n",
      "        \n",
      "        \n",
      "        \n",
      "        findFundamentalMat(points1, points2[, method[, ransacReprojThreshold[, confidence[, mask]]]]) -> retval, mask\n",
      "        .   @overload\n",
      "    \n",
      "    findHomography(...)\n",
      "        findHomography(srcPoints, dstPoints[, method[, ransacReprojThreshold[, mask[, maxIters[, confidence]]]]]) -> retval, mask\n",
      "        .   @brief Finds a perspective transformation between two planes.\n",
      "        .   \n",
      "        .   @param srcPoints Coordinates of the points in the original plane, a matrix of the type CV_32FC2\n",
      "        .   or vector\\<Point2f\\> .\n",
      "        .   @param dstPoints Coordinates of the points in the target plane, a matrix of the type CV_32FC2 or\n",
      "        .   a vector\\<Point2f\\> .\n",
      "        .   @param method Method used to compute a homography matrix. The following methods are possible:\n",
      "        .   -   **0** - a regular method using all the points, i.e., the least squares method\n",
      "        .   -   **RANSAC** - RANSAC-based robust method\n",
      "        .   -   **LMEDS** - Least-Median robust method\n",
      "        .   -   **RHO** - PROSAC-based robust method\n",
      "        .   @param ransacReprojThreshold Maximum allowed reprojection error to treat a point pair as an inlier\n",
      "        .   (used in the RANSAC and RHO methods only). That is, if\n",
      "        .   \\f[\\| \\texttt{dstPoints} _i -  \\texttt{convertPointsHomogeneous} ( \\texttt{H} * \\texttt{srcPoints} _i) \\|_2  >  \\texttt{ransacReprojThreshold}\\f]\n",
      "        .   then the point \\f$i\\f$ is considered as an outlier. If srcPoints and dstPoints are measured in pixels,\n",
      "        .   it usually makes sense to set this parameter somewhere in the range of 1 to 10.\n",
      "        .   @param mask Optional output mask set by a robust method ( RANSAC or LMEDS ). Note that the input\n",
      "        .   mask values are ignored.\n",
      "        .   @param maxIters The maximum number of RANSAC iterations.\n",
      "        .   @param confidence Confidence level, between 0 and 1.\n",
      "        .   \n",
      "        .   The function finds and returns the perspective transformation \\f$H\\f$ between the source and the\n",
      "        .   destination planes:\n",
      "        .   \n",
      "        .   \\f[s_i  \\vecthree{x'_i}{y'_i}{1} \\sim H  \\vecthree{x_i}{y_i}{1}\\f]\n",
      "        .   \n",
      "        .   so that the back-projection error\n",
      "        .   \n",
      "        .   \\f[\\sum _i \\left ( x'_i- \\frac{h_{11} x_i + h_{12} y_i + h_{13}}{h_{31} x_i + h_{32} y_i + h_{33}} \\right )^2+ \\left ( y'_i- \\frac{h_{21} x_i + h_{22} y_i + h_{23}}{h_{31} x_i + h_{32} y_i + h_{33}} \\right )^2\\f]\n",
      "        .   \n",
      "        .   is minimized. If the parameter method is set to the default value 0, the function uses all the point\n",
      "        .   pairs to compute an initial homography estimate with a simple least-squares scheme.\n",
      "        .   \n",
      "        .   However, if not all of the point pairs ( \\f$srcPoints_i\\f$, \\f$dstPoints_i\\f$ ) fit the rigid perspective\n",
      "        .   transformation (that is, there are some outliers), this initial estimate will be poor. In this case,\n",
      "        .   you can use one of the three robust methods. The methods RANSAC, LMeDS and RHO try many different\n",
      "        .   random subsets of the corresponding point pairs (of four pairs each, collinear pairs are discarded), estimate the homography matrix\n",
      "        .   using this subset and a simple least-squares algorithm, and then compute the quality/goodness of the\n",
      "        .   computed homography (which is the number of inliers for RANSAC or the least median re-projection error for\n",
      "        .   LMeDS). The best subset is then used to produce the initial estimate of the homography matrix and\n",
      "        .   the mask of inliers/outliers.\n",
      "        .   \n",
      "        .   Regardless of the method, robust or not, the computed homography matrix is refined further (using\n",
      "        .   inliers only in case of a robust method) with the Levenberg-Marquardt method to reduce the\n",
      "        .   re-projection error even more.\n",
      "        .   \n",
      "        .   The methods RANSAC and RHO can handle practically any ratio of outliers but need a threshold to\n",
      "        .   distinguish inliers from outliers. The method LMeDS does not need any threshold but it works\n",
      "        .   correctly only when there are more than 50% of inliers. Finally, if there are no outliers and the\n",
      "        .   noise is rather small, use the default method (method=0).\n",
      "        .   \n",
      "        .   The function is used to find initial intrinsic and extrinsic matrices. Homography matrix is\n",
      "        .   determined up to a scale. Thus, it is normalized so that \\f$h_{33}=1\\f$. Note that whenever an \\f$H\\f$ matrix\n",
      "        .   cannot be estimated, an empty one will be returned.\n",
      "        .   \n",
      "        .   @sa\n",
      "        .   getAffineTransform, estimateAffine2D, estimateAffinePartial2D, getPerspectiveTransform, warpPerspective,\n",
      "        .   perspectiveTransform\n",
      "    \n",
      "    findNonZero(...)\n",
      "        findNonZero(src[, idx]) -> idx\n",
      "        .   @brief Returns the list of locations of non-zero pixels\n",
      "        .   \n",
      "        .   Given a binary matrix (likely returned from an operation such\n",
      "        .   as threshold(), compare(), >, ==, etc, return all of\n",
      "        .   the non-zero indices as a cv::Mat or std::vector<cv::Point> (x,y)\n",
      "        .   For example:\n",
      "        .   @code{.cpp}\n",
      "        .       cv::Mat binaryImage; // input, binary image\n",
      "        .       cv::Mat locations;   // output, locations of non-zero pixels\n",
      "        .       cv::findNonZero(binaryImage, locations);\n",
      "        .   \n",
      "        .       // access pixel coordinates\n",
      "        .       Point pnt = locations.at<Point>(i);\n",
      "        .   @endcode\n",
      "        .   or\n",
      "        .   @code{.cpp}\n",
      "        .       cv::Mat binaryImage; // input, binary image\n",
      "        .       vector<Point> locations;   // output, locations of non-zero pixels\n",
      "        .       cv::findNonZero(binaryImage, locations);\n",
      "        .   \n",
      "        .       // access pixel coordinates\n",
      "        .       Point pnt = locations[i];\n",
      "        .   @endcode\n",
      "        .   @param src single-channel array\n",
      "        .   @param idx the output array, type of cv::Mat or std::vector<Point>, corresponding to non-zero indices in the input\n",
      "    \n",
      "    findTransformECC(...)\n",
      "        findTransformECC(templateImage, inputImage, warpMatrix, motionType, criteria, inputMask, gaussFiltSize) -> retval, warpMatrix\n",
      "        .   @brief Finds the geometric transform (warp) between two images in terms of the ECC criterion @cite EP08 .\n",
      "        .   \n",
      "        .   @param templateImage single-channel template image; CV_8U or CV_32F array.\n",
      "        .   @param inputImage single-channel input image which should be warped with the final warpMatrix in\n",
      "        .   order to provide an image similar to templateImage, same type as templateImage.\n",
      "        .   @param warpMatrix floating-point \\f$2\\times 3\\f$ or \\f$3\\times 3\\f$ mapping matrix (warp).\n",
      "        .   @param motionType parameter, specifying the type of motion:\n",
      "        .    -   **MOTION_TRANSLATION** sets a translational motion model; warpMatrix is \\f$2\\times 3\\f$ with\n",
      "        .        the first \\f$2\\times 2\\f$ part being the unity matrix and the rest two parameters being\n",
      "        .        estimated.\n",
      "        .    -   **MOTION_EUCLIDEAN** sets a Euclidean (rigid) transformation as motion model; three\n",
      "        .        parameters are estimated; warpMatrix is \\f$2\\times 3\\f$.\n",
      "        .    -   **MOTION_AFFINE** sets an affine motion model (DEFAULT); six parameters are estimated;\n",
      "        .        warpMatrix is \\f$2\\times 3\\f$.\n",
      "        .    -   **MOTION_HOMOGRAPHY** sets a homography as a motion model; eight parameters are\n",
      "        .        estimated;\\`warpMatrix\\` is \\f$3\\times 3\\f$.\n",
      "        .   @param criteria parameter, specifying the termination criteria of the ECC algorithm;\n",
      "        .   criteria.epsilon defines the threshold of the increment in the correlation coefficient between two\n",
      "        .   iterations (a negative criteria.epsilon makes criteria.maxcount the only termination criterion).\n",
      "        .   Default values are shown in the declaration above.\n",
      "        .   @param inputMask An optional mask to indicate valid values of inputImage.\n",
      "        .   @param gaussFiltSize An optional value indicating size of gaussian blur filter; (DEFAULT: 5)\n",
      "        .   \n",
      "        .   The function estimates the optimum transformation (warpMatrix) with respect to ECC criterion\n",
      "        .   (@cite EP08), that is\n",
      "        .   \n",
      "        .   \\f[\\texttt{warpMatrix} = \\arg\\max_{W} \\texttt{ECC}(\\texttt{templateImage}(x,y),\\texttt{inputImage}(x',y'))\\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \n",
      "        .   \\f[\\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = W \\cdot \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   (the equation holds with homogeneous coordinates for homography). It returns the final enhanced\n",
      "        .   correlation coefficient, that is the correlation coefficient between the template image and the\n",
      "        .   final warped input image. When a \\f$3\\times 3\\f$ matrix is given with motionType =0, 1 or 2, the third\n",
      "        .   row is ignored.\n",
      "        .   \n",
      "        .   Unlike findHomography and estimateRigidTransform, the function findTransformECC implements an\n",
      "        .   area-based alignment that builds on intensity similarities. In essence, the function updates the\n",
      "        .   initial transformation that roughly aligns the images. If this information is missing, the identity\n",
      "        .   warp (unity matrix) is used as an initialization. Note that if images undergo strong\n",
      "        .   displacements/rotations, an initial transformation that roughly aligns the images is necessary\n",
      "        .   (e.g., a simple euclidean/similarity transform that allows for the images showing the same image\n",
      "        .   content approximately). Use inverse warping in the second image to take an image close to the first\n",
      "        .   one, i.e. use the flag WARP_INVERSE_MAP with warpAffine or warpPerspective. See also the OpenCV\n",
      "        .   sample image_alignment.cpp that demonstrates the use of the function. Note that the function throws\n",
      "        .   an exception if algorithm does not converges.\n",
      "        .   \n",
      "        .   @sa\n",
      "        .   computeECC, estimateAffine2D, estimateAffinePartial2D, findHomography\n",
      "    \n",
      "    fitEllipse(...)\n",
      "        fitEllipse(points) -> retval\n",
      "        .   @brief Fits an ellipse around a set of 2D points.\n",
      "        .   \n",
      "        .   The function calculates the ellipse that fits (in a least-squares sense) a set of 2D points best of\n",
      "        .   all. It returns the rotated rectangle in which the ellipse is inscribed. The first algorithm described by @cite Fitzgibbon95\n",
      "        .   is used. Developer should keep in mind that it is possible that the returned\n",
      "        .   ellipse/rotatedRect data contains negative indices, due to the data points being close to the\n",
      "        .   border of the containing Mat element.\n",
      "        .   \n",
      "        .   @param points Input 2D point set, stored in std::vector\\<\\> or Mat\n",
      "    \n",
      "    fitEllipseAMS(...)\n",
      "        fitEllipseAMS(points) -> retval\n",
      "        .   @brief Fits an ellipse around a set of 2D points.\n",
      "        .   \n",
      "        .    The function calculates the ellipse that fits a set of 2D points.\n",
      "        .    It returns the rotated rectangle in which the ellipse is inscribed.\n",
      "        .    The Approximate Mean Square (AMS) proposed by @cite Taubin1991 is used.\n",
      "        .   \n",
      "        .    For an ellipse, this basis set is \\f$ \\chi= \\left(x^2, x y, y^2, x, y, 1\\right) \\f$,\n",
      "        .    which is a set of six free coefficients \\f$ A^T=\\left\\{A_{\\text{xx}},A_{\\text{xy}},A_{\\text{yy}},A_x,A_y,A_0\\right\\} \\f$.\n",
      "        .    However, to specify an ellipse, all that is needed is five numbers; the major and minor axes lengths \\f$ (a,b) \\f$,\n",
      "        .    the position \\f$ (x_0,y_0) \\f$, and the orientation \\f$ \\theta \\f$. This is because the basis set includes lines,\n",
      "        .    quadratics, parabolic and hyperbolic functions as well as elliptical functions as possible fits.\n",
      "        .    If the fit is found to be a parabolic or hyperbolic function then the standard #fitEllipse method is used.\n",
      "        .    The AMS method restricts the fit to parabolic, hyperbolic and elliptical curves\n",
      "        .    by imposing the condition that \\f$ A^T ( D_x^T D_x  +   D_y^T D_y) A = 1 \\f$ where\n",
      "        .    the matrices \\f$ Dx \\f$ and \\f$ Dy \\f$ are the partial derivatives of the design matrix \\f$ D \\f$ with\n",
      "        .    respect to x and y. The matrices are formed row by row applying the following to\n",
      "        .    each of the points in the set:\n",
      "        .    \\f{align*}{\n",
      "        .    D(i,:)&=\\left\\{x_i^2, x_i y_i, y_i^2, x_i, y_i, 1\\right\\} &\n",
      "        .    D_x(i,:)&=\\left\\{2 x_i,y_i,0,1,0,0\\right\\} &\n",
      "        .    D_y(i,:)&=\\left\\{0,x_i,2 y_i,0,1,0\\right\\}\n",
      "        .    \\f}\n",
      "        .    The AMS method minimizes the cost function\n",
      "        .    \\f{equation*}{\n",
      "        .    \\epsilon ^2=\\frac{ A^T D^T D A }{ A^T (D_x^T D_x +  D_y^T D_y) A^T }\n",
      "        .    \\f}\n",
      "        .   \n",
      "        .    The minimum cost is found by solving the generalized eigenvalue problem.\n",
      "        .   \n",
      "        .    \\f{equation*}{\n",
      "        .    D^T D A = \\lambda  \\left( D_x^T D_x +  D_y^T D_y\\right) A\n",
      "        .    \\f}\n",
      "        .   \n",
      "        .    @param points Input 2D point set, stored in std::vector\\<\\> or Mat\n",
      "    \n",
      "    fitEllipseDirect(...)\n",
      "        fitEllipseDirect(points) -> retval\n",
      "        .   @brief Fits an ellipse around a set of 2D points.\n",
      "        .   \n",
      "        .    The function calculates the ellipse that fits a set of 2D points.\n",
      "        .    It returns the rotated rectangle in which the ellipse is inscribed.\n",
      "        .    The Direct least square (Direct) method by @cite Fitzgibbon1999 is used.\n",
      "        .   \n",
      "        .    For an ellipse, this basis set is \\f$ \\chi= \\left(x^2, x y, y^2, x, y, 1\\right) \\f$,\n",
      "        .    which is a set of six free coefficients \\f$ A^T=\\left\\{A_{\\text{xx}},A_{\\text{xy}},A_{\\text{yy}},A_x,A_y,A_0\\right\\} \\f$.\n",
      "        .    However, to specify an ellipse, all that is needed is five numbers; the major and minor axes lengths \\f$ (a,b) \\f$,\n",
      "        .    the position \\f$ (x_0,y_0) \\f$, and the orientation \\f$ \\theta \\f$. This is because the basis set includes lines,\n",
      "        .    quadratics, parabolic and hyperbolic functions as well as elliptical functions as possible fits.\n",
      "        .    The Direct method confines the fit to ellipses by ensuring that \\f$ 4 A_{xx} A_{yy}- A_{xy}^2 > 0 \\f$.\n",
      "        .    The condition imposed is that \\f$ 4 A_{xx} A_{yy}- A_{xy}^2=1 \\f$ which satisfies the inequality\n",
      "        .    and as the coefficients can be arbitrarily scaled is not overly restrictive.\n",
      "        .   \n",
      "        .    \\f{equation*}{\n",
      "        .    \\epsilon ^2= A^T D^T D A \\quad \\text{with} \\quad A^T C A =1 \\quad \\text{and} \\quad C=\\left(\\begin{matrix}\n",
      "        .    0 & 0  & 2  & 0  & 0  &  0  \\\\\n",
      "        .    0 & -1  & 0  & 0  & 0  &  0 \\\\\n",
      "        .    2 & 0  & 0  & 0  & 0  &  0 \\\\\n",
      "        .    0 & 0  & 0  & 0  & 0  &  0 \\\\\n",
      "        .    0 & 0  & 0  & 0  & 0  &  0 \\\\\n",
      "        .    0 & 0  & 0  & 0  & 0  &  0\n",
      "        .    \\end{matrix} \\right)\n",
      "        .    \\f}\n",
      "        .   \n",
      "        .    The minimum cost is found by solving the generalized eigenvalue problem.\n",
      "        .   \n",
      "        .    \\f{equation*}{\n",
      "        .    D^T D A = \\lambda  \\left( C\\right) A\n",
      "        .    \\f}\n",
      "        .   \n",
      "        .    The system produces only one positive eigenvalue \\f$ \\lambda\\f$ which is chosen as the solution\n",
      "        .    with its eigenvector \\f$\\mathbf{u}\\f$. These are used to find the coefficients\n",
      "        .   \n",
      "        .    \\f{equation*}{\n",
      "        .    A = \\sqrt{\\frac{1}{\\mathbf{u}^T C \\mathbf{u}}}  \\mathbf{u}\n",
      "        .    \\f}\n",
      "        .    The scaling factor guarantees that  \\f$A^T C A =1\\f$.\n",
      "        .   \n",
      "        .    @param points Input 2D point set, stored in std::vector\\<\\> or Mat\n",
      "    \n",
      "    fitLine(...)\n",
      "        fitLine(points, distType, param, reps, aeps[, line]) -> line\n",
      "        .   @brief Fits a line to a 2D or 3D point set.\n",
      "        .   \n",
      "        .   The function fitLine fits a line to a 2D or 3D point set by minimizing \\f$\\sum_i \\rho(r_i)\\f$ where\n",
      "        .   \\f$r_i\\f$ is a distance between the \\f$i^{th}\\f$ point, the line and \\f$\\rho(r)\\f$ is a distance function, one\n",
      "        .   of the following:\n",
      "        .   -  DIST_L2\n",
      "        .   \\f[\\rho (r) = r^2/2  \\quad \\text{(the simplest and the fastest least-squares method)}\\f]\n",
      "        .   - DIST_L1\n",
      "        .   \\f[\\rho (r) = r\\f]\n",
      "        .   - DIST_L12\n",
      "        .   \\f[\\rho (r) = 2  \\cdot ( \\sqrt{1 + \\frac{r^2}{2}} - 1)\\f]\n",
      "        .   - DIST_FAIR\n",
      "        .   \\f[\\rho \\left (r \\right ) = C^2  \\cdot \\left (  \\frac{r}{C} -  \\log{\\left(1 + \\frac{r}{C}\\right)} \\right )  \\quad \\text{where} \\quad C=1.3998\\f]\n",
      "        .   - DIST_WELSCH\n",
      "        .   \\f[\\rho \\left (r \\right ) =  \\frac{C^2}{2} \\cdot \\left ( 1 -  \\exp{\\left(-\\left(\\frac{r}{C}\\right)^2\\right)} \\right )  \\quad \\text{where} \\quad C=2.9846\\f]\n",
      "        .   - DIST_HUBER\n",
      "        .   \\f[\\rho (r) =  \\fork{r^2/2}{if \\(r < C\\)}{C \\cdot (r-C/2)}{otherwise} \\quad \\text{where} \\quad C=1.345\\f]\n",
      "        .   \n",
      "        .   The algorithm is based on the M-estimator ( <http://en.wikipedia.org/wiki/M-estimator> ) technique\n",
      "        .   that iteratively fits the line using the weighted least-squares algorithm. After each iteration the\n",
      "        .   weights \\f$w_i\\f$ are adjusted to be inversely proportional to \\f$\\rho(r_i)\\f$ .\n",
      "        .   \n",
      "        .   @param points Input vector of 2D or 3D points, stored in std::vector\\<\\> or Mat.\n",
      "        .   @param line Output line parameters. In case of 2D fitting, it should be a vector of 4 elements\n",
      "        .   (like Vec4f) - (vx, vy, x0, y0), where (vx, vy) is a normalized vector collinear to the line and\n",
      "        .   (x0, y0) is a point on the line. In case of 3D fitting, it should be a vector of 6 elements (like\n",
      "        .   Vec6f) - (vx, vy, vz, x0, y0, z0), where (vx, vy, vz) is a normalized vector collinear to the line\n",
      "        .   and (x0, y0, z0) is a point on the line.\n",
      "        .   @param distType Distance used by the M-estimator, see #DistanceTypes\n",
      "        .   @param param Numerical parameter ( C ) for some types of distances. If it is 0, an optimal value\n",
      "        .   is chosen.\n",
      "        .   @param reps Sufficient accuracy for the radius (distance between the coordinate origin and the line).\n",
      "        .   @param aeps Sufficient accuracy for the angle. 0.01 would be a good default value for reps and aeps.\n",
      "    \n",
      "    flip(...)\n",
      "        flip(src, flipCode[, dst]) -> dst\n",
      "        .   @brief Flips a 2D array around vertical, horizontal, or both axes.\n",
      "        .   \n",
      "        .   The function cv::flip flips the array in one of three different ways (row\n",
      "        .   and column indices are 0-based):\n",
      "        .   \\f[\\texttt{dst} _{ij} =\n",
      "        .   \\left\\{\n",
      "        .   \\begin{array}{l l}\n",
      "        .   \\texttt{src} _{\\texttt{src.rows}-i-1,j} & if\\;  \\texttt{flipCode} = 0 \\\\\n",
      "        .   \\texttt{src} _{i, \\texttt{src.cols} -j-1} & if\\;  \\texttt{flipCode} > 0 \\\\\n",
      "        .   \\texttt{src} _{ \\texttt{src.rows} -i-1, \\texttt{src.cols} -j-1} & if\\; \\texttt{flipCode} < 0 \\\\\n",
      "        .   \\end{array}\n",
      "        .   \\right.\\f]\n",
      "        .   The example scenarios of using the function are the following:\n",
      "        .   *   Vertical flipping of the image (flipCode == 0) to switch between\n",
      "        .       top-left and bottom-left image origin. This is a typical operation\n",
      "        .       in video processing on Microsoft Windows\\* OS.\n",
      "        .   *   Horizontal flipping of the image with the subsequent horizontal\n",
      "        .       shift and absolute difference calculation to check for a\n",
      "        .       vertical-axis symmetry (flipCode \\> 0).\n",
      "        .   *   Simultaneous horizontal and vertical flipping of the image with\n",
      "        .       the subsequent shift and absolute difference calculation to check\n",
      "        .       for a central symmetry (flipCode \\< 0).\n",
      "        .   *   Reversing the order of point arrays (flipCode \\> 0 or\n",
      "        .       flipCode == 0).\n",
      "        .   @param src input array.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "        .   @param flipCode a flag to specify how to flip the array; 0 means\n",
      "        .   flipping around the x-axis and positive value (for example, 1) means\n",
      "        .   flipping around y-axis. Negative value (for example, -1) means flipping\n",
      "        .   around both axes.\n",
      "        .   @sa transpose , repeat , completeSymm\n",
      "    \n",
      "    floodFill(...)\n",
      "        floodFill(image, mask, seedPoint, newVal[, loDiff[, upDiff[, flags]]]) -> retval, image, mask, rect\n",
      "        .   @brief Fills a connected component with the given color.\n",
      "        .   \n",
      "        .   The function cv::floodFill fills a connected component starting from the seed point with the specified\n",
      "        .   color. The connectivity is determined by the color/brightness closeness of the neighbor pixels. The\n",
      "        .   pixel at \\f$(x,y)\\f$ is considered to belong to the repainted domain if:\n",
      "        .   \n",
      "        .   - in case of a grayscale image and floating range\n",
      "        .   \\f[\\texttt{src} (x',y')- \\texttt{loDiff} \\leq \\texttt{src} (x,y)  \\leq \\texttt{src} (x',y')+ \\texttt{upDiff}\\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   - in case of a grayscale image and fixed range\n",
      "        .   \\f[\\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)- \\texttt{loDiff} \\leq \\texttt{src} (x,y)  \\leq \\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)+ \\texttt{upDiff}\\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   - in case of a color image and floating range\n",
      "        .   \\f[\\texttt{src} (x',y')_r- \\texttt{loDiff} _r \\leq \\texttt{src} (x,y)_r \\leq \\texttt{src} (x',y')_r+ \\texttt{upDiff} _r,\\f]\n",
      "        .   \\f[\\texttt{src} (x',y')_g- \\texttt{loDiff} _g \\leq \\texttt{src} (x,y)_g \\leq \\texttt{src} (x',y')_g+ \\texttt{upDiff} _g\\f]\n",
      "        .   and\n",
      "        .   \\f[\\texttt{src} (x',y')_b- \\texttt{loDiff} _b \\leq \\texttt{src} (x,y)_b \\leq \\texttt{src} (x',y')_b+ \\texttt{upDiff} _b\\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   - in case of a color image and fixed range\n",
      "        .   \\f[\\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)_r- \\texttt{loDiff} _r \\leq \\texttt{src} (x,y)_r \\leq \\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)_r+ \\texttt{upDiff} _r,\\f]\n",
      "        .   \\f[\\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)_g- \\texttt{loDiff} _g \\leq \\texttt{src} (x,y)_g \\leq \\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)_g+ \\texttt{upDiff} _g\\f]\n",
      "        .   and\n",
      "        .   \\f[\\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)_b- \\texttt{loDiff} _b \\leq \\texttt{src} (x,y)_b \\leq \\texttt{src} ( \\texttt{seedPoint} .x, \\texttt{seedPoint} .y)_b+ \\texttt{upDiff} _b\\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   where \\f$src(x',y')\\f$ is the value of one of pixel neighbors that is already known to belong to the\n",
      "        .   component. That is, to be added to the connected component, a color/brightness of the pixel should\n",
      "        .   be close enough to:\n",
      "        .   - Color/brightness of one of its neighbors that already belong to the connected component in case\n",
      "        .   of a floating range.\n",
      "        .   - Color/brightness of the seed point in case of a fixed range.\n",
      "        .   \n",
      "        .   Use these functions to either mark a connected component with the specified color in-place, or build\n",
      "        .   a mask and then extract the contour, or copy the region to another image, and so on.\n",
      "        .   \n",
      "        .   @param image Input/output 1- or 3-channel, 8-bit, or floating-point image. It is modified by the\n",
      "        .   function unless the #FLOODFILL_MASK_ONLY flag is set in the second variant of the function. See\n",
      "        .   the details below.\n",
      "        .   @param mask Operation mask that should be a single-channel 8-bit image, 2 pixels wider and 2 pixels\n",
      "        .   taller than image. Since this is both an input and output parameter, you must take responsibility\n",
      "        .   of initializing it. Flood-filling cannot go across non-zero pixels in the input mask. For example,\n",
      "        .   an edge detector output can be used as a mask to stop filling at edges. On output, pixels in the\n",
      "        .   mask corresponding to filled pixels in the image are set to 1 or to the a value specified in flags\n",
      "        .   as described below. Additionally, the function fills the border of the mask with ones to simplify\n",
      "        .   internal processing. It is therefore possible to use the same mask in multiple calls to the function\n",
      "        .   to make sure the filled areas do not overlap.\n",
      "        .   @param seedPoint Starting point.\n",
      "        .   @param newVal New value of the repainted domain pixels.\n",
      "        .   @param loDiff Maximal lower brightness/color difference between the currently observed pixel and\n",
      "        .   one of its neighbors belonging to the component, or a seed pixel being added to the component.\n",
      "        .   @param upDiff Maximal upper brightness/color difference between the currently observed pixel and\n",
      "        .   one of its neighbors belonging to the component, or a seed pixel being added to the component.\n",
      "        .   @param rect Optional output parameter set by the function to the minimum bounding rectangle of the\n",
      "        .   repainted domain.\n",
      "        .   @param flags Operation flags. The first 8 bits contain a connectivity value. The default value of\n",
      "        .   4 means that only the four nearest neighbor pixels (those that share an edge) are considered. A\n",
      "        .   connectivity value of 8 means that the eight nearest neighbor pixels (those that share a corner)\n",
      "        .   will be considered. The next 8 bits (8-16) contain a value between 1 and 255 with which to fill\n",
      "        .   the mask (the default value is 1). For example, 4 | ( 255 \\<\\< 8 ) will consider 4 nearest\n",
      "        .   neighbours and fill the mask with a value of 255. The following additional options occupy higher\n",
      "        .   bits and therefore may be further combined with the connectivity and mask fill values using\n",
      "        .   bit-wise or (|), see #FloodFillFlags.\n",
      "        .   \n",
      "        .   @note Since the mask is larger than the filled image, a pixel \\f$(x, y)\\f$ in image corresponds to the\n",
      "        .   pixel \\f$(x+1, y+1)\\f$ in the mask .\n",
      "        .   \n",
      "        .   @sa findContours\n",
      "    \n",
      "    gemm(...)\n",
      "        gemm(src1, src2, alpha, src3, beta[, dst[, flags]]) -> dst\n",
      "        .   @brief Performs generalized matrix multiplication.\n",
      "        .   \n",
      "        .   The function cv::gemm performs generalized matrix multiplication similar to the\n",
      "        .   gemm functions in BLAS level 3. For example,\n",
      "        .   `gemm(src1, src2, alpha, src3, beta, dst, GEMM_1_T + GEMM_3_T)`\n",
      "        .   corresponds to\n",
      "        .   \\f[\\texttt{dst} =  \\texttt{alpha} \\cdot \\texttt{src1} ^T  \\cdot \\texttt{src2} +  \\texttt{beta} \\cdot \\texttt{src3} ^T\\f]\n",
      "        .   \n",
      "        .   In case of complex (two-channel) data, performed a complex matrix\n",
      "        .   multiplication.\n",
      "        .   \n",
      "        .   The function can be replaced with a matrix expression. For example, the\n",
      "        .   above call can be replaced with:\n",
      "        .   @code{.cpp}\n",
      "        .       dst = alpha*src1.t()*src2 + beta*src3.t();\n",
      "        .   @endcode\n",
      "        .   @param src1 first multiplied input matrix that could be real(CV_32FC1,\n",
      "        .   CV_64FC1) or complex(CV_32FC2, CV_64FC2).\n",
      "        .   @param src2 second multiplied input matrix of the same type as src1.\n",
      "        .   @param alpha weight of the matrix product.\n",
      "        .   @param src3 third optional delta matrix added to the matrix product; it\n",
      "        .   should have the same type as src1 and src2.\n",
      "        .   @param beta weight of src3.\n",
      "        .   @param dst output matrix; it has the proper size and the same type as\n",
      "        .   input matrices.\n",
      "        .   @param flags operation flags (cv::GemmFlags)\n",
      "        .   @sa mulTransposed , transform\n",
      "    \n",
      "    getAffineTransform(...)\n",
      "        getAffineTransform(src, dst) -> retval\n",
      "        .   @overload\n",
      "    \n",
      "    getBuildInformation(...)\n",
      "        getBuildInformation() -> retval\n",
      "        .   @brief Returns full configuration time cmake output.\n",
      "        .   \n",
      "        .   Returned value is raw cmake output including version control system revision, compiler version,\n",
      "        .   compiler flags, enabled modules and third party libraries, etc. Output format depends on target\n",
      "        .   architecture.\n",
      "    \n",
      "    getCPUFeaturesLine(...)\n",
      "        getCPUFeaturesLine() -> retval\n",
      "        .   @brief Returns list of CPU features enabled during compilation.\n",
      "        .   \n",
      "        .   Returned value is a string containing space separated list of CPU features with following markers:\n",
      "        .   \n",
      "        .   - no markers - baseline features\n",
      "        .   - prefix `*` - features enabled in dispatcher\n",
      "        .   - suffix `?` - features enabled but not available in HW\n",
      "        .   \n",
      "        .   Example: `SSE SSE2 SSE3 *SSE4.1 *SSE4.2 *FP16 *AVX *AVX2 *AVX512-SKX?`\n",
      "    \n",
      "    getCPUTickCount(...)\n",
      "        getCPUTickCount() -> retval\n",
      "        .   @brief Returns the number of CPU ticks.\n",
      "        .   \n",
      "        .   The function returns the current number of CPU ticks on some architectures (such as x86, x64,\n",
      "        .   PowerPC). On other platforms the function is equivalent to getTickCount. It can also be used for\n",
      "        .   very accurate time measurements, as well as for RNG initialization. Note that in case of multi-CPU\n",
      "        .   systems a thread, from which getCPUTickCount is called, can be suspended and resumed at another CPU\n",
      "        .   with its own counter. So, theoretically (and practically) the subsequent calls to the function do\n",
      "        .   not necessary return the monotonously increasing values. Also, since a modern CPU varies the CPU\n",
      "        .   frequency depending on the load, the number of CPU clocks spent in some code cannot be directly\n",
      "        .   converted to time units. Therefore, getTickCount is generally a preferable solution for measuring\n",
      "        .   execution time.\n",
      "    \n",
      "    getDefaultNewCameraMatrix(...)\n",
      "        getDefaultNewCameraMatrix(cameraMatrix[, imgsize[, centerPrincipalPoint]]) -> retval\n",
      "        .   @brief Returns the default new camera matrix.\n",
      "        .   \n",
      "        .   The function returns the camera matrix that is either an exact copy of the input cameraMatrix (when\n",
      "        .   centerPrinicipalPoint=false ), or the modified one (when centerPrincipalPoint=true).\n",
      "        .   \n",
      "        .   In the latter case, the new camera matrix will be:\n",
      "        .   \n",
      "        .   \\f[\\begin{bmatrix} f_x && 0 && ( \\texttt{imgSize.width} -1)*0.5  \\\\ 0 && f_y && ( \\texttt{imgSize.height} -1)*0.5  \\\\ 0 && 0 && 1 \\end{bmatrix} ,\\f]\n",
      "        .   \n",
      "        .   where \\f$f_x\\f$ and \\f$f_y\\f$ are \\f$(0,0)\\f$ and \\f$(1,1)\\f$ elements of cameraMatrix, respectively.\n",
      "        .   \n",
      "        .   By default, the undistortion functions in OpenCV (see #initUndistortRectifyMap, #undistort) do not\n",
      "        .   move the principal point. However, when you work with stereo, it is important to move the principal\n",
      "        .   points in both views to the same y-coordinate (which is required by most of stereo correspondence\n",
      "        .   algorithms), and may be to the same x-coordinate too. So, you can form the new camera matrix for\n",
      "        .   each view where the principal points are located at the center.\n",
      "        .   \n",
      "        .   @param cameraMatrix Input camera matrix.\n",
      "        .   @param imgsize Camera view image size in pixels.\n",
      "        .   @param centerPrincipalPoint Location of the principal point in the new camera matrix. The\n",
      "        .   parameter indicates whether this location should be at the image center or not.\n",
      "    \n",
      "    getDerivKernels(...)\n",
      "        getDerivKernels(dx, dy, ksize[, kx[, ky[, normalize[, ktype]]]]) -> kx, ky\n",
      "        .   @brief Returns filter coefficients for computing spatial image derivatives.\n",
      "        .   \n",
      "        .   The function computes and returns the filter coefficients for spatial image derivatives. When\n",
      "        .   `ksize=FILTER_SCHARR`, the Scharr \\f$3 \\times 3\\f$ kernels are generated (see #Scharr). Otherwise, Sobel\n",
      "        .   kernels are generated (see #Sobel). The filters are normally passed to #sepFilter2D or to\n",
      "        .   \n",
      "        .   @param kx Output matrix of row filter coefficients. It has the type ktype .\n",
      "        .   @param ky Output matrix of column filter coefficients. It has the type ktype .\n",
      "        .   @param dx Derivative order in respect of x.\n",
      "        .   @param dy Derivative order in respect of y.\n",
      "        .   @param ksize Aperture size. It can be FILTER_SCHARR, 1, 3, 5, or 7.\n",
      "        .   @param normalize Flag indicating whether to normalize (scale down) the filter coefficients or not.\n",
      "        .   Theoretically, the coefficients should have the denominator \\f$=2^{ksize*2-dx-dy-2}\\f$. If you are\n",
      "        .   going to filter floating-point images, you are likely to use the normalized kernels. But if you\n",
      "        .   compute derivatives of an 8-bit image, store the results in a 16-bit image, and wish to preserve\n",
      "        .   all the fractional bits, you may want to set normalize=false .\n",
      "        .   @param ktype Type of filter coefficients. It can be CV_32f or CV_64F .\n",
      "    \n",
      "    getFontScaleFromHeight(...)\n",
      "        getFontScaleFromHeight(fontFace, pixelHeight[, thickness]) -> retval\n",
      "        .   @brief Calculates the font-specific size to use to achieve a given height in pixels.\n",
      "        .   \n",
      "        .   @param fontFace Font to use, see cv::HersheyFonts.\n",
      "        .   @param pixelHeight Pixel height to compute the fontScale for\n",
      "        .   @param thickness Thickness of lines used to render the text.See putText for details.\n",
      "        .   @return The fontSize to use for cv::putText\n",
      "        .   \n",
      "        .   @see cv::putText\n",
      "    \n",
      "    getGaborKernel(...)\n",
      "        getGaborKernel(ksize, sigma, theta, lambd, gamma[, psi[, ktype]]) -> retval\n",
      "        .   @brief Returns Gabor filter coefficients.\n",
      "        .   \n",
      "        .   For more details about gabor filter equations and parameters, see: [Gabor\n",
      "        .   Filter](http://en.wikipedia.org/wiki/Gabor_filter).\n",
      "        .   \n",
      "        .   @param ksize Size of the filter returned.\n",
      "        .   @param sigma Standard deviation of the gaussian envelope.\n",
      "        .   @param theta Orientation of the normal to the parallel stripes of a Gabor function.\n",
      "        .   @param lambd Wavelength of the sinusoidal factor.\n",
      "        .   @param gamma Spatial aspect ratio.\n",
      "        .   @param psi Phase offset.\n",
      "        .   @param ktype Type of filter coefficients. It can be CV_32F or CV_64F .\n",
      "    \n",
      "    getGaussianKernel(...)\n",
      "        getGaussianKernel(ksize, sigma[, ktype]) -> retval\n",
      "        .   @brief Returns Gaussian filter coefficients.\n",
      "        .   \n",
      "        .   The function computes and returns the \\f$\\texttt{ksize} \\times 1\\f$ matrix of Gaussian filter\n",
      "        .   coefficients:\n",
      "        .   \n",
      "        .   \\f[G_i= \\alpha *e^{-(i-( \\texttt{ksize} -1)/2)^2/(2* \\texttt{sigma}^2)},\\f]\n",
      "        .   \n",
      "        .   where \\f$i=0..\\texttt{ksize}-1\\f$ and \\f$\\alpha\\f$ is the scale factor chosen so that \\f$\\sum_i G_i=1\\f$.\n",
      "        .   \n",
      "        .   Two of such generated kernels can be passed to sepFilter2D. Those functions automatically recognize\n",
      "        .   smoothing kernels (a symmetrical kernel with sum of weights equal to 1) and handle them accordingly.\n",
      "        .   You may also use the higher-level GaussianBlur.\n",
      "        .   @param ksize Aperture size. It should be odd ( \\f$\\texttt{ksize} \\mod 2 = 1\\f$ ) and positive.\n",
      "        .   @param sigma Gaussian standard deviation. If it is non-positive, it is computed from ksize as\n",
      "        .   `sigma = 0.3*((ksize-1)*0.5 - 1) + 0.8`.\n",
      "        .   @param ktype Type of filter coefficients. It can be CV_32F or CV_64F .\n",
      "        .   @sa  sepFilter2D, getDerivKernels, getStructuringElement, GaussianBlur\n",
      "    \n",
      "    getHardwareFeatureName(...)\n",
      "        getHardwareFeatureName(feature) -> retval\n",
      "        .   @brief Returns feature name by ID\n",
      "        .   \n",
      "        .   Returns empty string if feature is not defined\n",
      "    \n",
      "    getNumThreads(...)\n",
      "        getNumThreads() -> retval\n",
      "        .   @brief Returns the number of threads used by OpenCV for parallel regions.\n",
      "        .   \n",
      "        .   Always returns 1 if OpenCV is built without threading support.\n",
      "        .   \n",
      "        .   The exact meaning of return value depends on the threading framework used by OpenCV library:\n",
      "        .   - `TBB` - The number of threads, that OpenCV will try to use for parallel regions. If there is\n",
      "        .     any tbb::thread_scheduler_init in user code conflicting with OpenCV, then function returns\n",
      "        .     default number of threads used by TBB library.\n",
      "        .   - `OpenMP` - An upper bound on the number of threads that could be used to form a new team.\n",
      "        .   - `Concurrency` - The number of threads, that OpenCV will try to use for parallel regions.\n",
      "        .   - `GCD` - Unsupported; returns the GCD thread pool limit (512) for compatibility.\n",
      "        .   - `C=` - The number of threads, that OpenCV will try to use for parallel regions, if before\n",
      "        .     called setNumThreads with threads \\> 0, otherwise returns the number of logical CPUs,\n",
      "        .     available for the process.\n",
      "        .   @sa setNumThreads, getThreadNum\n",
      "    \n",
      "    getNumberOfCPUs(...)\n",
      "        getNumberOfCPUs() -> retval\n",
      "        .   @brief Returns the number of logical CPUs available for the process.\n",
      "    \n",
      "    getOptimalDFTSize(...)\n",
      "        getOptimalDFTSize(vecsize) -> retval\n",
      "        .   @brief Returns the optimal DFT size for a given vector size.\n",
      "        .   \n",
      "        .   DFT performance is not a monotonic function of a vector size. Therefore, when you calculate\n",
      "        .   convolution of two arrays or perform the spectral analysis of an array, it usually makes sense to\n",
      "        .   pad the input data with zeros to get a bit larger array that can be transformed much faster than the\n",
      "        .   original one. Arrays whose size is a power-of-two (2, 4, 8, 16, 32, ...) are the fastest to process.\n",
      "        .   Though, the arrays whose size is a product of 2's, 3's, and 5's (for example, 300 = 5\\*5\\*3\\*2\\*2)\n",
      "        .   are also processed quite efficiently.\n",
      "        .   \n",
      "        .   The function cv::getOptimalDFTSize returns the minimum number N that is greater than or equal to vecsize\n",
      "        .   so that the DFT of a vector of size N can be processed efficiently. In the current implementation N\n",
      "        .   = 2 ^p^ \\* 3 ^q^ \\* 5 ^r^ for some integer p, q, r.\n",
      "        .   \n",
      "        .   The function returns a negative number if vecsize is too large (very close to INT_MAX ).\n",
      "        .   \n",
      "        .   While the function cannot be used directly to estimate the optimal vector size for DCT transform\n",
      "        .   (since the current DCT implementation supports only even-size vectors), it can be easily processed\n",
      "        .   as getOptimalDFTSize((vecsize+1)/2)\\*2.\n",
      "        .   @param vecsize vector size.\n",
      "        .   @sa dft , dct , idft , idct , mulSpectrums\n",
      "    \n",
      "    getOptimalNewCameraMatrix(...)\n",
      "        getOptimalNewCameraMatrix(cameraMatrix, distCoeffs, imageSize, alpha[, newImgSize[, centerPrincipalPoint]]) -> retval, validPixROI\n",
      "        .   @brief Returns the new camera matrix based on the free scaling parameter.\n",
      "        .   \n",
      "        .   @param cameraMatrix Input camera matrix.\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are\n",
      "        .   assumed.\n",
      "        .   @param imageSize Original image size.\n",
      "        .   @param alpha Free scaling parameter between 0 (when all the pixels in the undistorted image are\n",
      "        .   valid) and 1 (when all the source image pixels are retained in the undistorted image). See\n",
      "        .   stereoRectify for details.\n",
      "        .   @param newImgSize Image size after rectification. By default, it is set to imageSize .\n",
      "        .   @param validPixROI Optional output rectangle that outlines all-good-pixels region in the\n",
      "        .   undistorted image. See roi1, roi2 description in stereoRectify .\n",
      "        .   @param centerPrincipalPoint Optional flag that indicates whether in the new camera matrix the\n",
      "        .   principal point should be at the image center or not. By default, the principal point is chosen to\n",
      "        .   best fit a subset of the source image (determined by alpha) to the corrected image.\n",
      "        .   @return new_camera_matrix Output new camera matrix.\n",
      "        .   \n",
      "        .   The function computes and returns the optimal new camera matrix based on the free scaling parameter.\n",
      "        .   By varying this parameter, you may retrieve only sensible pixels alpha=0 , keep all the original\n",
      "        .   image pixels if there is valuable information in the corners alpha=1 , or get something in between.\n",
      "        .   When alpha\\>0 , the undistorted result is likely to have some black pixels corresponding to\n",
      "        .   \"virtual\" pixels outside of the captured distorted image. The original camera matrix, distortion\n",
      "        .   coefficients, the computed new camera matrix, and newImageSize should be passed to\n",
      "        .   initUndistortRectifyMap to produce the maps for remap .\n",
      "    \n",
      "    getPerspectiveTransform(...)\n",
      "        getPerspectiveTransform(src, dst[, solveMethod]) -> retval\n",
      "        .   @brief Calculates a perspective transform from four pairs of the corresponding points.\n",
      "        .   \n",
      "        .   The function calculates the \\f$3 \\times 3\\f$ matrix of a perspective transform so that:\n",
      "        .   \n",
      "        .   \\f[\\begin{bmatrix} t_i x'_i \\\\ t_i y'_i \\\\ t_i \\end{bmatrix} = \\texttt{map_matrix} \\cdot \\begin{bmatrix} x_i \\\\ y_i \\\\ 1 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \n",
      "        .   \\f[dst(i)=(x'_i,y'_i), src(i)=(x_i, y_i), i=0,1,2,3\\f]\n",
      "        .   \n",
      "        .   @param src Coordinates of quadrangle vertices in the source image.\n",
      "        .   @param dst Coordinates of the corresponding quadrangle vertices in the destination image.\n",
      "        .   @param solveMethod method passed to cv::solve (#DecompTypes)\n",
      "        .   \n",
      "        .   @sa  findHomography, warpPerspective, perspectiveTransform\n",
      "    \n",
      "    getRectSubPix(...)\n",
      "        getRectSubPix(image, patchSize, center[, patch[, patchType]]) -> patch\n",
      "        .   @brief Retrieves a pixel rectangle from an image with sub-pixel accuracy.\n",
      "        .   \n",
      "        .   The function getRectSubPix extracts pixels from src:\n",
      "        .   \n",
      "        .   \\f[patch(x, y) = src(x +  \\texttt{center.x} - ( \\texttt{dst.cols} -1)*0.5, y +  \\texttt{center.y} - ( \\texttt{dst.rows} -1)*0.5)\\f]\n",
      "        .   \n",
      "        .   where the values of the pixels at non-integer coordinates are retrieved using bilinear\n",
      "        .   interpolation. Every channel of multi-channel images is processed independently. Also\n",
      "        .   the image should be a single channel or three channel image. While the center of the\n",
      "        .   rectangle must be inside the image, parts of the rectangle may be outside.\n",
      "        .   \n",
      "        .   @param image Source image.\n",
      "        .   @param patchSize Size of the extracted patch.\n",
      "        .   @param center Floating point coordinates of the center of the extracted rectangle within the\n",
      "        .   source image. The center must be inside the image.\n",
      "        .   @param patch Extracted patch that has the size patchSize and the same number of channels as src .\n",
      "        .   @param patchType Depth of the extracted pixels. By default, they have the same depth as src .\n",
      "        .   \n",
      "        .   @sa  warpAffine, warpPerspective\n",
      "    \n",
      "    getRotationMatrix2D(...)\n",
      "        getRotationMatrix2D(center, angle, scale) -> retval\n",
      "        .   @brief Calculates an affine matrix of 2D rotation.\n",
      "        .   \n",
      "        .   The function calculates the following matrix:\n",
      "        .   \n",
      "        .   \\f[\\begin{bmatrix} \\alpha &  \\beta & (1- \\alpha )  \\cdot \\texttt{center.x} -  \\beta \\cdot \\texttt{center.y} \\\\ - \\beta &  \\alpha &  \\beta \\cdot \\texttt{center.x} + (1- \\alpha )  \\cdot \\texttt{center.y} \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \n",
      "        .   \\f[\\begin{array}{l} \\alpha =  \\texttt{scale} \\cdot \\cos \\texttt{angle} , \\\\ \\beta =  \\texttt{scale} \\cdot \\sin \\texttt{angle} \\end{array}\\f]\n",
      "        .   \n",
      "        .   The transformation maps the rotation center to itself. If this is not the target, adjust the shift.\n",
      "        .   \n",
      "        .   @param center Center of the rotation in the source image.\n",
      "        .   @param angle Rotation angle in degrees. Positive values mean counter-clockwise rotation (the\n",
      "        .   coordinate origin is assumed to be the top-left corner).\n",
      "        .   @param scale Isotropic scale factor.\n",
      "        .   \n",
      "        .   @sa  getAffineTransform, warpAffine, transform\n",
      "    \n",
      "    getStructuringElement(...)\n",
      "        getStructuringElement(shape, ksize[, anchor]) -> retval\n",
      "        .   @brief Returns a structuring element of the specified size and shape for morphological operations.\n",
      "        .   \n",
      "        .   The function constructs and returns the structuring element that can be further passed to #erode,\n",
      "        .   #dilate or #morphologyEx. But you can also construct an arbitrary binary mask yourself and use it as\n",
      "        .   the structuring element.\n",
      "        .   \n",
      "        .   @param shape Element shape that could be one of #MorphShapes\n",
      "        .   @param ksize Size of the structuring element.\n",
      "        .   @param anchor Anchor position within the element. The default value \\f$(-1, -1)\\f$ means that the\n",
      "        .   anchor is at the center. Note that only the shape of a cross-shaped element depends on the anchor\n",
      "        .   position. In other cases the anchor just regulates how much the result of the morphological\n",
      "        .   operation is shifted.\n",
      "    \n",
      "    getTextSize(...)\n",
      "        getTextSize(text, fontFace, fontScale, thickness) -> retval, baseLine\n",
      "        .   @brief Calculates the width and height of a text string.\n",
      "        .   \n",
      "        .   The function cv::getTextSize calculates and returns the size of a box that contains the specified text.\n",
      "        .   That is, the following code renders some text, the tight box surrounding it, and the baseline: :\n",
      "        .   @code\n",
      "        .       String text = \"Funny text inside the box\";\n",
      "        .       int fontFace = FONT_HERSHEY_SCRIPT_SIMPLEX;\n",
      "        .       double fontScale = 2;\n",
      "        .       int thickness = 3;\n",
      "        .   \n",
      "        .       Mat img(600, 800, CV_8UC3, Scalar::all(0));\n",
      "        .   \n",
      "        .       int baseline=0;\n",
      "        .       Size textSize = getTextSize(text, fontFace,\n",
      "        .                                   fontScale, thickness, &baseline);\n",
      "        .       baseline += thickness;\n",
      "        .   \n",
      "        .       // center the text\n",
      "        .       Point textOrg((img.cols - textSize.width)/2,\n",
      "        .                     (img.rows + textSize.height)/2);\n",
      "        .   \n",
      "        .       // draw the box\n",
      "        .       rectangle(img, textOrg + Point(0, baseline),\n",
      "        .                 textOrg + Point(textSize.width, -textSize.height),\n",
      "        .                 Scalar(0,0,255));\n",
      "        .       // ... and the baseline first\n",
      "        .       line(img, textOrg + Point(0, thickness),\n",
      "        .            textOrg + Point(textSize.width, thickness),\n",
      "        .            Scalar(0, 0, 255));\n",
      "        .   \n",
      "        .       // then put the text itself\n",
      "        .       putText(img, text, textOrg, fontFace, fontScale,\n",
      "        .               Scalar::all(255), thickness, 8);\n",
      "        .   @endcode\n",
      "        .   \n",
      "        .   @param text Input text string.\n",
      "        .   @param fontFace Font to use, see #HersheyFonts.\n",
      "        .   @param fontScale Font scale factor that is multiplied by the font-specific base size.\n",
      "        .   @param thickness Thickness of lines used to render the text. See #putText for details.\n",
      "        .   @param[out] baseLine y-coordinate of the baseline relative to the bottom-most text\n",
      "        .   point.\n",
      "        .   @return The size of a box that contains the specified text.\n",
      "        .   \n",
      "        .   @see putText\n",
      "    \n",
      "    getThreadNum(...)\n",
      "        getThreadNum() -> retval\n",
      "        .   @brief Returns the index of the currently executed thread within the current parallel region. Always\n",
      "        .   returns 0 if called outside of parallel region.\n",
      "        .   \n",
      "        .   @deprecated Current implementation doesn't corresponding to this documentation.\n",
      "        .   \n",
      "        .   The exact meaning of the return value depends on the threading framework used by OpenCV library:\n",
      "        .   - `TBB` - Unsupported with current 4.1 TBB release. Maybe will be supported in future.\n",
      "        .   - `OpenMP` - The thread number, within the current team, of the calling thread.\n",
      "        .   - `Concurrency` - An ID for the virtual processor that the current context is executing on (0\n",
      "        .     for master thread and unique number for others, but not necessary 1,2,3,...).\n",
      "        .   - `GCD` - System calling thread's ID. Never returns 0 inside parallel region.\n",
      "        .   - `C=` - The index of the current parallel task.\n",
      "        .   @sa setNumThreads, getNumThreads\n",
      "    \n",
      "    getTickCount(...)\n",
      "        getTickCount() -> retval\n",
      "        .   @brief Returns the number of ticks.\n",
      "        .   \n",
      "        .   The function returns the number of ticks after the certain event (for example, when the machine was\n",
      "        .   turned on). It can be used to initialize RNG or to measure a function execution time by reading the\n",
      "        .   tick count before and after the function call.\n",
      "        .   @sa getTickFrequency, TickMeter\n",
      "    \n",
      "    getTickFrequency(...)\n",
      "        getTickFrequency() -> retval\n",
      "        .   @brief Returns the number of ticks per second.\n",
      "        .   \n",
      "        .   The function returns the number of ticks per second. That is, the following code computes the\n",
      "        .   execution time in seconds:\n",
      "        .   @code\n",
      "        .       double t = (double)getTickCount();\n",
      "        .       // do something ...\n",
      "        .       t = ((double)getTickCount() - t)/getTickFrequency();\n",
      "        .   @endcode\n",
      "        .   @sa getTickCount, TickMeter\n",
      "    \n",
      "    getTrackbarPos(...)\n",
      "        getTrackbarPos(trackbarname, winname) -> retval\n",
      "        .   @brief Returns the trackbar position.\n",
      "        .   \n",
      "        .   The function returns the current position of the specified trackbar.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   [__Qt Backend Only__] winname can be empty if the trackbar is attached to the control\n",
      "        .   panel.\n",
      "        .   \n",
      "        .   @param trackbarname Name of the trackbar.\n",
      "        .   @param winname Name of the window that is the parent of the trackbar.\n",
      "    \n",
      "    getValidDisparityROI(...)\n",
      "        getValidDisparityROI(roi1, roi2, minDisparity, numberOfDisparities, blockSize) -> retval\n",
      "        .\n",
      "    \n",
      "    getVersionMajor(...)\n",
      "        getVersionMajor() -> retval\n",
      "        .   @brief Returns major library version\n",
      "    \n",
      "    getVersionMinor(...)\n",
      "        getVersionMinor() -> retval\n",
      "        .   @brief Returns minor library version\n",
      "    \n",
      "    getVersionRevision(...)\n",
      "        getVersionRevision() -> retval\n",
      "        .   @brief Returns revision field of the library version\n",
      "    \n",
      "    getVersionString(...)\n",
      "        getVersionString() -> retval\n",
      "        .   @brief Returns library version string\n",
      "        .   \n",
      "        .   For example \"3.4.1-dev\".\n",
      "        .   \n",
      "        .   @sa getMajorVersion, getMinorVersion, getRevisionVersion\n",
      "    \n",
      "    getWindowImageRect(...)\n",
      "        getWindowImageRect(winname) -> retval\n",
      "        .   @brief Provides rectangle of image in the window.\n",
      "        .   \n",
      "        .   The function getWindowImageRect returns the client screen coordinates, width and height of the image rendering area.\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   \n",
      "        .   @sa resizeWindow moveWindow\n",
      "    \n",
      "    getWindowProperty(...)\n",
      "        getWindowProperty(winname, prop_id) -> retval\n",
      "        .   @brief Provides parameters of a window.\n",
      "        .   \n",
      "        .   The function getWindowProperty returns properties of a window.\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   @param prop_id Window property to retrieve. The following operation flags are available: (cv::WindowPropertyFlags)\n",
      "        .   \n",
      "        .   @sa setWindowProperty\n",
      "    \n",
      "    goodFeaturesToTrack(...)\n",
      "        goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance[, corners[, mask[, blockSize[, useHarrisDetector[, k]]]]]) -> corners\n",
      "        .   @brief Determines strong corners on an image.\n",
      "        .   \n",
      "        .   The function finds the most prominent corners in the image or in the specified image region, as\n",
      "        .   described in @cite Shi94\n",
      "        .   \n",
      "        .   -   Function calculates the corner quality measure at every source image pixel using the\n",
      "        .       #cornerMinEigenVal or #cornerHarris .\n",
      "        .   -   Function performs a non-maximum suppression (the local maximums in *3 x 3* neighborhood are\n",
      "        .       retained).\n",
      "        .   -   The corners with the minimal eigenvalue less than\n",
      "        .       \\f$\\texttt{qualityLevel} \\cdot \\max_{x,y} qualityMeasureMap(x,y)\\f$ are rejected.\n",
      "        .   -   The remaining corners are sorted by the quality measure in the descending order.\n",
      "        .   -   Function throws away each corner for which there is a stronger corner at a distance less than\n",
      "        .       maxDistance.\n",
      "        .   \n",
      "        .   The function can be used to initialize a point-based tracker of an object.\n",
      "        .   \n",
      "        .   @note If the function is called with different values A and B of the parameter qualityLevel , and\n",
      "        .   A \\> B, the vector of returned corners with qualityLevel=A will be the prefix of the output vector\n",
      "        .   with qualityLevel=B .\n",
      "        .   \n",
      "        .   @param image Input 8-bit or floating-point 32-bit, single-channel image.\n",
      "        .   @param corners Output vector of detected corners.\n",
      "        .   @param maxCorners Maximum number of corners to return. If there are more corners than are found,\n",
      "        .   the strongest of them is returned. `maxCorners <= 0` implies that no limit on the maximum is set\n",
      "        .   and all detected corners are returned.\n",
      "        .   @param qualityLevel Parameter characterizing the minimal accepted quality of image corners. The\n",
      "        .   parameter value is multiplied by the best corner quality measure, which is the minimal eigenvalue\n",
      "        .   (see #cornerMinEigenVal ) or the Harris function response (see #cornerHarris ). The corners with the\n",
      "        .   quality measure less than the product are rejected. For example, if the best corner has the\n",
      "        .   quality measure = 1500, and the qualityLevel=0.01 , then all the corners with the quality measure\n",
      "        .   less than 15 are rejected.\n",
      "        .   @param minDistance Minimum possible Euclidean distance between the returned corners.\n",
      "        .   @param mask Optional region of interest. If the image is not empty (it needs to have the type\n",
      "        .   CV_8UC1 and the same size as image ), it specifies the region in which the corners are detected.\n",
      "        .   @param blockSize Size of an average block for computing a derivative covariation matrix over each\n",
      "        .   pixel neighborhood. See cornerEigenValsAndVecs .\n",
      "        .   @param useHarrisDetector Parameter indicating whether to use a Harris detector (see #cornerHarris)\n",
      "        .   or #cornerMinEigenVal.\n",
      "        .   @param k Free parameter of the Harris detector.\n",
      "        .   \n",
      "        .   @sa  cornerMinEigenVal, cornerHarris, calcOpticalFlowPyrLK, estimateRigidTransform,\n",
      "        \n",
      "        \n",
      "        \n",
      "        goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance, mask, blockSize, gradientSize[, corners[, useHarrisDetector[, k]]]) -> corners\n",
      "        .\n",
      "    \n",
      "    grabCut(...)\n",
      "        grabCut(img, mask, rect, bgdModel, fgdModel, iterCount[, mode]) -> mask, bgdModel, fgdModel\n",
      "        .   @brief Runs the GrabCut algorithm.\n",
      "        .   \n",
      "        .   The function implements the [GrabCut image segmentation algorithm](http://en.wikipedia.org/wiki/GrabCut).\n",
      "        .   \n",
      "        .   @param img Input 8-bit 3-channel image.\n",
      "        .   @param mask Input/output 8-bit single-channel mask. The mask is initialized by the function when\n",
      "        .   mode is set to #GC_INIT_WITH_RECT. Its elements may have one of the #GrabCutClasses.\n",
      "        .   @param rect ROI containing a segmented object. The pixels outside of the ROI are marked as\n",
      "        .   \"obvious background\". The parameter is only used when mode==#GC_INIT_WITH_RECT .\n",
      "        .   @param bgdModel Temporary array for the background model. Do not modify it while you are\n",
      "        .   processing the same image.\n",
      "        .   @param fgdModel Temporary arrays for the foreground model. Do not modify it while you are\n",
      "        .   processing the same image.\n",
      "        .   @param iterCount Number of iterations the algorithm should make before returning the result. Note\n",
      "        .   that the result can be refined with further calls with mode==#GC_INIT_WITH_MASK or\n",
      "        .   mode==GC_EVAL .\n",
      "        .   @param mode Operation mode that could be one of the #GrabCutModes\n",
      "    \n",
      "    groupRectangles(...)\n",
      "        groupRectangles(rectList, groupThreshold[, eps]) -> rectList, weights\n",
      "        .   @overload\n",
      "    \n",
      "    haveImageReader(...)\n",
      "        haveImageReader(filename) -> retval\n",
      "        .   @brief Returns true if the specified image can be decoded by OpenCV\n",
      "        .   \n",
      "        .   @param filename File name of the image\n",
      "    \n",
      "    haveImageWriter(...)\n",
      "        haveImageWriter(filename) -> retval\n",
      "        .   @brief Returns true if an image with the specified filename can be encoded by OpenCV\n",
      "        .   \n",
      "        .    @param filename File name of the image\n",
      "    \n",
      "    haveOpenVX(...)\n",
      "        haveOpenVX() -> retval\n",
      "        .\n",
      "    \n",
      "    hconcat(...)\n",
      "        hconcat(src[, dst]) -> dst\n",
      "        .   @overload\n",
      "        .    @code{.cpp}\n",
      "        .       std::vector<cv::Mat> matrices = { cv::Mat(4, 1, CV_8UC1, cv::Scalar(1)),\n",
      "        .                                         cv::Mat(4, 1, CV_8UC1, cv::Scalar(2)),\n",
      "        .                                         cv::Mat(4, 1, CV_8UC1, cv::Scalar(3)),};\n",
      "        .   \n",
      "        .       cv::Mat out;\n",
      "        .       cv::hconcat( matrices, out );\n",
      "        .       //out:\n",
      "        .       //[1, 2, 3;\n",
      "        .       // 1, 2, 3;\n",
      "        .       // 1, 2, 3;\n",
      "        .       // 1, 2, 3]\n",
      "        .    @endcode\n",
      "        .    @param src input array or vector of matrices. all of the matrices must have the same number of rows and the same depth.\n",
      "        .    @param dst output array. It has the same number of rows and depth as the src, and the sum of cols of the src.\n",
      "        .   same depth.\n",
      "    \n",
      "    idct(...)\n",
      "        idct(src[, dst[, flags]]) -> dst\n",
      "        .   @brief Calculates the inverse Discrete Cosine Transform of a 1D or 2D array.\n",
      "        .   \n",
      "        .   idct(src, dst, flags) is equivalent to dct(src, dst, flags | DCT_INVERSE).\n",
      "        .   @param src input floating-point single-channel array.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "        .   @param flags operation flags.\n",
      "        .   @sa  dct, dft, idft, getOptimalDFTSize\n",
      "    \n",
      "    idft(...)\n",
      "        idft(src[, dst[, flags[, nonzeroRows]]]) -> dst\n",
      "        .   @brief Calculates the inverse Discrete Fourier Transform of a 1D or 2D array.\n",
      "        .   \n",
      "        .   idft(src, dst, flags) is equivalent to dft(src, dst, flags | #DFT_INVERSE) .\n",
      "        .   @note None of dft and idft scales the result by default. So, you should pass #DFT_SCALE to one of\n",
      "        .   dft or idft explicitly to make these transforms mutually inverse.\n",
      "        .   @sa dft, dct, idct, mulSpectrums, getOptimalDFTSize\n",
      "        .   @param src input floating-point real or complex array.\n",
      "        .   @param dst output array whose size and type depend on the flags.\n",
      "        .   @param flags operation flags (see dft and #DftFlags).\n",
      "        .   @param nonzeroRows number of dst rows to process; the rest of the rows have undefined content (see\n",
      "        .   the convolution sample in dft description.\n",
      "    \n",
      "    illuminationChange(...)\n",
      "        illuminationChange(src, mask[, dst[, alpha[, beta]]]) -> dst\n",
      "        .   @brief Applying an appropriate non-linear transformation to the gradient field inside the selection and\n",
      "        .   then integrating back with a Poisson solver, modifies locally the apparent illumination of an image.\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param mask Input 8-bit 1 or 3-channel image.\n",
      "        .   @param dst Output image with the same size and type as src.\n",
      "        .   @param alpha Value ranges between 0-2.\n",
      "        .   @param beta Value ranges between 0-2.\n",
      "        .   \n",
      "        .   This is useful to highlight under-exposed foreground objects or to reduce specular reflections.\n",
      "    \n",
      "    imdecode(...)\n",
      "        imdecode(buf, flags) -> retval\n",
      "        .   @brief Reads an image from a buffer in memory.\n",
      "        .   \n",
      "        .   The function imdecode reads an image from the specified buffer in the memory. If the buffer is too short or\n",
      "        .   contains invalid data, the function returns an empty matrix ( Mat::data==NULL ).\n",
      "        .   \n",
      "        .   See cv::imread for the list of supported formats and flags description.\n",
      "        .   \n",
      "        .   @note In the case of color images, the decoded images will have the channels stored in **B G R** order.\n",
      "        .   @param buf Input array or vector of bytes.\n",
      "        .   @param flags The same flags as in cv::imread, see cv::ImreadModes.\n",
      "    \n",
      "    imencode(...)\n",
      "        imencode(ext, img[, params]) -> retval, buf\n",
      "        .   @brief Encodes an image into a memory buffer.\n",
      "        .   \n",
      "        .   The function imencode compresses the image and stores it in the memory buffer that is resized to fit the\n",
      "        .   result. See cv::imwrite for the list of supported formats and flags description.\n",
      "        .   \n",
      "        .   @param ext File extension that defines the output format.\n",
      "        .   @param img Image to be written.\n",
      "        .   @param buf Output buffer resized to fit the compressed image.\n",
      "        .   @param params Format-specific parameters. See cv::imwrite and cv::ImwriteFlags.\n",
      "    \n",
      "    imread(...)\n",
      "        imread(filename[, flags]) -> retval\n",
      "        .   @brief Loads an image from a file.\n",
      "        .   \n",
      "        .   @anchor imread\n",
      "        .   \n",
      "        .   The function imread loads an image from the specified file and returns it. If the image cannot be\n",
      "        .   read (because of missing file, improper permissions, unsupported or invalid format), the function\n",
      "        .   returns an empty matrix ( Mat::data==NULL ).\n",
      "        .   \n",
      "        .   Currently, the following file formats are supported:\n",
      "        .   \n",
      "        .   -   Windows bitmaps - \\*.bmp, \\*.dib (always supported)\n",
      "        .   -   JPEG files - \\*.jpeg, \\*.jpg, \\*.jpe (see the *Note* section)\n",
      "        .   -   JPEG 2000 files - \\*.jp2 (see the *Note* section)\n",
      "        .   -   Portable Network Graphics - \\*.png (see the *Note* section)\n",
      "        .   -   WebP - \\*.webp (see the *Note* section)\n",
      "        .   -   Portable image format - \\*.pbm, \\*.pgm, \\*.ppm \\*.pxm, \\*.pnm (always supported)\n",
      "        .   -   PFM files - \\*.pfm (see the *Note* section)\n",
      "        .   -   Sun rasters - \\*.sr, \\*.ras (always supported)\n",
      "        .   -   TIFF files - \\*.tiff, \\*.tif (see the *Note* section)\n",
      "        .   -   OpenEXR Image files - \\*.exr (see the *Note* section)\n",
      "        .   -   Radiance HDR - \\*.hdr, \\*.pic (always supported)\n",
      "        .   -   Raster and Vector geospatial data supported by GDAL (see the *Note* section)\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   The function determines the type of an image by the content, not by the file extension.\n",
      "        .   -   In the case of color images, the decoded images will have the channels stored in **B G R** order.\n",
      "        .   -   When using IMREAD_GRAYSCALE, the codec's internal grayscale conversion will be used, if available.\n",
      "        .       Results may differ to the output of cvtColor()\n",
      "        .   -   On Microsoft Windows\\* OS and MacOSX\\*, the codecs shipped with an OpenCV image (libjpeg,\n",
      "        .       libpng, libtiff, and libjasper) are used by default. So, OpenCV can always read JPEGs, PNGs,\n",
      "        .       and TIFFs. On MacOSX, there is also an option to use native MacOSX image readers. But beware\n",
      "        .       that currently these native image loaders give images with different pixel values because of\n",
      "        .       the color management embedded into MacOSX.\n",
      "        .   -   On Linux\\*, BSD flavors and other Unix-like open-source operating systems, OpenCV looks for\n",
      "        .       codecs supplied with an OS image. Install the relevant packages (do not forget the development\n",
      "        .       files, for example, \"libjpeg-dev\", in Debian\\* and Ubuntu\\*) to get the codec support or turn\n",
      "        .       on the OPENCV_BUILD_3RDPARTY_LIBS flag in CMake.\n",
      "        .   -   In the case you set *WITH_GDAL* flag to true in CMake and @ref IMREAD_LOAD_GDAL to load the image,\n",
      "        .       then the [GDAL](http://www.gdal.org) driver will be used in order to decode the image, supporting\n",
      "        .       the following formats: [Raster](http://www.gdal.org/formats_list.html),\n",
      "        .       [Vector](http://www.gdal.org/ogr_formats.html).\n",
      "        .   -   If EXIF information is embedded in the image file, the EXIF orientation will be taken into account\n",
      "        .       and thus the image will be rotated accordingly except if the flags @ref IMREAD_IGNORE_ORIENTATION\n",
      "        .       or @ref IMREAD_UNCHANGED are passed.\n",
      "        .   -   Use the IMREAD_UNCHANGED flag to keep the floating point values from PFM image.\n",
      "        .   -   By default number of pixels must be less than 2^30. Limit can be set using system\n",
      "        .       variable OPENCV_IO_MAX_IMAGE_PIXELS\n",
      "        .   \n",
      "        .   @param filename Name of file to be loaded.\n",
      "        .   @param flags Flag that can take values of cv::ImreadModes\n",
      "    \n",
      "    imreadmulti(...)\n",
      "        imreadmulti(filename[, mats[, flags]]) -> retval, mats\n",
      "        .   @brief Loads a multi-page image from a file.\n",
      "        .   \n",
      "        .   The function imreadmulti loads a multi-page image from the specified file into a vector of Mat objects.\n",
      "        .   @param filename Name of file to be loaded.\n",
      "        .   @param flags Flag that can take values of cv::ImreadModes, default with cv::IMREAD_ANYCOLOR.\n",
      "        .   @param mats A vector of Mat objects holding each page, if more than one.\n",
      "        .   @sa cv::imread\n",
      "    \n",
      "    imshow(...)\n",
      "        imshow(winname, mat) -> None\n",
      "        .   @brief Displays an image in the specified window.\n",
      "        .   \n",
      "        .   The function imshow displays an image in the specified window. If the window was created with the\n",
      "        .   cv::WINDOW_AUTOSIZE flag, the image is shown with its original size, however it is still limited by the screen resolution.\n",
      "        .   Otherwise, the image is scaled to fit the window. The function may scale the image, depending on its depth:\n",
      "        .   \n",
      "        .   -   If the image is 8-bit unsigned, it is displayed as is.\n",
      "        .   -   If the image is 16-bit unsigned or 32-bit integer, the pixels are divided by 256. That is, the\n",
      "        .       value range [0,255\\*256] is mapped to [0,255].\n",
      "        .   -   If the image is 32-bit or 64-bit floating-point, the pixel values are multiplied by 255. That is, the\n",
      "        .       value range [0,1] is mapped to [0,255].\n",
      "        .   \n",
      "        .   If window was created with OpenGL support, cv::imshow also support ogl::Buffer , ogl::Texture2D and\n",
      "        .   cuda::GpuMat as input.\n",
      "        .   \n",
      "        .   If the window was not created before this function, it is assumed creating a window with cv::WINDOW_AUTOSIZE.\n",
      "        .   \n",
      "        .   If you need to show an image that is bigger than the screen resolution, you will need to call namedWindow(\"\", WINDOW_NORMAL) before the imshow.\n",
      "        .   \n",
      "        .   @note This function should be followed by cv::waitKey function which displays the image for specified\n",
      "        .   milliseconds. Otherwise, it won't display the image. For example, **waitKey(0)** will display the window\n",
      "        .   infinitely until any keypress (it is suitable for image display). **waitKey(25)** will display a frame\n",
      "        .   for 25 ms, after which display will be automatically closed. (If you put it in a loop to read\n",
      "        .   videos, it will display the video frame-by-frame)\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   [__Windows Backend Only__] Pressing Ctrl+C will copy the image to the clipboard.\n",
      "        .   \n",
      "        .   [__Windows Backend Only__] Pressing Ctrl+S will show a dialog to save the image.\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   @param mat Image to be shown.\n",
      "    \n",
      "    imwrite(...)\n",
      "        imwrite(filename, img[, params]) -> retval\n",
      "        .   @brief Saves an image to a specified file.\n",
      "        .   \n",
      "        .   The function imwrite saves the image to the specified file. The image format is chosen based on the\n",
      "        .   filename extension (see cv::imread for the list of extensions). In general, only 8-bit\n",
      "        .   single-channel or 3-channel (with 'BGR' channel order) images\n",
      "        .   can be saved using this function, with these exceptions:\n",
      "        .   \n",
      "        .   - 16-bit unsigned (CV_16U) images can be saved in the case of PNG, JPEG 2000, and TIFF formats\n",
      "        .   - 32-bit float (CV_32F) images can be saved in PFM, TIFF, OpenEXR, and Radiance HDR formats;\n",
      "        .     3-channel (CV_32FC3) TIFF images will be saved using the LogLuv high dynamic range encoding\n",
      "        .     (4 bytes per pixel)\n",
      "        .   - PNG images with an alpha channel can be saved using this function. To do this, create\n",
      "        .   8-bit (or 16-bit) 4-channel image BGRA, where the alpha channel goes last. Fully transparent pixels\n",
      "        .   should have alpha set to 0, fully opaque pixels should have alpha set to 255/65535 (see the code sample below).\n",
      "        .   - Multiple images (vector of Mat) can be saved in TIFF format (see the code sample below).\n",
      "        .   \n",
      "        .   If the format, depth or channel order is different, use\n",
      "        .   Mat::convertTo and cv::cvtColor to convert it before saving. Or, use the universal FileStorage I/O\n",
      "        .   functions to save the image to XML or YAML format.\n",
      "        .   \n",
      "        .   The sample below shows how to create a BGRA image, how to set custom compression parameters and save it to a PNG file.\n",
      "        .   It also demonstrates how to save multiple images in a TIFF file:\n",
      "        .   @include snippets/imgcodecs_imwrite.cpp\n",
      "        .   @param filename Name of the file.\n",
      "        .   @param img (Mat or vector of Mat) Image or Images to be saved.\n",
      "        .   @param params Format-specific parameters encoded as pairs (paramId_1, paramValue_1, paramId_2, paramValue_2, ... .) see cv::ImwriteFlags\n",
      "    \n",
      "    inRange(...)\n",
      "        inRange(src, lowerb, upperb[, dst]) -> dst\n",
      "        .   @brief  Checks if array elements lie between the elements of two other arrays.\n",
      "        .   \n",
      "        .   The function checks the range as follows:\n",
      "        .   -   For every element of a single-channel input array:\n",
      "        .       \\f[\\texttt{dst} (I)= \\texttt{lowerb} (I)_0  \\leq \\texttt{src} (I)_0 \\leq  \\texttt{upperb} (I)_0\\f]\n",
      "        .   -   For two-channel arrays:\n",
      "        .       \\f[\\texttt{dst} (I)= \\texttt{lowerb} (I)_0  \\leq \\texttt{src} (I)_0 \\leq  \\texttt{upperb} (I)_0  \\land \\texttt{lowerb} (I)_1  \\leq \\texttt{src} (I)_1 \\leq  \\texttt{upperb} (I)_1\\f]\n",
      "        .   -   and so forth.\n",
      "        .   \n",
      "        .   That is, dst (I) is set to 255 (all 1 -bits) if src (I) is within the\n",
      "        .   specified 1D, 2D, 3D, ... box and 0 otherwise.\n",
      "        .   \n",
      "        .   When the lower and/or upper boundary parameters are scalars, the indexes\n",
      "        .   (I) at lowerb and upperb in the above formulas should be omitted.\n",
      "        .   @param src first input array.\n",
      "        .   @param lowerb inclusive lower boundary array or a scalar.\n",
      "        .   @param upperb inclusive upper boundary array or a scalar.\n",
      "        .   @param dst output array of the same size as src and CV_8U type.\n",
      "    \n",
      "    initCameraMatrix2D(...)\n",
      "        initCameraMatrix2D(objectPoints, imagePoints, imageSize[, aspectRatio]) -> retval\n",
      "        .   @brief Finds an initial camera matrix from 3D-2D point correspondences.\n",
      "        .   \n",
      "        .   @param objectPoints Vector of vectors of the calibration pattern points in the calibration pattern\n",
      "        .   coordinate space. In the old interface all the per-view vectors are concatenated. See\n",
      "        .   calibrateCamera for details.\n",
      "        .   @param imagePoints Vector of vectors of the projections of the calibration pattern points. In the\n",
      "        .   old interface all the per-view vectors are concatenated.\n",
      "        .   @param imageSize Image size in pixels used to initialize the principal point.\n",
      "        .   @param aspectRatio If it is zero or negative, both \\f$f_x\\f$ and \\f$f_y\\f$ are estimated independently.\n",
      "        .   Otherwise, \\f$f_x = f_y * \\texttt{aspectRatio}\\f$ .\n",
      "        .   \n",
      "        .   The function estimates and returns an initial camera matrix for the camera calibration process.\n",
      "        .   Currently, the function only supports planar calibration patterns, which are patterns where each\n",
      "        .   object point has z-coordinate =0.\n",
      "    \n",
      "    initUndistortRectifyMap(...)\n",
      "        initUndistortRectifyMap(cameraMatrix, distCoeffs, R, newCameraMatrix, size, m1type[, map1[, map2]]) -> map1, map2\n",
      "        .   @brief Computes the undistortion and rectification transformation map.\n",
      "        .   \n",
      "        .   The function computes the joint undistortion and rectification transformation and represents the\n",
      "        .   result in the form of maps for remap. The undistorted image looks like original, as if it is\n",
      "        .   captured with a camera using the camera matrix =newCameraMatrix and zero distortion. In case of a\n",
      "        .   monocular camera, newCameraMatrix is usually equal to cameraMatrix, or it can be computed by\n",
      "        .   #getOptimalNewCameraMatrix for a better control over scaling. In case of a stereo camera,\n",
      "        .   newCameraMatrix is normally set to P1 or P2 computed by #stereoRectify .\n",
      "        .   \n",
      "        .   Also, this new camera is oriented differently in the coordinate space, according to R. That, for\n",
      "        .   example, helps to align two heads of a stereo camera so that the epipolar lines on both images\n",
      "        .   become horizontal and have the same y- coordinate (in case of a horizontally aligned stereo camera).\n",
      "        .   \n",
      "        .   The function actually builds the maps for the inverse mapping algorithm that is used by remap. That\n",
      "        .   is, for each pixel \\f$(u, v)\\f$ in the destination (corrected and rectified) image, the function\n",
      "        .   computes the corresponding coordinates in the source image (that is, in the original image from\n",
      "        .   camera). The following process is applied:\n",
      "        .   \\f[\n",
      "        .   \\begin{array}{l}\n",
      "        .   x  \\leftarrow (u - {c'}_x)/{f'}_x  \\\\\n",
      "        .   y  \\leftarrow (v - {c'}_y)/{f'}_y  \\\\\n",
      "        .   {[X\\,Y\\,W]} ^T  \\leftarrow R^{-1}*[x \\, y \\, 1]^T  \\\\\n",
      "        .   x'  \\leftarrow X/W  \\\\\n",
      "        .   y'  \\leftarrow Y/W  \\\\\n",
      "        .   r^2  \\leftarrow x'^2 + y'^2 \\\\\n",
      "        .   x''  \\leftarrow x' \\frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6}\n",
      "        .   + 2p_1 x' y' + p_2(r^2 + 2 x'^2)  + s_1 r^2 + s_2 r^4\\\\\n",
      "        .   y''  \\leftarrow y' \\frac{1 + k_1 r^2 + k_2 r^4 + k_3 r^6}{1 + k_4 r^2 + k_5 r^4 + k_6 r^6}\n",
      "        .   + p_1 (r^2 + 2 y'^2) + 2 p_2 x' y' + s_3 r^2 + s_4 r^4 \\\\\n",
      "        .   s\\vecthree{x'''}{y'''}{1} =\n",
      "        .   \\vecthreethree{R_{33}(\\tau_x, \\tau_y)}{0}{-R_{13}((\\tau_x, \\tau_y)}\n",
      "        .   {0}{R_{33}(\\tau_x, \\tau_y)}{-R_{23}(\\tau_x, \\tau_y)}\n",
      "        .   {0}{0}{1} R(\\tau_x, \\tau_y) \\vecthree{x''}{y''}{1}\\\\\n",
      "        .   map_x(u,v)  \\leftarrow x''' f_x + c_x  \\\\\n",
      "        .   map_y(u,v)  \\leftarrow y''' f_y + c_y\n",
      "        .   \\end{array}\n",
      "        .   \\f]\n",
      "        .   where \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$\n",
      "        .   are the distortion coefficients.\n",
      "        .   \n",
      "        .   In case of a stereo camera, this function is called twice: once for each camera head, after\n",
      "        .   stereoRectify, which in its turn is called after #stereoCalibrate. But if the stereo camera\n",
      "        .   was not calibrated, it is still possible to compute the rectification transformations directly from\n",
      "        .   the fundamental matrix using #stereoRectifyUncalibrated. For each camera, the function computes\n",
      "        .   homography H as the rectification transformation in a pixel domain, not a rotation matrix R in 3D\n",
      "        .   space. R can be computed from H as\n",
      "        .   \\f[\\texttt{R} = \\texttt{cameraMatrix} ^{-1} \\cdot \\texttt{H} \\cdot \\texttt{cameraMatrix}\\f]\n",
      "        .   where cameraMatrix can be chosen arbitrarily.\n",
      "        .   \n",
      "        .   @param cameraMatrix Input camera matrix \\f$A=\\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$\n",
      "        .   of 4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are assumed.\n",
      "        .   @param R Optional rectification transformation in the object space (3x3 matrix). R1 or R2 ,\n",
      "        .   computed by #stereoRectify can be passed here. If the matrix is empty, the identity transformation\n",
      "        .   is assumed. In cvInitUndistortMap R assumed to be an identity matrix.\n",
      "        .   @param newCameraMatrix New camera matrix \\f$A'=\\vecthreethree{f_x'}{0}{c_x'}{0}{f_y'}{c_y'}{0}{0}{1}\\f$.\n",
      "        .   @param size Undistorted image size.\n",
      "        .   @param m1type Type of the first output map that can be CV_32FC1, CV_32FC2 or CV_16SC2, see #convertMaps\n",
      "        .   @param map1 The first output map.\n",
      "        .   @param map2 The second output map.\n",
      "    \n",
      "    inpaint(...)\n",
      "        inpaint(src, inpaintMask, inpaintRadius, flags[, dst]) -> dst\n",
      "        .   @brief Restores the selected region in an image using the region neighborhood.\n",
      "        .   \n",
      "        .   @param src Input 8-bit, 16-bit unsigned or 32-bit float 1-channel or 8-bit 3-channel image.\n",
      "        .   @param inpaintMask Inpainting mask, 8-bit 1-channel image. Non-zero pixels indicate the area that\n",
      "        .   needs to be inpainted.\n",
      "        .   @param dst Output image with the same size and type as src .\n",
      "        .   @param inpaintRadius Radius of a circular neighborhood of each point inpainted that is considered\n",
      "        .   by the algorithm.\n",
      "        .   @param flags Inpainting method that could be cv::INPAINT_NS or cv::INPAINT_TELEA\n",
      "        .   \n",
      "        .   The function reconstructs the selected image area from the pixel near the area boundary. The\n",
      "        .   function may be used to remove dust and scratches from a scanned photo, or to remove undesirable\n",
      "        .   objects from still images or video. See <http://en.wikipedia.org/wiki/Inpainting> for more details.\n",
      "        .   \n",
      "        .   @note\n",
      "        .      -   An example using the inpainting technique can be found at\n",
      "        .           opencv_source_code/samples/cpp/inpaint.cpp\n",
      "        .      -   (Python) An example using the inpainting technique can be found at\n",
      "        .           opencv_source_code/samples/python/inpaint.py\n",
      "    \n",
      "    insertChannel(...)\n",
      "        insertChannel(src, dst, coi) -> dst\n",
      "        .   @brief Inserts a single channel to dst (coi is 0-based index)\n",
      "        .   @param src input array\n",
      "        .   @param dst output array\n",
      "        .   @param coi index of channel for insertion\n",
      "        .   @sa mixChannels, merge\n",
      "    \n",
      "    integral(...)\n",
      "        integral(src[, sum[, sdepth]]) -> sum\n",
      "        .   @overload\n",
      "    \n",
      "    integral2(...)\n",
      "        integral2(src[, sum[, sqsum[, sdepth[, sqdepth]]]]) -> sum, sqsum\n",
      "        .   @overload\n",
      "    \n",
      "    integral3(...)\n",
      "        integral3(src[, sum[, sqsum[, tilted[, sdepth[, sqdepth]]]]]) -> sum, sqsum, tilted\n",
      "        .   @brief Calculates the integral of an image.\n",
      "        .   \n",
      "        .   The function calculates one or more integral images for the source image as follows:\n",
      "        .   \n",
      "        .   \\f[\\texttt{sum} (X,Y) =  \\sum _{x<X,y<Y}  \\texttt{image} (x,y)\\f]\n",
      "        .   \n",
      "        .   \\f[\\texttt{sqsum} (X,Y) =  \\sum _{x<X,y<Y}  \\texttt{image} (x,y)^2\\f]\n",
      "        .   \n",
      "        .   \\f[\\texttt{tilted} (X,Y) =  \\sum _{y<Y,abs(x-X+1) \\leq Y-y-1}  \\texttt{image} (x,y)\\f]\n",
      "        .   \n",
      "        .   Using these integral images, you can calculate sum, mean, and standard deviation over a specific\n",
      "        .   up-right or rotated rectangular region of the image in a constant time, for example:\n",
      "        .   \n",
      "        .   \\f[\\sum _{x_1 \\leq x < x_2,  \\, y_1  \\leq y < y_2}  \\texttt{image} (x,y) =  \\texttt{sum} (x_2,y_2)- \\texttt{sum} (x_1,y_2)- \\texttt{sum} (x_2,y_1)+ \\texttt{sum} (x_1,y_1)\\f]\n",
      "        .   \n",
      "        .   It makes possible to do a fast blurring or fast block correlation with a variable window size, for\n",
      "        .   example. In case of multi-channel images, sums for each channel are accumulated independently.\n",
      "        .   \n",
      "        .   As a practical example, the next figure shows the calculation of the integral of a straight\n",
      "        .   rectangle Rect(3,3,3,2) and of a tilted rectangle Rect(5,1,2,3) . The selected pixels in the\n",
      "        .   original image are shown, as well as the relative pixels in the integral images sum and tilted .\n",
      "        .   \n",
      "        .   ![integral calculation example](pics/integral.png)\n",
      "        .   \n",
      "        .   @param src input image as \\f$W \\times H\\f$, 8-bit or floating-point (32f or 64f).\n",
      "        .   @param sum integral image as \\f$(W+1)\\times (H+1)\\f$ , 32-bit integer or floating-point (32f or 64f).\n",
      "        .   @param sqsum integral image for squared pixel values; it is \\f$(W+1)\\times (H+1)\\f$, double-precision\n",
      "        .   floating-point (64f) array.\n",
      "        .   @param tilted integral for the image rotated by 45 degrees; it is \\f$(W+1)\\times (H+1)\\f$ array with\n",
      "        .   the same data type as sum.\n",
      "        .   @param sdepth desired depth of the integral and the tilted integral images, CV_32S, CV_32F, or\n",
      "        .   CV_64F.\n",
      "        .   @param sqdepth desired depth of the integral image of squared pixel values, CV_32F or CV_64F.\n",
      "    \n",
      "    intersectConvexConvex(...)\n",
      "        intersectConvexConvex(_p1, _p2[, _p12[, handleNested]]) -> retval, _p12\n",
      "        .   @brief Finds intersection of two convex polygons\n",
      "        .   \n",
      "        .   @param _p1 First polygon\n",
      "        .   @param _p2 Second polygon\n",
      "        .   @param _p12 Output polygon describing the intersecting area\n",
      "        .   @param handleNested When true, an intersection is found if one of the polygons is fully enclosed in the other.\n",
      "        .   When false, no intersection is found. If the polygons share a side or the vertex of one polygon lies on an edge\n",
      "        .   of the other, they are not considered nested and an intersection will be found regardless of the value of handleNested.\n",
      "        .   \n",
      "        .   @returns Absolute value of area of intersecting polygon\n",
      "        .   \n",
      "        .   @note intersectConvexConvex doesn't confirm that both polygons are convex and will return invalid results if they aren't.\n",
      "    \n",
      "    invert(...)\n",
      "        invert(src[, dst[, flags]]) -> retval, dst\n",
      "        .   @brief Finds the inverse or pseudo-inverse of a matrix.\n",
      "        .   \n",
      "        .   The function cv::invert inverts the matrix src and stores the result in dst\n",
      "        .   . When the matrix src is singular or non-square, the function calculates\n",
      "        .   the pseudo-inverse matrix (the dst matrix) so that norm(src\\*dst - I) is\n",
      "        .   minimal, where I is an identity matrix.\n",
      "        .   \n",
      "        .   In case of the #DECOMP_LU method, the function returns non-zero value if\n",
      "        .   the inverse has been successfully calculated and 0 if src is singular.\n",
      "        .   \n",
      "        .   In case of the #DECOMP_SVD method, the function returns the inverse\n",
      "        .   condition number of src (the ratio of the smallest singular value to the\n",
      "        .   largest singular value) and 0 if src is singular. The SVD method\n",
      "        .   calculates a pseudo-inverse matrix if src is singular.\n",
      "        .   \n",
      "        .   Similarly to #DECOMP_LU, the method #DECOMP_CHOLESKY works only with\n",
      "        .   non-singular square matrices that should also be symmetrical and\n",
      "        .   positively defined. In this case, the function stores the inverted\n",
      "        .   matrix in dst and returns non-zero. Otherwise, it returns 0.\n",
      "        .   \n",
      "        .   @param src input floating-point M x N matrix.\n",
      "        .   @param dst output matrix of N x M size and the same type as src.\n",
      "        .   @param flags inversion method (cv::DecompTypes)\n",
      "        .   @sa solve, SVD\n",
      "    \n",
      "    invertAffineTransform(...)\n",
      "        invertAffineTransform(M[, iM]) -> iM\n",
      "        .   @brief Inverts an affine transformation.\n",
      "        .   \n",
      "        .   The function computes an inverse affine transformation represented by \\f$2 \\times 3\\f$ matrix M:\n",
      "        .   \n",
      "        .   \\f[\\begin{bmatrix} a_{11} & a_{12} & b_1  \\\\ a_{21} & a_{22} & b_2 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   The result is also a \\f$2 \\times 3\\f$ matrix of the same type as M.\n",
      "        .   \n",
      "        .   @param M Original affine transformation.\n",
      "        .   @param iM Output reverse affine transformation.\n",
      "    \n",
      "    isContourConvex(...)\n",
      "        isContourConvex(contour) -> retval\n",
      "        .   @brief Tests a contour convexity.\n",
      "        .   \n",
      "        .   The function tests whether the input contour is convex or not. The contour must be simple, that is,\n",
      "        .   without self-intersections. Otherwise, the function output is undefined.\n",
      "        .   \n",
      "        .   @param contour Input vector of 2D points, stored in std::vector\\<\\> or Mat\n",
      "    \n",
      "    kmeans(...)\n",
      "        kmeans(data, K, bestLabels, criteria, attempts, flags[, centers]) -> retval, bestLabels, centers\n",
      "        .   @brief Finds centers of clusters and groups input samples around the clusters.\n",
      "        .   \n",
      "        .   The function kmeans implements a k-means algorithm that finds the centers of cluster_count clusters\n",
      "        .   and groups the input samples around the clusters. As an output, \\f$\\texttt{bestLabels}_i\\f$ contains a\n",
      "        .   0-based cluster index for the sample stored in the \\f$i^{th}\\f$ row of the samples matrix.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   (Python) An example on K-means clustering can be found at\n",
      "        .       opencv_source_code/samples/python/kmeans.py\n",
      "        .   @param data Data for clustering. An array of N-Dimensional points with float coordinates is needed.\n",
      "        .   Examples of this array can be:\n",
      "        .   -   Mat points(count, 2, CV_32F);\n",
      "        .   -   Mat points(count, 1, CV_32FC2);\n",
      "        .   -   Mat points(1, count, CV_32FC2);\n",
      "        .   -   std::vector\\<cv::Point2f\\> points(sampleCount);\n",
      "        .   @param K Number of clusters to split the set by.\n",
      "        .   @param bestLabels Input/output integer array that stores the cluster indices for every sample.\n",
      "        .   @param criteria The algorithm termination criteria, that is, the maximum number of iterations and/or\n",
      "        .   the desired accuracy. The accuracy is specified as criteria.epsilon. As soon as each of the cluster\n",
      "        .   centers moves by less than criteria.epsilon on some iteration, the algorithm stops.\n",
      "        .   @param attempts Flag to specify the number of times the algorithm is executed using different\n",
      "        .   initial labellings. The algorithm returns the labels that yield the best compactness (see the last\n",
      "        .   function parameter).\n",
      "        .   @param flags Flag that can take values of cv::KmeansFlags\n",
      "        .   @param centers Output matrix of the cluster centers, one row per each cluster center.\n",
      "        .   @return The function returns the compactness measure that is computed as\n",
      "        .   \\f[\\sum _i  \\| \\texttt{samples} _i -  \\texttt{centers} _{ \\texttt{labels} _i} \\| ^2\\f]\n",
      "        .   after every attempt. The best (minimum) value is chosen and the corresponding labels and the\n",
      "        .   compactness value are returned by the function. Basically, you can use only the core of the\n",
      "        .   function, set the number of attempts to 1, initialize labels each time using a custom algorithm,\n",
      "        .   pass them with the ( flags = #KMEANS_USE_INITIAL_LABELS ) flag, and then choose the best\n",
      "        .   (most-compact) clustering.\n",
      "    \n",
      "    line(...)\n",
      "        line(img, pt1, pt2, color[, thickness[, lineType[, shift]]]) -> img\n",
      "        .   @brief Draws a line segment connecting two points.\n",
      "        .   \n",
      "        .   The function line draws the line segment between pt1 and pt2 points in the image. The line is\n",
      "        .   clipped by the image boundaries. For non-antialiased lines with integer coordinates, the 8-connected\n",
      "        .   or 4-connected Bresenham algorithm is used. Thick lines are drawn with rounding endings. Antialiased\n",
      "        .   lines are drawn using Gaussian filtering.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param pt1 First point of the line segment.\n",
      "        .   @param pt2 Second point of the line segment.\n",
      "        .   @param color Line color.\n",
      "        .   @param thickness Line thickness.\n",
      "        .   @param lineType Type of the line. See #LineTypes.\n",
      "        .   @param shift Number of fractional bits in the point coordinates.\n",
      "    \n",
      "    linearPolar(...)\n",
      "        linearPolar(src, center, maxRadius, flags[, dst]) -> dst\n",
      "        .   @brief Remaps an image to polar coordinates space.\n",
      "        .   \n",
      "        .   @deprecated This function produces same result as cv::warpPolar(src, dst, src.size(), center, maxRadius, flags)\n",
      "        .   \n",
      "        .   @internal\n",
      "        .   Transform the source image using the following transformation (See @ref polar_remaps_reference_image \"Polar remaps reference image c)\"):\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .     dst( \\rho , \\phi ) = src(x,y) \\\\\n",
      "        .     dst.size() \\leftarrow src.size()\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .     I = (dx,dy) = (x - center.x,y - center.y) \\\\\n",
      "        .     \\rho = Kmag \\cdot \\texttt{magnitude} (I) ,\\\\\n",
      "        .     \\phi = angle \\cdot \\texttt{angle} (I)\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   and\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .     Kx = src.cols / maxRadius \\\\\n",
      "        .     Ky = src.rows / 2\\Pi\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   @param src Source image\n",
      "        .   @param dst Destination image. It will have same size and type as src.\n",
      "        .   @param center The transformation center;\n",
      "        .   @param maxRadius The radius of the bounding circle to transform. It determines the inverse magnitude scale parameter too.\n",
      "        .   @param flags A combination of interpolation methods, see #InterpolationFlags\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   The function can not operate in-place.\n",
      "        .   -   To calculate magnitude and angle in degrees #cartToPolar is used internally thus angles are measured from 0 to 360 with accuracy about 0.3 degrees.\n",
      "        .   \n",
      "        .   @sa cv::logPolar\n",
      "        .   @endinternal\n",
      "    \n",
      "    log(...)\n",
      "        log(src[, dst]) -> dst\n",
      "        .   @brief Calculates the natural logarithm of every array element.\n",
      "        .   \n",
      "        .   The function cv::log calculates the natural logarithm of every element of the input array:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\log (\\texttt{src}(I)) \\f]\n",
      "        .   \n",
      "        .   Output on zero, negative and special (NaN, Inf) values is undefined.\n",
      "        .   \n",
      "        .   @param src input array.\n",
      "        .   @param dst output array of the same size and type as src .\n",
      "        .   @sa exp, cartToPolar, polarToCart, phase, pow, sqrt, magnitude\n",
      "    \n",
      "    logPolar(...)\n",
      "        logPolar(src, center, M, flags[, dst]) -> dst\n",
      "        .   @brief Remaps an image to semilog-polar coordinates space.\n",
      "        .   \n",
      "        .   @deprecated This function produces same result as cv::warpPolar(src, dst, src.size(), center, maxRadius, flags+WARP_POLAR_LOG);\n",
      "        .   \n",
      "        .   @internal\n",
      "        .   Transform the source image using the following transformation (See @ref polar_remaps_reference_image \"Polar remaps reference image d)\"):\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .     dst( \\rho , \\phi ) = src(x,y) \\\\\n",
      "        .     dst.size() \\leftarrow src.size()\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .     I = (dx,dy) = (x - center.x,y - center.y) \\\\\n",
      "        .     \\rho = M \\cdot log_e(\\texttt{magnitude} (I)) ,\\\\\n",
      "        .     \\phi = Kangle \\cdot \\texttt{angle} (I) \\\\\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   and\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .     M = src.cols / log_e(maxRadius) \\\\\n",
      "        .     Kangle = src.rows / 2\\Pi \\\\\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   The function emulates the human \"foveal\" vision and can be used for fast scale and\n",
      "        .   rotation-invariant template matching, for object tracking and so forth.\n",
      "        .   @param src Source image\n",
      "        .   @param dst Destination image. It will have same size and type as src.\n",
      "        .   @param center The transformation center; where the output precision is maximal\n",
      "        .   @param M Magnitude scale parameter. It determines the radius of the bounding circle to transform too.\n",
      "        .   @param flags A combination of interpolation methods, see #InterpolationFlags\n",
      "        .   \n",
      "        .   @note\n",
      "        .   -   The function can not operate in-place.\n",
      "        .   -   To calculate magnitude and angle in degrees #cartToPolar is used internally thus angles are measured from 0 to 360 with accuracy about 0.3 degrees.\n",
      "        .   \n",
      "        .   @sa cv::linearPolar\n",
      "        .   @endinternal\n",
      "    \n",
      "    magnitude(...)\n",
      "        magnitude(x, y[, magnitude]) -> magnitude\n",
      "        .   @brief Calculates the magnitude of 2D vectors.\n",
      "        .   \n",
      "        .   The function cv::magnitude calculates the magnitude of 2D vectors formed\n",
      "        .   from the corresponding elements of x and y arrays:\n",
      "        .   \\f[\\texttt{dst} (I) =  \\sqrt{\\texttt{x}(I)^2 + \\texttt{y}(I)^2}\\f]\n",
      "        .   @param x floating-point array of x-coordinates of the vectors.\n",
      "        .   @param y floating-point array of y-coordinates of the vectors; it must\n",
      "        .   have the same size as x.\n",
      "        .   @param magnitude output array of the same size and type as x.\n",
      "        .   @sa cartToPolar, polarToCart, phase, sqrt\n",
      "    \n",
      "    matMulDeriv(...)\n",
      "        matMulDeriv(A, B[, dABdA[, dABdB]]) -> dABdA, dABdB\n",
      "        .   @brief Computes partial derivatives of the matrix product for each multiplied matrix.\n",
      "        .   \n",
      "        .   @param A First multiplied matrix.\n",
      "        .   @param B Second multiplied matrix.\n",
      "        .   @param dABdA First output derivative matrix d(A\\*B)/dA of size\n",
      "        .   \\f$\\texttt{A.rows*B.cols} \\times {A.rows*A.cols}\\f$ .\n",
      "        .   @param dABdB Second output derivative matrix d(A\\*B)/dB of size\n",
      "        .   \\f$\\texttt{A.rows*B.cols} \\times {B.rows*B.cols}\\f$ .\n",
      "        .   \n",
      "        .   The function computes partial derivatives of the elements of the matrix product \\f$A*B\\f$ with regard to\n",
      "        .   the elements of each of the two input matrices. The function is used to compute the Jacobian\n",
      "        .   matrices in stereoCalibrate but can also be used in any other similar optimization function.\n",
      "    \n",
      "    matchShapes(...)\n",
      "        matchShapes(contour1, contour2, method, parameter) -> retval\n",
      "        .   @brief Compares two shapes.\n",
      "        .   \n",
      "        .   The function compares two shapes. All three implemented methods use the Hu invariants (see #HuMoments)\n",
      "        .   \n",
      "        .   @param contour1 First contour or grayscale image.\n",
      "        .   @param contour2 Second contour or grayscale image.\n",
      "        .   @param method Comparison method, see #ShapeMatchModes\n",
      "        .   @param parameter Method-specific parameter (not supported now).\n",
      "    \n",
      "    matchTemplate(...)\n",
      "        matchTemplate(image, templ, method[, result[, mask]]) -> result\n",
      "        .   @brief Compares a template against overlapped image regions.\n",
      "        .   \n",
      "        .   The function slides through image , compares the overlapped patches of size \\f$w \\times h\\f$ against\n",
      "        .   templ using the specified method and stores the comparison results in result . #TemplateMatchModes\n",
      "        .   describes the formulae for the available comparison methods ( \\f$I\\f$ denotes image, \\f$T\\f$\n",
      "        .   template, \\f$R\\f$ result, \\f$M\\f$ the optional mask ). The summation is done over template and/or\n",
      "        .   the image patch: \\f$x' = 0...w-1, y' = 0...h-1\\f$\n",
      "        .   \n",
      "        .   After the function finishes the comparison, the best matches can be found as global minimums (when\n",
      "        .   #TM_SQDIFF was used) or maximums (when #TM_CCORR or #TM_CCOEFF was used) using the\n",
      "        .   #minMaxLoc function. In case of a color image, template summation in the numerator and each sum in\n",
      "        .   the denominator is done over all of the channels and separate mean values are used for each channel.\n",
      "        .   That is, the function can take a color template and a color image. The result will still be a\n",
      "        .   single-channel image, which is easier to analyze.\n",
      "        .   \n",
      "        .   @param image Image where the search is running. It must be 8-bit or 32-bit floating-point.\n",
      "        .   @param templ Searched template. It must be not greater than the source image and have the same\n",
      "        .   data type.\n",
      "        .   @param result Map of comparison results. It must be single-channel 32-bit floating-point. If image\n",
      "        .   is \\f$W \\times H\\f$ and templ is \\f$w \\times h\\f$ , then result is \\f$(W-w+1) \\times (H-h+1)\\f$ .\n",
      "        .   @param method Parameter specifying the comparison method, see #TemplateMatchModes\n",
      "        .   @param mask Optional mask. It must have the same size as templ. It must either have the same number\n",
      "        .               of channels as template or only one channel, which is then used for all template and\n",
      "        .               image channels. If the data type is #CV_8U, the mask is interpreted as a binary mask,\n",
      "        .               meaning only elements where mask is nonzero are used and are kept unchanged independent\n",
      "        .               of the actual mask value (weight equals 1). For data tpye #CV_32F, the mask values are\n",
      "        .               used as weights. The exact formulas are documented in #TemplateMatchModes.\n",
      "    \n",
      "    max(...)\n",
      "        max(src1, src2[, dst]) -> dst\n",
      "        .   @brief Calculates per-element maximum of two arrays or an array and a scalar.\n",
      "        .   \n",
      "        .   The function cv::max calculates the per-element maximum of two arrays:\n",
      "        .   \\f[\\texttt{dst} (I)= \\max ( \\texttt{src1} (I), \\texttt{src2} (I))\\f]\n",
      "        .   or array and a scalar:\n",
      "        .   \\f[\\texttt{dst} (I)= \\max ( \\texttt{src1} (I), \\texttt{value} )\\f]\n",
      "        .   @param src1 first input array.\n",
      "        .   @param src2 second input array of the same size and type as src1 .\n",
      "        .   @param dst output array of the same size and type as src1.\n",
      "        .   @sa  min, compare, inRange, minMaxLoc, @ref MatrixExpressions\n",
      "    \n",
      "    mean(...)\n",
      "        mean(src[, mask]) -> retval\n",
      "        .   @brief Calculates an average (mean) of array elements.\n",
      "        .   \n",
      "        .   The function cv::mean calculates the mean value M of array elements,\n",
      "        .   independently for each channel, and return it:\n",
      "        .   \\f[\\begin{array}{l} N =  \\sum _{I: \\; \\texttt{mask} (I) \\ne 0} 1 \\\\ M_c =  \\left ( \\sum _{I: \\; \\texttt{mask} (I) \\ne 0}{ \\texttt{mtx} (I)_c} \\right )/N \\end{array}\\f]\n",
      "        .   When all the mask elements are 0's, the function returns Scalar::all(0)\n",
      "        .   @param src input array that should have from 1 to 4 channels so that the result can be stored in\n",
      "        .   Scalar_ .\n",
      "        .   @param mask optional operation mask.\n",
      "        .   @sa  countNonZero, meanStdDev, norm, minMaxLoc\n",
      "    \n",
      "    meanShift(...)\n",
      "        meanShift(probImage, window, criteria) -> retval, window\n",
      "        .   @brief Finds an object on a back projection image.\n",
      "        .   \n",
      "        .   @param probImage Back projection of the object histogram. See calcBackProject for details.\n",
      "        .   @param window Initial search window.\n",
      "        .   @param criteria Stop criteria for the iterative search algorithm.\n",
      "        .   returns\n",
      "        .   :   Number of iterations CAMSHIFT took to converge.\n",
      "        .   The function implements the iterative object search algorithm. It takes the input back projection of\n",
      "        .   an object and the initial position. The mass center in window of the back projection image is\n",
      "        .   computed and the search window center shifts to the mass center. The procedure is repeated until the\n",
      "        .   specified number of iterations criteria.maxCount is done or until the window center shifts by less\n",
      "        .   than criteria.epsilon. The algorithm is used inside CamShift and, unlike CamShift , the search\n",
      "        .   window size or orientation do not change during the search. You can simply pass the output of\n",
      "        .   calcBackProject to this function. But better results can be obtained if you pre-filter the back\n",
      "        .   projection and remove the noise. For example, you can do this by retrieving connected components\n",
      "        .   with findContours , throwing away contours with small area ( contourArea ), and rendering the\n",
      "        .   remaining contours with drawContours.\n",
      "    \n",
      "    meanStdDev(...)\n",
      "        meanStdDev(src[, mean[, stddev[, mask]]]) -> mean, stddev\n",
      "        .   Calculates a mean and standard deviation of array elements.\n",
      "        .   \n",
      "        .   The function cv::meanStdDev calculates the mean and the standard deviation M\n",
      "        .   of array elements independently for each channel and returns it via the\n",
      "        .   output parameters:\n",
      "        .   \\f[\\begin{array}{l} N =  \\sum _{I, \\texttt{mask} (I)  \\ne 0} 1 \\\\ \\texttt{mean} _c =  \\frac{\\sum_{ I: \\; \\texttt{mask}(I) \\ne 0} \\texttt{src} (I)_c}{N} \\\\ \\texttt{stddev} _c =  \\sqrt{\\frac{\\sum_{ I: \\; \\texttt{mask}(I) \\ne 0} \\left ( \\texttt{src} (I)_c -  \\texttt{mean} _c \\right )^2}{N}} \\end{array}\\f]\n",
      "        .   When all the mask elements are 0's, the function returns\n",
      "        .   mean=stddev=Scalar::all(0).\n",
      "        .   @note The calculated standard deviation is only the diagonal of the\n",
      "        .   complete normalized covariance matrix. If the full matrix is needed, you\n",
      "        .   can reshape the multi-channel array M x N to the single-channel array\n",
      "        .   M\\*N x mtx.channels() (only possible when the matrix is continuous) and\n",
      "        .   then pass the matrix to calcCovarMatrix .\n",
      "        .   @param src input array that should have from 1 to 4 channels so that the results can be stored in\n",
      "        .   Scalar_ 's.\n",
      "        .   @param mean output parameter: calculated mean value.\n",
      "        .   @param stddev output parameter: calculated standard deviation.\n",
      "        .   @param mask optional operation mask.\n",
      "        .   @sa  countNonZero, mean, norm, minMaxLoc, calcCovarMatrix\n",
      "    \n",
      "    medianBlur(...)\n",
      "        medianBlur(src, ksize[, dst]) -> dst\n",
      "        .   @brief Blurs an image using the median filter.\n",
      "        .   \n",
      "        .   The function smoothes an image using the median filter with the \\f$\\texttt{ksize} \\times\n",
      "        .   \\texttt{ksize}\\f$ aperture. Each channel of a multi-channel image is processed independently.\n",
      "        .   In-place operation is supported.\n",
      "        .   \n",
      "        .   @note The median filter uses #BORDER_REPLICATE internally to cope with border pixels, see #BorderTypes\n",
      "        .   \n",
      "        .   @param src input 1-, 3-, or 4-channel image; when ksize is 3 or 5, the image depth should be\n",
      "        .   CV_8U, CV_16U, or CV_32F, for larger aperture sizes, it can only be CV_8U.\n",
      "        .   @param dst destination array of the same size and type as src.\n",
      "        .   @param ksize aperture linear size; it must be odd and greater than 1, for example: 3, 5, 7 ...\n",
      "        .   @sa  bilateralFilter, blur, boxFilter, GaussianBlur\n",
      "    \n",
      "    merge(...)\n",
      "        merge(mv[, dst]) -> dst\n",
      "        .   @overload\n",
      "        .   @param mv input vector of matrices to be merged; all the matrices in mv must have the same\n",
      "        .   size and the same depth.\n",
      "        .   @param dst output array of the same size and the same depth as mv[0]; The number of channels will\n",
      "        .   be the total number of channels in the matrix array.\n",
      "    \n",
      "    min(...)\n",
      "        min(src1, src2[, dst]) -> dst\n",
      "        .   @brief Calculates per-element minimum of two arrays or an array and a scalar.\n",
      "        .   \n",
      "        .   The function cv::min calculates the per-element minimum of two arrays:\n",
      "        .   \\f[\\texttt{dst} (I)= \\min ( \\texttt{src1} (I), \\texttt{src2} (I))\\f]\n",
      "        .   or array and a scalar:\n",
      "        .   \\f[\\texttt{dst} (I)= \\min ( \\texttt{src1} (I), \\texttt{value} )\\f]\n",
      "        .   @param src1 first input array.\n",
      "        .   @param src2 second input array of the same size and type as src1.\n",
      "        .   @param dst output array of the same size and type as src1.\n",
      "        .   @sa max, compare, inRange, minMaxLoc\n",
      "    \n",
      "    minAreaRect(...)\n",
      "        minAreaRect(points) -> retval\n",
      "        .   @brief Finds a rotated rectangle of the minimum area enclosing the input 2D point set.\n",
      "        .   \n",
      "        .   The function calculates and returns the minimum-area bounding rectangle (possibly rotated) for a\n",
      "        .   specified point set. Developer should keep in mind that the returned RotatedRect can contain negative\n",
      "        .   indices when data is close to the containing Mat element boundary.\n",
      "        .   \n",
      "        .   @param points Input vector of 2D points, stored in std::vector\\<\\> or Mat\n",
      "    \n",
      "    minEnclosingCircle(...)\n",
      "        minEnclosingCircle(points) -> center, radius\n",
      "        .   @brief Finds a circle of the minimum area enclosing a 2D point set.\n",
      "        .   \n",
      "        .   The function finds the minimal enclosing circle of a 2D point set using an iterative algorithm.\n",
      "        .   \n",
      "        .   @param points Input vector of 2D points, stored in std::vector\\<\\> or Mat\n",
      "        .   @param center Output center of the circle.\n",
      "        .   @param radius Output radius of the circle.\n",
      "    \n",
      "    minEnclosingTriangle(...)\n",
      "        minEnclosingTriangle(points[, triangle]) -> retval, triangle\n",
      "        .   @brief Finds a triangle of minimum area enclosing a 2D point set and returns its area.\n",
      "        .   \n",
      "        .   The function finds a triangle of minimum area enclosing the given set of 2D points and returns its\n",
      "        .   area. The output for a given 2D point set is shown in the image below. 2D points are depicted in\n",
      "        .   *red* and the enclosing triangle in *yellow*.\n",
      "        .   \n",
      "        .   ![Sample output of the minimum enclosing triangle function](pics/minenclosingtriangle.png)\n",
      "        .   \n",
      "        .   The implementation of the algorithm is based on O'Rourke's @cite ORourke86 and Klee and Laskowski's\n",
      "        .   @cite KleeLaskowski85 papers. O'Rourke provides a \\f$\\theta(n)\\f$ algorithm for finding the minimal\n",
      "        .   enclosing triangle of a 2D convex polygon with n vertices. Since the #minEnclosingTriangle function\n",
      "        .   takes a 2D point set as input an additional preprocessing step of computing the convex hull of the\n",
      "        .   2D point set is required. The complexity of the #convexHull function is \\f$O(n log(n))\\f$ which is higher\n",
      "        .   than \\f$\\theta(n)\\f$. Thus the overall complexity of the function is \\f$O(n log(n))\\f$.\n",
      "        .   \n",
      "        .   @param points Input vector of 2D points with depth CV_32S or CV_32F, stored in std::vector\\<\\> or Mat\n",
      "        .   @param triangle Output vector of three 2D points defining the vertices of the triangle. The depth\n",
      "        .   of the OutputArray must be CV_32F.\n",
      "    \n",
      "    minMaxLoc(...)\n",
      "        minMaxLoc(src[, mask]) -> minVal, maxVal, minLoc, maxLoc\n",
      "        .   @brief Finds the global minimum and maximum in an array.\n",
      "        .   \n",
      "        .   The function cv::minMaxLoc finds the minimum and maximum element values and their positions. The\n",
      "        .   extremums are searched across the whole array or, if mask is not an empty array, in the specified\n",
      "        .   array region.\n",
      "        .   \n",
      "        .   The function do not work with multi-channel arrays. If you need to find minimum or maximum\n",
      "        .   elements across all the channels, use Mat::reshape first to reinterpret the array as\n",
      "        .   single-channel. Or you may extract the particular channel using either extractImageCOI , or\n",
      "        .   mixChannels , or split .\n",
      "        .   @param src input single-channel array.\n",
      "        .   @param minVal pointer to the returned minimum value; NULL is used if not required.\n",
      "        .   @param maxVal pointer to the returned maximum value; NULL is used if not required.\n",
      "        .   @param minLoc pointer to the returned minimum location (in 2D case); NULL is used if not required.\n",
      "        .   @param maxLoc pointer to the returned maximum location (in 2D case); NULL is used if not required.\n",
      "        .   @param mask optional mask used to select a sub-array.\n",
      "        .   @sa max, min, compare, inRange, extractImageCOI, mixChannels, split, Mat::reshape\n",
      "    \n",
      "    mixChannels(...)\n",
      "        mixChannels(src, dst, fromTo) -> dst\n",
      "        .   @overload\n",
      "        .   @param src input array or vector of matrices; all of the matrices must have the same size and the\n",
      "        .   same depth.\n",
      "        .   @param dst output array or vector of matrices; all the matrices **must be allocated**; their size and\n",
      "        .   depth must be the same as in src[0].\n",
      "        .   @param fromTo array of index pairs specifying which channels are copied and where; fromTo[k\\*2] is\n",
      "        .   a 0-based index of the input channel in src, fromTo[k\\*2+1] is an index of the output channel in\n",
      "        .   dst; the continuous channel numbering is used: the first input image channels are indexed from 0 to\n",
      "        .   src[0].channels()-1, the second input image channels are indexed from src[0].channels() to\n",
      "        .   src[0].channels() + src[1].channels()-1, and so on, the same scheme is used for the output image\n",
      "        .   channels; as a special case, when fromTo[k\\*2] is negative, the corresponding output channel is\n",
      "        .   filled with zero .\n",
      "    \n",
      "    moments(...)\n",
      "        moments(array[, binaryImage]) -> retval\n",
      "        .   @brief Calculates all of the moments up to the third order of a polygon or rasterized shape.\n",
      "        .   \n",
      "        .   The function computes moments, up to the 3rd order, of a vector shape or a rasterized shape. The\n",
      "        .   results are returned in the structure cv::Moments.\n",
      "        .   \n",
      "        .   @param array Raster image (single-channel, 8-bit or floating-point 2D array) or an array (\n",
      "        .   \\f$1 \\times N\\f$ or \\f$N \\times 1\\f$ ) of 2D points (Point or Point2f ).\n",
      "        .   @param binaryImage If it is true, all non-zero image pixels are treated as 1's. The parameter is\n",
      "        .   used for images only.\n",
      "        .   @returns moments.\n",
      "        .   \n",
      "        .   @note Only applicable to contour moments calculations from Python bindings: Note that the numpy\n",
      "        .   type for the input array should be either np.int32 or np.float32.\n",
      "        .   \n",
      "        .   @sa  contourArea, arcLength\n",
      "    \n",
      "    morphologyEx(...)\n",
      "        morphologyEx(src, op, kernel[, dst[, anchor[, iterations[, borderType[, borderValue]]]]]) -> dst\n",
      "        .   @brief Performs advanced morphological transformations.\n",
      "        .   \n",
      "        .   The function cv::morphologyEx can perform advanced morphological transformations using an erosion and dilation as\n",
      "        .   basic operations.\n",
      "        .   \n",
      "        .   Any of the operations can be done in-place. In case of multi-channel images, each channel is\n",
      "        .   processed independently.\n",
      "        .   \n",
      "        .   @param src Source image. The number of channels can be arbitrary. The depth should be one of\n",
      "        .   CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
      "        .   @param dst Destination image of the same size and type as source image.\n",
      "        .   @param op Type of a morphological operation, see #MorphTypes\n",
      "        .   @param kernel Structuring element. It can be created using #getStructuringElement.\n",
      "        .   @param anchor Anchor position with the kernel. Negative values mean that the anchor is at the\n",
      "        .   kernel center.\n",
      "        .   @param iterations Number of times erosion and dilation are applied.\n",
      "        .   @param borderType Pixel extrapolation method, see #BorderTypes. #BORDER_WRAP is not supported.\n",
      "        .   @param borderValue Border value in case of a constant border. The default value has a special\n",
      "        .   meaning.\n",
      "        .   @sa  dilate, erode, getStructuringElement\n",
      "        .   @note The number of iterations is the number of times erosion or dilatation operation will be applied.\n",
      "        .   For instance, an opening operation (#MORPH_OPEN) with two iterations is equivalent to apply\n",
      "        .   successively: erode -> erode -> dilate -> dilate (and not erode -> dilate -> erode -> dilate).\n",
      "    \n",
      "    moveWindow(...)\n",
      "        moveWindow(winname, x, y) -> None\n",
      "        .   @brief Moves window to the specified position\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   @param x The new x-coordinate of the window.\n",
      "        .   @param y The new y-coordinate of the window.\n",
      "    \n",
      "    mulSpectrums(...)\n",
      "        mulSpectrums(a, b, flags[, c[, conjB]]) -> c\n",
      "        .   @brief Performs the per-element multiplication of two Fourier spectrums.\n",
      "        .   \n",
      "        .   The function cv::mulSpectrums performs the per-element multiplication of the two CCS-packed or complex\n",
      "        .   matrices that are results of a real or complex Fourier transform.\n",
      "        .   \n",
      "        .   The function, together with dft and idft , may be used to calculate convolution (pass conjB=false )\n",
      "        .   or correlation (pass conjB=true ) of two arrays rapidly. When the arrays are complex, they are\n",
      "        .   simply multiplied (per element) with an optional conjugation of the second-array elements. When the\n",
      "        .   arrays are real, they are assumed to be CCS-packed (see dft for details).\n",
      "        .   @param a first input array.\n",
      "        .   @param b second input array of the same size and type as src1 .\n",
      "        .   @param c output array of the same size and type as src1 .\n",
      "        .   @param flags operation flags; currently, the only supported flag is cv::DFT_ROWS, which indicates that\n",
      "        .   each row of src1 and src2 is an independent 1D Fourier spectrum. If you do not want to use this flag, then simply add a `0` as value.\n",
      "        .   @param conjB optional flag that conjugates the second input array before the multiplication (true)\n",
      "        .   or not (false).\n",
      "    \n",
      "    mulTransposed(...)\n",
      "        mulTransposed(src, aTa[, dst[, delta[, scale[, dtype]]]]) -> dst\n",
      "        .   @brief Calculates the product of a matrix and its transposition.\n",
      "        .   \n",
      "        .   The function cv::mulTransposed calculates the product of src and its\n",
      "        .   transposition:\n",
      "        .   \\f[\\texttt{dst} = \\texttt{scale} ( \\texttt{src} - \\texttt{delta} )^T ( \\texttt{src} - \\texttt{delta} )\\f]\n",
      "        .   if aTa=true , and\n",
      "        .   \\f[\\texttt{dst} = \\texttt{scale} ( \\texttt{src} - \\texttt{delta} ) ( \\texttt{src} - \\texttt{delta} )^T\\f]\n",
      "        .   otherwise. The function is used to calculate the covariance matrix. With\n",
      "        .   zero delta, it can be used as a faster substitute for general matrix\n",
      "        .   product A\\*B when B=A'\n",
      "        .   @param src input single-channel matrix. Note that unlike gemm, the\n",
      "        .   function can multiply not only floating-point matrices.\n",
      "        .   @param dst output square matrix.\n",
      "        .   @param aTa Flag specifying the multiplication ordering. See the\n",
      "        .   description below.\n",
      "        .   @param delta Optional delta matrix subtracted from src before the\n",
      "        .   multiplication. When the matrix is empty ( delta=noArray() ), it is\n",
      "        .   assumed to be zero, that is, nothing is subtracted. If it has the same\n",
      "        .   size as src , it is simply subtracted. Otherwise, it is \"repeated\" (see\n",
      "        .   repeat ) to cover the full src and then subtracted. Type of the delta\n",
      "        .   matrix, when it is not empty, must be the same as the type of created\n",
      "        .   output matrix. See the dtype parameter description below.\n",
      "        .   @param scale Optional scale factor for the matrix product.\n",
      "        .   @param dtype Optional type of the output matrix. When it is negative,\n",
      "        .   the output matrix will have the same type as src . Otherwise, it will be\n",
      "        .   type=CV_MAT_DEPTH(dtype) that should be either CV_32F or CV_64F .\n",
      "        .   @sa calcCovarMatrix, gemm, repeat, reduce\n",
      "    \n",
      "    multiply(...)\n",
      "        multiply(src1, src2[, dst[, scale[, dtype]]]) -> dst\n",
      "        .   @brief Calculates the per-element scaled product of two arrays.\n",
      "        .   \n",
      "        .   The function multiply calculates the per-element product of two arrays:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (I)= \\texttt{saturate} ( \\texttt{scale} \\cdot \\texttt{src1} (I)  \\cdot \\texttt{src2} (I))\\f]\n",
      "        .   \n",
      "        .   There is also a @ref MatrixExpressions -friendly variant of the first function. See Mat::mul .\n",
      "        .   \n",
      "        .   For a not-per-element matrix product, see gemm .\n",
      "        .   \n",
      "        .   @note Saturation is not applied when the output array has the depth\n",
      "        .   CV_32S. You may even get result of an incorrect sign in the case of\n",
      "        .   overflow.\n",
      "        .   @param src1 first input array.\n",
      "        .   @param src2 second input array of the same size and the same type as src1.\n",
      "        .   @param dst output array of the same size and type as src1.\n",
      "        .   @param scale optional scale factor.\n",
      "        .   @param dtype optional depth of the output array\n",
      "        .   @sa add, subtract, divide, scaleAdd, addWeighted, accumulate, accumulateProduct, accumulateSquare,\n",
      "        .   Mat::convertTo\n",
      "    \n",
      "    namedWindow(...)\n",
      "        namedWindow(winname[, flags]) -> None\n",
      "        .   @brief Creates a window.\n",
      "        .   \n",
      "        .   The function namedWindow creates a window that can be used as a placeholder for images and\n",
      "        .   trackbars. Created windows are referred to by their names.\n",
      "        .   \n",
      "        .   If a window with the same name already exists, the function does nothing.\n",
      "        .   \n",
      "        .   You can call cv::destroyWindow or cv::destroyAllWindows to close the window and de-allocate any associated\n",
      "        .   memory usage. For a simple program, you do not really have to call these functions because all the\n",
      "        .   resources and windows of the application are closed automatically by the operating system upon exit.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   Qt backend supports additional flags:\n",
      "        .    -   **WINDOW_NORMAL or WINDOW_AUTOSIZE:** WINDOW_NORMAL enables you to resize the\n",
      "        .        window, whereas WINDOW_AUTOSIZE adjusts automatically the window size to fit the\n",
      "        .        displayed image (see imshow ), and you cannot change the window size manually.\n",
      "        .    -   **WINDOW_FREERATIO or WINDOW_KEEPRATIO:** WINDOW_FREERATIO adjusts the image\n",
      "        .        with no respect to its ratio, whereas WINDOW_KEEPRATIO keeps the image ratio.\n",
      "        .    -   **WINDOW_GUI_NORMAL or WINDOW_GUI_EXPANDED:** WINDOW_GUI_NORMAL is the old way to draw the window\n",
      "        .        without statusbar and toolbar, whereas WINDOW_GUI_EXPANDED is a new enhanced GUI.\n",
      "        .   By default, flags == WINDOW_AUTOSIZE | WINDOW_KEEPRATIO | WINDOW_GUI_EXPANDED\n",
      "        .   \n",
      "        .   @param winname Name of the window in the window caption that may be used as a window identifier.\n",
      "        .   @param flags Flags of the window. The supported flags are: (cv::WindowFlags)\n",
      "    \n",
      "    norm(...)\n",
      "        norm(src1[, normType[, mask]]) -> retval\n",
      "        .   @brief Calculates the  absolute norm of an array.\n",
      "        .   \n",
      "        .   This version of #norm calculates the absolute norm of src1. The type of norm to calculate is specified using #NormTypes.\n",
      "        .   \n",
      "        .   As example for one array consider the function \\f$r(x)= \\begin{pmatrix} x \\\\ 1-x \\end{pmatrix}, x \\in [-1;1]\\f$.\n",
      "        .   The \\f$ L_{1}, L_{2} \\f$ and \\f$ L_{\\infty} \\f$ norm for the sample value \\f$r(-1) = \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix}\\f$\n",
      "        .   is calculated as follows\n",
      "        .   \\f{align*}\n",
      "        .       \\| r(-1) \\|_{L_1} &= |-1| + |2| = 3 \\\\\n",
      "        .       \\| r(-1) \\|_{L_2} &= \\sqrt{(-1)^{2} + (2)^{2}} = \\sqrt{5} \\\\\n",
      "        .       \\| r(-1) \\|_{L_\\infty} &= \\max(|-1|,|2|) = 2\n",
      "        .   \\f}\n",
      "        .   and for \\f$r(0.5) = \\begin{pmatrix} 0.5 \\\\ 0.5 \\end{pmatrix}\\f$ the calculation is\n",
      "        .   \\f{align*}\n",
      "        .       \\| r(0.5) \\|_{L_1} &= |0.5| + |0.5| = 1 \\\\\n",
      "        .       \\| r(0.5) \\|_{L_2} &= \\sqrt{(0.5)^{2} + (0.5)^{2}} = \\sqrt{0.5} \\\\\n",
      "        .       \\| r(0.5) \\|_{L_\\infty} &= \\max(|0.5|,|0.5|) = 0.5.\n",
      "        .   \\f}\n",
      "        .   The following graphic shows all values for the three norm functions \\f$\\| r(x) \\|_{L_1}, \\| r(x) \\|_{L_2}\\f$ and \\f$\\| r(x) \\|_{L_\\infty}\\f$.\n",
      "        .   It is notable that the \\f$ L_{1} \\f$ norm forms the upper and the \\f$ L_{\\infty} \\f$ norm forms the lower border for the example function \\f$ r(x) \\f$.\n",
      "        .   ![Graphs for the different norm functions from the above example](pics/NormTypes_OneArray_1-2-INF.png)\n",
      "        .   \n",
      "        .   When the mask parameter is specified and it is not empty, the norm is\n",
      "        .   \n",
      "        .   If normType is not specified, #NORM_L2 is used.\n",
      "        .   calculated only over the region specified by the mask.\n",
      "        .   \n",
      "        .   Multi-channel input arrays are treated as single-channel arrays, that is,\n",
      "        .   the results for all channels are combined.\n",
      "        .   \n",
      "        .   Hamming norms can only be calculated with CV_8U depth arrays.\n",
      "        .   \n",
      "        .   @param src1 first input array.\n",
      "        .   @param normType type of the norm (see #NormTypes).\n",
      "        .   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n",
      "        \n",
      "        \n",
      "        \n",
      "        norm(src1, src2[, normType[, mask]]) -> retval\n",
      "        .   @brief Calculates an absolute difference norm or a relative difference norm.\n",
      "        .   \n",
      "        .   This version of cv::norm calculates the absolute difference norm\n",
      "        .   or the relative difference norm of arrays src1 and src2.\n",
      "        .   The type of norm to calculate is specified using #NormTypes.\n",
      "        .   \n",
      "        .   @param src1 first input array.\n",
      "        .   @param src2 second input array of the same size and the same type as src1.\n",
      "        .   @param normType type of the norm (see #NormTypes).\n",
      "        .   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n",
      "    \n",
      "    normalize(...)\n",
      "        normalize(src, dst[, alpha[, beta[, norm_type[, dtype[, mask]]]]]) -> dst\n",
      "        .   @brief Normalizes the norm or value range of an array.\n",
      "        .   \n",
      "        .   The function cv::normalize normalizes scale and shift the input array elements so that\n",
      "        .   \\f[\\| \\texttt{dst} \\| _{L_p}= \\texttt{alpha}\\f]\n",
      "        .   (where p=Inf, 1 or 2) when normType=NORM_INF, NORM_L1, or NORM_L2, respectively; or so that\n",
      "        .   \\f[\\min _I  \\texttt{dst} (I)= \\texttt{alpha} , \\, \\, \\max _I  \\texttt{dst} (I)= \\texttt{beta}\\f]\n",
      "        .   \n",
      "        .   when normType=NORM_MINMAX (for dense arrays only). The optional mask specifies a sub-array to be\n",
      "        .   normalized. This means that the norm or min-n-max are calculated over the sub-array, and then this\n",
      "        .   sub-array is modified to be normalized. If you want to only use the mask to calculate the norm or\n",
      "        .   min-max but modify the whole array, you can use norm and Mat::convertTo.\n",
      "        .   \n",
      "        .   In case of sparse matrices, only the non-zero values are analyzed and transformed. Because of this,\n",
      "        .   the range transformation for sparse matrices is not allowed since it can shift the zero level.\n",
      "        .   \n",
      "        .   Possible usage with some positive example data:\n",
      "        .   @code{.cpp}\n",
      "        .       vector<double> positiveData = { 2.0, 8.0, 10.0 };\n",
      "        .       vector<double> normalizedData_l1, normalizedData_l2, normalizedData_inf, normalizedData_minmax;\n",
      "        .   \n",
      "        .       // Norm to probability (total count)\n",
      "        .       // sum(numbers) = 20.0\n",
      "        .       // 2.0      0.1     (2.0/20.0)\n",
      "        .       // 8.0      0.4     (8.0/20.0)\n",
      "        .       // 10.0     0.5     (10.0/20.0)\n",
      "        .       normalize(positiveData, normalizedData_l1, 1.0, 0.0, NORM_L1);\n",
      "        .   \n",
      "        .       // Norm to unit vector: ||positiveData|| = 1.0\n",
      "        .       // 2.0      0.15\n",
      "        .       // 8.0      0.62\n",
      "        .       // 10.0     0.77\n",
      "        .       normalize(positiveData, normalizedData_l2, 1.0, 0.0, NORM_L2);\n",
      "        .   \n",
      "        .       // Norm to max element\n",
      "        .       // 2.0      0.2     (2.0/10.0)\n",
      "        .       // 8.0      0.8     (8.0/10.0)\n",
      "        .       // 10.0     1.0     (10.0/10.0)\n",
      "        .       normalize(positiveData, normalizedData_inf, 1.0, 0.0, NORM_INF);\n",
      "        .   \n",
      "        .       // Norm to range [0.0;1.0]\n",
      "        .       // 2.0      0.0     (shift to left border)\n",
      "        .       // 8.0      0.75    (6.0/8.0)\n",
      "        .       // 10.0     1.0     (shift to right border)\n",
      "        .       normalize(positiveData, normalizedData_minmax, 1.0, 0.0, NORM_MINMAX);\n",
      "        .   @endcode\n",
      "        .   \n",
      "        .   @param src input array.\n",
      "        .   @param dst output array of the same size as src .\n",
      "        .   @param alpha norm value to normalize to or the lower range boundary in case of the range\n",
      "        .   normalization.\n",
      "        .   @param beta upper range boundary in case of the range normalization; it is not used for the norm\n",
      "        .   normalization.\n",
      "        .   @param norm_type normalization type (see cv::NormTypes).\n",
      "        .   @param dtype when negative, the output array has the same type as src; otherwise, it has the same\n",
      "        .   number of channels as src and the depth =CV_MAT_DEPTH(dtype).\n",
      "        .   @param mask optional operation mask.\n",
      "        .   @sa norm, Mat::convertTo, SparseMat::convertTo\n",
      "    \n",
      "    patchNaNs(...)\n",
      "        patchNaNs(a[, val]) -> a\n",
      "        .   @brief converts NaN's to the given number\n",
      "    \n",
      "    pencilSketch(...)\n",
      "        pencilSketch(src[, dst1[, dst2[, sigma_s[, sigma_r[, shade_factor]]]]]) -> dst1, dst2\n",
      "        .   @brief Pencil-like non-photorealistic line drawing\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param dst1 Output 8-bit 1-channel image.\n",
      "        .   @param dst2 Output image with the same size and type as src.\n",
      "        .   @param sigma_s %Range between 0 to 200.\n",
      "        .   @param sigma_r %Range between 0 to 1.\n",
      "        .   @param shade_factor %Range between 0 to 0.1.\n",
      "    \n",
      "    perspectiveTransform(...)\n",
      "        perspectiveTransform(src, m[, dst]) -> dst\n",
      "        .   @brief Performs the perspective matrix transformation of vectors.\n",
      "        .   \n",
      "        .   The function cv::perspectiveTransform transforms every element of src by\n",
      "        .   treating it as a 2D or 3D vector, in the following way:\n",
      "        .   \\f[(x, y, z)  \\rightarrow (x'/w, y'/w, z'/w)\\f]\n",
      "        .   where\n",
      "        .   \\f[(x', y', z', w') =  \\texttt{mat} \\cdot \\begin{bmatrix} x & y & z & 1  \\end{bmatrix}\\f]\n",
      "        .   and\n",
      "        .   \\f[w =  \\fork{w'}{if \\(w' \\ne 0\\)}{\\infty}{otherwise}\\f]\n",
      "        .   \n",
      "        .   Here a 3D vector transformation is shown. In case of a 2D vector\n",
      "        .   transformation, the z component is omitted.\n",
      "        .   \n",
      "        .   @note The function transforms a sparse set of 2D or 3D vectors. If you\n",
      "        .   want to transform an image using perspective transformation, use\n",
      "        .   warpPerspective . If you have an inverse problem, that is, you want to\n",
      "        .   compute the most probable perspective transformation out of several\n",
      "        .   pairs of corresponding points, you can use getPerspectiveTransform or\n",
      "        .   findHomography .\n",
      "        .   @param src input two-channel or three-channel floating-point array; each\n",
      "        .   element is a 2D/3D vector to be transformed.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "        .   @param m 3x3 or 4x4 floating-point transformation matrix.\n",
      "        .   @sa  transform, warpPerspective, getPerspectiveTransform, findHomography\n",
      "    \n",
      "    phase(...)\n",
      "        phase(x, y[, angle[, angleInDegrees]]) -> angle\n",
      "        .   @brief Calculates the rotation angle of 2D vectors.\n",
      "        .   \n",
      "        .   The function cv::phase calculates the rotation angle of each 2D vector that\n",
      "        .   is formed from the corresponding elements of x and y :\n",
      "        .   \\f[\\texttt{angle} (I) =  \\texttt{atan2} ( \\texttt{y} (I), \\texttt{x} (I))\\f]\n",
      "        .   \n",
      "        .   The angle estimation accuracy is about 0.3 degrees. When x(I)=y(I)=0 ,\n",
      "        .   the corresponding angle(I) is set to 0.\n",
      "        .   @param x input floating-point array of x-coordinates of 2D vectors.\n",
      "        .   @param y input array of y-coordinates of 2D vectors; it must have the\n",
      "        .   same size and the same type as x.\n",
      "        .   @param angle output array of vector angles; it has the same size and\n",
      "        .   same type as x .\n",
      "        .   @param angleInDegrees when true, the function calculates the angle in\n",
      "        .   degrees, otherwise, they are measured in radians.\n",
      "    \n",
      "    phaseCorrelate(...)\n",
      "        phaseCorrelate(src1, src2[, window]) -> retval, response\n",
      "        .   @brief The function is used to detect translational shifts that occur between two images.\n",
      "        .   \n",
      "        .   The operation takes advantage of the Fourier shift theorem for detecting the translational shift in\n",
      "        .   the frequency domain. It can be used for fast image registration as well as motion estimation. For\n",
      "        .   more information please see <http://en.wikipedia.org/wiki/Phase_correlation>\n",
      "        .   \n",
      "        .   Calculates the cross-power spectrum of two supplied source arrays. The arrays are padded if needed\n",
      "        .   with getOptimalDFTSize.\n",
      "        .   \n",
      "        .   The function performs the following equations:\n",
      "        .   - First it applies a Hanning window (see <http://en.wikipedia.org/wiki/Hann_function>) to each\n",
      "        .   image to remove possible edge effects. This window is cached until the array size changes to speed\n",
      "        .   up processing time.\n",
      "        .   - Next it computes the forward DFTs of each source array:\n",
      "        .   \\f[\\mathbf{G}_a = \\mathcal{F}\\{src_1\\}, \\; \\mathbf{G}_b = \\mathcal{F}\\{src_2\\}\\f]\n",
      "        .   where \\f$\\mathcal{F}\\f$ is the forward DFT.\n",
      "        .   - It then computes the cross-power spectrum of each frequency domain array:\n",
      "        .   \\f[R = \\frac{ \\mathbf{G}_a \\mathbf{G}_b^*}{|\\mathbf{G}_a \\mathbf{G}_b^*|}\\f]\n",
      "        .   - Next the cross-correlation is converted back into the time domain via the inverse DFT:\n",
      "        .   \\f[r = \\mathcal{F}^{-1}\\{R\\}\\f]\n",
      "        .   - Finally, it computes the peak location and computes a 5x5 weighted centroid around the peak to\n",
      "        .   achieve sub-pixel accuracy.\n",
      "        .   \\f[(\\Delta x, \\Delta y) = \\texttt{weightedCentroid} \\{\\arg \\max_{(x, y)}\\{r\\}\\}\\f]\n",
      "        .   - If non-zero, the response parameter is computed as the sum of the elements of r within the 5x5\n",
      "        .   centroid around the peak location. It is normalized to a maximum of 1 (meaning there is a single\n",
      "        .   peak) and will be smaller when there are multiple peaks.\n",
      "        .   \n",
      "        .   @param src1 Source floating point array (CV_32FC1 or CV_64FC1)\n",
      "        .   @param src2 Source floating point array (CV_32FC1 or CV_64FC1)\n",
      "        .   @param window Floating point array with windowing coefficients to reduce edge effects (optional).\n",
      "        .   @param response Signal power within the 5x5 centroid around the peak, between 0 and 1 (optional).\n",
      "        .   @returns detected phase shift (sub-pixel) between the two arrays.\n",
      "        .   \n",
      "        .   @sa dft, getOptimalDFTSize, idft, mulSpectrums createHanningWindow\n",
      "    \n",
      "    pointPolygonTest(...)\n",
      "        pointPolygonTest(contour, pt, measureDist) -> retval\n",
      "        .   @brief Performs a point-in-contour test.\n",
      "        .   \n",
      "        .   The function determines whether the point is inside a contour, outside, or lies on an edge (or\n",
      "        .   coincides with a vertex). It returns positive (inside), negative (outside), or zero (on an edge)\n",
      "        .   value, correspondingly. When measureDist=false , the return value is +1, -1, and 0, respectively.\n",
      "        .   Otherwise, the return value is a signed distance between the point and the nearest contour edge.\n",
      "        .   \n",
      "        .   See below a sample output of the function where each image pixel is tested against the contour:\n",
      "        .   \n",
      "        .   ![sample output](pics/pointpolygon.png)\n",
      "        .   \n",
      "        .   @param contour Input contour.\n",
      "        .   @param pt Point tested against the contour.\n",
      "        .   @param measureDist If true, the function estimates the signed distance from the point to the\n",
      "        .   nearest contour edge. Otherwise, the function only checks if the point is inside a contour or not.\n",
      "    \n",
      "    polarToCart(...)\n",
      "        polarToCart(magnitude, angle[, x[, y[, angleInDegrees]]]) -> x, y\n",
      "        .   @brief Calculates x and y coordinates of 2D vectors from their magnitude and angle.\n",
      "        .   \n",
      "        .   The function cv::polarToCart calculates the Cartesian coordinates of each 2D\n",
      "        .   vector represented by the corresponding elements of magnitude and angle:\n",
      "        .   \\f[\\begin{array}{l} \\texttt{x} (I) =  \\texttt{magnitude} (I) \\cos ( \\texttt{angle} (I)) \\\\ \\texttt{y} (I) =  \\texttt{magnitude} (I) \\sin ( \\texttt{angle} (I)) \\\\ \\end{array}\\f]\n",
      "        .   \n",
      "        .   The relative accuracy of the estimated coordinates is about 1e-6.\n",
      "        .   @param magnitude input floating-point array of magnitudes of 2D vectors;\n",
      "        .   it can be an empty matrix (=Mat()), in this case, the function assumes\n",
      "        .   that all the magnitudes are =1; if it is not empty, it must have the\n",
      "        .   same size and type as angle.\n",
      "        .   @param angle input floating-point array of angles of 2D vectors.\n",
      "        .   @param x output array of x-coordinates of 2D vectors; it has the same\n",
      "        .   size and type as angle.\n",
      "        .   @param y output array of y-coordinates of 2D vectors; it has the same\n",
      "        .   size and type as angle.\n",
      "        .   @param angleInDegrees when true, the input angles are measured in\n",
      "        .   degrees, otherwise, they are measured in radians.\n",
      "        .   @sa cartToPolar, magnitude, phase, exp, log, pow, sqrt\n",
      "    \n",
      "    polylines(...)\n",
      "        polylines(img, pts, isClosed, color[, thickness[, lineType[, shift]]]) -> img\n",
      "        .   @brief Draws several polygonal curves.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param pts Array of polygonal curves.\n",
      "        .   @param isClosed Flag indicating whether the drawn polylines are closed or not. If they are closed,\n",
      "        .   the function draws a line from the last vertex of each curve to its first vertex.\n",
      "        .   @param color Polyline color.\n",
      "        .   @param thickness Thickness of the polyline edges.\n",
      "        .   @param lineType Type of the line segments. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the vertex coordinates.\n",
      "        .   \n",
      "        .   The function cv::polylines draws one or more polygonal curves.\n",
      "    \n",
      "    pow(...)\n",
      "        pow(src, power[, dst]) -> dst\n",
      "        .   @brief Raises every array element to a power.\n",
      "        .   \n",
      "        .   The function cv::pow raises every element of the input array to power :\n",
      "        .   \\f[\\texttt{dst} (I) =  \\fork{\\texttt{src}(I)^{power}}{if \\(\\texttt{power}\\) is integer}{|\\texttt{src}(I)|^{power}}{otherwise}\\f]\n",
      "        .   \n",
      "        .   So, for a non-integer power exponent, the absolute values of input array\n",
      "        .   elements are used. However, it is possible to get true values for\n",
      "        .   negative values using some extra operations. In the example below,\n",
      "        .   computing the 5th root of array src shows:\n",
      "        .   @code{.cpp}\n",
      "        .       Mat mask = src < 0;\n",
      "        .       pow(src, 1./5, dst);\n",
      "        .       subtract(Scalar::all(0), dst, dst, mask);\n",
      "        .   @endcode\n",
      "        .   For some values of power, such as integer values, 0.5 and -0.5,\n",
      "        .   specialized faster algorithms are used.\n",
      "        .   \n",
      "        .   Special values (NaN, Inf) are not handled.\n",
      "        .   @param src input array.\n",
      "        .   @param power exponent of power.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "        .   @sa sqrt, exp, log, cartToPolar, polarToCart\n",
      "    \n",
      "    preCornerDetect(...)\n",
      "        preCornerDetect(src, ksize[, dst[, borderType]]) -> dst\n",
      "        .   @brief Calculates a feature map for corner detection.\n",
      "        .   \n",
      "        .   The function calculates the complex spatial derivative-based function of the source image\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} = (D_x  \\texttt{src} )^2  \\cdot D_{yy}  \\texttt{src} + (D_y  \\texttt{src} )^2  \\cdot D_{xx}  \\texttt{src} - 2 D_x  \\texttt{src} \\cdot D_y  \\texttt{src} \\cdot D_{xy}  \\texttt{src}\\f]\n",
      "        .   \n",
      "        .   where \\f$D_x\\f$,\\f$D_y\\f$ are the first image derivatives, \\f$D_{xx}\\f$,\\f$D_{yy}\\f$ are the second image\n",
      "        .   derivatives, and \\f$D_{xy}\\f$ is the mixed derivative.\n",
      "        .   \n",
      "        .   The corners can be found as local maximums of the functions, as shown below:\n",
      "        .   @code\n",
      "        .       Mat corners, dilated_corners;\n",
      "        .       preCornerDetect(image, corners, 3);\n",
      "        .       // dilation with 3x3 rectangular structuring element\n",
      "        .       dilate(corners, dilated_corners, Mat(), 1);\n",
      "        .       Mat corner_mask = corners == dilated_corners;\n",
      "        .   @endcode\n",
      "        .   \n",
      "        .   @param src Source single-channel 8-bit of floating-point image.\n",
      "        .   @param dst Output image that has the type CV_32F and the same size as src .\n",
      "        .   @param ksize %Aperture size of the Sobel .\n",
      "        .   @param borderType Pixel extrapolation method. See #BorderTypes. #BORDER_WRAP is not supported.\n",
      "    \n",
      "    projectPoints(...)\n",
      "        projectPoints(objectPoints, rvec, tvec, cameraMatrix, distCoeffs[, imagePoints[, jacobian[, aspectRatio]]]) -> imagePoints, jacobian\n",
      "        .   @brief Projects 3D points to an image plane.\n",
      "        .   \n",
      "        .   @param objectPoints Array of object points expressed wrt. the world coordinate frame. A 3xN/Nx3\n",
      "        .   1-channel or 1xN/Nx1 3-channel (or vector\\<Point3f\\> ), where N is the number of points in the view.\n",
      "        .   @param rvec The rotation vector (@ref Rodrigues) that, together with tvec, performs a change of\n",
      "        .   basis from world to camera coordinate system, see @ref calibrateCamera for details.\n",
      "        .   @param tvec The translation vector, see parameter description above.\n",
      "        .   @param cameraMatrix Camera matrix \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{_1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is empty, the zero distortion coefficients are assumed.\n",
      "        .   @param imagePoints Output array of image points, 1xN/Nx1 2-channel, or\n",
      "        .   vector\\<Point2f\\> .\n",
      "        .   @param jacobian Optional output 2Nx(10+\\<numDistCoeffs\\>) jacobian matrix of derivatives of image\n",
      "        .   points with respect to components of the rotation vector, translation vector, focal lengths,\n",
      "        .   coordinates of the principal point and the distortion coefficients. In the old interface different\n",
      "        .   components of the jacobian are returned via different output parameters.\n",
      "        .   @param aspectRatio Optional \"fixed aspect ratio\" parameter. If the parameter is not 0, the\n",
      "        .   function assumes that the aspect ratio (\\f$f_x / f_y\\f$) is fixed and correspondingly adjusts the\n",
      "        .   jacobian matrix.\n",
      "        .   \n",
      "        .   The function computes the 2D projections of 3D points to the image plane, given intrinsic and\n",
      "        .   extrinsic camera parameters. Optionally, the function computes Jacobians -matrices of partial\n",
      "        .   derivatives of image points coordinates (as functions of all the input parameters) with respect to\n",
      "        .   the particular parameters, intrinsic and/or extrinsic. The Jacobians are used during the global\n",
      "        .   optimization in @ref calibrateCamera, @ref solvePnP, and @ref stereoCalibrate. The function itself\n",
      "        .   can also be used to compute a re-projection error, given the current intrinsic and extrinsic\n",
      "        .   parameters.\n",
      "        .   \n",
      "        .   @note By setting rvec = tvec = \\f$[0, 0, 0]\\f$, or by setting cameraMatrix to a 3x3 identity matrix,\n",
      "        .   or by passing zero distortion coefficients, one can get various useful partial cases of the\n",
      "        .   function. This means, one can compute the distorted coordinates for a sparse set of points or apply\n",
      "        .   a perspective transformation (and also compute the derivatives) in the ideal zero-distortion setup.\n",
      "    \n",
      "    putText(...)\n",
      "        putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]]) -> img\n",
      "        .   @brief Draws a text string.\n",
      "        .   \n",
      "        .   The function cv::putText renders the specified text string in the image. Symbols that cannot be rendered\n",
      "        .   using the specified font are replaced by question marks. See #getTextSize for a text rendering code\n",
      "        .   example.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param text Text string to be drawn.\n",
      "        .   @param org Bottom-left corner of the text string in the image.\n",
      "        .   @param fontFace Font type, see #HersheyFonts.\n",
      "        .   @param fontScale Font scale factor that is multiplied by the font-specific base size.\n",
      "        .   @param color Text color.\n",
      "        .   @param thickness Thickness of the lines used to draw a text.\n",
      "        .   @param lineType Line type. See #LineTypes\n",
      "        .   @param bottomLeftOrigin When true, the image data origin is at the bottom-left corner. Otherwise,\n",
      "        .   it is at the top-left corner.\n",
      "    \n",
      "    pyrDown(...)\n",
      "        pyrDown(src[, dst[, dstsize[, borderType]]]) -> dst\n",
      "        .   @brief Blurs an image and downsamples it.\n",
      "        .   \n",
      "        .   By default, size of the output image is computed as `Size((src.cols+1)/2, (src.rows+1)/2)`, but in\n",
      "        .   any case, the following conditions should be satisfied:\n",
      "        .   \n",
      "        .   \\f[\\begin{array}{l} | \\texttt{dstsize.width} *2-src.cols| \\leq 2 \\\\ | \\texttt{dstsize.height} *2-src.rows| \\leq 2 \\end{array}\\f]\n",
      "        .   \n",
      "        .   The function performs the downsampling step of the Gaussian pyramid construction. First, it\n",
      "        .   convolves the source image with the kernel:\n",
      "        .   \n",
      "        .   \\f[\\frac{1}{256} \\begin{bmatrix} 1 & 4 & 6 & 4 & 1  \\\\ 4 & 16 & 24 & 16 & 4  \\\\ 6 & 24 & 36 & 24 & 6  \\\\ 4 & 16 & 24 & 16 & 4  \\\\ 1 & 4 & 6 & 4 & 1 \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .   Then, it downsamples the image by rejecting even rows and columns.\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image; it has the specified size and the same type as src.\n",
      "        .   @param dstsize size of the output image.\n",
      "        .   @param borderType Pixel extrapolation method, see #BorderTypes (#BORDER_CONSTANT isn't supported)\n",
      "    \n",
      "    pyrMeanShiftFiltering(...)\n",
      "        pyrMeanShiftFiltering(src, sp, sr[, dst[, maxLevel[, termcrit]]]) -> dst\n",
      "        .   @brief Performs initial step of meanshift segmentation of an image.\n",
      "        .   \n",
      "        .   The function implements the filtering stage of meanshift segmentation, that is, the output of the\n",
      "        .   function is the filtered \"posterized\" image with color gradients and fine-grain texture flattened.\n",
      "        .   At every pixel (X,Y) of the input image (or down-sized input image, see below) the function executes\n",
      "        .   meanshift iterations, that is, the pixel (X,Y) neighborhood in the joint space-color hyperspace is\n",
      "        .   considered:\n",
      "        .   \n",
      "        .   \\f[(x,y): X- \\texttt{sp} \\le x  \\le X+ \\texttt{sp} , Y- \\texttt{sp} \\le y  \\le Y+ \\texttt{sp} , ||(R,G,B)-(r,g,b)||   \\le \\texttt{sr}\\f]\n",
      "        .   \n",
      "        .   where (R,G,B) and (r,g,b) are the vectors of color components at (X,Y) and (x,y), respectively\n",
      "        .   (though, the algorithm does not depend on the color space used, so any 3-component color space can\n",
      "        .   be used instead). Over the neighborhood the average spatial value (X',Y') and average color vector\n",
      "        .   (R',G',B') are found and they act as the neighborhood center on the next iteration:\n",
      "        .   \n",
      "        .   \\f[(X,Y)~(X',Y'), (R,G,B)~(R',G',B').\\f]\n",
      "        .   \n",
      "        .   After the iterations over, the color components of the initial pixel (that is, the pixel from where\n",
      "        .   the iterations started) are set to the final value (average color at the last iteration):\n",
      "        .   \n",
      "        .   \\f[I(X,Y) <- (R*,G*,B*)\\f]\n",
      "        .   \n",
      "        .   When maxLevel \\> 0, the gaussian pyramid of maxLevel+1 levels is built, and the above procedure is\n",
      "        .   run on the smallest layer first. After that, the results are propagated to the larger layer and the\n",
      "        .   iterations are run again only on those pixels where the layer colors differ by more than sr from the\n",
      "        .   lower-resolution layer of the pyramid. That makes boundaries of color regions sharper. Note that the\n",
      "        .   results will be actually different from the ones obtained by running the meanshift procedure on the\n",
      "        .   whole original image (i.e. when maxLevel==0).\n",
      "        .   \n",
      "        .   @param src The source 8-bit, 3-channel image.\n",
      "        .   @param dst The destination image of the same format and the same size as the source.\n",
      "        .   @param sp The spatial window radius.\n",
      "        .   @param sr The color window radius.\n",
      "        .   @param maxLevel Maximum level of the pyramid for the segmentation.\n",
      "        .   @param termcrit Termination criteria: when to stop meanshift iterations.\n",
      "    \n",
      "    pyrUp(...)\n",
      "        pyrUp(src[, dst[, dstsize[, borderType]]]) -> dst\n",
      "        .   @brief Upsamples an image and then blurs it.\n",
      "        .   \n",
      "        .   By default, size of the output image is computed as `Size(src.cols\\*2, (src.rows\\*2)`, but in any\n",
      "        .   case, the following conditions should be satisfied:\n",
      "        .   \n",
      "        .   \\f[\\begin{array}{l} | \\texttt{dstsize.width} -src.cols*2| \\leq  ( \\texttt{dstsize.width}   \\mod  2)  \\\\ | \\texttt{dstsize.height} -src.rows*2| \\leq  ( \\texttt{dstsize.height}   \\mod  2) \\end{array}\\f]\n",
      "        .   \n",
      "        .   The function performs the upsampling step of the Gaussian pyramid construction, though it can\n",
      "        .   actually be used to construct the Laplacian pyramid. First, it upsamples the source image by\n",
      "        .   injecting even zero rows and columns and then convolves the result with the same kernel as in\n",
      "        .   pyrDown multiplied by 4.\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image. It has the specified size and the same type as src .\n",
      "        .   @param dstsize size of the output image.\n",
      "        .   @param borderType Pixel extrapolation method, see #BorderTypes (only #BORDER_DEFAULT is supported)\n",
      "    \n",
      "    randShuffle(...)\n",
      "        randShuffle(dst[, iterFactor]) -> dst\n",
      "        .   @brief Shuffles the array elements randomly.\n",
      "        .   \n",
      "        .   The function cv::randShuffle shuffles the specified 1D array by randomly choosing pairs of elements and\n",
      "        .   swapping them. The number of such swap operations will be dst.rows\\*dst.cols\\*iterFactor .\n",
      "        .   @param dst input/output numerical 1D array.\n",
      "        .   @param iterFactor scale factor that determines the number of random swap operations (see the details\n",
      "        .   below).\n",
      "        .   @param rng optional random number generator used for shuffling; if it is zero, theRNG () is used\n",
      "        .   instead.\n",
      "        .   @sa RNG, sort\n",
      "    \n",
      "    randn(...)\n",
      "        randn(dst, mean, stddev) -> dst\n",
      "        .   @brief Fills the array with normally distributed random numbers.\n",
      "        .   \n",
      "        .   The function cv::randn fills the matrix dst with normally distributed random numbers with the specified\n",
      "        .   mean vector and the standard deviation matrix. The generated random numbers are clipped to fit the\n",
      "        .   value range of the output array data type.\n",
      "        .   @param dst output array of random numbers; the array must be pre-allocated and have 1 to 4 channels.\n",
      "        .   @param mean mean value (expectation) of the generated random numbers.\n",
      "        .   @param stddev standard deviation of the generated random numbers; it can be either a vector (in\n",
      "        .   which case a diagonal standard deviation matrix is assumed) or a square matrix.\n",
      "        .   @sa RNG, randu\n",
      "    \n",
      "    randu(...)\n",
      "        randu(dst, low, high) -> dst\n",
      "        .   @brief Generates a single uniformly-distributed random number or an array of random numbers.\n",
      "        .   \n",
      "        .   Non-template variant of the function fills the matrix dst with uniformly-distributed\n",
      "        .   random numbers from the specified range:\n",
      "        .   \\f[\\texttt{low} _c  \\leq \\texttt{dst} (I)_c <  \\texttt{high} _c\\f]\n",
      "        .   @param dst output array of random numbers; the array must be pre-allocated.\n",
      "        .   @param low inclusive lower boundary of the generated random numbers.\n",
      "        .   @param high exclusive upper boundary of the generated random numbers.\n",
      "        .   @sa RNG, randn, theRNG\n",
      "    \n",
      "    readOpticalFlow(...)\n",
      "        readOpticalFlow(path) -> retval\n",
      "        .   @brief Read a .flo file\n",
      "        .   \n",
      "        .    @param path Path to the file to be loaded\n",
      "        .   \n",
      "        .    The function readOpticalFlow loads a flow field from a file and returns it as a single matrix.\n",
      "        .    Resulting Mat has a type CV_32FC2 - floating-point, 2-channel. First channel corresponds to the\n",
      "        .    flow in the horizontal direction (u), second - vertical (v).\n",
      "    \n",
      "    recoverPose(...)\n",
      "        recoverPose(E, points1, points2, cameraMatrix[, R[, t[, mask]]]) -> retval, R, t, mask\n",
      "        .   @brief Recovers the relative camera rotation and the translation from an estimated essential\n",
      "        .   matrix and the corresponding points in two images, using cheirality check. Returns the number of\n",
      "        .   inliers that pass the check.\n",
      "        .   \n",
      "        .   @param E The input essential matrix.\n",
      "        .   @param points1 Array of N 2D points from the first image. The point coordinates should be\n",
      "        .   floating-point (single or double precision).\n",
      "        .   @param points2 Array of the second image points of the same size and format as points1 .\n",
      "        .   @param cameraMatrix Camera matrix \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   Note that this function assumes that points1 and points2 are feature points from cameras with the\n",
      "        .   same camera matrix.\n",
      "        .   @param R Output rotation matrix. Together with the translation vector, this matrix makes up a tuple\n",
      "        .   that performs a change of basis from the first camera's coordinate system to the second camera's\n",
      "        .   coordinate system. Note that, in general, t can not be used for this tuple, see the parameter\n",
      "        .   described below.\n",
      "        .   @param t Output translation vector. This vector is obtained by @ref decomposeEssentialMat and\n",
      "        .   therefore is only known up to scale, i.e. t is the direction of the translation vector and has unit\n",
      "        .   length.\n",
      "        .   @param mask Input/output mask for inliers in points1 and points2. If it is not empty, then it marks\n",
      "        .   inliers in points1 and points2 for then given essential matrix E. Only these inliers will be used to\n",
      "        .   recover pose. In the output mask only inliers which pass the cheirality check.\n",
      "        .   \n",
      "        .   This function decomposes an essential matrix using @ref decomposeEssentialMat and then verifies\n",
      "        .   possible pose hypotheses by doing cheirality check. The cheirality check means that the\n",
      "        .   triangulated 3D points should have positive depth. Some details can be found in @cite Nister03.\n",
      "        .   \n",
      "        .   This function can be used to process the output E and mask from @ref findEssentialMat. In this\n",
      "        .   scenario, points1 and points2 are the same input for findEssentialMat.:\n",
      "        .   @code\n",
      "        .       // Example. Estimation of fundamental matrix using the RANSAC algorithm\n",
      "        .       int point_count = 100;\n",
      "        .       vector<Point2f> points1(point_count);\n",
      "        .       vector<Point2f> points2(point_count);\n",
      "        .   \n",
      "        .       // initialize the points here ...\n",
      "        .       for( int i = 0; i < point_count; i++ )\n",
      "        .       {\n",
      "        .           points1[i] = ...;\n",
      "        .           points2[i] = ...;\n",
      "        .       }\n",
      "        .   \n",
      "        .       // cametra matrix with both focal lengths = 1, and principal point = (0, 0)\n",
      "        .       Mat cameraMatrix = Mat::eye(3, 3, CV_64F);\n",
      "        .   \n",
      "        .       Mat E, R, t, mask;\n",
      "        .   \n",
      "        .       E = findEssentialMat(points1, points2, cameraMatrix, RANSAC, 0.999, 1.0, mask);\n",
      "        .       recoverPose(E, points1, points2, cameraMatrix, R, t, mask);\n",
      "        .   @endcode\n",
      "        \n",
      "        \n",
      "        \n",
      "        recoverPose(E, points1, points2[, R[, t[, focal[, pp[, mask]]]]]) -> retval, R, t, mask\n",
      "        .   @overload\n",
      "        .   @param E The input essential matrix.\n",
      "        .   @param points1 Array of N 2D points from the first image. The point coordinates should be\n",
      "        .   floating-point (single or double precision).\n",
      "        .   @param points2 Array of the second image points of the same size and format as points1 .\n",
      "        .   @param R Output rotation matrix. Together with the translation vector, this matrix makes up a tuple\n",
      "        .   that performs a change of basis from the first camera's coordinate system to the second camera's\n",
      "        .   coordinate system. Note that, in general, t can not be used for this tuple, see the parameter\n",
      "        .   description below.\n",
      "        .   @param t Output translation vector. This vector is obtained by @ref decomposeEssentialMat and\n",
      "        .   therefore is only known up to scale, i.e. t is the direction of the translation vector and has unit\n",
      "        .   length.\n",
      "        .   @param focal Focal length of the camera. Note that this function assumes that points1 and points2\n",
      "        .   are feature points from cameras with same focal length and principal point.\n",
      "        .   @param pp principal point of the camera.\n",
      "        .   @param mask Input/output mask for inliers in points1 and points2. If it is not empty, then it marks\n",
      "        .   inliers in points1 and points2 for then given essential matrix E. Only these inliers will be used to\n",
      "        .   recover pose. In the output mask only inliers which pass the cheirality check.\n",
      "        .   \n",
      "        .   This function differs from the one above that it computes camera matrix from focal length and\n",
      "        .   principal point:\n",
      "        .   \n",
      "        .   \\f[A =\n",
      "        .   \\begin{bmatrix}\n",
      "        .   f & 0 & x_{pp}  \\\\\n",
      "        .   0 & f & y_{pp}  \\\\\n",
      "        .   0 & 0 & 1\n",
      "        .   \\end{bmatrix}\\f]\n",
      "        \n",
      "        \n",
      "        \n",
      "        recoverPose(E, points1, points2, cameraMatrix, distanceThresh[, R[, t[, mask[, triangulatedPoints]]]]) -> retval, R, t, mask, triangulatedPoints\n",
      "        .   @overload\n",
      "        .   @param E The input essential matrix.\n",
      "        .   @param points1 Array of N 2D points from the first image. The point coordinates should be\n",
      "        .   floating-point (single or double precision).\n",
      "        .   @param points2 Array of the second image points of the same size and format as points1.\n",
      "        .   @param cameraMatrix Camera matrix \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   Note that this function assumes that points1 and points2 are feature points from cameras with the\n",
      "        .   same camera matrix.\n",
      "        .   @param R Output rotation matrix. Together with the translation vector, this matrix makes up a tuple\n",
      "        .   that performs a change of basis from the first camera's coordinate system to the second camera's\n",
      "        .   coordinate system. Note that, in general, t can not be used for this tuple, see the parameter\n",
      "        .   description below.\n",
      "        .   @param t Output translation vector. This vector is obtained by @ref decomposeEssentialMat and\n",
      "        .   therefore is only known up to scale, i.e. t is the direction of the translation vector and has unit\n",
      "        .   length.\n",
      "        .   @param distanceThresh threshold distance which is used to filter out far away points (i.e. infinite\n",
      "        .   points).\n",
      "        .   @param mask Input/output mask for inliers in points1 and points2. If it is not empty, then it marks\n",
      "        .   inliers in points1 and points2 for then given essential matrix E. Only these inliers will be used to\n",
      "        .   recover pose. In the output mask only inliers which pass the cheirality check.\n",
      "        .   @param triangulatedPoints 3D points which were reconstructed by triangulation.\n",
      "        .   \n",
      "        .   This function differs from the one above that it outputs the triangulated 3D point that are used for\n",
      "        .   the cheirality check.\n",
      "    \n",
      "    rectangle(...)\n",
      "        rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]]) -> img\n",
      "        .   @brief Draws a simple, thick, or filled up-right rectangle.\n",
      "        .   \n",
      "        .   The function cv::rectangle draws a rectangle outline or a filled rectangle whose two opposite corners\n",
      "        .   are pt1 and pt2.\n",
      "        .   \n",
      "        .   @param img Image.\n",
      "        .   @param pt1 Vertex of the rectangle.\n",
      "        .   @param pt2 Vertex of the rectangle opposite to pt1 .\n",
      "        .   @param color Rectangle color or brightness (grayscale image).\n",
      "        .   @param thickness Thickness of lines that make up the rectangle. Negative values, like #FILLED,\n",
      "        .   mean that the function has to draw a filled rectangle.\n",
      "        .   @param lineType Type of the line. See #LineTypes\n",
      "        .   @param shift Number of fractional bits in the point coordinates.\n",
      "        \n",
      "        \n",
      "        \n",
      "        rectangle(img, rec, color[, thickness[, lineType[, shift]]]) -> img\n",
      "        .   @overload\n",
      "        .   \n",
      "        .   use `rec` parameter as alternative specification of the drawn rectangle: `r.tl() and\n",
      "        .   r.br()-Point(1,1)` are opposite corners\n",
      "    \n",
      "    rectify3Collinear(...)\n",
      "        rectify3Collinear(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, cameraMatrix3, distCoeffs3, imgpt1, imgpt3, imageSize, R12, T12, R13, T13, alpha, newImgSize, flags[, R1[, R2[, R3[, P1[, P2[, P3[, Q]]]]]]]) -> retval, R1, R2, R3, P1, P2, P3, Q, roi1, roi2\n",
      "        .\n",
      "    \n",
      "    redirectError(...)\n",
      "        redirectError(onError) -> None\n",
      "    \n",
      "    reduce(...)\n",
      "        reduce(src, dim, rtype[, dst[, dtype]]) -> dst\n",
      "        .   @brief Reduces a matrix to a vector.\n",
      "        .   \n",
      "        .   The function #reduce reduces the matrix to a vector by treating the matrix rows/columns as a set of\n",
      "        .   1D vectors and performing the specified operation on the vectors until a single row/column is\n",
      "        .   obtained. For example, the function can be used to compute horizontal and vertical projections of a\n",
      "        .   raster image. In case of #REDUCE_MAX and #REDUCE_MIN , the output image should have the same type as the source one.\n",
      "        .   In case of #REDUCE_SUM and #REDUCE_AVG , the output may have a larger element bit-depth to preserve accuracy.\n",
      "        .   And multi-channel arrays are also supported in these two reduction modes.\n",
      "        .   \n",
      "        .   The following code demonstrates its usage for a single channel matrix.\n",
      "        .   @snippet snippets/core_reduce.cpp example\n",
      "        .   \n",
      "        .   And the following code demonstrates its usage for a two-channel matrix.\n",
      "        .   @snippet snippets/core_reduce.cpp example2\n",
      "        .   \n",
      "        .   @param src input 2D matrix.\n",
      "        .   @param dst output vector. Its size and type is defined by dim and dtype parameters.\n",
      "        .   @param dim dimension index along which the matrix is reduced. 0 means that the matrix is reduced to\n",
      "        .   a single row. 1 means that the matrix is reduced to a single column.\n",
      "        .   @param rtype reduction operation that could be one of #ReduceTypes\n",
      "        .   @param dtype when negative, the output vector will have the same type as the input matrix,\n",
      "        .   otherwise, its type will be CV_MAKE_TYPE(CV_MAT_DEPTH(dtype), src.channels()).\n",
      "        .   @sa repeat\n",
      "    \n",
      "    remap(...)\n",
      "        remap(src, map1, map2, interpolation[, dst[, borderMode[, borderValue]]]) -> dst\n",
      "        .   @brief Applies a generic geometrical transformation to an image.\n",
      "        .   \n",
      "        .   The function remap transforms the source image using the specified map:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\texttt{src} (map_x(x,y),map_y(x,y))\\f]\n",
      "        .   \n",
      "        .   where values of pixels with non-integer coordinates are computed using one of available\n",
      "        .   interpolation methods. \\f$map_x\\f$ and \\f$map_y\\f$ can be encoded as separate floating-point maps\n",
      "        .   in \\f$map_1\\f$ and \\f$map_2\\f$ respectively, or interleaved floating-point maps of \\f$(x,y)\\f$ in\n",
      "        .   \\f$map_1\\f$, or fixed-point maps created by using convertMaps. The reason you might want to\n",
      "        .   convert from floating to fixed-point representations of a map is that they can yield much faster\n",
      "        .   (\\~2x) remapping operations. In the converted case, \\f$map_1\\f$ contains pairs (cvFloor(x),\n",
      "        .   cvFloor(y)) and \\f$map_2\\f$ contains indices in a table of interpolation coefficients.\n",
      "        .   \n",
      "        .   This function cannot operate in-place.\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image. It has the same size as map1 and the same type as src .\n",
      "        .   @param map1 The first map of either (x,y) points or just x values having the type CV_16SC2 ,\n",
      "        .   CV_32FC1, or CV_32FC2. See convertMaps for details on converting a floating point\n",
      "        .   representation to fixed-point for speed.\n",
      "        .   @param map2 The second map of y values having the type CV_16UC1, CV_32FC1, or none (empty map\n",
      "        .   if map1 is (x,y) points), respectively.\n",
      "        .   @param interpolation Interpolation method (see #InterpolationFlags). The method #INTER_AREA is\n",
      "        .   not supported by this function.\n",
      "        .   @param borderMode Pixel extrapolation method (see #BorderTypes). When\n",
      "        .   borderMode=#BORDER_TRANSPARENT, it means that the pixels in the destination image that\n",
      "        .   corresponds to the \"outliers\" in the source image are not modified by the function.\n",
      "        .   @param borderValue Value used in case of a constant border. By default, it is 0.\n",
      "        .   @note\n",
      "        .   Due to current implementation limitations the size of an input and output images should be less than 32767x32767.\n",
      "    \n",
      "    repeat(...)\n",
      "        repeat(src, ny, nx[, dst]) -> dst\n",
      "        .   @brief Fills the output array with repeated copies of the input array.\n",
      "        .   \n",
      "        .   The function cv::repeat duplicates the input array one or more times along each of the two axes:\n",
      "        .   \\f[\\texttt{dst} _{ij}= \\texttt{src} _{i\\mod src.rows, \\; j\\mod src.cols }\\f]\n",
      "        .   The second variant of the function is more convenient to use with @ref MatrixExpressions.\n",
      "        .   @param src input array to replicate.\n",
      "        .   @param ny Flag to specify how many times the `src` is repeated along the\n",
      "        .   vertical axis.\n",
      "        .   @param nx Flag to specify how many times the `src` is repeated along the\n",
      "        .   horizontal axis.\n",
      "        .   @param dst output array of the same type as `src`.\n",
      "        .   @sa cv::reduce\n",
      "    \n",
      "    reprojectImageTo3D(...)\n",
      "        reprojectImageTo3D(disparity, Q[, _3dImage[, handleMissingValues[, ddepth]]]) -> _3dImage\n",
      "        .   @brief Reprojects a disparity image to 3D space.\n",
      "        .   \n",
      "        .   @param disparity Input single-channel 8-bit unsigned, 16-bit signed, 32-bit signed or 32-bit\n",
      "        .   floating-point disparity image. The values of 8-bit / 16-bit signed formats are assumed to have no\n",
      "        .   fractional bits. If the disparity is 16-bit signed format, as computed by @ref StereoBM or\n",
      "        .   @ref StereoSGBM and maybe other algorithms, it should be divided by 16 (and scaled to float) before\n",
      "        .   being used here.\n",
      "        .   @param _3dImage Output 3-channel floating-point image of the same size as disparity. Each element of\n",
      "        .   _3dImage(x,y) contains 3D coordinates of the point (x,y) computed from the disparity map. If one\n",
      "        .   uses Q obtained by @ref stereoRectify, then the returned points are represented in the first\n",
      "        .   camera's rectified coordinate system.\n",
      "        .   @param Q \\f$4 \\times 4\\f$ perspective transformation matrix that can be obtained with\n",
      "        .   @ref stereoRectify.\n",
      "        .   @param handleMissingValues Indicates, whether the function should handle missing values (i.e.\n",
      "        .   points where the disparity was not computed). If handleMissingValues=true, then pixels with the\n",
      "        .   minimal disparity that corresponds to the outliers (see StereoMatcher::compute ) are transformed\n",
      "        .   to 3D points with a very large Z value (currently set to 10000).\n",
      "        .   @param ddepth The optional output array depth. If it is -1, the output image will have CV_32F\n",
      "        .   depth. ddepth can also be set to CV_16S, CV_32S or CV_32F.\n",
      "        .   \n",
      "        .   The function transforms a single-channel disparity map to a 3-channel image representing a 3D\n",
      "        .   surface. That is, for each pixel (x,y) and the corresponding disparity d=disparity(x,y) , it\n",
      "        .   computes:\n",
      "        .   \n",
      "        .   \\f[\\begin{bmatrix}\n",
      "        .   X \\\\\n",
      "        .   Y \\\\\n",
      "        .   Z \\\\\n",
      "        .   W\n",
      "        .   \\end{bmatrix} = Q \\begin{bmatrix}\n",
      "        .   x \\\\\n",
      "        .   y \\\\\n",
      "        .   \\texttt{disparity} (x,y) \\\\\n",
      "        .   z\n",
      "        .   \\end{bmatrix}.\\f]\n",
      "        .   \n",
      "        .   @sa\n",
      "        .      To reproject a sparse set of points {(x,y,d),...} to 3D space, use perspectiveTransform.\n",
      "    \n",
      "    resize(...)\n",
      "        resize(src, dsize[, dst[, fx[, fy[, interpolation]]]]) -> dst\n",
      "        .   @brief Resizes an image.\n",
      "        .   \n",
      "        .   The function resize resizes the image src down to or up to the specified size. Note that the\n",
      "        .   initial dst type or size are not taken into account. Instead, the size and type are derived from\n",
      "        .   the `src`,`dsize`,`fx`, and `fy`. If you want to resize src so that it fits the pre-created dst,\n",
      "        .   you may call the function as follows:\n",
      "        .   @code\n",
      "        .       // explicitly specify dsize=dst.size(); fx and fy will be computed from that.\n",
      "        .       resize(src, dst, dst.size(), 0, 0, interpolation);\n",
      "        .   @endcode\n",
      "        .   If you want to decimate the image by factor of 2 in each direction, you can call the function this\n",
      "        .   way:\n",
      "        .   @code\n",
      "        .       // specify fx and fy and let the function compute the destination image size.\n",
      "        .       resize(src, dst, Size(), 0.5, 0.5, interpolation);\n",
      "        .   @endcode\n",
      "        .   To shrink an image, it will generally look best with #INTER_AREA interpolation, whereas to\n",
      "        .   enlarge an image, it will generally look best with c#INTER_CUBIC (slow) or #INTER_LINEAR\n",
      "        .   (faster but still looks OK).\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image; it has the size dsize (when it is non-zero) or the size computed from\n",
      "        .   src.size(), fx, and fy; the type of dst is the same as of src.\n",
      "        .   @param dsize output image size; if it equals zero, it is computed as:\n",
      "        .    \\f[\\texttt{dsize = Size(round(fx*src.cols), round(fy*src.rows))}\\f]\n",
      "        .    Either dsize or both fx and fy must be non-zero.\n",
      "        .   @param fx scale factor along the horizontal axis; when it equals 0, it is computed as\n",
      "        .   \\f[\\texttt{(double)dsize.width/src.cols}\\f]\n",
      "        .   @param fy scale factor along the vertical axis; when it equals 0, it is computed as\n",
      "        .   \\f[\\texttt{(double)dsize.height/src.rows}\\f]\n",
      "        .   @param interpolation interpolation method, see #InterpolationFlags\n",
      "        .   \n",
      "        .   @sa  warpAffine, warpPerspective, remap\n",
      "    \n",
      "    resizeWindow(...)\n",
      "        resizeWindow(winname, width, height) -> None\n",
      "        .   @brief Resizes window to the specified size\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   -   The specified window size is for the image area. Toolbars are not counted.\n",
      "        .   -   Only windows created without cv::WINDOW_AUTOSIZE flag can be resized.\n",
      "        .   \n",
      "        .   @param winname Window name.\n",
      "        .   @param width The new window width.\n",
      "        .   @param height The new window height.\n",
      "        \n",
      "        \n",
      "        \n",
      "        resizeWindow(winname, size) -> None\n",
      "        .   @overload\n",
      "        .   @param winname Window name.\n",
      "        .   @param size The new window size.\n",
      "    \n",
      "    rotate(...)\n",
      "        rotate(src, rotateCode[, dst]) -> dst\n",
      "        .   @brief Rotates a 2D array in multiples of 90 degrees.\n",
      "        .   The function cv::rotate rotates the array in one of three different ways:\n",
      "        .   *   Rotate by 90 degrees clockwise (rotateCode = ROTATE_90_CLOCKWISE).\n",
      "        .   *   Rotate by 180 degrees clockwise (rotateCode = ROTATE_180).\n",
      "        .   *   Rotate by 270 degrees clockwise (rotateCode = ROTATE_90_COUNTERCLOCKWISE).\n",
      "        .   @param src input array.\n",
      "        .   @param dst output array of the same type as src.  The size is the same with ROTATE_180,\n",
      "        .   and the rows and cols are switched for ROTATE_90_CLOCKWISE and ROTATE_90_COUNTERCLOCKWISE.\n",
      "        .   @param rotateCode an enum to specify how to rotate the array; see the enum #RotateFlags\n",
      "        .   @sa transpose , repeat , completeSymm, flip, RotateFlags\n",
      "    \n",
      "    rotatedRectangleIntersection(...)\n",
      "        rotatedRectangleIntersection(rect1, rect2[, intersectingRegion]) -> retval, intersectingRegion\n",
      "        .   @brief Finds out if there is any intersection between two rotated rectangles.\n",
      "        .   \n",
      "        .   If there is then the vertices of the intersecting region are returned as well.\n",
      "        .   \n",
      "        .   Below are some examples of intersection configurations. The hatched pattern indicates the\n",
      "        .   intersecting region and the red vertices are returned by the function.\n",
      "        .   \n",
      "        .   ![intersection examples](pics/intersection.png)\n",
      "        .   \n",
      "        .   @param rect1 First rectangle\n",
      "        .   @param rect2 Second rectangle\n",
      "        .   @param intersectingRegion The output array of the vertices of the intersecting region. It returns\n",
      "        .   at most 8 vertices. Stored as std::vector\\<cv::Point2f\\> or cv::Mat as Mx1 of type CV_32FC2.\n",
      "        .   @returns One of #RectanglesIntersectTypes\n",
      "    \n",
      "    sampsonDistance(...)\n",
      "        sampsonDistance(pt1, pt2, F) -> retval\n",
      "        .   @brief Calculates the Sampson Distance between two points.\n",
      "        .   \n",
      "        .   The function cv::sampsonDistance calculates and returns the first order approximation of the geometric error as:\n",
      "        .   \\f[\n",
      "        .   sd( \\texttt{pt1} , \\texttt{pt2} )=\n",
      "        .   \\frac{(\\texttt{pt2}^t \\cdot \\texttt{F} \\cdot \\texttt{pt1})^2}\n",
      "        .   {((\\texttt{F} \\cdot \\texttt{pt1})(0))^2 +\n",
      "        .   ((\\texttt{F} \\cdot \\texttt{pt1})(1))^2 +\n",
      "        .   ((\\texttt{F}^t \\cdot \\texttt{pt2})(0))^2 +\n",
      "        .   ((\\texttt{F}^t \\cdot \\texttt{pt2})(1))^2}\n",
      "        .   \\f]\n",
      "        .   The fundamental matrix may be calculated using the cv::findFundamentalMat function. See @cite HartleyZ00 11.4.3 for details.\n",
      "        .   @param pt1 first homogeneous 2d point\n",
      "        .   @param pt2 second homogeneous 2d point\n",
      "        .   @param F fundamental matrix\n",
      "        .   @return The computed Sampson distance.\n",
      "    \n",
      "    scaleAdd(...)\n",
      "        scaleAdd(src1, alpha, src2[, dst]) -> dst\n",
      "        .   @brief Calculates the sum of a scaled array and another array.\n",
      "        .   \n",
      "        .   The function scaleAdd is one of the classical primitive linear algebra operations, known as DAXPY\n",
      "        .   or SAXPY in [BLAS](http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms). It calculates\n",
      "        .   the sum of a scaled array and another array:\n",
      "        .   \\f[\\texttt{dst} (I)= \\texttt{scale} \\cdot \\texttt{src1} (I) +  \\texttt{src2} (I)\\f]\n",
      "        .   The function can also be emulated with a matrix expression, for example:\n",
      "        .   @code{.cpp}\n",
      "        .       Mat A(3, 3, CV_64F);\n",
      "        .       ...\n",
      "        .       A.row(0) = A.row(1)*2 + A.row(2);\n",
      "        .   @endcode\n",
      "        .   @param src1 first input array.\n",
      "        .   @param alpha scale factor for the first array.\n",
      "        .   @param src2 second input array of the same size and type as src1.\n",
      "        .   @param dst output array of the same size and type as src1.\n",
      "        .   @sa add, addWeighted, subtract, Mat::dot, Mat::convertTo\n",
      "    \n",
      "    seamlessClone(...)\n",
      "        seamlessClone(src, dst, mask, p, flags[, blend]) -> blend\n",
      "        .   @brief Image editing tasks concern either global changes (color/intensity corrections, filters,\n",
      "        .   deformations) or local changes concerned to a selection. Here we are interested in achieving local\n",
      "        .   changes, ones that are restricted to a region manually selected (ROI), in a seamless and effortless\n",
      "        .   manner. The extent of the changes ranges from slight distortions to complete replacement by novel\n",
      "        .   content @cite PM03 .\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param dst Input 8-bit 3-channel image.\n",
      "        .   @param mask Input 8-bit 1 or 3-channel image.\n",
      "        .   @param p Point in dst image where object is placed.\n",
      "        .   @param blend Output image with the same size and type as dst.\n",
      "        .   @param flags Cloning method that could be cv::NORMAL_CLONE, cv::MIXED_CLONE or cv::MONOCHROME_TRANSFER\n",
      "    \n",
      "    selectROI(...)\n",
      "        selectROI(windowName, img[, showCrosshair[, fromCenter]]) -> retval\n",
      "        .   @brief Selects ROI on the given image.\n",
      "        .   Function creates a window and allows user to select a ROI using mouse.\n",
      "        .   Controls: use `space` or `enter` to finish selection, use key `c` to cancel selection (function will return the zero cv::Rect).\n",
      "        .   \n",
      "        .   @param windowName name of the window where selection process will be shown.\n",
      "        .   @param img image to select a ROI.\n",
      "        .   @param showCrosshair if true crosshair of selection rectangle will be shown.\n",
      "        .   @param fromCenter if true center of selection will match initial mouse position. In opposite case a corner of\n",
      "        .   selection rectangle will correspont to the initial mouse position.\n",
      "        .   @return selected ROI or empty rect if selection canceled.\n",
      "        .   \n",
      "        .   @note The function sets it's own mouse callback for specified window using cv::setMouseCallback(windowName, ...).\n",
      "        .   After finish of work an empty callback will be set for the used window.\n",
      "        \n",
      "        \n",
      "        \n",
      "        selectROI(img[, showCrosshair[, fromCenter]]) -> retval\n",
      "        .   @overload\n",
      "    \n",
      "    selectROIs(...)\n",
      "        selectROIs(windowName, img[, showCrosshair[, fromCenter]]) -> boundingBoxes\n",
      "        .   @brief Selects ROIs on the given image.\n",
      "        .   Function creates a window and allows user to select a ROIs using mouse.\n",
      "        .   Controls: use `space` or `enter` to finish current selection and start a new one,\n",
      "        .   use `esc` to terminate multiple ROI selection process.\n",
      "        .   \n",
      "        .   @param windowName name of the window where selection process will be shown.\n",
      "        .   @param img image to select a ROI.\n",
      "        .   @param boundingBoxes selected ROIs.\n",
      "        .   @param showCrosshair if true crosshair of selection rectangle will be shown.\n",
      "        .   @param fromCenter if true center of selection will match initial mouse position. In opposite case a corner of\n",
      "        .   selection rectangle will correspont to the initial mouse position.\n",
      "        .   \n",
      "        .   @note The function sets it's own mouse callback for specified window using cv::setMouseCallback(windowName, ...).\n",
      "        .   After finish of work an empty callback will be set for the used window.\n",
      "    \n",
      "    sepFilter2D(...)\n",
      "        sepFilter2D(src, ddepth, kernelX, kernelY[, dst[, anchor[, delta[, borderType]]]]) -> dst\n",
      "        .   @brief Applies a separable linear filter to an image.\n",
      "        .   \n",
      "        .   The function applies a separable linear filter to the image. That is, first, every row of src is\n",
      "        .   filtered with the 1D kernel kernelX. Then, every column of the result is filtered with the 1D\n",
      "        .   kernel kernelY. The final result shifted by delta is stored in dst .\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image of the same size and the same number of channels as src .\n",
      "        .   @param ddepth Destination image depth, see @ref filter_depths \"combinations\"\n",
      "        .   @param kernelX Coefficients for filtering each row.\n",
      "        .   @param kernelY Coefficients for filtering each column.\n",
      "        .   @param anchor Anchor position within the kernel. The default value \\f$(-1,-1)\\f$ means that the anchor\n",
      "        .   is at the kernel center.\n",
      "        .   @param delta Value added to the filtered results before storing them.\n",
      "        .   @param borderType Pixel extrapolation method, see #BorderTypes. #BORDER_WRAP is not supported.\n",
      "        .   @sa  filter2D, Sobel, GaussianBlur, boxFilter, blur\n",
      "    \n",
      "    setIdentity(...)\n",
      "        setIdentity(mtx[, s]) -> mtx\n",
      "        .   @brief Initializes a scaled identity matrix.\n",
      "        .   \n",
      "        .   The function cv::setIdentity initializes a scaled identity matrix:\n",
      "        .   \\f[\\texttt{mtx} (i,j)= \\fork{\\texttt{value}}{ if \\(i=j\\)}{0}{otherwise}\\f]\n",
      "        .   \n",
      "        .   The function can also be emulated using the matrix initializers and the\n",
      "        .   matrix expressions:\n",
      "        .   @code\n",
      "        .       Mat A = Mat::eye(4, 3, CV_32F)*5;\n",
      "        .       // A will be set to [[5, 0, 0], [0, 5, 0], [0, 0, 5], [0, 0, 0]]\n",
      "        .   @endcode\n",
      "        .   @param mtx matrix to initialize (not necessarily square).\n",
      "        .   @param s value to assign to diagonal elements.\n",
      "        .   @sa Mat::zeros, Mat::ones, Mat::setTo, Mat::operator=\n",
      "    \n",
      "    setMouseCallback(...)\n",
      "        setMouseCallback(windowName, onMouse [, param]) -> None\n",
      "    \n",
      "    setNumThreads(...)\n",
      "        setNumThreads(nthreads) -> None\n",
      "        .   @brief OpenCV will try to set the number of threads for the next parallel region.\n",
      "        .   \n",
      "        .   If threads == 0, OpenCV will disable threading optimizations and run all it's functions\n",
      "        .   sequentially. Passing threads \\< 0 will reset threads number to system default. This function must\n",
      "        .   be called outside of parallel region.\n",
      "        .   \n",
      "        .   OpenCV will try to run its functions with specified threads number, but some behaviour differs from\n",
      "        .   framework:\n",
      "        .   -   `TBB` - User-defined parallel constructions will run with the same threads number, if\n",
      "        .       another is not specified. If later on user creates his own scheduler, OpenCV will use it.\n",
      "        .   -   `OpenMP` - No special defined behaviour.\n",
      "        .   -   `Concurrency` - If threads == 1, OpenCV will disable threading optimizations and run its\n",
      "        .       functions sequentially.\n",
      "        .   -   `GCD` - Supports only values \\<= 0.\n",
      "        .   -   `C=` - No special defined behaviour.\n",
      "        .   @param nthreads Number of threads used by OpenCV.\n",
      "        .   @sa getNumThreads, getThreadNum\n",
      "    \n",
      "    setRNGSeed(...)\n",
      "        setRNGSeed(seed) -> None\n",
      "        .   @brief Sets state of default random number generator.\n",
      "        .   \n",
      "        .   The function cv::setRNGSeed sets state of default random number generator to custom value.\n",
      "        .   @param seed new state for default random number generator\n",
      "        .   @sa RNG, randu, randn\n",
      "    \n",
      "    setTrackbarMax(...)\n",
      "        setTrackbarMax(trackbarname, winname, maxval) -> None\n",
      "        .   @brief Sets the trackbar maximum position.\n",
      "        .   \n",
      "        .   The function sets the maximum position of the specified trackbar in the specified window.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   [__Qt Backend Only__] winname can be empty if the trackbar is attached to the control\n",
      "        .   panel.\n",
      "        .   \n",
      "        .   @param trackbarname Name of the trackbar.\n",
      "        .   @param winname Name of the window that is the parent of trackbar.\n",
      "        .   @param maxval New maximum position.\n",
      "    \n",
      "    setTrackbarMin(...)\n",
      "        setTrackbarMin(trackbarname, winname, minval) -> None\n",
      "        .   @brief Sets the trackbar minimum position.\n",
      "        .   \n",
      "        .   The function sets the minimum position of the specified trackbar in the specified window.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   [__Qt Backend Only__] winname can be empty if the trackbar is attached to the control\n",
      "        .   panel.\n",
      "        .   \n",
      "        .   @param trackbarname Name of the trackbar.\n",
      "        .   @param winname Name of the window that is the parent of trackbar.\n",
      "        .   @param minval New minimum position.\n",
      "    \n",
      "    setTrackbarPos(...)\n",
      "        setTrackbarPos(trackbarname, winname, pos) -> None\n",
      "        .   @brief Sets the trackbar position.\n",
      "        .   \n",
      "        .   The function sets the position of the specified trackbar in the specified window.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   [__Qt Backend Only__] winname can be empty if the trackbar is attached to the control\n",
      "        .   panel.\n",
      "        .   \n",
      "        .   @param trackbarname Name of the trackbar.\n",
      "        .   @param winname Name of the window that is the parent of trackbar.\n",
      "        .   @param pos New position.\n",
      "    \n",
      "    setUseOpenVX(...)\n",
      "        setUseOpenVX(flag) -> None\n",
      "        .\n",
      "    \n",
      "    setUseOptimized(...)\n",
      "        setUseOptimized(onoff) -> None\n",
      "        .   @brief Enables or disables the optimized code.\n",
      "        .   \n",
      "        .   The function can be used to dynamically turn on and off optimized dispatched code (code that uses SSE4.2, AVX/AVX2,\n",
      "        .   and other instructions on the platforms that support it). It sets a global flag that is further\n",
      "        .   checked by OpenCV functions. Since the flag is not checked in the inner OpenCV loops, it is only\n",
      "        .   safe to call the function on the very top level in your application where you can be sure that no\n",
      "        .   other OpenCV function is currently executed.\n",
      "        .   \n",
      "        .   By default, the optimized code is enabled unless you disable it in CMake. The current status can be\n",
      "        .   retrieved using useOptimized.\n",
      "        .   @param onoff The boolean flag specifying whether the optimized code should be used (onoff=true)\n",
      "        .   or not (onoff=false).\n",
      "    \n",
      "    setWindowProperty(...)\n",
      "        setWindowProperty(winname, prop_id, prop_value) -> None\n",
      "        .   @brief Changes parameters of a window dynamically.\n",
      "        .   \n",
      "        .   The function setWindowProperty enables changing properties of a window.\n",
      "        .   \n",
      "        .   @param winname Name of the window.\n",
      "        .   @param prop_id Window property to edit. The supported operation flags are: (cv::WindowPropertyFlags)\n",
      "        .   @param prop_value New value of the window property. The supported flags are: (cv::WindowFlags)\n",
      "    \n",
      "    setWindowTitle(...)\n",
      "        setWindowTitle(winname, title) -> None\n",
      "        .   @brief Updates window title\n",
      "        .   @param winname Name of the window.\n",
      "        .   @param title New title.\n",
      "    \n",
      "    solve(...)\n",
      "        solve(src1, src2[, dst[, flags]]) -> retval, dst\n",
      "        .   @brief Solves one or more linear systems or least-squares problems.\n",
      "        .   \n",
      "        .   The function cv::solve solves a linear system or least-squares problem (the\n",
      "        .   latter is possible with SVD or QR methods, or by specifying the flag\n",
      "        .   #DECOMP_NORMAL ):\n",
      "        .   \\f[\\texttt{dst} =  \\arg \\min _X \\| \\texttt{src1} \\cdot \\texttt{X} -  \\texttt{src2} \\|\\f]\n",
      "        .   \n",
      "        .   If #DECOMP_LU or #DECOMP_CHOLESKY method is used, the function returns 1\n",
      "        .   if src1 (or \\f$\\texttt{src1}^T\\texttt{src1}\\f$ ) is non-singular. Otherwise,\n",
      "        .   it returns 0. In the latter case, dst is not valid. Other methods find a\n",
      "        .   pseudo-solution in case of a singular left-hand side part.\n",
      "        .   \n",
      "        .   @note If you want to find a unity-norm solution of an under-defined\n",
      "        .   singular system \\f$\\texttt{src1}\\cdot\\texttt{dst}=0\\f$ , the function solve\n",
      "        .   will not do the work. Use SVD::solveZ instead.\n",
      "        .   \n",
      "        .   @param src1 input matrix on the left-hand side of the system.\n",
      "        .   @param src2 input matrix on the right-hand side of the system.\n",
      "        .   @param dst output solution.\n",
      "        .   @param flags solution (matrix inversion) method (#DecompTypes)\n",
      "        .   @sa invert, SVD, eigen\n",
      "    \n",
      "    solveCubic(...)\n",
      "        solveCubic(coeffs[, roots]) -> retval, roots\n",
      "        .   @brief Finds the real roots of a cubic equation.\n",
      "        .   \n",
      "        .   The function solveCubic finds the real roots of a cubic equation:\n",
      "        .   -   if coeffs is a 4-element vector:\n",
      "        .   \\f[\\texttt{coeffs} [0] x^3 +  \\texttt{coeffs} [1] x^2 +  \\texttt{coeffs} [2] x +  \\texttt{coeffs} [3] = 0\\f]\n",
      "        .   -   if coeffs is a 3-element vector:\n",
      "        .   \\f[x^3 +  \\texttt{coeffs} [0] x^2 +  \\texttt{coeffs} [1] x +  \\texttt{coeffs} [2] = 0\\f]\n",
      "        .   \n",
      "        .   The roots are stored in the roots array.\n",
      "        .   @param coeffs equation coefficients, an array of 3 or 4 elements.\n",
      "        .   @param roots output array of real roots that has 1 or 3 elements.\n",
      "        .   @return number of real roots. It can be 0, 1 or 2.\n",
      "    \n",
      "    solveLP(...)\n",
      "        solveLP(Func, Constr[, z]) -> retval, z\n",
      "        .   @brief Solve given (non-integer) linear programming problem using the Simplex Algorithm (Simplex Method).\n",
      "        .   \n",
      "        .   What we mean here by \"linear programming problem\" (or LP problem, for short) can be formulated as:\n",
      "        .   \n",
      "        .   \\f[\\mbox{Maximize } c\\cdot x\\\\\n",
      "        .    \\mbox{Subject to:}\\\\\n",
      "        .    Ax\\leq b\\\\\n",
      "        .    x\\geq 0\\f]\n",
      "        .   \n",
      "        .   Where \\f$c\\f$ is fixed `1`-by-`n` row-vector, \\f$A\\f$ is fixed `m`-by-`n` matrix, \\f$b\\f$ is fixed `m`-by-`1`\n",
      "        .   column vector and \\f$x\\f$ is an arbitrary `n`-by-`1` column vector, which satisfies the constraints.\n",
      "        .   \n",
      "        .   Simplex algorithm is one of many algorithms that are designed to handle this sort of problems\n",
      "        .   efficiently. Although it is not optimal in theoretical sense (there exist algorithms that can solve\n",
      "        .   any problem written as above in polynomial time, while simplex method degenerates to exponential\n",
      "        .   time for some special cases), it is well-studied, easy to implement and is shown to work well for\n",
      "        .   real-life purposes.\n",
      "        .   \n",
      "        .   The particular implementation is taken almost verbatim from **Introduction to Algorithms, third\n",
      "        .   edition** by T. H. Cormen, C. E. Leiserson, R. L. Rivest and Clifford Stein. In particular, the\n",
      "        .   Bland's rule <http://en.wikipedia.org/wiki/Bland%27s_rule> is used to prevent cycling.\n",
      "        .   \n",
      "        .   @param Func This row-vector corresponds to \\f$c\\f$ in the LP problem formulation (see above). It should\n",
      "        .   contain 32- or 64-bit floating point numbers. As a convenience, column-vector may be also submitted,\n",
      "        .   in the latter case it is understood to correspond to \\f$c^T\\f$.\n",
      "        .   @param Constr `m`-by-`n+1` matrix, whose rightmost column corresponds to \\f$b\\f$ in formulation above\n",
      "        .   and the remaining to \\f$A\\f$. It should contain 32- or 64-bit floating point numbers.\n",
      "        .   @param z The solution will be returned here as a column-vector - it corresponds to \\f$c\\f$ in the\n",
      "        .   formulation above. It will contain 64-bit floating point numbers.\n",
      "        .   @return One of cv::SolveLPResult\n",
      "    \n",
      "    solveP3P(...)\n",
      "        solveP3P(objectPoints, imagePoints, cameraMatrix, distCoeffs, flags[, rvecs[, tvecs]]) -> retval, rvecs, tvecs\n",
      "        .   @brief Finds an object pose from 3 3D-2D point correspondences.\n",
      "        .   \n",
      "        .   @param objectPoints Array of object points in the object coordinate space, 3x3 1-channel or\n",
      "        .   1x3/3x1 3-channel. vector\\<Point3f\\> can be also passed here.\n",
      "        .   @param imagePoints Array of corresponding image points, 3x2 1-channel or 1x3/3x1 2-channel.\n",
      "        .    vector\\<Point2f\\> can be also passed here.\n",
      "        .   @param cameraMatrix Input camera matrix \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are\n",
      "        .   assumed.\n",
      "        .   @param rvecs Output rotation vectors (see @ref Rodrigues ) that, together with tvecs, brings points from\n",
      "        .   the model coordinate system to the camera coordinate system. A P3P problem has up to 4 solutions.\n",
      "        .   @param tvecs Output translation vectors.\n",
      "        .   @param flags Method for solving a P3P problem:\n",
      "        .   -   **SOLVEPNP_P3P** Method is based on the paper of X.S. Gao, X.-R. Hou, J. Tang, H.-F. Chang\n",
      "        .   \"Complete Solution Classification for the Perspective-Three-Point Problem\" (@cite gao2003complete).\n",
      "        .   -   **SOLVEPNP_AP3P** Method is based on the paper of T. Ke and S. Roumeliotis.\n",
      "        .   \"An Efficient Algebraic Solution to the Perspective-Three-Point Problem\" (@cite Ke17).\n",
      "        .   \n",
      "        .   The function estimates the object pose given 3 object points, their corresponding image\n",
      "        .   projections, as well as the camera matrix and the distortion coefficients.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   The solutions are sorted by reprojection errors (lowest to highest).\n",
      "    \n",
      "    solvePnP(...)\n",
      "        solvePnP(objectPoints, imagePoints, cameraMatrix, distCoeffs[, rvec[, tvec[, useExtrinsicGuess[, flags]]]]) -> retval, rvec, tvec\n",
      "        .   @brief Finds an object pose from 3D-2D point correspondences.\n",
      "        .   This function returns the rotation and the translation vectors that transform a 3D point expressed in the object\n",
      "        .   coordinate frame to the camera coordinate frame, using different methods:\n",
      "        .   - P3P methods (@ref SOLVEPNP_P3P, @ref SOLVEPNP_AP3P): need 4 input points to return a unique solution.\n",
      "        .   - @ref SOLVEPNP_IPPE Input points must be >= 4 and object points must be coplanar.\n",
      "        .   - @ref SOLVEPNP_IPPE_SQUARE Special case suitable for marker pose estimation.\n",
      "        .   Number of input points must be 4. Object points must be defined in the following order:\n",
      "        .     - point 0: [-squareLength / 2,  squareLength / 2, 0]\n",
      "        .     - point 1: [ squareLength / 2,  squareLength / 2, 0]\n",
      "        .     - point 2: [ squareLength / 2, -squareLength / 2, 0]\n",
      "        .     - point 3: [-squareLength / 2, -squareLength / 2, 0]\n",
      "        .   - for all the other flags, number of input points must be >= 4 and object points can be in any configuration.\n",
      "        .   \n",
      "        .   @param objectPoints Array of object points in the object coordinate space, Nx3 1-channel or\n",
      "        .   1xN/Nx1 3-channel, where N is the number of points. vector\\<Point3d\\> can be also passed here.\n",
      "        .   @param imagePoints Array of corresponding image points, Nx2 1-channel or 1xN/Nx1 2-channel,\n",
      "        .   where N is the number of points. vector\\<Point2d\\> can be also passed here.\n",
      "        .   @param cameraMatrix Input camera matrix \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are\n",
      "        .   assumed.\n",
      "        .   @param rvec Output rotation vector (see @ref Rodrigues ) that, together with tvec, brings points from\n",
      "        .   the model coordinate system to the camera coordinate system.\n",
      "        .   @param tvec Output translation vector.\n",
      "        .   @param useExtrinsicGuess Parameter used for #SOLVEPNP_ITERATIVE. If true (1), the function uses\n",
      "        .   the provided rvec and tvec values as initial approximations of the rotation and translation\n",
      "        .   vectors, respectively, and further optimizes them.\n",
      "        .   @param flags Method for solving a PnP problem:\n",
      "        .   -   **SOLVEPNP_ITERATIVE** Iterative method is based on a Levenberg-Marquardt optimization. In\n",
      "        .   this case the function finds such a pose that minimizes reprojection error, that is the sum\n",
      "        .   of squared distances between the observed projections imagePoints and the projected (using\n",
      "        .   projectPoints ) objectPoints .\n",
      "        .   -   **SOLVEPNP_P3P** Method is based on the paper of X.S. Gao, X.-R. Hou, J. Tang, H.-F. Chang\n",
      "        .   \"Complete Solution Classification for the Perspective-Three-Point Problem\" (@cite gao2003complete).\n",
      "        .   In this case the function requires exactly four object and image points.\n",
      "        .   -   **SOLVEPNP_AP3P** Method is based on the paper of T. Ke, S. Roumeliotis\n",
      "        .   \"An Efficient Algebraic Solution to the Perspective-Three-Point Problem\" (@cite Ke17).\n",
      "        .   In this case the function requires exactly four object and image points.\n",
      "        .   -   **SOLVEPNP_EPNP** Method has been introduced by F. Moreno-Noguer, V. Lepetit and P. Fua in the\n",
      "        .   paper \"EPnP: Efficient Perspective-n-Point Camera Pose Estimation\" (@cite lepetit2009epnp).\n",
      "        .   -   **SOLVEPNP_DLS** Method is based on the paper of J. Hesch and S. Roumeliotis.\n",
      "        .   \"A Direct Least-Squares (DLS) Method for PnP\" (@cite hesch2011direct).\n",
      "        .   -   **SOLVEPNP_UPNP** Method is based on the paper of A. Penate-Sanchez, J. Andrade-Cetto,\n",
      "        .   F. Moreno-Noguer. \"Exhaustive Linearization for Robust Camera Pose and Focal Length\n",
      "        .   Estimation\" (@cite penate2013exhaustive). In this case the function also estimates the parameters \\f$f_x\\f$ and \\f$f_y\\f$\n",
      "        .   assuming that both have the same value. Then the cameraMatrix is updated with the estimated\n",
      "        .   focal length.\n",
      "        .   -   **SOLVEPNP_IPPE** Method is based on the paper of T. Collins and A. Bartoli.\n",
      "        .   \"Infinitesimal Plane-Based Pose Estimation\" (@cite Collins14). This method requires coplanar object points.\n",
      "        .   -   **SOLVEPNP_IPPE_SQUARE** Method is based on the paper of Toby Collins and Adrien Bartoli.\n",
      "        .   \"Infinitesimal Plane-Based Pose Estimation\" (@cite Collins14). This method is suitable for marker pose estimation.\n",
      "        .   It requires 4 coplanar object points defined in the following order:\n",
      "        .     - point 0: [-squareLength / 2,  squareLength / 2, 0]\n",
      "        .     - point 1: [ squareLength / 2,  squareLength / 2, 0]\n",
      "        .     - point 2: [ squareLength / 2, -squareLength / 2, 0]\n",
      "        .     - point 3: [-squareLength / 2, -squareLength / 2, 0]\n",
      "        .   \n",
      "        .   The function estimates the object pose given a set of object points, their corresponding image\n",
      "        .   projections, as well as the camera matrix and the distortion coefficients, see the figure below\n",
      "        .   (more precisely, the X-axis of the camera frame is pointing to the right, the Y-axis downward\n",
      "        .   and the Z-axis forward).\n",
      "        .   \n",
      "        .   ![](pnp.jpg)\n",
      "        .   \n",
      "        .   Points expressed in the world frame \\f$ \\bf{X}_w \\f$ are projected into the image plane \\f$ \\left[ u, v \\right] \\f$\n",
      "        .   using the perspective projection model \\f$ \\Pi \\f$ and the camera intrinsic parameters matrix \\f$ \\bf{A} \\f$:\n",
      "        .   \n",
      "        .   \\f[\n",
      "        .     \\begin{align*}\n",
      "        .     \\begin{bmatrix}\n",
      "        .     u \\\\\n",
      "        .     v \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix} &=\n",
      "        .     \\bf{A} \\hspace{0.1em} \\Pi \\hspace{0.2em} ^{c}\\bf{T}_w\n",
      "        .     \\begin{bmatrix}\n",
      "        .     X_{w} \\\\\n",
      "        .     Y_{w} \\\\\n",
      "        .     Z_{w} \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix} \\\\\n",
      "        .     \\begin{bmatrix}\n",
      "        .     u \\\\\n",
      "        .     v \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix} &=\n",
      "        .     \\begin{bmatrix}\n",
      "        .     f_x & 0 & c_x \\\\\n",
      "        .     0 & f_y & c_y \\\\\n",
      "        .     0 & 0 & 1\n",
      "        .     \\end{bmatrix}\n",
      "        .     \\begin{bmatrix}\n",
      "        .     1 & 0 & 0 & 0 \\\\\n",
      "        .     0 & 1 & 0 & 0 \\\\\n",
      "        .     0 & 0 & 1 & 0\n",
      "        .     \\end{bmatrix}\n",
      "        .     \\begin{bmatrix}\n",
      "        .     r_{11} & r_{12} & r_{13} & t_x \\\\\n",
      "        .     r_{21} & r_{22} & r_{23} & t_y \\\\\n",
      "        .     r_{31} & r_{32} & r_{33} & t_z \\\\\n",
      "        .     0 & 0 & 0 & 1\n",
      "        .     \\end{bmatrix}\n",
      "        .     \\begin{bmatrix}\n",
      "        .     X_{w} \\\\\n",
      "        .     Y_{w} \\\\\n",
      "        .     Z_{w} \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix}\n",
      "        .     \\end{align*}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   The estimated pose is thus the rotation (`rvec`) and the translation (`tvec`) vectors that allow transforming\n",
      "        .   a 3D point expressed in the world frame into the camera frame:\n",
      "        .   \n",
      "        .   \\f[\n",
      "        .     \\begin{align*}\n",
      "        .     \\begin{bmatrix}\n",
      "        .     X_c \\\\\n",
      "        .     Y_c \\\\\n",
      "        .     Z_c \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix} &=\n",
      "        .     \\hspace{0.2em} ^{c}\\bf{T}_w\n",
      "        .     \\begin{bmatrix}\n",
      "        .     X_{w} \\\\\n",
      "        .     Y_{w} \\\\\n",
      "        .     Z_{w} \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix} \\\\\n",
      "        .     \\begin{bmatrix}\n",
      "        .     X_c \\\\\n",
      "        .     Y_c \\\\\n",
      "        .     Z_c \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix} &=\n",
      "        .     \\begin{bmatrix}\n",
      "        .     r_{11} & r_{12} & r_{13} & t_x \\\\\n",
      "        .     r_{21} & r_{22} & r_{23} & t_y \\\\\n",
      "        .     r_{31} & r_{32} & r_{33} & t_z \\\\\n",
      "        .     0 & 0 & 0 & 1\n",
      "        .     \\end{bmatrix}\n",
      "        .     \\begin{bmatrix}\n",
      "        .     X_{w} \\\\\n",
      "        .     Y_{w} \\\\\n",
      "        .     Z_{w} \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix}\n",
      "        .     \\end{align*}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   @note\n",
      "        .      -   An example of how to use solvePnP for planar augmented reality can be found at\n",
      "        .           opencv_source_code/samples/python/plane_ar.py\n",
      "        .      -   If you are using Python:\n",
      "        .           - Numpy array slices won't work as input because solvePnP requires contiguous\n",
      "        .           arrays (enforced by the assertion using cv::Mat::checkVector() around line 55 of\n",
      "        .           modules/calib3d/src/solvepnp.cpp version 2.4.9)\n",
      "        .           - The P3P algorithm requires image points to be in an array of shape (N,1,2) due\n",
      "        .           to its calling of cv::undistortPoints (around line 75 of modules/calib3d/src/solvepnp.cpp version 2.4.9)\n",
      "        .           which requires 2-channel information.\n",
      "        .           - Thus, given some data D = np.array(...) where D.shape = (N,M), in order to use a subset of\n",
      "        .           it as, e.g., imagePoints, one must effectively copy it into a new array: imagePoints =\n",
      "        .           np.ascontiguousarray(D[:,:2]).reshape((N,1,2))\n",
      "        .      -   The methods **SOLVEPNP_DLS** and **SOLVEPNP_UPNP** cannot be used as the current implementations are\n",
      "        .          unstable and sometimes give completely wrong results. If you pass one of these two\n",
      "        .          flags, **SOLVEPNP_EPNP** method will be used instead.\n",
      "        .      -   The minimum number of points is 4 in the general case. In the case of **SOLVEPNP_P3P** and **SOLVEPNP_AP3P**\n",
      "        .          methods, it is required to use exactly 4 points (the first 3 points are used to estimate all the solutions\n",
      "        .          of the P3P problem, the last one is used to retain the best solution that minimizes the reprojection error).\n",
      "        .      -   With **SOLVEPNP_ITERATIVE** method and `useExtrinsicGuess=true`, the minimum number of points is 3 (3 points\n",
      "        .          are sufficient to compute a pose but there are up to 4 solutions). The initial solution should be close to the\n",
      "        .          global solution to converge.\n",
      "        .      -   With **SOLVEPNP_IPPE** input points must be >= 4 and object points must be coplanar.\n",
      "        .      -   With **SOLVEPNP_IPPE_SQUARE** this is a special case suitable for marker pose estimation.\n",
      "        .          Number of input points must be 4. Object points must be defined in the following order:\n",
      "        .            - point 0: [-squareLength / 2,  squareLength / 2, 0]\n",
      "        .            - point 1: [ squareLength / 2,  squareLength / 2, 0]\n",
      "        .            - point 2: [ squareLength / 2, -squareLength / 2, 0]\n",
      "        .            - point 3: [-squareLength / 2, -squareLength / 2, 0]\n",
      "    \n",
      "    solvePnPGeneric(...)\n",
      "        solvePnPGeneric(objectPoints, imagePoints, cameraMatrix, distCoeffs[, rvecs[, tvecs[, useExtrinsicGuess[, flags[, rvec[, tvec[, reprojectionError]]]]]]]) -> retval, rvecs, tvecs, reprojectionError\n",
      "        .   @brief Finds an object pose from 3D-2D point correspondences.\n",
      "        .   This function returns a list of all the possible solutions (a solution is a <rotation vector, translation vector>\n",
      "        .   couple), depending on the number of input points and the chosen method:\n",
      "        .   - P3P methods (@ref SOLVEPNP_P3P, @ref SOLVEPNP_AP3P): 3 or 4 input points. Number of returned solutions can be between 0 and 4 with 3 input points.\n",
      "        .   - @ref SOLVEPNP_IPPE Input points must be >= 4 and object points must be coplanar. Returns 2 solutions.\n",
      "        .   - @ref SOLVEPNP_IPPE_SQUARE Special case suitable for marker pose estimation.\n",
      "        .   Number of input points must be 4 and 2 solutions are returned. Object points must be defined in the following order:\n",
      "        .     - point 0: [-squareLength / 2,  squareLength / 2, 0]\n",
      "        .     - point 1: [ squareLength / 2,  squareLength / 2, 0]\n",
      "        .     - point 2: [ squareLength / 2, -squareLength / 2, 0]\n",
      "        .     - point 3: [-squareLength / 2, -squareLength / 2, 0]\n",
      "        .   - for all the other flags, number of input points must be >= 4 and object points can be in any configuration.\n",
      "        .   Only 1 solution is returned.\n",
      "        .   \n",
      "        .   @param objectPoints Array of object points in the object coordinate space, Nx3 1-channel or\n",
      "        .   1xN/Nx1 3-channel, where N is the number of points. vector\\<Point3d\\> can be also passed here.\n",
      "        .   @param imagePoints Array of corresponding image points, Nx2 1-channel or 1xN/Nx1 2-channel,\n",
      "        .   where N is the number of points. vector\\<Point2d\\> can be also passed here.\n",
      "        .   @param cameraMatrix Input camera matrix \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are\n",
      "        .   assumed.\n",
      "        .   @param rvecs Vector of output rotation vectors (see @ref Rodrigues ) that, together with tvecs, brings points from\n",
      "        .   the model coordinate system to the camera coordinate system.\n",
      "        .   @param tvecs Vector of output translation vectors.\n",
      "        .   @param useExtrinsicGuess Parameter used for #SOLVEPNP_ITERATIVE. If true (1), the function uses\n",
      "        .   the provided rvec and tvec values as initial approximations of the rotation and translation\n",
      "        .   vectors, respectively, and further optimizes them.\n",
      "        .   @param flags Method for solving a PnP problem:\n",
      "        .   -   **SOLVEPNP_ITERATIVE** Iterative method is based on a Levenberg-Marquardt optimization. In\n",
      "        .   this case the function finds such a pose that minimizes reprojection error, that is the sum\n",
      "        .   of squared distances between the observed projections imagePoints and the projected (using\n",
      "        .   projectPoints ) objectPoints .\n",
      "        .   -   **SOLVEPNP_P3P** Method is based on the paper of X.S. Gao, X.-R. Hou, J. Tang, H.-F. Chang\n",
      "        .   \"Complete Solution Classification for the Perspective-Three-Point Problem\" (@cite gao2003complete).\n",
      "        .   In this case the function requires exactly four object and image points.\n",
      "        .   -   **SOLVEPNP_AP3P** Method is based on the paper of T. Ke, S. Roumeliotis\n",
      "        .   \"An Efficient Algebraic Solution to the Perspective-Three-Point Problem\" (@cite Ke17).\n",
      "        .   In this case the function requires exactly four object and image points.\n",
      "        .   -   **SOLVEPNP_EPNP** Method has been introduced by F.Moreno-Noguer, V.Lepetit and P.Fua in the\n",
      "        .   paper \"EPnP: Efficient Perspective-n-Point Camera Pose Estimation\" (@cite lepetit2009epnp).\n",
      "        .   -   **SOLVEPNP_DLS** Method is based on the paper of Joel A. Hesch and Stergios I. Roumeliotis.\n",
      "        .   \"A Direct Least-Squares (DLS) Method for PnP\" (@cite hesch2011direct).\n",
      "        .   -   **SOLVEPNP_UPNP** Method is based on the paper of A.Penate-Sanchez, J.Andrade-Cetto,\n",
      "        .   F.Moreno-Noguer. \"Exhaustive Linearization for Robust Camera Pose and Focal Length\n",
      "        .   Estimation\" (@cite penate2013exhaustive). In this case the function also estimates the parameters \\f$f_x\\f$ and \\f$f_y\\f$\n",
      "        .   assuming that both have the same value. Then the cameraMatrix is updated with the estimated\n",
      "        .   focal length.\n",
      "        .   -   **SOLVEPNP_IPPE** Method is based on the paper of T. Collins and A. Bartoli.\n",
      "        .   \"Infinitesimal Plane-Based Pose Estimation\" (@cite Collins14). This method requires coplanar object points.\n",
      "        .   -   **SOLVEPNP_IPPE_SQUARE** Method is based on the paper of Toby Collins and Adrien Bartoli.\n",
      "        .   \"Infinitesimal Plane-Based Pose Estimation\" (@cite Collins14). This method is suitable for marker pose estimation.\n",
      "        .   It requires 4 coplanar object points defined in the following order:\n",
      "        .     - point 0: [-squareLength / 2,  squareLength / 2, 0]\n",
      "        .     - point 1: [ squareLength / 2,  squareLength / 2, 0]\n",
      "        .     - point 2: [ squareLength / 2, -squareLength / 2, 0]\n",
      "        .     - point 3: [-squareLength / 2, -squareLength / 2, 0]\n",
      "        .   @param rvec Rotation vector used to initialize an iterative PnP refinement algorithm, when flag is SOLVEPNP_ITERATIVE\n",
      "        .   and useExtrinsicGuess is set to true.\n",
      "        .   @param tvec Translation vector used to initialize an iterative PnP refinement algorithm, when flag is SOLVEPNP_ITERATIVE\n",
      "        .   and useExtrinsicGuess is set to true.\n",
      "        .   @param reprojectionError Optional vector of reprojection error, that is the RMS error\n",
      "        .   (\\f$ \\text{RMSE} = \\sqrt{\\frac{\\sum_{i}^{N} \\left ( \\hat{y_i} - y_i \\right )^2}{N}} \\f$) between the input image points\n",
      "        .   and the 3D object points projected with the estimated pose.\n",
      "        .   \n",
      "        .   The function estimates the object pose given a set of object points, their corresponding image\n",
      "        .   projections, as well as the camera matrix and the distortion coefficients, see the figure below\n",
      "        .   (more precisely, the X-axis of the camera frame is pointing to the right, the Y-axis downward\n",
      "        .   and the Z-axis forward).\n",
      "        .   \n",
      "        .   ![](pnp.jpg)\n",
      "        .   \n",
      "        .   Points expressed in the world frame \\f$ \\bf{X}_w \\f$ are projected into the image plane \\f$ \\left[ u, v \\right] \\f$\n",
      "        .   using the perspective projection model \\f$ \\Pi \\f$ and the camera intrinsic parameters matrix \\f$ \\bf{A} \\f$:\n",
      "        .   \n",
      "        .   \\f[\n",
      "        .     \\begin{align*}\n",
      "        .     \\begin{bmatrix}\n",
      "        .     u \\\\\n",
      "        .     v \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix} &=\n",
      "        .     \\bf{A} \\hspace{0.1em} \\Pi \\hspace{0.2em} ^{c}\\bf{T}_w\n",
      "        .     \\begin{bmatrix}\n",
      "        .     X_{w} \\\\\n",
      "        .     Y_{w} \\\\\n",
      "        .     Z_{w} \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix} \\\\\n",
      "        .     \\begin{bmatrix}\n",
      "        .     u \\\\\n",
      "        .     v \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix} &=\n",
      "        .     \\begin{bmatrix}\n",
      "        .     f_x & 0 & c_x \\\\\n",
      "        .     0 & f_y & c_y \\\\\n",
      "        .     0 & 0 & 1\n",
      "        .     \\end{bmatrix}\n",
      "        .     \\begin{bmatrix}\n",
      "        .     1 & 0 & 0 & 0 \\\\\n",
      "        .     0 & 1 & 0 & 0 \\\\\n",
      "        .     0 & 0 & 1 & 0\n",
      "        .     \\end{bmatrix}\n",
      "        .     \\begin{bmatrix}\n",
      "        .     r_{11} & r_{12} & r_{13} & t_x \\\\\n",
      "        .     r_{21} & r_{22} & r_{23} & t_y \\\\\n",
      "        .     r_{31} & r_{32} & r_{33} & t_z \\\\\n",
      "        .     0 & 0 & 0 & 1\n",
      "        .     \\end{bmatrix}\n",
      "        .     \\begin{bmatrix}\n",
      "        .     X_{w} \\\\\n",
      "        .     Y_{w} \\\\\n",
      "        .     Z_{w} \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix}\n",
      "        .     \\end{align*}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   The estimated pose is thus the rotation (`rvec`) and the translation (`tvec`) vectors that allow transforming\n",
      "        .   a 3D point expressed in the world frame into the camera frame:\n",
      "        .   \n",
      "        .   \\f[\n",
      "        .     \\begin{align*}\n",
      "        .     \\begin{bmatrix}\n",
      "        .     X_c \\\\\n",
      "        .     Y_c \\\\\n",
      "        .     Z_c \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix} &=\n",
      "        .     \\hspace{0.2em} ^{c}\\bf{T}_w\n",
      "        .     \\begin{bmatrix}\n",
      "        .     X_{w} \\\\\n",
      "        .     Y_{w} \\\\\n",
      "        .     Z_{w} \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix} \\\\\n",
      "        .     \\begin{bmatrix}\n",
      "        .     X_c \\\\\n",
      "        .     Y_c \\\\\n",
      "        .     Z_c \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix} &=\n",
      "        .     \\begin{bmatrix}\n",
      "        .     r_{11} & r_{12} & r_{13} & t_x \\\\\n",
      "        .     r_{21} & r_{22} & r_{23} & t_y \\\\\n",
      "        .     r_{31} & r_{32} & r_{33} & t_z \\\\\n",
      "        .     0 & 0 & 0 & 1\n",
      "        .     \\end{bmatrix}\n",
      "        .     \\begin{bmatrix}\n",
      "        .     X_{w} \\\\\n",
      "        .     Y_{w} \\\\\n",
      "        .     Z_{w} \\\\\n",
      "        .     1\n",
      "        .     \\end{bmatrix}\n",
      "        .     \\end{align*}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   @note\n",
      "        .      -   An example of how to use solvePnP for planar augmented reality can be found at\n",
      "        .           opencv_source_code/samples/python/plane_ar.py\n",
      "        .      -   If you are using Python:\n",
      "        .           - Numpy array slices won't work as input because solvePnP requires contiguous\n",
      "        .           arrays (enforced by the assertion using cv::Mat::checkVector() around line 55 of\n",
      "        .           modules/calib3d/src/solvepnp.cpp version 2.4.9)\n",
      "        .           - The P3P algorithm requires image points to be in an array of shape (N,1,2) due\n",
      "        .           to its calling of cv::undistortPoints (around line 75 of modules/calib3d/src/solvepnp.cpp version 2.4.9)\n",
      "        .           which requires 2-channel information.\n",
      "        .           - Thus, given some data D = np.array(...) where D.shape = (N,M), in order to use a subset of\n",
      "        .           it as, e.g., imagePoints, one must effectively copy it into a new array: imagePoints =\n",
      "        .           np.ascontiguousarray(D[:,:2]).reshape((N,1,2))\n",
      "        .      -   The methods **SOLVEPNP_DLS** and **SOLVEPNP_UPNP** cannot be used as the current implementations are\n",
      "        .          unstable and sometimes give completely wrong results. If you pass one of these two\n",
      "        .          flags, **SOLVEPNP_EPNP** method will be used instead.\n",
      "        .      -   The minimum number of points is 4 in the general case. In the case of **SOLVEPNP_P3P** and **SOLVEPNP_AP3P**\n",
      "        .          methods, it is required to use exactly 4 points (the first 3 points are used to estimate all the solutions\n",
      "        .          of the P3P problem, the last one is used to retain the best solution that minimizes the reprojection error).\n",
      "        .      -   With **SOLVEPNP_ITERATIVE** method and `useExtrinsicGuess=true`, the minimum number of points is 3 (3 points\n",
      "        .          are sufficient to compute a pose but there are up to 4 solutions). The initial solution should be close to the\n",
      "        .          global solution to converge.\n",
      "        .      -   With **SOLVEPNP_IPPE** input points must be >= 4 and object points must be coplanar.\n",
      "        .      -   With **SOLVEPNP_IPPE_SQUARE** this is a special case suitable for marker pose estimation.\n",
      "        .          Number of input points must be 4. Object points must be defined in the following order:\n",
      "        .            - point 0: [-squareLength / 2,  squareLength / 2, 0]\n",
      "        .            - point 1: [ squareLength / 2,  squareLength / 2, 0]\n",
      "        .            - point 2: [ squareLength / 2, -squareLength / 2, 0]\n",
      "        .            - point 3: [-squareLength / 2, -squareLength / 2, 0]\n",
      "    \n",
      "    solvePnPRansac(...)\n",
      "        solvePnPRansac(objectPoints, imagePoints, cameraMatrix, distCoeffs[, rvec[, tvec[, useExtrinsicGuess[, iterationsCount[, reprojectionError[, confidence[, inliers[, flags]]]]]]]]) -> retval, rvec, tvec, inliers\n",
      "        .   @brief Finds an object pose from 3D-2D point correspondences using the RANSAC scheme.\n",
      "        .   \n",
      "        .   @param objectPoints Array of object points in the object coordinate space, Nx3 1-channel or\n",
      "        .   1xN/Nx1 3-channel, where N is the number of points. vector\\<Point3d\\> can be also passed here.\n",
      "        .   @param imagePoints Array of corresponding image points, Nx2 1-channel or 1xN/Nx1 2-channel,\n",
      "        .   where N is the number of points. vector\\<Point2d\\> can be also passed here.\n",
      "        .   @param cameraMatrix Input camera matrix \\f$A = \\vecthreethree{fx}{0}{cx}{0}{fy}{cy}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are\n",
      "        .   assumed.\n",
      "        .   @param rvec Output rotation vector (see @ref Rodrigues ) that, together with tvec, brings points from\n",
      "        .   the model coordinate system to the camera coordinate system.\n",
      "        .   @param tvec Output translation vector.\n",
      "        .   @param useExtrinsicGuess Parameter used for @ref SOLVEPNP_ITERATIVE. If true (1), the function uses\n",
      "        .   the provided rvec and tvec values as initial approximations of the rotation and translation\n",
      "        .   vectors, respectively, and further optimizes them.\n",
      "        .   @param iterationsCount Number of iterations.\n",
      "        .   @param reprojectionError Inlier threshold value used by the RANSAC procedure. The parameter value\n",
      "        .   is the maximum allowed distance between the observed and computed point projections to consider it\n",
      "        .   an inlier.\n",
      "        .   @param confidence The probability that the algorithm produces a useful result.\n",
      "        .   @param inliers Output vector that contains indices of inliers in objectPoints and imagePoints .\n",
      "        .   @param flags Method for solving a PnP problem (see @ref solvePnP ).\n",
      "        .   \n",
      "        .   The function estimates an object pose given a set of object points, their corresponding image\n",
      "        .   projections, as well as the camera matrix and the distortion coefficients. This function finds such\n",
      "        .   a pose that minimizes reprojection error, that is, the sum of squared distances between the observed\n",
      "        .   projections imagePoints and the projected (using @ref projectPoints ) objectPoints. The use of RANSAC\n",
      "        .   makes the function resistant to outliers.\n",
      "        .   \n",
      "        .   @note\n",
      "        .      -   An example of how to use solvePNPRansac for object detection can be found at\n",
      "        .           opencv_source_code/samples/cpp/tutorial_code/calib3d/real_time_pose_estimation/\n",
      "        .      -   The default method used to estimate the camera pose for the Minimal Sample Sets step\n",
      "        .          is #SOLVEPNP_EPNP. Exceptions are:\n",
      "        .            - if you choose #SOLVEPNP_P3P or #SOLVEPNP_AP3P, these methods will be used.\n",
      "        .            - if the number of input points is equal to 4, #SOLVEPNP_P3P is used.\n",
      "        .      -   The method used to estimate the camera pose using all the inliers is defined by the\n",
      "        .          flags parameters unless it is equal to #SOLVEPNP_P3P or #SOLVEPNP_AP3P. In this case,\n",
      "        .          the method #SOLVEPNP_EPNP will be used instead.\n",
      "    \n",
      "    solvePnPRefineLM(...)\n",
      "        solvePnPRefineLM(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec[, criteria]) -> rvec, tvec\n",
      "        .   @brief Refine a pose (the translation and the rotation that transform a 3D point expressed in the object coordinate frame\n",
      "        .   to the camera coordinate frame) from a 3D-2D point correspondences and starting from an initial solution.\n",
      "        .   \n",
      "        .   @param objectPoints Array of object points in the object coordinate space, Nx3 1-channel or 1xN/Nx1 3-channel,\n",
      "        .   where N is the number of points. vector\\<Point3d\\> can also be passed here.\n",
      "        .   @param imagePoints Array of corresponding image points, Nx2 1-channel or 1xN/Nx1 2-channel,\n",
      "        .   where N is the number of points. vector\\<Point2d\\> can also be passed here.\n",
      "        .   @param cameraMatrix Input camera matrix \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are\n",
      "        .   assumed.\n",
      "        .   @param rvec Input/Output rotation vector (see @ref Rodrigues ) that, together with tvec, brings points from\n",
      "        .   the model coordinate system to the camera coordinate system. Input values are used as an initial solution.\n",
      "        .   @param tvec Input/Output translation vector. Input values are used as an initial solution.\n",
      "        .   @param criteria Criteria when to stop the Levenberg-Marquard iterative algorithm.\n",
      "        .   \n",
      "        .   The function refines the object pose given at least 3 object points, their corresponding image\n",
      "        .   projections, an initial solution for the rotation and translation vector,\n",
      "        .   as well as the camera matrix and the distortion coefficients.\n",
      "        .   The function minimizes the projection error with respect to the rotation and the translation vectors, according\n",
      "        .   to a Levenberg-Marquardt iterative minimization @cite Madsen04 @cite Eade13 process.\n",
      "    \n",
      "    solvePnPRefineVVS(...)\n",
      "        solvePnPRefineVVS(objectPoints, imagePoints, cameraMatrix, distCoeffs, rvec, tvec[, criteria[, VVSlambda]]) -> rvec, tvec\n",
      "        .   @brief Refine a pose (the translation and the rotation that transform a 3D point expressed in the object coordinate frame\n",
      "        .   to the camera coordinate frame) from a 3D-2D point correspondences and starting from an initial solution.\n",
      "        .   \n",
      "        .   @param objectPoints Array of object points in the object coordinate space, Nx3 1-channel or 1xN/Nx1 3-channel,\n",
      "        .   where N is the number of points. vector\\<Point3d\\> can also be passed here.\n",
      "        .   @param imagePoints Array of corresponding image points, Nx2 1-channel or 1xN/Nx1 2-channel,\n",
      "        .   where N is the number of points. vector\\<Point2d\\> can also be passed here.\n",
      "        .   @param cameraMatrix Input camera matrix \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$ of\n",
      "        .   4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are\n",
      "        .   assumed.\n",
      "        .   @param rvec Input/Output rotation vector (see @ref Rodrigues ) that, together with tvec, brings points from\n",
      "        .   the model coordinate system to the camera coordinate system. Input values are used as an initial solution.\n",
      "        .   @param tvec Input/Output translation vector. Input values are used as an initial solution.\n",
      "        .   @param criteria Criteria when to stop the Levenberg-Marquard iterative algorithm.\n",
      "        .   @param VVSlambda Gain for the virtual visual servoing control law, equivalent to the \\f$\\alpha\\f$\n",
      "        .   gain in the Damped Gauss-Newton formulation.\n",
      "        .   \n",
      "        .   The function refines the object pose given at least 3 object points, their corresponding image\n",
      "        .   projections, an initial solution for the rotation and translation vector,\n",
      "        .   as well as the camera matrix and the distortion coefficients.\n",
      "        .   The function minimizes the projection error with respect to the rotation and the translation vectors, using a\n",
      "        .   virtual visual servoing (VVS) @cite Chaumette06 @cite Marchand16 scheme.\n",
      "    \n",
      "    solvePoly(...)\n",
      "        solvePoly(coeffs[, roots[, maxIters]]) -> retval, roots\n",
      "        .   @brief Finds the real or complex roots of a polynomial equation.\n",
      "        .   \n",
      "        .   The function cv::solvePoly finds real and complex roots of a polynomial equation:\n",
      "        .   \\f[\\texttt{coeffs} [n] x^{n} +  \\texttt{coeffs} [n-1] x^{n-1} + ... +  \\texttt{coeffs} [1] x +  \\texttt{coeffs} [0] = 0\\f]\n",
      "        .   @param coeffs array of polynomial coefficients.\n",
      "        .   @param roots output (complex) array of roots.\n",
      "        .   @param maxIters maximum number of iterations the algorithm does.\n",
      "    \n",
      "    sort(...)\n",
      "        sort(src, flags[, dst]) -> dst\n",
      "        .   @brief Sorts each row or each column of a matrix.\n",
      "        .   \n",
      "        .   The function cv::sort sorts each matrix row or each matrix column in\n",
      "        .   ascending or descending order. So you should pass two operation flags to\n",
      "        .   get desired behaviour. If you want to sort matrix rows or columns\n",
      "        .   lexicographically, you can use STL std::sort generic function with the\n",
      "        .   proper comparison predicate.\n",
      "        .   \n",
      "        .   @param src input single-channel array.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "        .   @param flags operation flags, a combination of #SortFlags\n",
      "        .   @sa sortIdx, randShuffle\n",
      "    \n",
      "    sortIdx(...)\n",
      "        sortIdx(src, flags[, dst]) -> dst\n",
      "        .   @brief Sorts each row or each column of a matrix.\n",
      "        .   \n",
      "        .   The function cv::sortIdx sorts each matrix row or each matrix column in the\n",
      "        .   ascending or descending order. So you should pass two operation flags to\n",
      "        .   get desired behaviour. Instead of reordering the elements themselves, it\n",
      "        .   stores the indices of sorted elements in the output array. For example:\n",
      "        .   @code\n",
      "        .       Mat A = Mat::eye(3,3,CV_32F), B;\n",
      "        .       sortIdx(A, B, SORT_EVERY_ROW + SORT_ASCENDING);\n",
      "        .       // B will probably contain\n",
      "        .       // (because of equal elements in A some permutations are possible):\n",
      "        .       // [[1, 2, 0], [0, 2, 1], [0, 1, 2]]\n",
      "        .   @endcode\n",
      "        .   @param src input single-channel array.\n",
      "        .   @param dst output integer array of the same size as src.\n",
      "        .   @param flags operation flags that could be a combination of cv::SortFlags\n",
      "        .   @sa sort, randShuffle\n",
      "    \n",
      "    spatialGradient(...)\n",
      "        spatialGradient(src[, dx[, dy[, ksize[, borderType]]]]) -> dx, dy\n",
      "        .   @brief Calculates the first order image derivative in both x and y using a Sobel operator\n",
      "        .   \n",
      "        .   Equivalent to calling:\n",
      "        .   \n",
      "        .   @code\n",
      "        .   Sobel( src, dx, CV_16SC1, 1, 0, 3 );\n",
      "        .   Sobel( src, dy, CV_16SC1, 0, 1, 3 );\n",
      "        .   @endcode\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dx output image with first-order derivative in x.\n",
      "        .   @param dy output image with first-order derivative in y.\n",
      "        .   @param ksize size of Sobel kernel. It must be 3.\n",
      "        .   @param borderType pixel extrapolation method, see #BorderTypes.\n",
      "        .                     Only #BORDER_DEFAULT=#BORDER_REFLECT_101 and #BORDER_REPLICATE are supported.\n",
      "        .   \n",
      "        .   @sa Sobel\n",
      "    \n",
      "    split(...)\n",
      "        split(m[, mv]) -> mv\n",
      "        .   @overload\n",
      "        .   @param m input multi-channel array.\n",
      "        .   @param mv output vector of arrays; the arrays themselves are reallocated, if needed.\n",
      "    \n",
      "    sqrBoxFilter(...)\n",
      "        sqrBoxFilter(src, ddepth, ksize[, dst[, anchor[, normalize[, borderType]]]]) -> dst\n",
      "        .   @brief Calculates the normalized sum of squares of the pixel values overlapping the filter.\n",
      "        .   \n",
      "        .   For every pixel \\f$ (x, y) \\f$ in the source image, the function calculates the sum of squares of those neighboring\n",
      "        .   pixel values which overlap the filter placed over the pixel \\f$ (x, y) \\f$.\n",
      "        .   \n",
      "        .   The unnormalized square box filter can be useful in computing local image statistics such as the the local\n",
      "        .   variance and standard deviation around the neighborhood of a pixel.\n",
      "        .   \n",
      "        .   @param src input image\n",
      "        .   @param dst output image of the same size and type as _src\n",
      "        .   @param ddepth the output image depth (-1 to use src.depth())\n",
      "        .   @param ksize kernel size\n",
      "        .   @param anchor kernel anchor point. The default value of Point(-1, -1) denotes that the anchor is at the kernel\n",
      "        .   center.\n",
      "        .   @param normalize flag, specifying whether the kernel is to be normalized by it's area or not.\n",
      "        .   @param borderType border mode used to extrapolate pixels outside of the image, see #BorderTypes. #BORDER_WRAP is not supported.\n",
      "        .   @sa boxFilter\n",
      "    \n",
      "    sqrt(...)\n",
      "        sqrt(src[, dst]) -> dst\n",
      "        .   @brief Calculates a square root of array elements.\n",
      "        .   \n",
      "        .   The function cv::sqrt calculates a square root of each input array element.\n",
      "        .   In case of multi-channel arrays, each channel is processed\n",
      "        .   independently. The accuracy is approximately the same as of the built-in\n",
      "        .   std::sqrt .\n",
      "        .   @param src input floating-point array.\n",
      "        .   @param dst output array of the same size and type as src.\n",
      "    \n",
      "    startWindowThread(...)\n",
      "        startWindowThread() -> retval\n",
      "        .\n",
      "    \n",
      "    stereoCalibrate(...)\n",
      "        stereoCalibrate(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize[, R[, T[, E[, F[, flags[, criteria]]]]]]) -> retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F\n",
      "        .\n",
      "    \n",
      "    stereoCalibrateExtended(...)\n",
      "        stereoCalibrateExtended(objectPoints, imagePoints1, imagePoints2, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T[, E[, F[, perViewErrors[, flags[, criteria]]]]]) -> retval, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F, perViewErrors\n",
      "        .   @brief Calibrates a stereo camera set up. This function finds the intrinsic parameters\n",
      "        .   for each of the two cameras and the extrinsic parameters between the two cameras.\n",
      "        .   \n",
      "        .   @param objectPoints Vector of vectors of the calibration pattern points. The same structure as\n",
      "        .   in @ref calibrateCamera. For each pattern view, both cameras need to see the same object\n",
      "        .   points. Therefore, objectPoints.size(), imagePoints1.size(), and imagePoints2.size() need to be\n",
      "        .   equal as well as objectPoints[i].size(), imagePoints1[i].size(), and imagePoints2[i].size() need to\n",
      "        .   be equal for each i.\n",
      "        .   @param imagePoints1 Vector of vectors of the projections of the calibration pattern points,\n",
      "        .   observed by the first camera. The same structure as in @ref calibrateCamera.\n",
      "        .   @param imagePoints2 Vector of vectors of the projections of the calibration pattern points,\n",
      "        .   observed by the second camera. The same structure as in @ref calibrateCamera.\n",
      "        .   @param cameraMatrix1 Input/output camera matrix for the first camera, the same as in\n",
      "        .   @ref calibrateCamera. Furthermore, for the stereo case, additional flags may be used, see below.\n",
      "        .   @param distCoeffs1 Input/output vector of distortion coefficients, the same as in\n",
      "        .   @ref calibrateCamera.\n",
      "        .   @param cameraMatrix2 Input/output second camera matrix for the second camera. See description for\n",
      "        .   cameraMatrix1.\n",
      "        .   @param distCoeffs2 Input/output lens distortion coefficients for the second camera. See\n",
      "        .   description for distCoeffs1.\n",
      "        .   @param imageSize Size of the image used only to initialize the intrinsic camera matrices.\n",
      "        .   @param R Output rotation matrix. Together with the translation vector T, this matrix brings\n",
      "        .   points given in the first camera's coordinate system to points in the second camera's\n",
      "        .   coordinate system. In more technical terms, the tuple of R and T performs a change of basis\n",
      "        .   from the first camera's coordinate system to the second camera's coordinate system. Due to its\n",
      "        .   duality, this tuple is equivalent to the position of the first camera with respect to the\n",
      "        .   second camera coordinate system.\n",
      "        .   @param T Output translation vector, see description above.\n",
      "        .   @param E Output essential matrix.\n",
      "        .   @param F Output fundamental matrix.\n",
      "        .   @param perViewErrors Output vector of the RMS re-projection error estimated for each pattern view.\n",
      "        .   @param flags Different flags that may be zero or a combination of the following values:\n",
      "        .   -   **CALIB_FIX_INTRINSIC** Fix cameraMatrix? and distCoeffs? so that only R, T, E, and F\n",
      "        .   matrices are estimated.\n",
      "        .   -   **CALIB_USE_INTRINSIC_GUESS** Optimize some or all of the intrinsic parameters\n",
      "        .   according to the specified flags. Initial values are provided by the user.\n",
      "        .   -   **CALIB_USE_EXTRINSIC_GUESS** R and T contain valid initial values that are optimized further.\n",
      "        .   Otherwise R and T are initialized to the median value of the pattern views (each dimension separately).\n",
      "        .   -   **CALIB_FIX_PRINCIPAL_POINT** Fix the principal points during the optimization.\n",
      "        .   -   **CALIB_FIX_FOCAL_LENGTH** Fix \\f$f^{(j)}_x\\f$ and \\f$f^{(j)}_y\\f$ .\n",
      "        .   -   **CALIB_FIX_ASPECT_RATIO** Optimize \\f$f^{(j)}_y\\f$ . Fix the ratio \\f$f^{(j)}_x/f^{(j)}_y\\f$\n",
      "        .   .\n",
      "        .   -   **CALIB_SAME_FOCAL_LENGTH** Enforce \\f$f^{(0)}_x=f^{(1)}_x\\f$ and \\f$f^{(0)}_y=f^{(1)}_y\\f$ .\n",
      "        .   -   **CALIB_ZERO_TANGENT_DIST** Set tangential distortion coefficients for each camera to\n",
      "        .   zeros and fix there.\n",
      "        .   -   **CALIB_FIX_K1,...,CALIB_FIX_K6** Do not change the corresponding radial\n",
      "        .   distortion coefficient during the optimization. If CALIB_USE_INTRINSIC_GUESS is set,\n",
      "        .   the coefficient from the supplied distCoeffs matrix is used. Otherwise, it is set to 0.\n",
      "        .   -   **CALIB_RATIONAL_MODEL** Enable coefficients k4, k5, and k6. To provide the backward\n",
      "        .   compatibility, this extra flag should be explicitly specified to make the calibration\n",
      "        .   function use the rational model and return 8 coefficients. If the flag is not set, the\n",
      "        .   function computes and returns only 5 distortion coefficients.\n",
      "        .   -   **CALIB_THIN_PRISM_MODEL** Coefficients s1, s2, s3 and s4 are enabled. To provide the\n",
      "        .   backward compatibility, this extra flag should be explicitly specified to make the\n",
      "        .   calibration function use the thin prism model and return 12 coefficients. If the flag is not\n",
      "        .   set, the function computes and returns only 5 distortion coefficients.\n",
      "        .   -   **CALIB_FIX_S1_S2_S3_S4** The thin prism distortion coefficients are not changed during\n",
      "        .   the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the\n",
      "        .   supplied distCoeffs matrix is used. Otherwise, it is set to 0.\n",
      "        .   -   **CALIB_TILTED_MODEL** Coefficients tauX and tauY are enabled. To provide the\n",
      "        .   backward compatibility, this extra flag should be explicitly specified to make the\n",
      "        .   calibration function use the tilted sensor model and return 14 coefficients. If the flag is not\n",
      "        .   set, the function computes and returns only 5 distortion coefficients.\n",
      "        .   -   **CALIB_FIX_TAUX_TAUY** The coefficients of the tilted sensor model are not changed during\n",
      "        .   the optimization. If CALIB_USE_INTRINSIC_GUESS is set, the coefficient from the\n",
      "        .   supplied distCoeffs matrix is used. Otherwise, it is set to 0.\n",
      "        .   @param criteria Termination criteria for the iterative optimization algorithm.\n",
      "        .   \n",
      "        .   The function estimates the transformation between two cameras making a stereo pair. If one computes\n",
      "        .   the poses of an object relative to the first camera and to the second camera,\n",
      "        .   ( \\f$R_1\\f$,\\f$T_1\\f$ ) and (\\f$R_2\\f$,\\f$T_2\\f$), respectively, for a stereo camera where the\n",
      "        .   relative position and orientation between the two cameras are fixed, then those poses definitely\n",
      "        .   relate to each other. This means, if the relative position and orientation (\\f$R\\f$,\\f$T\\f$) of the\n",
      "        .   two cameras is known, it is possible to compute (\\f$R_2\\f$,\\f$T_2\\f$) when (\\f$R_1\\f$,\\f$T_1\\f$) is\n",
      "        .   given. This is what the described function does. It computes (\\f$R\\f$,\\f$T\\f$) such that:\n",
      "        .   \n",
      "        .   \\f[R_2=R R_1\\f]\n",
      "        .   \\f[T_2=R T_1 + T.\\f]\n",
      "        .   \n",
      "        .   Therefore, one can compute the coordinate representation of a 3D point for the second camera's\n",
      "        .   coordinate system when given the point's coordinate representation in the first camera's coordinate\n",
      "        .   system:\n",
      "        .   \n",
      "        .   \\f[\\begin{bmatrix}\n",
      "        .   X_2 \\\\\n",
      "        .   Y_2 \\\\\n",
      "        .   Z_2 \\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix} = \\begin{bmatrix}\n",
      "        .   R & T \\\\\n",
      "        .   0 & 1\n",
      "        .   \\end{bmatrix} \\begin{bmatrix}\n",
      "        .   X_1 \\\\\n",
      "        .   Y_1 \\\\\n",
      "        .   Z_1 \\\\\n",
      "        .   1\n",
      "        .   \\end{bmatrix}.\\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   Optionally, it computes the essential matrix E:\n",
      "        .   \n",
      "        .   \\f[E= \\vecthreethree{0}{-T_2}{T_1}{T_2}{0}{-T_0}{-T_1}{T_0}{0} R\\f]\n",
      "        .   \n",
      "        .   where \\f$T_i\\f$ are components of the translation vector \\f$T\\f$ : \\f$T=[T_0, T_1, T_2]^T\\f$ .\n",
      "        .   And the function can also compute the fundamental matrix F:\n",
      "        .   \n",
      "        .   \\f[F = cameraMatrix2^{-T}\\cdot E \\cdot cameraMatrix1^{-1}\\f]\n",
      "        .   \n",
      "        .   Besides the stereo-related information, the function can also perform a full calibration of each of\n",
      "        .   the two cameras. However, due to the high dimensionality of the parameter space and noise in the\n",
      "        .   input data, the function can diverge from the correct solution. If the intrinsic parameters can be\n",
      "        .   estimated with high accuracy for each of the cameras individually (for example, using\n",
      "        .   calibrateCamera ), you are recommended to do so and then pass CALIB_FIX_INTRINSIC flag to the\n",
      "        .   function along with the computed intrinsic parameters. Otherwise, if all the parameters are\n",
      "        .   estimated at once, it makes sense to restrict some parameters, for example, pass\n",
      "        .   CALIB_SAME_FOCAL_LENGTH and CALIB_ZERO_TANGENT_DIST flags, which is usually a\n",
      "        .   reasonable assumption.\n",
      "        .   \n",
      "        .   Similarly to calibrateCamera, the function minimizes the total re-projection error for all the\n",
      "        .   points in all the available views from both cameras. The function returns the final value of the\n",
      "        .   re-projection error.\n",
      "    \n",
      "    stereoRectify(...)\n",
      "        stereoRectify(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, imageSize, R, T[, R1[, R2[, P1[, P2[, Q[, flags[, alpha[, newImageSize]]]]]]]]) -> R1, R2, P1, P2, Q, validPixROI1, validPixROI2\n",
      "        .   @brief Computes rectification transforms for each head of a calibrated stereo camera.\n",
      "        .   \n",
      "        .   @param cameraMatrix1 First camera matrix.\n",
      "        .   @param distCoeffs1 First camera distortion parameters.\n",
      "        .   @param cameraMatrix2 Second camera matrix.\n",
      "        .   @param distCoeffs2 Second camera distortion parameters.\n",
      "        .   @param imageSize Size of the image used for stereo calibration.\n",
      "        .   @param R Rotation matrix from the coordinate system of the first camera to the second camera,\n",
      "        .   see @ref stereoCalibrate.\n",
      "        .   @param T Translation vector from the coordinate system of the first camera to the second camera,\n",
      "        .   see @ref stereoCalibrate.\n",
      "        .   @param R1 Output 3x3 rectification transform (rotation matrix) for the first camera. This matrix\n",
      "        .   brings points given in the unrectified first camera's coordinate system to points in the rectified\n",
      "        .   first camera's coordinate system. In more technical terms, it performs a change of basis from the\n",
      "        .   unrectified first camera's coordinate system to the rectified first camera's coordinate system.\n",
      "        .   @param R2 Output 3x3 rectification transform (rotation matrix) for the second camera. This matrix\n",
      "        .   brings points given in the unrectified second camera's coordinate system to points in the rectified\n",
      "        .   second camera's coordinate system. In more technical terms, it performs a change of basis from the\n",
      "        .   unrectified second camera's coordinate system to the rectified second camera's coordinate system.\n",
      "        .   @param P1 Output 3x4 projection matrix in the new (rectified) coordinate systems for the first\n",
      "        .   camera, i.e. it projects points given in the rectified first camera coordinate system into the\n",
      "        .   rectified first camera's image.\n",
      "        .   @param P2 Output 3x4 projection matrix in the new (rectified) coordinate systems for the second\n",
      "        .   camera, i.e. it projects points given in the rectified first camera coordinate system into the\n",
      "        .   rectified second camera's image.\n",
      "        .   @param Q Output \\f$4 \\times 4\\f$ disparity-to-depth mapping matrix (see @ref reprojectImageTo3D).\n",
      "        .   @param flags Operation flags that may be zero or CALIB_ZERO_DISPARITY . If the flag is set,\n",
      "        .   the function makes the principal points of each camera have the same pixel coordinates in the\n",
      "        .   rectified views. And if the flag is not set, the function may still shift the images in the\n",
      "        .   horizontal or vertical direction (depending on the orientation of epipolar lines) to maximize the\n",
      "        .   useful image area.\n",
      "        .   @param alpha Free scaling parameter. If it is -1 or absent, the function performs the default\n",
      "        .   scaling. Otherwise, the parameter should be between 0 and 1. alpha=0 means that the rectified\n",
      "        .   images are zoomed and shifted so that only valid pixels are visible (no black areas after\n",
      "        .   rectification). alpha=1 means that the rectified image is decimated and shifted so that all the\n",
      "        .   pixels from the original images from the cameras are retained in the rectified images (no source\n",
      "        .   image pixels are lost). Any intermediate value yields an intermediate result between\n",
      "        .   those two extreme cases.\n",
      "        .   @param newImageSize New image resolution after rectification. The same size should be passed to\n",
      "        .   initUndistortRectifyMap (see the stereo_calib.cpp sample in OpenCV samples directory). When (0,0)\n",
      "        .   is passed (default), it is set to the original imageSize . Setting it to a larger value can help you\n",
      "        .   preserve details in the original image, especially when there is a big radial distortion.\n",
      "        .   @param validPixROI1 Optional output rectangles inside the rectified images where all the pixels\n",
      "        .   are valid. If alpha=0 , the ROIs cover the whole images. Otherwise, they are likely to be smaller\n",
      "        .   (see the picture below).\n",
      "        .   @param validPixROI2 Optional output rectangles inside the rectified images where all the pixels\n",
      "        .   are valid. If alpha=0 , the ROIs cover the whole images. Otherwise, they are likely to be smaller\n",
      "        .   (see the picture below).\n",
      "        .   \n",
      "        .   The function computes the rotation matrices for each camera that (virtually) make both camera image\n",
      "        .   planes the same plane. Consequently, this makes all the epipolar lines parallel and thus simplifies\n",
      "        .   the dense stereo correspondence problem. The function takes the matrices computed by stereoCalibrate\n",
      "        .   as input. As output, it provides two rotation matrices and also two projection matrices in the new\n",
      "        .   coordinates. The function distinguishes the following two cases:\n",
      "        .   \n",
      "        .   -   **Horizontal stereo**: the first and the second camera views are shifted relative to each other\n",
      "        .       mainly along the x-axis (with possible small vertical shift). In the rectified images, the\n",
      "        .       corresponding epipolar lines in the left and right cameras are horizontal and have the same\n",
      "        .       y-coordinate. P1 and P2 look like:\n",
      "        .   \n",
      "        .       \\f[\\texttt{P1} = \\begin{bmatrix}\n",
      "        .                           f & 0 & cx_1 & 0 \\\\\n",
      "        .                           0 & f & cy & 0 \\\\\n",
      "        .                           0 & 0 & 1 & 0\n",
      "        .                        \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .       \\f[\\texttt{P2} = \\begin{bmatrix}\n",
      "        .                           f & 0 & cx_2 & T_x*f \\\\\n",
      "        .                           0 & f & cy & 0 \\\\\n",
      "        .                           0 & 0 & 1 & 0\n",
      "        .                        \\end{bmatrix} ,\\f]\n",
      "        .   \n",
      "        .       where \\f$T_x\\f$ is a horizontal shift between the cameras and \\f$cx_1=cx_2\\f$ if\n",
      "        .       CALIB_ZERO_DISPARITY is set.\n",
      "        .   \n",
      "        .   -   **Vertical stereo**: the first and the second camera views are shifted relative to each other\n",
      "        .       mainly in the vertical direction (and probably a bit in the horizontal direction too). The epipolar\n",
      "        .       lines in the rectified images are vertical and have the same x-coordinate. P1 and P2 look like:\n",
      "        .   \n",
      "        .       \\f[\\texttt{P1} = \\begin{bmatrix}\n",
      "        .                           f & 0 & cx & 0 \\\\\n",
      "        .                           0 & f & cy_1 & 0 \\\\\n",
      "        .                           0 & 0 & 1 & 0\n",
      "        .                        \\end{bmatrix}\\f]\n",
      "        .   \n",
      "        .       \\f[\\texttt{P2} = \\begin{bmatrix}\n",
      "        .                           f & 0 & cx & 0 \\\\\n",
      "        .                           0 & f & cy_2 & T_y*f \\\\\n",
      "        .                           0 & 0 & 1 & 0\n",
      "        .                        \\end{bmatrix},\\f]\n",
      "        .   \n",
      "        .       where \\f$T_y\\f$ is a vertical shift between the cameras and \\f$cy_1=cy_2\\f$ if\n",
      "        .       CALIB_ZERO_DISPARITY is set.\n",
      "        .   \n",
      "        .   As you can see, the first three columns of P1 and P2 will effectively be the new \"rectified\" camera\n",
      "        .   matrices. The matrices, together with R1 and R2 , can then be passed to initUndistortRectifyMap to\n",
      "        .   initialize the rectification map for each camera.\n",
      "        .   \n",
      "        .   See below the screenshot from the stereo_calib.cpp sample. Some red horizontal lines pass through\n",
      "        .   the corresponding image regions. This means that the images are well rectified, which is what most\n",
      "        .   stereo correspondence algorithms rely on. The green rectangles are roi1 and roi2 . You see that\n",
      "        .   their interiors are all valid pixels.\n",
      "        .   \n",
      "        .   ![image](pics/stereo_undistort.jpg)\n",
      "    \n",
      "    stereoRectifyUncalibrated(...)\n",
      "        stereoRectifyUncalibrated(points1, points2, F, imgSize[, H1[, H2[, threshold]]]) -> retval, H1, H2\n",
      "        .   @brief Computes a rectification transform for an uncalibrated stereo camera.\n",
      "        .   \n",
      "        .   @param points1 Array of feature points in the first image.\n",
      "        .   @param points2 The corresponding points in the second image. The same formats as in\n",
      "        .   findFundamentalMat are supported.\n",
      "        .   @param F Input fundamental matrix. It can be computed from the same set of point pairs using\n",
      "        .   findFundamentalMat .\n",
      "        .   @param imgSize Size of the image.\n",
      "        .   @param H1 Output rectification homography matrix for the first image.\n",
      "        .   @param H2 Output rectification homography matrix for the second image.\n",
      "        .   @param threshold Optional threshold used to filter out the outliers. If the parameter is greater\n",
      "        .   than zero, all the point pairs that do not comply with the epipolar geometry (that is, the points\n",
      "        .   for which \\f$|\\texttt{points2[i]}^T*\\texttt{F}*\\texttt{points1[i]}|>\\texttt{threshold}\\f$ ) are\n",
      "        .   rejected prior to computing the homographies. Otherwise, all the points are considered inliers.\n",
      "        .   \n",
      "        .   The function computes the rectification transformations without knowing intrinsic parameters of the\n",
      "        .   cameras and their relative position in the space, which explains the suffix \"uncalibrated\". Another\n",
      "        .   related difference from stereoRectify is that the function outputs not the rectification\n",
      "        .   transformations in the object (3D) space, but the planar perspective transformations encoded by the\n",
      "        .   homography matrices H1 and H2 . The function implements the algorithm @cite Hartley99 .\n",
      "        .   \n",
      "        .   @note\n",
      "        .      While the algorithm does not need to know the intrinsic parameters of the cameras, it heavily\n",
      "        .       depends on the epipolar geometry. Therefore, if the camera lenses have a significant distortion,\n",
      "        .       it would be better to correct it before computing the fundamental matrix and calling this\n",
      "        .       function. For example, distortion coefficients can be estimated for each head of stereo camera\n",
      "        .       separately by using calibrateCamera . Then, the images can be corrected using undistort , or\n",
      "        .       just the point coordinates can be corrected with undistortPoints .\n",
      "    \n",
      "    stylization(...)\n",
      "        stylization(src[, dst[, sigma_s[, sigma_r]]]) -> dst\n",
      "        .   @brief Stylization aims to produce digital imagery with a wide variety of effects not focused on\n",
      "        .   photorealism. Edge-aware filters are ideal for stylization, as they can abstract regions of low\n",
      "        .   contrast while preserving, or enhancing, high-contrast features.\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param dst Output image with the same size and type as src.\n",
      "        .   @param sigma_s %Range between 0 to 200.\n",
      "        .   @param sigma_r %Range between 0 to 1.\n",
      "    \n",
      "    subtract(...)\n",
      "        subtract(src1, src2[, dst[, mask[, dtype]]]) -> dst\n",
      "        .   @brief Calculates the per-element difference between two arrays or array and a scalar.\n",
      "        .   \n",
      "        .   The function subtract calculates:\n",
      "        .   - Difference between two arrays, when both input arrays have the same size and the same number of\n",
      "        .   channels:\n",
      "        .       \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src1}(I) -  \\texttt{src2}(I)) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   - Difference between an array and a scalar, when src2 is constructed from Scalar or has the same\n",
      "        .   number of elements as `src1.channels()`:\n",
      "        .       \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src1}(I) -  \\texttt{src2} ) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   - Difference between a scalar and an array, when src1 is constructed from Scalar or has the same\n",
      "        .   number of elements as `src2.channels()`:\n",
      "        .       \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src1} -  \\texttt{src2}(I) ) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   - The reverse difference between a scalar and an array in the case of `SubRS`:\n",
      "        .       \\f[\\texttt{dst}(I) =  \\texttt{saturate} ( \\texttt{src2} -  \\texttt{src1}(I) ) \\quad \\texttt{if mask}(I) \\ne0\\f]\n",
      "        .   where I is a multi-dimensional index of array elements. In case of multi-channel arrays, each\n",
      "        .   channel is processed independently.\n",
      "        .   \n",
      "        .   The first function in the list above can be replaced with matrix expressions:\n",
      "        .   @code{.cpp}\n",
      "        .       dst = src1 - src2;\n",
      "        .       dst -= src1; // equivalent to subtract(dst, src1, dst);\n",
      "        .   @endcode\n",
      "        .   The input arrays and the output array can all have the same or different depths. For example, you\n",
      "        .   can subtract to 8-bit unsigned arrays and store the difference in a 16-bit signed array. Depth of\n",
      "        .   the output array is determined by dtype parameter. In the second and third cases above, as well as\n",
      "        .   in the first case, when src1.depth() == src2.depth(), dtype can be set to the default -1. In this\n",
      "        .   case the output array will have the same depth as the input array, be it src1, src2 or both.\n",
      "        .   @note Saturation is not applied when the output array has the depth CV_32S. You may even get\n",
      "        .   result of an incorrect sign in the case of overflow.\n",
      "        .   @param src1 first input array or a scalar.\n",
      "        .   @param src2 second input array or a scalar.\n",
      "        .   @param dst output array of the same size and the same number of channels as the input array.\n",
      "        .   @param mask optional operation mask; this is an 8-bit single channel array that specifies elements\n",
      "        .   of the output array to be changed.\n",
      "        .   @param dtype optional depth of the output array\n",
      "        .   @sa  add, addWeighted, scaleAdd, Mat::convertTo\n",
      "    \n",
      "    sumElems(...)\n",
      "        sumElems(src) -> retval\n",
      "        .   @brief Calculates the sum of array elements.\n",
      "        .   \n",
      "        .   The function cv::sum calculates and returns the sum of array elements,\n",
      "        .   independently for each channel.\n",
      "        .   @param src input array that must have from 1 to 4 channels.\n",
      "        .   @sa  countNonZero, mean, meanStdDev, norm, minMaxLoc, reduce\n",
      "    \n",
      "    textureFlattening(...)\n",
      "        textureFlattening(src, mask[, dst[, low_threshold[, high_threshold[, kernel_size]]]]) -> dst\n",
      "        .   @brief By retaining only the gradients at edge locations, before integrating with the Poisson solver, one\n",
      "        .   washes out the texture of the selected region, giving its contents a flat aspect. Here Canny Edge %Detector is used.\n",
      "        .   \n",
      "        .   @param src Input 8-bit 3-channel image.\n",
      "        .   @param mask Input 8-bit 1 or 3-channel image.\n",
      "        .   @param dst Output image with the same size and type as src.\n",
      "        .   @param low_threshold %Range from 0 to 100.\n",
      "        .   @param high_threshold Value \\> 100.\n",
      "        .   @param kernel_size The size of the Sobel kernel to be used.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   The algorithm assumes that the color of the source image is close to that of the destination. This\n",
      "        .   assumption means that when the colors don't match, the source image color gets tinted toward the\n",
      "        .   color of the destination image.\n",
      "    \n",
      "    threshold(...)\n",
      "        threshold(src, thresh, maxval, type[, dst]) -> retval, dst\n",
      "        .   @brief Applies a fixed-level threshold to each array element.\n",
      "        .   \n",
      "        .   The function applies fixed-level thresholding to a multiple-channel array. The function is typically\n",
      "        .   used to get a bi-level (binary) image out of a grayscale image ( #compare could be also used for\n",
      "        .   this purpose) or for removing a noise, that is, filtering out pixels with too small or too large\n",
      "        .   values. There are several types of thresholding supported by the function. They are determined by\n",
      "        .   type parameter.\n",
      "        .   \n",
      "        .   Also, the special values #THRESH_OTSU or #THRESH_TRIANGLE may be combined with one of the\n",
      "        .   above values. In these cases, the function determines the optimal threshold value using the Otsu's\n",
      "        .   or Triangle algorithm and uses it instead of the specified thresh.\n",
      "        .   \n",
      "        .   @note Currently, the Otsu's and Triangle methods are implemented only for 8-bit single-channel images.\n",
      "        .   \n",
      "        .   @param src input array (multiple-channel, 8-bit or 32-bit floating point).\n",
      "        .   @param dst output array of the same size  and type and the same number of channels as src.\n",
      "        .   @param thresh threshold value.\n",
      "        .   @param maxval maximum value to use with the #THRESH_BINARY and #THRESH_BINARY_INV thresholding\n",
      "        .   types.\n",
      "        .   @param type thresholding type (see #ThresholdTypes).\n",
      "        .   @return the computed threshold value if Otsu's or Triangle methods used.\n",
      "        .   \n",
      "        .   @sa  adaptiveThreshold, findContours, compare, min, max\n",
      "    \n",
      "    trace(...)\n",
      "        trace(mtx) -> retval\n",
      "        .   @brief Returns the trace of a matrix.\n",
      "        .   \n",
      "        .   The function cv::trace returns the sum of the diagonal elements of the\n",
      "        .   matrix mtx .\n",
      "        .   \\f[\\mathrm{tr} ( \\texttt{mtx} ) =  \\sum _i  \\texttt{mtx} (i,i)\\f]\n",
      "        .   @param mtx input matrix.\n",
      "    \n",
      "    transform(...)\n",
      "        transform(src, m[, dst]) -> dst\n",
      "        .   @brief Performs the matrix transformation of every array element.\n",
      "        .   \n",
      "        .   The function cv::transform performs the matrix transformation of every\n",
      "        .   element of the array src and stores the results in dst :\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{m} \\cdot \\texttt{src} (I)\\f]\n",
      "        .   (when m.cols=src.channels() ), or\n",
      "        .   \\f[\\texttt{dst} (I) =  \\texttt{m} \\cdot [ \\texttt{src} (I); 1]\\f]\n",
      "        .   (when m.cols=src.channels()+1 )\n",
      "        .   \n",
      "        .   Every element of the N -channel array src is interpreted as N -element\n",
      "        .   vector that is transformed using the M x N or M x (N+1) matrix m to\n",
      "        .   M-element vector - the corresponding element of the output array dst .\n",
      "        .   \n",
      "        .   The function may be used for geometrical transformation of\n",
      "        .   N -dimensional points, arbitrary linear color space transformation (such\n",
      "        .   as various kinds of RGB to YUV transforms), shuffling the image\n",
      "        .   channels, and so forth.\n",
      "        .   @param src input array that must have as many channels (1 to 4) as\n",
      "        .   m.cols or m.cols-1.\n",
      "        .   @param dst output array of the same size and depth as src; it has as\n",
      "        .   many channels as m.rows.\n",
      "        .   @param m transformation 2x2 or 2x3 floating-point matrix.\n",
      "        .   @sa perspectiveTransform, getAffineTransform, estimateAffine2D, warpAffine, warpPerspective\n",
      "    \n",
      "    transpose(...)\n",
      "        transpose(src[, dst]) -> dst\n",
      "        .   @brief Transposes a matrix.\n",
      "        .   \n",
      "        .   The function cv::transpose transposes the matrix src :\n",
      "        .   \\f[\\texttt{dst} (i,j) =  \\texttt{src} (j,i)\\f]\n",
      "        .   @note No complex conjugation is done in case of a complex matrix. It\n",
      "        .   should be done separately if needed.\n",
      "        .   @param src input array.\n",
      "        .   @param dst output array of the same type as src.\n",
      "    \n",
      "    triangulatePoints(...)\n",
      "        triangulatePoints(projMatr1, projMatr2, projPoints1, projPoints2[, points4D]) -> points4D\n",
      "        .   @brief This function reconstructs 3-dimensional points (in homogeneous coordinates) by using\n",
      "        .   their observations with a stereo camera.\n",
      "        .   \n",
      "        .   @param projMatr1 3x4 projection matrix of the first camera, i.e. this matrix projects 3D points\n",
      "        .   given in the world's coordinate system into the first image.\n",
      "        .   @param projMatr2 3x4 projection matrix of the second camera, i.e. this matrix projects 3D points\n",
      "        .   given in the world's coordinate system into the second image.\n",
      "        .   @param projPoints1 2xN array of feature points in the first image. In the case of the c++ version,\n",
      "        .   it can be also a vector of feature points or two-channel matrix of size 1xN or Nx1.\n",
      "        .   @param projPoints2 2xN array of corresponding points in the second image. In the case of the c++\n",
      "        .   version, it can be also a vector of feature points or two-channel matrix of size 1xN or Nx1.\n",
      "        .   @param points4D 4xN array of reconstructed points in homogeneous coordinates. These points are\n",
      "        .   returned in the world's coordinate system.\n",
      "        .   \n",
      "        .   @note\n",
      "        .      Keep in mind that all input data should be of float type in order for this function to work.\n",
      "        .   \n",
      "        .   @note\n",
      "        .      If the projection matrices from @ref stereoRectify are used, then the returned points are\n",
      "        .      represented in the first camera's rectified coordinate system.\n",
      "        .   \n",
      "        .   @sa\n",
      "        .      reprojectImageTo3D\n",
      "    \n",
      "    undistort(...)\n",
      "        undistort(src, cameraMatrix, distCoeffs[, dst[, newCameraMatrix]]) -> dst\n",
      "        .   @brief Transforms an image to compensate for lens distortion.\n",
      "        .   \n",
      "        .   The function transforms an image to compensate radial and tangential lens distortion.\n",
      "        .   \n",
      "        .   The function is simply a combination of #initUndistortRectifyMap (with unity R ) and #remap\n",
      "        .   (with bilinear interpolation). See the former function for details of the transformation being\n",
      "        .   performed.\n",
      "        .   \n",
      "        .   Those pixels in the destination image, for which there is no correspondent pixels in the source\n",
      "        .   image, are filled with zeros (black color).\n",
      "        .   \n",
      "        .   A particular subset of the source image that will be visible in the corrected image can be regulated\n",
      "        .   by newCameraMatrix. You can use #getOptimalNewCameraMatrix to compute the appropriate\n",
      "        .   newCameraMatrix depending on your requirements.\n",
      "        .   \n",
      "        .   The camera matrix and the distortion parameters can be determined using #calibrateCamera. If\n",
      "        .   the resolution of images is different from the resolution used at the calibration stage, \\f$f_x,\n",
      "        .   f_y, c_x\\f$ and \\f$c_y\\f$ need to be scaled accordingly, while the distortion coefficients remain\n",
      "        .   the same.\n",
      "        .   \n",
      "        .   @param src Input (distorted) image.\n",
      "        .   @param dst Output (corrected) image that has the same size and type as src .\n",
      "        .   @param cameraMatrix Input camera matrix \\f$A = \\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$\n",
      "        .   of 4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are assumed.\n",
      "        .   @param newCameraMatrix Camera matrix of the distorted image. By default, it is the same as\n",
      "        .   cameraMatrix but you may additionally scale and shift the result by using a different matrix.\n",
      "    \n",
      "    undistortPoints(...)\n",
      "        undistortPoints(src, cameraMatrix, distCoeffs[, dst[, R[, P]]]) -> dst\n",
      "        .   @brief Computes the ideal point coordinates from the observed point coordinates.\n",
      "        .   \n",
      "        .   The function is similar to #undistort and #initUndistortRectifyMap but it operates on a\n",
      "        .   sparse set of points instead of a raster image. Also the function performs a reverse transformation\n",
      "        .   to projectPoints. In case of a 3D object, it does not reconstruct its 3D coordinates, but for a\n",
      "        .   planar object, it does, up to a translation vector, if the proper R is specified.\n",
      "        .   \n",
      "        .   For each observed point coordinate \\f$(u, v)\\f$ the function computes:\n",
      "        .   \\f[\n",
      "        .   \\begin{array}{l}\n",
      "        .   x^{\"}  \\leftarrow (u - c_x)/f_x  \\\\\n",
      "        .   y^{\"}  \\leftarrow (v - c_y)/f_y  \\\\\n",
      "        .   (x',y') = undistort(x^{\"},y^{\"}, \\texttt{distCoeffs}) \\\\\n",
      "        .   {[X\\,Y\\,W]} ^T  \\leftarrow R*[x' \\, y' \\, 1]^T  \\\\\n",
      "        .   x  \\leftarrow X/W  \\\\\n",
      "        .   y  \\leftarrow Y/W  \\\\\n",
      "        .   \\text{only performed if P is specified:} \\\\\n",
      "        .   u'  \\leftarrow x {f'}_x + {c'}_x  \\\\\n",
      "        .   v'  \\leftarrow y {f'}_y + {c'}_y\n",
      "        .   \\end{array}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   where *undistort* is an approximate iterative algorithm that estimates the normalized original\n",
      "        .   point coordinates out of the normalized distorted point coordinates (\"normalized\" means that the\n",
      "        .   coordinates do not depend on the camera matrix).\n",
      "        .   \n",
      "        .   The function can be used for both a stereo camera head or a monocular camera (when R is empty).\n",
      "        .   @param src Observed point coordinates, 2xN/Nx2 1-channel or 1xN/Nx1 2-channel (CV_32FC2 or CV_64FC2) (or\n",
      "        .   vector\\<Point2f\\> ).\n",
      "        .   @param dst Output ideal point coordinates (1xN/Nx1 2-channel or vector\\<Point2f\\> ) after undistortion and reverse perspective\n",
      "        .   transformation. If matrix P is identity or omitted, dst will contain normalized point coordinates.\n",
      "        .   @param cameraMatrix Camera matrix \\f$\\vecthreethree{f_x}{0}{c_x}{0}{f_y}{c_y}{0}{0}{1}\\f$ .\n",
      "        .   @param distCoeffs Input vector of distortion coefficients\n",
      "        .   \\f$(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6[, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]])\\f$\n",
      "        .   of 4, 5, 8, 12 or 14 elements. If the vector is NULL/empty, the zero distortion coefficients are assumed.\n",
      "        .   @param R Rectification transformation in the object space (3x3 matrix). R1 or R2 computed by\n",
      "        .   #stereoRectify can be passed here. If the matrix is empty, the identity transformation is used.\n",
      "        .   @param P New camera matrix (3x3) or new projection matrix (3x4) \\f$\\begin{bmatrix} {f'}_x & 0 & {c'}_x & t_x \\\\ 0 & {f'}_y & {c'}_y & t_y \\\\ 0 & 0 & 1 & t_z \\end{bmatrix}\\f$. P1 or P2 computed by\n",
      "        .   #stereoRectify can be passed here. If the matrix is empty, the identity new camera matrix is used.\n",
      "    \n",
      "    undistortPointsIter(...)\n",
      "        undistortPointsIter(src, cameraMatrix, distCoeffs, R, P, criteria[, dst]) -> dst\n",
      "        .   @overload\n",
      "        .       @note Default version of #undistortPoints does 5 iterations to compute undistorted points.\n",
      "    \n",
      "    useOpenVX(...)\n",
      "        useOpenVX() -> retval\n",
      "        .\n",
      "    \n",
      "    useOptimized(...)\n",
      "        useOptimized() -> retval\n",
      "        .   @brief Returns the status of optimized code usage.\n",
      "        .   \n",
      "        .   The function returns true if the optimized code is enabled. Otherwise, it returns false.\n",
      "    \n",
      "    validateDisparity(...)\n",
      "        validateDisparity(disparity, cost, minDisparity, numberOfDisparities[, disp12MaxDisp]) -> disparity\n",
      "        .\n",
      "    \n",
      "    vconcat(...)\n",
      "        vconcat(src[, dst]) -> dst\n",
      "        .   @overload\n",
      "        .    @code{.cpp}\n",
      "        .       std::vector<cv::Mat> matrices = { cv::Mat(1, 4, CV_8UC1, cv::Scalar(1)),\n",
      "        .                                         cv::Mat(1, 4, CV_8UC1, cv::Scalar(2)),\n",
      "        .                                         cv::Mat(1, 4, CV_8UC1, cv::Scalar(3)),};\n",
      "        .   \n",
      "        .       cv::Mat out;\n",
      "        .       cv::vconcat( matrices, out );\n",
      "        .       //out:\n",
      "        .       //[1,   1,   1,   1;\n",
      "        .       // 2,   2,   2,   2;\n",
      "        .       // 3,   3,   3,   3]\n",
      "        .    @endcode\n",
      "        .    @param src input array or vector of matrices. all of the matrices must have the same number of cols and the same depth\n",
      "        .    @param dst output array. It has the same number of cols and depth as the src, and the sum of rows of the src.\n",
      "        .   same depth.\n",
      "    \n",
      "    waitKey(...)\n",
      "        waitKey([, delay]) -> retval\n",
      "        .   @brief Waits for a pressed key.\n",
      "        .   \n",
      "        .   The function waitKey waits for a key event infinitely (when \\f$\\texttt{delay}\\leq 0\\f$ ) or for delay\n",
      "        .   milliseconds, when it is positive. Since the OS has a minimum time between switching threads, the\n",
      "        .   function will not wait exactly delay ms, it will wait at least delay ms, depending on what else is\n",
      "        .   running on your computer at that time. It returns the code of the pressed key or -1 if no key was\n",
      "        .   pressed before the specified time had elapsed.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   This function is the only method in HighGUI that can fetch and handle events, so it needs to be\n",
      "        .   called periodically for normal event processing unless HighGUI is used within an environment that\n",
      "        .   takes care of event processing.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   The function only works if there is at least one HighGUI window created and the window is active.\n",
      "        .   If there are several HighGUI windows, any of them can be active.\n",
      "        .   \n",
      "        .   @param delay Delay in milliseconds. 0 is the special value that means \"forever\".\n",
      "    \n",
      "    waitKeyEx(...)\n",
      "        waitKeyEx([, delay]) -> retval\n",
      "        .   @brief Similar to #waitKey, but returns full key code.\n",
      "        .   \n",
      "        .   @note\n",
      "        .   \n",
      "        .   Key code is implementation specific and depends on used backend: QT/GTK/Win32/etc\n",
      "    \n",
      "    warpAffine(...)\n",
      "        warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]]) -> dst\n",
      "        .   @brief Applies an affine transformation to an image.\n",
      "        .   \n",
      "        .   The function warpAffine transforms the source image using the specified matrix:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\texttt{src} ( \\texttt{M} _{11} x +  \\texttt{M} _{12} y +  \\texttt{M} _{13}, \\texttt{M} _{21} x +  \\texttt{M} _{22} y +  \\texttt{M} _{23})\\f]\n",
      "        .   \n",
      "        .   when the flag #WARP_INVERSE_MAP is set. Otherwise, the transformation is first inverted\n",
      "        .   with #invertAffineTransform and then put in the formula above instead of M. The function cannot\n",
      "        .   operate in-place.\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image that has the size dsize and the same type as src .\n",
      "        .   @param M \\f$2\\times 3\\f$ transformation matrix.\n",
      "        .   @param dsize size of the output image.\n",
      "        .   @param flags combination of interpolation methods (see #InterpolationFlags) and the optional\n",
      "        .   flag #WARP_INVERSE_MAP that means that M is the inverse transformation (\n",
      "        .   \\f$\\texttt{dst}\\rightarrow\\texttt{src}\\f$ ).\n",
      "        .   @param borderMode pixel extrapolation method (see #BorderTypes); when\n",
      "        .   borderMode=#BORDER_TRANSPARENT, it means that the pixels in the destination image corresponding to\n",
      "        .   the \"outliers\" in the source image are not modified by the function.\n",
      "        .   @param borderValue value used in case of a constant border; by default, it is 0.\n",
      "        .   \n",
      "        .   @sa  warpPerspective, resize, remap, getRectSubPix, transform\n",
      "    \n",
      "    warpPerspective(...)\n",
      "        warpPerspective(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]]) -> dst\n",
      "        .   @brief Applies a perspective transformation to an image.\n",
      "        .   \n",
      "        .   The function warpPerspective transforms the source image using the specified matrix:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\texttt{src} \\left ( \\frac{M_{11} x + M_{12} y + M_{13}}{M_{31} x + M_{32} y + M_{33}} ,\n",
      "        .        \\frac{M_{21} x + M_{22} y + M_{23}}{M_{31} x + M_{32} y + M_{33}} \\right )\\f]\n",
      "        .   \n",
      "        .   when the flag #WARP_INVERSE_MAP is set. Otherwise, the transformation is first inverted with invert\n",
      "        .   and then put in the formula above instead of M. The function cannot operate in-place.\n",
      "        .   \n",
      "        .   @param src input image.\n",
      "        .   @param dst output image that has the size dsize and the same type as src .\n",
      "        .   @param M \\f$3\\times 3\\f$ transformation matrix.\n",
      "        .   @param dsize size of the output image.\n",
      "        .   @param flags combination of interpolation methods (#INTER_LINEAR or #INTER_NEAREST) and the\n",
      "        .   optional flag #WARP_INVERSE_MAP, that sets M as the inverse transformation (\n",
      "        .   \\f$\\texttt{dst}\\rightarrow\\texttt{src}\\f$ ).\n",
      "        .   @param borderMode pixel extrapolation method (#BORDER_CONSTANT or #BORDER_REPLICATE).\n",
      "        .   @param borderValue value used in case of a constant border; by default, it equals 0.\n",
      "        .   \n",
      "        .   @sa  warpAffine, resize, remap, getRectSubPix, perspectiveTransform\n",
      "    \n",
      "    warpPolar(...)\n",
      "        warpPolar(src, dsize, center, maxRadius, flags[, dst]) -> dst\n",
      "        .   \\brief Remaps an image to polar or semilog-polar coordinates space\n",
      "        .   \n",
      "        .   @anchor polar_remaps_reference_image\n",
      "        .   ![Polar remaps reference](pics/polar_remap_doc.png)\n",
      "        .   \n",
      "        .   Transform the source image using the following transformation:\n",
      "        .   \\f[\n",
      "        .   dst(\\rho , \\phi ) = src(x,y)\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   where\n",
      "        .   \\f[\n",
      "        .   \\begin{array}{l}\n",
      "        .   \\vec{I} = (x - center.x, \\;y - center.y) \\\\\n",
      "        .   \\phi = Kangle \\cdot \\texttt{angle} (\\vec{I}) \\\\\n",
      "        .   \\rho = \\left\\{\\begin{matrix}\n",
      "        .   Klin \\cdot \\texttt{magnitude} (\\vec{I}) & default \\\\\n",
      "        .   Klog \\cdot log_e(\\texttt{magnitude} (\\vec{I})) & if \\; semilog \\\\\n",
      "        .   \\end{matrix}\\right.\n",
      "        .   \\end{array}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   and\n",
      "        .   \\f[\n",
      "        .   \\begin{array}{l}\n",
      "        .   Kangle = dsize.height / 2\\Pi \\\\\n",
      "        .   Klin = dsize.width / maxRadius \\\\\n",
      "        .   Klog = dsize.width / log_e(maxRadius) \\\\\n",
      "        .   \\end{array}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   \\par Linear vs semilog mapping\n",
      "        .   \n",
      "        .   Polar mapping can be linear or semi-log. Add one of #WarpPolarMode to `flags` to specify the polar mapping mode.\n",
      "        .   \n",
      "        .   Linear is the default mode.\n",
      "        .   \n",
      "        .   The semilog mapping emulates the human \"foveal\" vision that permit very high acuity on the line of sight (central vision)\n",
      "        .   in contrast to peripheral vision where acuity is minor.\n",
      "        .   \n",
      "        .   \\par Option on `dsize`:\n",
      "        .   \n",
      "        .   - if both values in `dsize <=0 ` (default),\n",
      "        .   the destination image will have (almost) same area of source bounding circle:\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .   dsize.area  \\leftarrow (maxRadius^2 \\cdot \\Pi) \\\\\n",
      "        .   dsize.width = \\texttt{cvRound}(maxRadius) \\\\\n",
      "        .   dsize.height = \\texttt{cvRound}(maxRadius \\cdot \\Pi) \\\\\n",
      "        .   \\end{array}\\f]\n",
      "        .   \n",
      "        .   \n",
      "        .   - if only `dsize.height <= 0`,\n",
      "        .   the destination image area will be proportional to the bounding circle area but scaled by `Kx * Kx`:\n",
      "        .   \\f[\\begin{array}{l}\n",
      "        .   dsize.height = \\texttt{cvRound}(dsize.width \\cdot \\Pi) \\\\\n",
      "        .   \\end{array}\n",
      "        .   \\f]\n",
      "        .   \n",
      "        .   - if both values in `dsize > 0 `,\n",
      "        .   the destination image will have the given size therefore the area of the bounding circle will be scaled to `dsize`.\n",
      "        .   \n",
      "        .   \n",
      "        .   \\par Reverse mapping\n",
      "        .   \n",
      "        .   You can get reverse mapping adding #WARP_INVERSE_MAP to `flags`\n",
      "        .   \\snippet polar_transforms.cpp InverseMap\n",
      "        .   \n",
      "        .   In addiction, to calculate the original coordinate from a polar mapped coordinate \\f$(rho, phi)->(x, y)\\f$:\n",
      "        .   \\snippet polar_transforms.cpp InverseCoordinate\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image. It will have same type as src.\n",
      "        .   @param dsize The destination image size (see description for valid options).\n",
      "        .   @param center The transformation center.\n",
      "        .   @param maxRadius The radius of the bounding circle to transform. It determines the inverse magnitude scale parameter too.\n",
      "        .   @param flags A combination of interpolation methods, #InterpolationFlags + #WarpPolarMode.\n",
      "        .               - Add #WARP_POLAR_LINEAR to select linear polar mapping (default)\n",
      "        .               - Add #WARP_POLAR_LOG to select semilog polar mapping\n",
      "        .               - Add #WARP_INVERSE_MAP for reverse mapping.\n",
      "        .   @note\n",
      "        .   -  The function can not operate in-place.\n",
      "        .   -  To calculate magnitude and angle in degrees #cartToPolar is used internally thus angles are measured from 0 to 360 with accuracy about 0.3 degrees.\n",
      "        .   -  This function uses #remap. Due to current implementation limitations the size of an input and output images should be less than 32767x32767.\n",
      "        .   \n",
      "        .   @sa cv::remap\n",
      "    \n",
      "    watershed(...)\n",
      "        watershed(image, markers) -> markers\n",
      "        .   @brief Performs a marker-based image segmentation using the watershed algorithm.\n",
      "        .   \n",
      "        .   The function implements one of the variants of watershed, non-parametric marker-based segmentation\n",
      "        .   algorithm, described in @cite Meyer92 .\n",
      "        .   \n",
      "        .   Before passing the image to the function, you have to roughly outline the desired regions in the\n",
      "        .   image markers with positive (\\>0) indices. So, every region is represented as one or more connected\n",
      "        .   components with the pixel values 1, 2, 3, and so on. Such markers can be retrieved from a binary\n",
      "        .   mask using #findContours and #drawContours (see the watershed.cpp demo). The markers are \"seeds\" of\n",
      "        .   the future image regions. All the other pixels in markers , whose relation to the outlined regions\n",
      "        .   is not known and should be defined by the algorithm, should be set to 0's. In the function output,\n",
      "        .   each pixel in markers is set to a value of the \"seed\" components or to -1 at boundaries between the\n",
      "        .   regions.\n",
      "        .   \n",
      "        .   @note Any two neighbor connected components are not necessarily separated by a watershed boundary\n",
      "        .   (-1's pixels); for example, they can touch each other in the initial marker image passed to the\n",
      "        .   function.\n",
      "        .   \n",
      "        .   @param image Input 8-bit 3-channel image.\n",
      "        .   @param markers Input/output 32-bit single-channel image (map) of markers. It should have the same\n",
      "        .   size as image .\n",
      "        .   \n",
      "        .   @sa findContours\n",
      "        .   \n",
      "        .   @ingroup imgproc_misc\n",
      "    \n",
      "    writeOpticalFlow(...)\n",
      "        writeOpticalFlow(path, flow) -> retval\n",
      "        .   @brief Write a .flo to disk\n",
      "        .   \n",
      "        .    @param path Path to the file to be written\n",
      "        .    @param flow Flow field to be stored\n",
      "        .   \n",
      "        .    The function stores a flow field in a file, returns true on success, false otherwise.\n",
      "        .    The flow field must be a 2-channel, floating-point matrix (CV_32FC2). First channel corresponds\n",
      "        .    to the flow in the horizontal direction (u), second - vertical (v).\n",
      "\n",
      "DATA\n",
      "    ACCESS_FAST = 67108864\n",
      "    ACCESS_MASK = 50331648\n",
      "    ACCESS_READ = 16777216\n",
      "    ACCESS_RW = 50331648\n",
      "    ACCESS_WRITE = 33554432\n",
      "    ADAPTIVE_THRESH_GAUSSIAN_C = 1\n",
      "    ADAPTIVE_THRESH_MEAN_C = 0\n",
      "    AGAST_FEATURE_DETECTOR_AGAST_5_8 = 0\n",
      "    AGAST_FEATURE_DETECTOR_AGAST_7_12D = 1\n",
      "    AGAST_FEATURE_DETECTOR_AGAST_7_12S = 2\n",
      "    AGAST_FEATURE_DETECTOR_NONMAX_SUPPRESSION = 10001\n",
      "    AGAST_FEATURE_DETECTOR_OAST_9_16 = 3\n",
      "    AGAST_FEATURE_DETECTOR_THRESHOLD = 10000\n",
      "    AKAZE_DESCRIPTOR_KAZE = 3\n",
      "    AKAZE_DESCRIPTOR_KAZE_UPRIGHT = 2\n",
      "    AKAZE_DESCRIPTOR_MLDB = 5\n",
      "    AKAZE_DESCRIPTOR_MLDB_UPRIGHT = 4\n",
      "    AgastFeatureDetector_AGAST_5_8 = 0\n",
      "    AgastFeatureDetector_AGAST_7_12d = 1\n",
      "    AgastFeatureDetector_AGAST_7_12s = 2\n",
      "    AgastFeatureDetector_NONMAX_SUPPRESSION = 10001\n",
      "    AgastFeatureDetector_OAST_9_16 = 3\n",
      "    AgastFeatureDetector_THRESHOLD = 10000\n",
      "    BORDER_CONSTANT = 0\n",
      "    BORDER_DEFAULT = 4\n",
      "    BORDER_ISOLATED = 16\n",
      "    BORDER_REFLECT = 2\n",
      "    BORDER_REFLECT101 = 4\n",
      "    BORDER_REFLECT_101 = 4\n",
      "    BORDER_REPLICATE = 1\n",
      "    BORDER_TRANSPARENT = 5\n",
      "    BORDER_WRAP = 3\n",
      "    CALIB_CB_ACCURACY = 32\n",
      "    CALIB_CB_ADAPTIVE_THRESH = 1\n",
      "    CALIB_CB_ASYMMETRIC_GRID = 2\n",
      "    CALIB_CB_CLUSTERING = 4\n",
      "    CALIB_CB_EXHAUSTIVE = 16\n",
      "    CALIB_CB_FAST_CHECK = 8\n",
      "    CALIB_CB_FILTER_QUADS = 4\n",
      "    CALIB_CB_LARGER = 64\n",
      "    CALIB_CB_MARKER = 128\n",
      "    CALIB_CB_NORMALIZE_IMAGE = 2\n",
      "    CALIB_CB_SYMMETRIC_GRID = 1\n",
      "    CALIB_FIX_ASPECT_RATIO = 2\n",
      "    CALIB_FIX_FOCAL_LENGTH = 16\n",
      "    CALIB_FIX_INTRINSIC = 256\n",
      "    CALIB_FIX_K1 = 32\n",
      "    CALIB_FIX_K2 = 64\n",
      "    CALIB_FIX_K3 = 128\n",
      "    CALIB_FIX_K4 = 2048\n",
      "    CALIB_FIX_K5 = 4096\n",
      "    CALIB_FIX_K6 = 8192\n",
      "    CALIB_FIX_PRINCIPAL_POINT = 4\n",
      "    CALIB_FIX_S1_S2_S3_S4 = 65536\n",
      "    CALIB_FIX_TANGENT_DIST = 2097152\n",
      "    CALIB_FIX_TAUX_TAUY = 524288\n",
      "    CALIB_HAND_EYE_ANDREFF = 3\n",
      "    CALIB_HAND_EYE_DANIILIDIS = 4\n",
      "    CALIB_HAND_EYE_HORAUD = 2\n",
      "    CALIB_HAND_EYE_PARK = 1\n",
      "    CALIB_HAND_EYE_TSAI = 0\n",
      "    CALIB_NINTRINSIC = 18\n",
      "    CALIB_RATIONAL_MODEL = 16384\n",
      "    CALIB_SAME_FOCAL_LENGTH = 512\n",
      "    CALIB_THIN_PRISM_MODEL = 32768\n",
      "    CALIB_TILTED_MODEL = 262144\n",
      "    CALIB_USE_EXTRINSIC_GUESS = 4194304\n",
      "    CALIB_USE_INTRINSIC_GUESS = 1\n",
      "    CALIB_USE_LU = 131072\n",
      "    CALIB_USE_QR = 1048576\n",
      "    CALIB_ZERO_DISPARITY = 1024\n",
      "    CALIB_ZERO_TANGENT_DIST = 8\n",
      "    CAP_ANDROID = 1000\n",
      "    CAP_ANY = 0\n",
      "    CAP_ARAVIS = 2100\n",
      "    CAP_AVFOUNDATION = 1200\n",
      "    CAP_CMU1394 = 300\n",
      "    CAP_DC1394 = 300\n",
      "    CAP_DSHOW = 700\n",
      "    CAP_FFMPEG = 1900\n",
      "    CAP_FIREWARE = 300\n",
      "    CAP_FIREWIRE = 300\n",
      "    CAP_GIGANETIX = 1300\n",
      "    CAP_GPHOTO2 = 1700\n",
      "    CAP_GSTREAMER = 1800\n",
      "    CAP_IEEE1394 = 300\n",
      "    CAP_IMAGES = 2000\n",
      "    CAP_INTELPERC = 1500\n",
      "    CAP_INTELPERC_DEPTH_GENERATOR = 536870912\n",
      "    CAP_INTELPERC_DEPTH_MAP = 0\n",
      "    CAP_INTELPERC_GENERATORS_MASK = 939524096\n",
      "    CAP_INTELPERC_IMAGE = 3\n",
      "    CAP_INTELPERC_IMAGE_GENERATOR = 268435456\n",
      "    CAP_INTELPERC_IR_GENERATOR = 134217728\n",
      "    CAP_INTELPERC_IR_MAP = 2\n",
      "    CAP_INTELPERC_UVDEPTH_MAP = 1\n",
      "    CAP_INTEL_MFX = 2300\n",
      "    CAP_MSMF = 1400\n",
      "    CAP_OPENCV_MJPEG = 2200\n",
      "    CAP_OPENNI = 900\n",
      "    CAP_OPENNI2 = 1600\n",
      "    CAP_OPENNI2_ASUS = 1610\n",
      "    CAP_OPENNI_ASUS = 910\n",
      "    CAP_OPENNI_BGR_IMAGE = 5\n",
      "    CAP_OPENNI_DEPTH_GENERATOR = -2147483648\n",
      "    CAP_OPENNI_DEPTH_GENERATOR_BASELINE = -2147483546\n",
      "    CAP_OPENNI_DEPTH_GENERATOR_FOCAL_LENGTH = -2147483545\n",
      "    CAP_OPENNI_DEPTH_GENERATOR_PRESENT = -2147483539\n",
      "    CAP_OPENNI_DEPTH_GENERATOR_REGISTRATION = -2147483544\n",
      "    CAP_OPENNI_DEPTH_GENERATOR_REGISTRATION_ON = -2147483544\n",
      "    CAP_OPENNI_DEPTH_MAP = 0\n",
      "    CAP_OPENNI_DISPARITY_MAP = 2\n",
      "    CAP_OPENNI_DISPARITY_MAP_32F = 3\n",
      "    CAP_OPENNI_GENERATORS_MASK = -536870912\n",
      "    CAP_OPENNI_GRAY_IMAGE = 6\n",
      "    CAP_OPENNI_IMAGE_GENERATOR = 1073741824\n",
      "    CAP_OPENNI_IMAGE_GENERATOR_OUTPUT_MODE = 1073741924\n",
      "    CAP_OPENNI_IMAGE_GENERATOR_PRESENT = 1073741933\n",
      "    CAP_OPENNI_IR_GENERATOR = 536870912\n",
      "    CAP_OPENNI_IR_GENERATOR_PRESENT = 536871021\n",
      "    CAP_OPENNI_IR_IMAGE = 7\n",
      "    CAP_OPENNI_POINT_CLOUD_MAP = 1\n",
      "    CAP_OPENNI_QVGA_30HZ = 3\n",
      "    CAP_OPENNI_QVGA_60HZ = 4\n",
      "    CAP_OPENNI_SXGA_15HZ = 1\n",
      "    CAP_OPENNI_SXGA_30HZ = 2\n",
      "    CAP_OPENNI_VALID_DEPTH_MASK = 4\n",
      "    CAP_OPENNI_VGA_30HZ = 0\n",
      "    CAP_PROP_APERTURE = 17008\n",
      "    CAP_PROP_ARAVIS_AUTOTRIGGER = 600\n",
      "    CAP_PROP_AUTOFOCUS = 39\n",
      "    CAP_PROP_AUTO_EXPOSURE = 21\n",
      "    CAP_PROP_AUTO_WB = 44\n",
      "    CAP_PROP_BACKEND = 42\n",
      "    CAP_PROP_BACKLIGHT = 32\n",
      "    CAP_PROP_BITRATE = 47\n",
      "    CAP_PROP_BRIGHTNESS = 10\n",
      "    CAP_PROP_BUFFERSIZE = 38\n",
      "    CAP_PROP_CHANNEL = 43\n",
      "    CAP_PROP_CODEC_PIXEL_FORMAT = 46\n",
      "    CAP_PROP_CONTRAST = 11\n",
      "    CAP_PROP_CONVERT_RGB = 16\n",
      "    CAP_PROP_DC1394_MAX = 31\n",
      "    CAP_PROP_DC1394_MODE_AUTO = -2\n",
      "    CAP_PROP_DC1394_MODE_MANUAL = -3\n",
      "    CAP_PROP_DC1394_MODE_ONE_PUSH_AUTO = -1\n",
      "    CAP_PROP_DC1394_OFF = -4\n",
      "    CAP_PROP_EXPOSURE = 15\n",
      "    CAP_PROP_EXPOSUREPROGRAM = 17009\n",
      "    CAP_PROP_FOCUS = 28\n",
      "    CAP_PROP_FORMAT = 8\n",
      "    CAP_PROP_FOURCC = 6\n",
      "    CAP_PROP_FPS = 5\n",
      "    CAP_PROP_FRAME_COUNT = 7\n",
      "    CAP_PROP_FRAME_HEIGHT = 4\n",
      "    CAP_PROP_FRAME_WIDTH = 3\n",
      "    CAP_PROP_GAIN = 14\n",
      "    CAP_PROP_GAMMA = 22\n",
      "    CAP_PROP_GIGA_FRAME_HEIGH_MAX = 10004\n",
      "    CAP_PROP_GIGA_FRAME_OFFSET_X = 10001\n",
      "    CAP_PROP_GIGA_FRAME_OFFSET_Y = 10002\n",
      "    CAP_PROP_GIGA_FRAME_SENS_HEIGH = 10006\n",
      "    CAP_PROP_GIGA_FRAME_SENS_WIDTH = 10005\n",
      "    CAP_PROP_GIGA_FRAME_WIDTH_MAX = 10003\n",
      "    CAP_PROP_GPHOTO2_COLLECT_MSGS = 17005\n",
      "    CAP_PROP_GPHOTO2_FLUSH_MSGS = 17006\n",
      "    CAP_PROP_GPHOTO2_PREVIEW = 17001\n",
      "    CAP_PROP_GPHOTO2_RELOAD_CONFIG = 17003\n",
      "    CAP_PROP_GPHOTO2_RELOAD_ON_CHANGE = 17004\n",
      "    CAP_PROP_GPHOTO2_WIDGET_ENUMERATE = 17002\n",
      "    CAP_PROP_GSTREAMER_QUEUE_LENGTH = 200\n",
      "    CAP_PROP_GUID = 29\n",
      "    CAP_PROP_HUE = 13\n",
      "    CAP_PROP_IMAGES_BASE = 18000\n",
      "    CAP_PROP_IMAGES_LAST = 19000\n",
      "    CAP_PROP_INTELPERC_DEPTH_CONFIDENCE_THRESHOLD = 11005\n",
      "    CAP_PROP_INTELPERC_DEPTH_FOCAL_LENGTH_HORZ = 11006\n",
      "    CAP_PROP_INTELPERC_DEPTH_FOCAL_LENGTH_VERT = 11007\n",
      "    CAP_PROP_INTELPERC_DEPTH_LOW_CONFIDENCE_VALUE = 11003\n",
      "    CAP_PROP_INTELPERC_DEPTH_SATURATION_VALUE = 11004\n",
      "    CAP_PROP_INTELPERC_PROFILE_COUNT = 11001\n",
      "    CAP_PROP_INTELPERC_PROFILE_IDX = 11002\n",
      "    CAP_PROP_IOS_DEVICE_EXPOSURE = 9002\n",
      "    CAP_PROP_IOS_DEVICE_FLASH = 9003\n",
      "    CAP_PROP_IOS_DEVICE_FOCUS = 9001\n",
      "    CAP_PROP_IOS_DEVICE_TORCH = 9005\n",
      "    CAP_PROP_IOS_DEVICE_WHITEBALANCE = 9004\n",
      "    CAP_PROP_IRIS = 36\n",
      "    CAP_PROP_ISO_SPEED = 30\n",
      "    CAP_PROP_MODE = 9\n",
      "    CAP_PROP_MONOCHROME = 19\n",
      "    CAP_PROP_OPENNI2_MIRROR = 111\n",
      "    CAP_PROP_OPENNI2_SYNC = 110\n",
      "    CAP_PROP_OPENNI_APPROX_FRAME_SYNC = 105\n",
      "    CAP_PROP_OPENNI_BASELINE = 102\n",
      "    CAP_PROP_OPENNI_CIRCLE_BUFFER = 107\n",
      "    CAP_PROP_OPENNI_FOCAL_LENGTH = 103\n",
      "    CAP_PROP_OPENNI_FRAME_MAX_DEPTH = 101\n",
      "    CAP_PROP_OPENNI_GENERATOR_PRESENT = 109\n",
      "    CAP_PROP_OPENNI_MAX_BUFFER_SIZE = 106\n",
      "    CAP_PROP_OPENNI_MAX_TIME_DURATION = 108\n",
      "    CAP_PROP_OPENNI_OUTPUT_MODE = 100\n",
      "    CAP_PROP_OPENNI_REGISTRATION = 104\n",
      "    CAP_PROP_OPENNI_REGISTRATION_ON = 104\n",
      "    CAP_PROP_PAN = 33\n",
      "    CAP_PROP_POS_AVI_RATIO = 2\n",
      "    CAP_PROP_POS_FRAMES = 1\n",
      "    CAP_PROP_POS_MSEC = 0\n",
      "    CAP_PROP_PVAPI_BINNINGX = 304\n",
      "    CAP_PROP_PVAPI_BINNINGY = 305\n",
      "    CAP_PROP_PVAPI_DECIMATIONHORIZONTAL = 302\n",
      "    CAP_PROP_PVAPI_DECIMATIONVERTICAL = 303\n",
      "    CAP_PROP_PVAPI_FRAMESTARTTRIGGERMODE = 301\n",
      "    CAP_PROP_PVAPI_MULTICASTIP = 300\n",
      "    CAP_PROP_PVAPI_PIXELFORMAT = 306\n",
      "    CAP_PROP_RECTIFICATION = 18\n",
      "    CAP_PROP_ROLL = 35\n",
      "    CAP_PROP_SAR_DEN = 41\n",
      "    CAP_PROP_SAR_NUM = 40\n",
      "    CAP_PROP_SATURATION = 12\n",
      "    CAP_PROP_SETTINGS = 37\n",
      "    CAP_PROP_SHARPNESS = 20\n",
      "    CAP_PROP_SPEED = 17007\n",
      "    CAP_PROP_TEMPERATURE = 23\n",
      "    CAP_PROP_TILT = 34\n",
      "    CAP_PROP_TRIGGER = 24\n",
      "    CAP_PROP_TRIGGER_DELAY = 25\n",
      "    CAP_PROP_VIEWFINDER = 17010\n",
      "    CAP_PROP_WB_TEMPERATURE = 45\n",
      "    CAP_PROP_WHITE_BALANCE_BLUE_U = 17\n",
      "    CAP_PROP_WHITE_BALANCE_RED_V = 26\n",
      "    CAP_PROP_XI_ACQ_BUFFER_SIZE = 548\n",
      "    CAP_PROP_XI_ACQ_BUFFER_SIZE_UNIT = 549\n",
      "    CAP_PROP_XI_ACQ_FRAME_BURST_COUNT = 499\n",
      "    CAP_PROP_XI_ACQ_TIMING_MODE = 538\n",
      "    CAP_PROP_XI_ACQ_TRANSPORT_BUFFER_COMMIT = 552\n",
      "    CAP_PROP_XI_ACQ_TRANSPORT_BUFFER_SIZE = 550\n",
      "    CAP_PROP_XI_AEAG = 415\n",
      "    CAP_PROP_XI_AEAG_LEVEL = 419\n",
      "    CAP_PROP_XI_AEAG_ROI_HEIGHT = 442\n",
      "    CAP_PROP_XI_AEAG_ROI_OFFSET_X = 439\n",
      "    CAP_PROP_XI_AEAG_ROI_OFFSET_Y = 440\n",
      "    CAP_PROP_XI_AEAG_ROI_WIDTH = 441\n",
      "    CAP_PROP_XI_AE_MAX_LIMIT = 417\n",
      "    CAP_PROP_XI_AG_MAX_LIMIT = 418\n",
      "    CAP_PROP_XI_APPLY_CMS = 471\n",
      "    CAP_PROP_XI_AUTO_BANDWIDTH_CALCULATION = 573\n",
      "    CAP_PROP_XI_AUTO_WB = 414\n",
      "    CAP_PROP_XI_AVAILABLE_BANDWIDTH = 539\n",
      "    CAP_PROP_XI_BINNING_HORIZONTAL = 429\n",
      "    CAP_PROP_XI_BINNING_PATTERN = 430\n",
      "    CAP_PROP_XI_BINNING_SELECTOR = 427\n",
      "    CAP_PROP_XI_BINNING_VERTICAL = 428\n",
      "    CAP_PROP_XI_BPC = 445\n",
      "    CAP_PROP_XI_BUFFERS_QUEUE_SIZE = 551\n",
      "    CAP_PROP_XI_BUFFER_POLICY = 540\n",
      "    CAP_PROP_XI_CC_MATRIX_00 = 479\n",
      "    CAP_PROP_XI_CC_MATRIX_01 = 480\n",
      "    CAP_PROP_XI_CC_MATRIX_02 = 481\n",
      "    CAP_PROP_XI_CC_MATRIX_03 = 482\n",
      "    CAP_PROP_XI_CC_MATRIX_10 = 483\n",
      "    CAP_PROP_XI_CC_MATRIX_11 = 484\n",
      "    CAP_PROP_XI_CC_MATRIX_12 = 485\n",
      "    CAP_PROP_XI_CC_MATRIX_13 = 486\n",
      "    CAP_PROP_XI_CC_MATRIX_20 = 487\n",
      "    CAP_PROP_XI_CC_MATRIX_21 = 488\n",
      "    CAP_PROP_XI_CC_MATRIX_22 = 489\n",
      "    CAP_PROP_XI_CC_MATRIX_23 = 490\n",
      "    CAP_PROP_XI_CC_MATRIX_30 = 491\n",
      "    CAP_PROP_XI_CC_MATRIX_31 = 492\n",
      "    CAP_PROP_XI_CC_MATRIX_32 = 493\n",
      "    CAP_PROP_XI_CC_MATRIX_33 = 494\n",
      "    CAP_PROP_XI_CHIP_TEMP = 468\n",
      "    CAP_PROP_XI_CMS = 470\n",
      "    CAP_PROP_XI_COLOR_FILTER_ARRAY = 475\n",
      "    CAP_PROP_XI_COLUMN_FPN_CORRECTION = 555\n",
      "    CAP_PROP_XI_COOLING = 466\n",
      "    CAP_PROP_XI_COUNTER_SELECTOR = 536\n",
      "    CAP_PROP_XI_COUNTER_VALUE = 537\n",
      "    CAP_PROP_XI_DATA_FORMAT = 401\n",
      "    CAP_PROP_XI_DEBOUNCE_EN = 507\n",
      "    CAP_PROP_XI_DEBOUNCE_POL = 510\n",
      "    CAP_PROP_XI_DEBOUNCE_T0 = 508\n",
      "    CAP_PROP_XI_DEBOUNCE_T1 = 509\n",
      "    CAP_PROP_XI_DEBUG_LEVEL = 572\n",
      "    CAP_PROP_XI_DECIMATION_HORIZONTAL = 433\n",
      "    CAP_PROP_XI_DECIMATION_PATTERN = 434\n",
      "    CAP_PROP_XI_DECIMATION_SELECTOR = 431\n",
      "    CAP_PROP_XI_DECIMATION_VERTICAL = 432\n",
      "    CAP_PROP_XI_DEFAULT_CC_MATRIX = 495\n",
      "    CAP_PROP_XI_DEVICE_MODEL_ID = 521\n",
      "    CAP_PROP_XI_DEVICE_RESET = 554\n",
      "    CAP_PROP_XI_DEVICE_SN = 522\n",
      "    CAP_PROP_XI_DOWNSAMPLING = 400\n",
      "    CAP_PROP_XI_DOWNSAMPLING_TYPE = 426\n",
      "    CAP_PROP_XI_EXPOSURE = 421\n",
      "    CAP_PROP_XI_EXPOSURE_BURST_COUNT = 422\n",
      "    CAP_PROP_XI_EXP_PRIORITY = 416\n",
      "    CAP_PROP_XI_FFS_ACCESS_KEY = 583\n",
      "    CAP_PROP_XI_FFS_FILE_ID = 594\n",
      "    CAP_PROP_XI_FFS_FILE_SIZE = 580\n",
      "    CAP_PROP_XI_FRAMERATE = 535\n",
      "    CAP_PROP_XI_FREE_FFS_SIZE = 581\n",
      "    CAP_PROP_XI_GAIN = 424\n",
      "    CAP_PROP_XI_GAIN_SELECTOR = 423\n",
      "    CAP_PROP_XI_GAMMAC = 477\n",
      "    CAP_PROP_XI_GAMMAY = 476\n",
      "    CAP_PROP_XI_GPI_LEVEL = 408\n",
      "    CAP_PROP_XI_GPI_MODE = 407\n",
      "    CAP_PROP_XI_GPI_SELECTOR = 406\n",
      "    CAP_PROP_XI_GPO_MODE = 410\n",
      "    CAP_PROP_XI_GPO_SELECTOR = 409\n",
      "    CAP_PROP_XI_HDR = 559\n",
      "    CAP_PROP_XI_HDR_KNEEPOINT_COUNT = 560\n",
      "    CAP_PROP_XI_HDR_T1 = 561\n",
      "    CAP_PROP_XI_HDR_T2 = 562\n",
      "    CAP_PROP_XI_HEIGHT = 452\n",
      "    CAP_PROP_XI_HOUS_BACK_SIDE_TEMP = 590\n",
      "    CAP_PROP_XI_HOUS_TEMP = 469\n",
      "    CAP_PROP_XI_HW_REVISION = 571\n",
      "    CAP_PROP_XI_IMAGE_BLACK_LEVEL = 565\n",
      "    CAP_PROP_XI_IMAGE_DATA_BIT_DEPTH = 462\n",
      "    CAP_PROP_XI_IMAGE_DATA_FORMAT = 435\n",
      "    CAP_PROP_XI_IMAGE_DATA_FORMAT_RGB32_ALPHA = 529\n",
      "    CAP_PROP_XI_IMAGE_IS_COLOR = 474\n",
      "    CAP_PROP_XI_IMAGE_PAYLOAD_SIZE = 530\n",
      "    CAP_PROP_XI_IS_COOLED = 465\n",
      "    CAP_PROP_XI_IS_DEVICE_EXIST = 547\n",
      "    CAP_PROP_XI_KNEEPOINT1 = 563\n",
      "    CAP_PROP_XI_KNEEPOINT2 = 564\n",
      "    CAP_PROP_XI_LED_MODE = 412\n",
      "    CAP_PROP_XI_LED_SELECTOR = 411\n",
      "    CAP_PROP_XI_LENS_APERTURE_VALUE = 512\n",
      "    CAP_PROP_XI_LENS_FEATURE = 518\n",
      "    CAP_PROP_XI_LENS_FEATURE_SELECTOR = 517\n",
      "    CAP_PROP_XI_LENS_FOCAL_LENGTH = 516\n",
      "    CAP_PROP_XI_LENS_FOCUS_DISTANCE = 515\n",
      "    CAP_PROP_XI_LENS_FOCUS_MOVE = 514\n",
      "    CAP_PROP_XI_LENS_FOCUS_MOVEMENT_VALUE = 513\n",
      "    CAP_PROP_XI_LENS_MODE = 511\n",
      "    CAP_PROP_XI_LIMIT_BANDWIDTH = 459\n",
      "    CAP_PROP_XI_LUT_EN = 541\n",
      "    CAP_PROP_XI_LUT_INDEX = 542\n",
      "    CAP_PROP_XI_LUT_VALUE = 543\n",
      "    CAP_PROP_XI_MANUAL_WB = 413\n",
      "    CAP_PROP_XI_OFFSET_X = 402\n",
      "    CAP_PROP_XI_OFFSET_Y = 403\n",
      "    CAP_PROP_XI_OUTPUT_DATA_BIT_DEPTH = 461\n",
      "    CAP_PROP_XI_OUTPUT_DATA_PACKING = 463\n",
      "    CAP_PROP_XI_OUTPUT_DATA_PACKING_TYPE = 464\n",
      "    CAP_PROP_XI_RECENT_FRAME = 553\n",
      "    CAP_PROP_XI_REGION_MODE = 595\n",
      "    CAP_PROP_XI_REGION_SELECTOR = 589\n",
      "    CAP_PROP_XI_ROW_FPN_CORRECTION = 591\n",
      "    CAP_PROP_XI_SENSOR_BOARD_TEMP = 596\n",
      "    CAP_PROP_XI_SENSOR_CLOCK_FREQ_HZ = 532\n",
      "    CAP_PROP_XI_SENSOR_CLOCK_FREQ_INDEX = 533\n",
      "    CAP_PROP_XI_SENSOR_DATA_BIT_DEPTH = 460\n",
      "    CAP_PROP_XI_SENSOR_FEATURE_SELECTOR = 585\n",
      "    CAP_PROP_XI_SENSOR_FEATURE_VALUE = 586\n",
      "    CAP_PROP_XI_SENSOR_MODE = 558\n",
      "    CAP_PROP_XI_SENSOR_OUTPUT_CHANNEL_COUNT = 534\n",
      "    CAP_PROP_XI_SENSOR_TAPS = 437\n",
      "    CAP_PROP_XI_SHARPNESS = 478\n",
      "    CAP_PROP_XI_SHUTTER_TYPE = 436\n",
      "    CAP_PROP_XI_TARGET_TEMP = 467\n",
      "    CAP_PROP_XI_TEST_PATTERN = 588\n",
      "    CAP_PROP_XI_TEST_PATTERN_GENERATOR_SELECTOR = 587\n",
      "    CAP_PROP_XI_TIMEOUT = 420\n",
      "    CAP_PROP_XI_TRANSPORT_PIXEL_FORMAT = 531\n",
      "    CAP_PROP_XI_TRG_DELAY = 544\n",
      "    CAP_PROP_XI_TRG_SELECTOR = 498\n",
      "    CAP_PROP_XI_TRG_SOFTWARE = 405\n",
      "    CAP_PROP_XI_TRG_SOURCE = 404\n",
      "    CAP_PROP_XI_TS_RST_MODE = 545\n",
      "    CAP_PROP_XI_TS_RST_SOURCE = 546\n",
      "    CAP_PROP_XI_USED_FFS_SIZE = 582\n",
      "    CAP_PROP_XI_WB_KB = 450\n",
      "    CAP_PROP_XI_WB_KG = 449\n",
      "    CAP_PROP_XI_WB_KR = 448\n",
      "    CAP_PROP_XI_WIDTH = 451\n",
      "    CAP_PROP_ZOOM = 27\n",
      "    CAP_PVAPI = 800\n",
      "    CAP_PVAPI_DECIMATION_2OUTOF16 = 8\n",
      "    CAP_PVAPI_DECIMATION_2OUTOF4 = 2\n",
      "    CAP_PVAPI_DECIMATION_2OUTOF8 = 4\n",
      "    CAP_PVAPI_DECIMATION_OFF = 1\n",
      "    CAP_PVAPI_FSTRIGMODE_FIXEDRATE = 3\n",
      "    CAP_PVAPI_FSTRIGMODE_FREERUN = 0\n",
      "    CAP_PVAPI_FSTRIGMODE_SOFTWARE = 4\n",
      "    CAP_PVAPI_FSTRIGMODE_SYNCIN1 = 1\n",
      "    CAP_PVAPI_FSTRIGMODE_SYNCIN2 = 2\n",
      "    CAP_PVAPI_PIXELFORMAT_BAYER16 = 4\n",
      "    CAP_PVAPI_PIXELFORMAT_BAYER8 = 3\n",
      "    CAP_PVAPI_PIXELFORMAT_BGR24 = 6\n",
      "    CAP_PVAPI_PIXELFORMAT_BGRA32 = 8\n",
      "    CAP_PVAPI_PIXELFORMAT_MONO16 = 2\n",
      "    CAP_PVAPI_PIXELFORMAT_MONO8 = 1\n",
      "    CAP_PVAPI_PIXELFORMAT_RGB24 = 5\n",
      "    CAP_PVAPI_PIXELFORMAT_RGBA32 = 7\n",
      "    CAP_QT = 500\n",
      "    CAP_REALSENSE = 1500\n",
      "    CAP_UNICAP = 600\n",
      "    CAP_V4L = 200\n",
      "    CAP_V4L2 = 200\n",
      "    CAP_VFW = 200\n",
      "    CAP_WINRT = 1410\n",
      "    CAP_XIAPI = 1100\n",
      "    CAP_XINE = 2400\n",
      "    CASCADE_DO_CANNY_PRUNING = 1\n",
      "    CASCADE_DO_ROUGH_SEARCH = 8\n",
      "    CASCADE_FIND_BIGGEST_OBJECT = 4\n",
      "    CASCADE_SCALE_IMAGE = 2\n",
      "    CCL_DEFAULT = -1\n",
      "    CCL_GRANA = 1\n",
      "    CCL_WU = 0\n",
      "    CC_STAT_AREA = 4\n",
      "    CC_STAT_HEIGHT = 3\n",
      "    CC_STAT_LEFT = 0\n",
      "    CC_STAT_MAX = 5\n",
      "    CC_STAT_TOP = 1\n",
      "    CC_STAT_WIDTH = 2\n",
      "    CHAIN_APPROX_NONE = 1\n",
      "    CHAIN_APPROX_SIMPLE = 2\n",
      "    CHAIN_APPROX_TC89_KCOS = 4\n",
      "    CHAIN_APPROX_TC89_L1 = 3\n",
      "    CIRCLES_GRID_FINDER_PARAMETERS_ASYMMETRIC_GRID = 1\n",
      "    CIRCLES_GRID_FINDER_PARAMETERS_SYMMETRIC_GRID = 0\n",
      "    CMP_EQ = 0\n",
      "    CMP_GE = 2\n",
      "    CMP_GT = 1\n",
      "    CMP_LE = 4\n",
      "    CMP_LT = 3\n",
      "    CMP_NE = 5\n",
      "    COLORMAP_AUTUMN = 0\n",
      "    COLORMAP_BONE = 1\n",
      "    COLORMAP_CIVIDIS = 17\n",
      "    COLORMAP_COOL = 8\n",
      "    COLORMAP_DEEPGREEN = 21\n",
      "    COLORMAP_HOT = 11\n",
      "    COLORMAP_HSV = 9\n",
      "    COLORMAP_INFERNO = 14\n",
      "    COLORMAP_JET = 2\n",
      "    COLORMAP_MAGMA = 13\n",
      "    COLORMAP_OCEAN = 5\n",
      "    COLORMAP_PARULA = 12\n",
      "    COLORMAP_PINK = 10\n",
      "    COLORMAP_PLASMA = 15\n",
      "    COLORMAP_RAINBOW = 4\n",
      "    COLORMAP_SPRING = 7\n",
      "    COLORMAP_SUMMER = 6\n",
      "    COLORMAP_TURBO = 20\n",
      "    COLORMAP_TWILIGHT = 18\n",
      "    COLORMAP_TWILIGHT_SHIFTED = 19\n",
      "    COLORMAP_VIRIDIS = 16\n",
      "    COLORMAP_WINTER = 3\n",
      "    COLOR_BAYER_BG2BGR = 46\n",
      "    COLOR_BAYER_BG2BGRA = 139\n",
      "    COLOR_BAYER_BG2BGR_EA = 135\n",
      "    COLOR_BAYER_BG2BGR_VNG = 62\n",
      "    COLOR_BAYER_BG2GRAY = 86\n",
      "    COLOR_BAYER_BG2RGB = 48\n",
      "    COLOR_BAYER_BG2RGBA = 141\n",
      "    COLOR_BAYER_BG2RGB_EA = 137\n",
      "    COLOR_BAYER_BG2RGB_VNG = 64\n",
      "    COLOR_BAYER_GB2BGR = 47\n",
      "    COLOR_BAYER_GB2BGRA = 140\n",
      "    COLOR_BAYER_GB2BGR_EA = 136\n",
      "    COLOR_BAYER_GB2BGR_VNG = 63\n",
      "    COLOR_BAYER_GB2GRAY = 87\n",
      "    COLOR_BAYER_GB2RGB = 49\n",
      "    COLOR_BAYER_GB2RGBA = 142\n",
      "    COLOR_BAYER_GB2RGB_EA = 138\n",
      "    COLOR_BAYER_GB2RGB_VNG = 65\n",
      "    COLOR_BAYER_GR2BGR = 49\n",
      "    COLOR_BAYER_GR2BGRA = 142\n",
      "    COLOR_BAYER_GR2BGR_EA = 138\n",
      "    COLOR_BAYER_GR2BGR_VNG = 65\n",
      "    COLOR_BAYER_GR2GRAY = 89\n",
      "    COLOR_BAYER_GR2RGB = 47\n",
      "    COLOR_BAYER_GR2RGBA = 140\n",
      "    COLOR_BAYER_GR2RGB_EA = 136\n",
      "    COLOR_BAYER_GR2RGB_VNG = 63\n",
      "    COLOR_BAYER_RG2BGR = 48\n",
      "    COLOR_BAYER_RG2BGRA = 141\n",
      "    COLOR_BAYER_RG2BGR_EA = 137\n",
      "    COLOR_BAYER_RG2BGR_VNG = 64\n",
      "    COLOR_BAYER_RG2GRAY = 88\n",
      "    COLOR_BAYER_RG2RGB = 46\n",
      "    COLOR_BAYER_RG2RGBA = 139\n",
      "    COLOR_BAYER_RG2RGB_EA = 135\n",
      "    COLOR_BAYER_RG2RGB_VNG = 62\n",
      "    COLOR_BGR2BGR555 = 22\n",
      "    COLOR_BGR2BGR565 = 12\n",
      "    COLOR_BGR2BGRA = 0\n",
      "    COLOR_BGR2GRAY = 6\n",
      "    COLOR_BGR2HLS = 52\n",
      "    COLOR_BGR2HLS_FULL = 68\n",
      "    COLOR_BGR2HSV = 40\n",
      "    COLOR_BGR2HSV_FULL = 66\n",
      "    COLOR_BGR2LAB = 44\n",
      "    COLOR_BGR2LUV = 50\n",
      "    COLOR_BGR2Lab = 44\n",
      "    COLOR_BGR2Luv = 50\n",
      "    COLOR_BGR2RGB = 4\n",
      "    COLOR_BGR2RGBA = 2\n",
      "    COLOR_BGR2XYZ = 32\n",
      "    COLOR_BGR2YCR_CB = 36\n",
      "    COLOR_BGR2YCrCb = 36\n",
      "    COLOR_BGR2YUV = 82\n",
      "    COLOR_BGR2YUV_I420 = 128\n",
      "    COLOR_BGR2YUV_IYUV = 128\n",
      "    COLOR_BGR2YUV_YV12 = 132\n",
      "    COLOR_BGR5552BGR = 24\n",
      "    COLOR_BGR5552BGRA = 28\n",
      "    COLOR_BGR5552GRAY = 31\n",
      "    COLOR_BGR5552RGB = 25\n",
      "    COLOR_BGR5552RGBA = 29\n",
      "    COLOR_BGR5652BGR = 14\n",
      "    COLOR_BGR5652BGRA = 18\n",
      "    COLOR_BGR5652GRAY = 21\n",
      "    COLOR_BGR5652RGB = 15\n",
      "    COLOR_BGR5652RGBA = 19\n",
      "    COLOR_BGRA2BGR = 1\n",
      "    COLOR_BGRA2BGR555 = 26\n",
      "    COLOR_BGRA2BGR565 = 16\n",
      "    COLOR_BGRA2GRAY = 10\n",
      "    COLOR_BGRA2RGB = 3\n",
      "    COLOR_BGRA2RGBA = 5\n",
      "    COLOR_BGRA2YUV_I420 = 130\n",
      "    COLOR_BGRA2YUV_IYUV = 130\n",
      "    COLOR_BGRA2YUV_YV12 = 134\n",
      "    COLOR_BayerBG2BGR = 46\n",
      "    COLOR_BayerBG2BGRA = 139\n",
      "    COLOR_BayerBG2BGR_EA = 135\n",
      "    COLOR_BayerBG2BGR_VNG = 62\n",
      "    COLOR_BayerBG2GRAY = 86\n",
      "    COLOR_BayerBG2RGB = 48\n",
      "    COLOR_BayerBG2RGBA = 141\n",
      "    COLOR_BayerBG2RGB_EA = 137\n",
      "    COLOR_BayerBG2RGB_VNG = 64\n",
      "    COLOR_BayerGB2BGR = 47\n",
      "    COLOR_BayerGB2BGRA = 140\n",
      "    COLOR_BayerGB2BGR_EA = 136\n",
      "    COLOR_BayerGB2BGR_VNG = 63\n",
      "    COLOR_BayerGB2GRAY = 87\n",
      "    COLOR_BayerGB2RGB = 49\n",
      "    COLOR_BayerGB2RGBA = 142\n",
      "    COLOR_BayerGB2RGB_EA = 138\n",
      "    COLOR_BayerGB2RGB_VNG = 65\n",
      "    COLOR_BayerGR2BGR = 49\n",
      "    COLOR_BayerGR2BGRA = 142\n",
      "    COLOR_BayerGR2BGR_EA = 138\n",
      "    COLOR_BayerGR2BGR_VNG = 65\n",
      "    COLOR_BayerGR2GRAY = 89\n",
      "    COLOR_BayerGR2RGB = 47\n",
      "    COLOR_BayerGR2RGBA = 140\n",
      "    COLOR_BayerGR2RGB_EA = 136\n",
      "    COLOR_BayerGR2RGB_VNG = 63\n",
      "    COLOR_BayerRG2BGR = 48\n",
      "    COLOR_BayerRG2BGRA = 141\n",
      "    COLOR_BayerRG2BGR_EA = 137\n",
      "    COLOR_BayerRG2BGR_VNG = 64\n",
      "    COLOR_BayerRG2GRAY = 88\n",
      "    COLOR_BayerRG2RGB = 46\n",
      "    COLOR_BayerRG2RGBA = 139\n",
      "    COLOR_BayerRG2RGB_EA = 135\n",
      "    COLOR_BayerRG2RGB_VNG = 62\n",
      "    COLOR_COLORCVT_MAX = 143\n",
      "    COLOR_GRAY2BGR = 8\n",
      "    COLOR_GRAY2BGR555 = 30\n",
      "    COLOR_GRAY2BGR565 = 20\n",
      "    COLOR_GRAY2BGRA = 9\n",
      "    COLOR_GRAY2RGB = 8\n",
      "    COLOR_GRAY2RGBA = 9\n",
      "    COLOR_HLS2BGR = 60\n",
      "    COLOR_HLS2BGR_FULL = 72\n",
      "    COLOR_HLS2RGB = 61\n",
      "    COLOR_HLS2RGB_FULL = 73\n",
      "    COLOR_HSV2BGR = 54\n",
      "    COLOR_HSV2BGR_FULL = 70\n",
      "    COLOR_HSV2RGB = 55\n",
      "    COLOR_HSV2RGB_FULL = 71\n",
      "    COLOR_LAB2BGR = 56\n",
      "    COLOR_LAB2LBGR = 78\n",
      "    COLOR_LAB2LRGB = 79\n",
      "    COLOR_LAB2RGB = 57\n",
      "    COLOR_LBGR2LAB = 74\n",
      "    COLOR_LBGR2LUV = 76\n",
      "    COLOR_LBGR2Lab = 74\n",
      "    COLOR_LBGR2Luv = 76\n",
      "    COLOR_LRGB2LAB = 75\n",
      "    COLOR_LRGB2LUV = 77\n",
      "    COLOR_LRGB2Lab = 75\n",
      "    COLOR_LRGB2Luv = 77\n",
      "    COLOR_LUV2BGR = 58\n",
      "    COLOR_LUV2LBGR = 80\n",
      "    COLOR_LUV2LRGB = 81\n",
      "    COLOR_LUV2RGB = 59\n",
      "    COLOR_Lab2BGR = 56\n",
      "    COLOR_Lab2LBGR = 78\n",
      "    COLOR_Lab2LRGB = 79\n",
      "    COLOR_Lab2RGB = 57\n",
      "    COLOR_Luv2BGR = 58\n",
      "    COLOR_Luv2LBGR = 80\n",
      "    COLOR_Luv2LRGB = 81\n",
      "    COLOR_Luv2RGB = 59\n",
      "    COLOR_M_RGBA2RGBA = 126\n",
      "    COLOR_RGB2BGR = 4\n",
      "    COLOR_RGB2BGR555 = 23\n",
      "    COLOR_RGB2BGR565 = 13\n",
      "    COLOR_RGB2BGRA = 2\n",
      "    COLOR_RGB2GRAY = 7\n",
      "    COLOR_RGB2HLS = 53\n",
      "    COLOR_RGB2HLS_FULL = 69\n",
      "    COLOR_RGB2HSV = 41\n",
      "    COLOR_RGB2HSV_FULL = 67\n",
      "    COLOR_RGB2LAB = 45\n",
      "    COLOR_RGB2LUV = 51\n",
      "    COLOR_RGB2Lab = 45\n",
      "    COLOR_RGB2Luv = 51\n",
      "    COLOR_RGB2RGBA = 0\n",
      "    COLOR_RGB2XYZ = 33\n",
      "    COLOR_RGB2YCR_CB = 37\n",
      "    COLOR_RGB2YCrCb = 37\n",
      "    COLOR_RGB2YUV = 83\n",
      "    COLOR_RGB2YUV_I420 = 127\n",
      "    COLOR_RGB2YUV_IYUV = 127\n",
      "    COLOR_RGB2YUV_YV12 = 131\n",
      "    COLOR_RGBA2BGR = 3\n",
      "    COLOR_RGBA2BGR555 = 27\n",
      "    COLOR_RGBA2BGR565 = 17\n",
      "    COLOR_RGBA2BGRA = 5\n",
      "    COLOR_RGBA2GRAY = 11\n",
      "    COLOR_RGBA2M_RGBA = 125\n",
      "    COLOR_RGBA2RGB = 1\n",
      "    COLOR_RGBA2YUV_I420 = 129\n",
      "    COLOR_RGBA2YUV_IYUV = 129\n",
      "    COLOR_RGBA2YUV_YV12 = 133\n",
      "    COLOR_RGBA2mRGBA = 125\n",
      "    COLOR_XYZ2BGR = 34\n",
      "    COLOR_XYZ2RGB = 35\n",
      "    COLOR_YCR_CB2BGR = 38\n",
      "    COLOR_YCR_CB2RGB = 39\n",
      "    COLOR_YCrCb2BGR = 38\n",
      "    COLOR_YCrCb2RGB = 39\n",
      "    COLOR_YUV2BGR = 84\n",
      "    COLOR_YUV2BGRA_I420 = 105\n",
      "    COLOR_YUV2BGRA_IYUV = 105\n",
      "    COLOR_YUV2BGRA_NV12 = 95\n",
      "    COLOR_YUV2BGRA_NV21 = 97\n",
      "    COLOR_YUV2BGRA_UYNV = 112\n",
      "    COLOR_YUV2BGRA_UYVY = 112\n",
      "    COLOR_YUV2BGRA_Y422 = 112\n",
      "    COLOR_YUV2BGRA_YUNV = 120\n",
      "    COLOR_YUV2BGRA_YUY2 = 120\n",
      "    COLOR_YUV2BGRA_YUYV = 120\n",
      "    COLOR_YUV2BGRA_YV12 = 103\n",
      "    COLOR_YUV2BGRA_YVYU = 122\n",
      "    COLOR_YUV2BGR_I420 = 101\n",
      "    COLOR_YUV2BGR_IYUV = 101\n",
      "    COLOR_YUV2BGR_NV12 = 91\n",
      "    COLOR_YUV2BGR_NV21 = 93\n",
      "    COLOR_YUV2BGR_UYNV = 108\n",
      "    COLOR_YUV2BGR_UYVY = 108\n",
      "    COLOR_YUV2BGR_Y422 = 108\n",
      "    COLOR_YUV2BGR_YUNV = 116\n",
      "    COLOR_YUV2BGR_YUY2 = 116\n",
      "    COLOR_YUV2BGR_YUYV = 116\n",
      "    COLOR_YUV2BGR_YV12 = 99\n",
      "    COLOR_YUV2BGR_YVYU = 118\n",
      "    COLOR_YUV2GRAY_420 = 106\n",
      "    COLOR_YUV2GRAY_I420 = 106\n",
      "    COLOR_YUV2GRAY_IYUV = 106\n",
      "    COLOR_YUV2GRAY_NV12 = 106\n",
      "    COLOR_YUV2GRAY_NV21 = 106\n",
      "    COLOR_YUV2GRAY_UYNV = 123\n",
      "    COLOR_YUV2GRAY_UYVY = 123\n",
      "    COLOR_YUV2GRAY_Y422 = 123\n",
      "    COLOR_YUV2GRAY_YUNV = 124\n",
      "    COLOR_YUV2GRAY_YUY2 = 124\n",
      "    COLOR_YUV2GRAY_YUYV = 124\n",
      "    COLOR_YUV2GRAY_YV12 = 106\n",
      "    COLOR_YUV2GRAY_YVYU = 124\n",
      "    COLOR_YUV2RGB = 85\n",
      "    COLOR_YUV2RGBA_I420 = 104\n",
      "    COLOR_YUV2RGBA_IYUV = 104\n",
      "    COLOR_YUV2RGBA_NV12 = 94\n",
      "    COLOR_YUV2RGBA_NV21 = 96\n",
      "    COLOR_YUV2RGBA_UYNV = 111\n",
      "    COLOR_YUV2RGBA_UYVY = 111\n",
      "    COLOR_YUV2RGBA_Y422 = 111\n",
      "    COLOR_YUV2RGBA_YUNV = 119\n",
      "    COLOR_YUV2RGBA_YUY2 = 119\n",
      "    COLOR_YUV2RGBA_YUYV = 119\n",
      "    COLOR_YUV2RGBA_YV12 = 102\n",
      "    COLOR_YUV2RGBA_YVYU = 121\n",
      "    COLOR_YUV2RGB_I420 = 100\n",
      "    COLOR_YUV2RGB_IYUV = 100\n",
      "    COLOR_YUV2RGB_NV12 = 90\n",
      "    COLOR_YUV2RGB_NV21 = 92\n",
      "    COLOR_YUV2RGB_UYNV = 107\n",
      "    COLOR_YUV2RGB_UYVY = 107\n",
      "    COLOR_YUV2RGB_Y422 = 107\n",
      "    COLOR_YUV2RGB_YUNV = 115\n",
      "    COLOR_YUV2RGB_YUY2 = 115\n",
      "    COLOR_YUV2RGB_YUYV = 115\n",
      "    COLOR_YUV2RGB_YV12 = 98\n",
      "    COLOR_YUV2RGB_YVYU = 117\n",
      "    COLOR_YUV420P2BGR = 99\n",
      "    COLOR_YUV420P2BGRA = 103\n",
      "    COLOR_YUV420P2GRAY = 106\n",
      "    COLOR_YUV420P2RGB = 98\n",
      "    COLOR_YUV420P2RGBA = 102\n",
      "    COLOR_YUV420SP2BGR = 93\n",
      "    COLOR_YUV420SP2BGRA = 97\n",
      "    COLOR_YUV420SP2GRAY = 106\n",
      "    COLOR_YUV420SP2RGB = 92\n",
      "    COLOR_YUV420SP2RGBA = 96\n",
      "    COLOR_YUV420p2BGR = 99\n",
      "    COLOR_YUV420p2BGRA = 103\n",
      "    COLOR_YUV420p2GRAY = 106\n",
      "    COLOR_YUV420p2RGB = 98\n",
      "    COLOR_YUV420p2RGBA = 102\n",
      "    COLOR_YUV420sp2BGR = 93\n",
      "    COLOR_YUV420sp2BGRA = 97\n",
      "    COLOR_YUV420sp2GRAY = 106\n",
      "    COLOR_YUV420sp2RGB = 92\n",
      "    COLOR_YUV420sp2RGBA = 96\n",
      "    COLOR_mRGBA2RGBA = 126\n",
      "    CONTOURS_MATCH_I1 = 1\n",
      "    CONTOURS_MATCH_I2 = 2\n",
      "    CONTOURS_MATCH_I3 = 3\n",
      "    COVAR_COLS = 16\n",
      "    COVAR_NORMAL = 1\n",
      "    COVAR_ROWS = 8\n",
      "    COVAR_SCALE = 4\n",
      "    COVAR_SCRAMBLED = 0\n",
      "    COVAR_USE_AVG = 2\n",
      "    CV_16S = 3\n",
      "    CV_16SC1 = 3\n",
      "    CV_16SC2 = 11\n",
      "    CV_16SC3 = 19\n",
      "    CV_16SC4 = 27\n",
      "    CV_16U = 2\n",
      "    CV_16UC1 = 2\n",
      "    CV_16UC2 = 10\n",
      "    CV_16UC3 = 18\n",
      "    CV_16UC4 = 26\n",
      "    CV_32F = 5\n",
      "    CV_32FC1 = 5\n",
      "    CV_32FC2 = 13\n",
      "    CV_32FC3 = 21\n",
      "    CV_32FC4 = 29\n",
      "    CV_32S = 4\n",
      "    CV_32SC1 = 4\n",
      "    CV_32SC2 = 12\n",
      "    CV_32SC3 = 20\n",
      "    CV_32SC4 = 28\n",
      "    CV_64F = 6\n",
      "    CV_64FC1 = 6\n",
      "    CV_64FC2 = 14\n",
      "    CV_64FC3 = 22\n",
      "    CV_64FC4 = 30\n",
      "    CV_8S = 1\n",
      "    CV_8SC1 = 1\n",
      "    CV_8SC2 = 9\n",
      "    CV_8SC3 = 17\n",
      "    CV_8SC4 = 25\n",
      "    CV_8U = 0\n",
      "    CV_8UC1 = 0\n",
      "    CV_8UC2 = 8\n",
      "    CV_8UC3 = 16\n",
      "    CV_8UC4 = 24\n",
      "    CirclesGridFinderParameters_ASYMMETRIC_GRID = 1\n",
      "    CirclesGridFinderParameters_SYMMETRIC_GRID = 0\n",
      "    DCT_INVERSE = 1\n",
      "    DCT_ROWS = 4\n",
      "    DECOMP_CHOLESKY = 3\n",
      "    DECOMP_EIG = 2\n",
      "    DECOMP_LU = 0\n",
      "    DECOMP_NORMAL = 16\n",
      "    DECOMP_QR = 4\n",
      "    DECOMP_SVD = 1\n",
      "    DESCRIPTOR_MATCHER_BRUTEFORCE = 2\n",
      "    DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING = 4\n",
      "    DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMINGLUT = 5\n",
      "    DESCRIPTOR_MATCHER_BRUTEFORCE_L1 = 3\n",
      "    DESCRIPTOR_MATCHER_BRUTEFORCE_SL2 = 6\n",
      "    DESCRIPTOR_MATCHER_FLANNBASED = 1\n",
      "    DFT_COMPLEX_INPUT = 64\n",
      "    DFT_COMPLEX_OUTPUT = 16\n",
      "    DFT_INVERSE = 1\n",
      "    DFT_REAL_OUTPUT = 32\n",
      "    DFT_ROWS = 4\n",
      "    DFT_SCALE = 2\n",
      "    DISOPTICAL_FLOW_PRESET_FAST = 1\n",
      "    DISOPTICAL_FLOW_PRESET_MEDIUM = 2\n",
      "    DISOPTICAL_FLOW_PRESET_ULTRAFAST = 0\n",
      "    DISOpticalFlow_PRESET_FAST = 1\n",
      "    DISOpticalFlow_PRESET_MEDIUM = 2\n",
      "    DISOpticalFlow_PRESET_ULTRAFAST = 0\n",
      "    DIST_C = 3\n",
      "    DIST_FAIR = 5\n",
      "    DIST_HUBER = 7\n",
      "    DIST_L1 = 1\n",
      "    DIST_L12 = 4\n",
      "    DIST_L2 = 2\n",
      "    DIST_LABEL_CCOMP = 0\n",
      "    DIST_LABEL_PIXEL = 1\n",
      "    DIST_MASK_3 = 3\n",
      "    DIST_MASK_5 = 5\n",
      "    DIST_MASK_PRECISE = 0\n",
      "    DIST_USER = -1\n",
      "    DIST_WELSCH = 6\n",
      "    DRAW_MATCHES_FLAGS_DEFAULT = 0\n",
      "    DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG = 1\n",
      "    DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS = 4\n",
      "    DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS = 2\n",
      "    DescriptorMatcher_BRUTEFORCE = 2\n",
      "    DescriptorMatcher_BRUTEFORCE_HAMMING = 4\n",
      "    DescriptorMatcher_BRUTEFORCE_HAMMINGLUT = 5\n",
      "    DescriptorMatcher_BRUTEFORCE_L1 = 3\n",
      "    DescriptorMatcher_BRUTEFORCE_SL2 = 6\n",
      "    DescriptorMatcher_FLANNBASED = 1\n",
      "    DrawMatchesFlags_DEFAULT = 0\n",
      "    DrawMatchesFlags_DRAW_OVER_OUTIMG = 1\n",
      "    DrawMatchesFlags_DRAW_RICH_KEYPOINTS = 4\n",
      "    DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS = 2\n",
      "    EVENT_FLAG_ALTKEY = 32\n",
      "    EVENT_FLAG_CTRLKEY = 8\n",
      "    EVENT_FLAG_LBUTTON = 1\n",
      "    EVENT_FLAG_MBUTTON = 4\n",
      "    EVENT_FLAG_RBUTTON = 2\n",
      "    EVENT_FLAG_SHIFTKEY = 16\n",
      "    EVENT_LBUTTONDBLCLK = 7\n",
      "    EVENT_LBUTTONDOWN = 1\n",
      "    EVENT_LBUTTONUP = 4\n",
      "    EVENT_MBUTTONDBLCLK = 9\n",
      "    EVENT_MBUTTONDOWN = 3\n",
      "    EVENT_MBUTTONUP = 6\n",
      "    EVENT_MOUSEHWHEEL = 11\n",
      "    EVENT_MOUSEMOVE = 0\n",
      "    EVENT_MOUSEWHEEL = 10\n",
      "    EVENT_RBUTTONDBLCLK = 8\n",
      "    EVENT_RBUTTONDOWN = 2\n",
      "    EVENT_RBUTTONUP = 5\n",
      "    FAST_FEATURE_DETECTOR_FAST_N = 10002\n",
      "    FAST_FEATURE_DETECTOR_NONMAX_SUPPRESSION = 10001\n",
      "    FAST_FEATURE_DETECTOR_THRESHOLD = 10000\n",
      "    FAST_FEATURE_DETECTOR_TYPE_5_8 = 0\n",
      "    FAST_FEATURE_DETECTOR_TYPE_7_12 = 1\n",
      "    FAST_FEATURE_DETECTOR_TYPE_9_16 = 2\n",
      "    FILE_NODE_EMPTY = 16\n",
      "    FILE_NODE_FLOAT = 2\n",
      "    FILE_NODE_FLOW = 8\n",
      "    FILE_NODE_INT = 1\n",
      "    FILE_NODE_MAP = 5\n",
      "    FILE_NODE_NAMED = 32\n",
      "    FILE_NODE_NONE = 0\n",
      "    FILE_NODE_REAL = 2\n",
      "    FILE_NODE_SEQ = 4\n",
      "    FILE_NODE_STR = 3\n",
      "    FILE_NODE_STRING = 3\n",
      "    FILE_NODE_TYPE_MASK = 7\n",
      "    FILE_NODE_UNIFORM = 8\n",
      "    FILE_STORAGE_APPEND = 2\n",
      "    FILE_STORAGE_BASE64 = 64\n",
      "    FILE_STORAGE_FORMAT_AUTO = 0\n",
      "    FILE_STORAGE_FORMAT_JSON = 24\n",
      "    FILE_STORAGE_FORMAT_MASK = 56\n",
      "    FILE_STORAGE_FORMAT_XML = 8\n",
      "    FILE_STORAGE_FORMAT_YAML = 16\n",
      "    FILE_STORAGE_INSIDE_MAP = 4\n",
      "    FILE_STORAGE_MEMORY = 4\n",
      "    FILE_STORAGE_NAME_EXPECTED = 2\n",
      "    FILE_STORAGE_READ = 0\n",
      "    FILE_STORAGE_UNDEFINED = 0\n",
      "    FILE_STORAGE_VALUE_EXPECTED = 1\n",
      "    FILE_STORAGE_WRITE = 1\n",
      "    FILE_STORAGE_WRITE_BASE64 = 65\n",
      "    FILLED = -1\n",
      "    FILTER_SCHARR = -1\n",
      "    FLOODFILL_FIXED_RANGE = 65536\n",
      "    FLOODFILL_MASK_ONLY = 131072\n",
      "    FM_7POINT = 1\n",
      "    FM_8POINT = 2\n",
      "    FM_LMEDS = 4\n",
      "    FM_RANSAC = 8\n",
      "    FONT_HERSHEY_COMPLEX = 3\n",
      "    FONT_HERSHEY_COMPLEX_SMALL = 5\n",
      "    FONT_HERSHEY_DUPLEX = 2\n",
      "    FONT_HERSHEY_PLAIN = 1\n",
      "    FONT_HERSHEY_SCRIPT_COMPLEX = 7\n",
      "    FONT_HERSHEY_SCRIPT_SIMPLEX = 6\n",
      "    FONT_HERSHEY_SIMPLEX = 0\n",
      "    FONT_HERSHEY_TRIPLEX = 4\n",
      "    FONT_ITALIC = 16\n",
      "    FORMATTER_FMT_C = 5\n",
      "    FORMATTER_FMT_CSV = 2\n",
      "    FORMATTER_FMT_DEFAULT = 0\n",
      "    FORMATTER_FMT_MATLAB = 1\n",
      "    FORMATTER_FMT_NUMPY = 4\n",
      "    FORMATTER_FMT_PYTHON = 3\n",
      "    FastFeatureDetector_FAST_N = 10002\n",
      "    FastFeatureDetector_NONMAX_SUPPRESSION = 10001\n",
      "    FastFeatureDetector_THRESHOLD = 10000\n",
      "    FastFeatureDetector_TYPE_5_8 = 0\n",
      "    FastFeatureDetector_TYPE_7_12 = 1\n",
      "    FastFeatureDetector_TYPE_9_16 = 2\n",
      "    FileNode_EMPTY = 16\n",
      "    FileNode_FLOAT = 2\n",
      "    FileNode_FLOW = 8\n",
      "    FileNode_INT = 1\n",
      "    FileNode_MAP = 5\n",
      "    FileNode_NAMED = 32\n",
      "    FileNode_NONE = 0\n",
      "    FileNode_REAL = 2\n",
      "    FileNode_SEQ = 4\n",
      "    FileNode_STR = 3\n",
      "    FileNode_STRING = 3\n",
      "    FileNode_TYPE_MASK = 7\n",
      "    FileNode_UNIFORM = 8\n",
      "    FileStorage_APPEND = 2\n",
      "    FileStorage_BASE64 = 64\n",
      "    FileStorage_FORMAT_AUTO = 0\n",
      "    FileStorage_FORMAT_JSON = 24\n",
      "    FileStorage_FORMAT_MASK = 56\n",
      "    FileStorage_FORMAT_XML = 8\n",
      "    FileStorage_FORMAT_YAML = 16\n",
      "    FileStorage_INSIDE_MAP = 4\n",
      "    FileStorage_MEMORY = 4\n",
      "    FileStorage_NAME_EXPECTED = 2\n",
      "    FileStorage_READ = 0\n",
      "    FileStorage_UNDEFINED = 0\n",
      "    FileStorage_VALUE_EXPECTED = 1\n",
      "    FileStorage_WRITE = 1\n",
      "    FileStorage_WRITE_BASE64 = 65\n",
      "    Formatter_FMT_C = 5\n",
      "    Formatter_FMT_CSV = 2\n",
      "    Formatter_FMT_DEFAULT = 0\n",
      "    Formatter_FMT_MATLAB = 1\n",
      "    Formatter_FMT_NUMPY = 4\n",
      "    Formatter_FMT_PYTHON = 3\n",
      "    GC_BGD = 0\n",
      "    GC_EVAL = 2\n",
      "    GC_EVAL_FREEZE_MODEL = 3\n",
      "    GC_FGD = 1\n",
      "    GC_INIT_WITH_MASK = 1\n",
      "    GC_INIT_WITH_RECT = 0\n",
      "    GC_PR_BGD = 2\n",
      "    GC_PR_FGD = 3\n",
      "    GEMM_1_T = 1\n",
      "    GEMM_2_T = 2\n",
      "    GEMM_3_T = 4\n",
      "    HISTCMP_BHATTACHARYYA = 3\n",
      "    HISTCMP_CHISQR = 1\n",
      "    HISTCMP_CHISQR_ALT = 4\n",
      "    HISTCMP_CORREL = 0\n",
      "    HISTCMP_HELLINGER = 3\n",
      "    HISTCMP_INTERSECT = 2\n",
      "    HISTCMP_KL_DIV = 5\n",
      "    HOGDESCRIPTOR_DEFAULT_NLEVELS = 64\n",
      "    HOGDESCRIPTOR_DESCR_FORMAT_COL_BY_COL = 0\n",
      "    HOGDESCRIPTOR_DESCR_FORMAT_ROW_BY_ROW = 1\n",
      "    HOGDESCRIPTOR_L2HYS = 0\n",
      "    HOGDescriptor_DEFAULT_NLEVELS = 64\n",
      "    HOGDescriptor_DESCR_FORMAT_COL_BY_COL = 0\n",
      "    HOGDescriptor_DESCR_FORMAT_ROW_BY_ROW = 1\n",
      "    HOGDescriptor_L2Hys = 0\n",
      "    HOUGH_GRADIENT = 3\n",
      "    HOUGH_GRADIENT_ALT = 4\n",
      "    HOUGH_MULTI_SCALE = 2\n",
      "    HOUGH_PROBABILISTIC = 1\n",
      "    HOUGH_STANDARD = 0\n",
      "    IMREAD_ANYCOLOR = 4\n",
      "    IMREAD_ANYDEPTH = 2\n",
      "    IMREAD_COLOR = 1\n",
      "    IMREAD_GRAYSCALE = 0\n",
      "    IMREAD_IGNORE_ORIENTATION = 128\n",
      "    IMREAD_LOAD_GDAL = 8\n",
      "    IMREAD_REDUCED_COLOR_2 = 17\n",
      "    IMREAD_REDUCED_COLOR_4 = 33\n",
      "    IMREAD_REDUCED_COLOR_8 = 65\n",
      "    IMREAD_REDUCED_GRAYSCALE_2 = 16\n",
      "    IMREAD_REDUCED_GRAYSCALE_4 = 32\n",
      "    IMREAD_REDUCED_GRAYSCALE_8 = 64\n",
      "    IMREAD_UNCHANGED = -1\n",
      "    IMWRITE_EXR_TYPE = 48\n",
      "    IMWRITE_EXR_TYPE_FLOAT = 2\n",
      "    IMWRITE_EXR_TYPE_HALF = 1\n",
      "    IMWRITE_JPEG2000_COMPRESSION_X1000 = 272\n",
      "    IMWRITE_JPEG_CHROMA_QUALITY = 6\n",
      "    IMWRITE_JPEG_LUMA_QUALITY = 5\n",
      "    IMWRITE_JPEG_OPTIMIZE = 3\n",
      "    IMWRITE_JPEG_PROGRESSIVE = 2\n",
      "    IMWRITE_JPEG_QUALITY = 1\n",
      "    IMWRITE_JPEG_RST_INTERVAL = 4\n",
      "    IMWRITE_PAM_FORMAT_BLACKANDWHITE = 1\n",
      "    IMWRITE_PAM_FORMAT_GRAYSCALE = 2\n",
      "    IMWRITE_PAM_FORMAT_GRAYSCALE_ALPHA = 3\n",
      "    IMWRITE_PAM_FORMAT_NULL = 0\n",
      "    IMWRITE_PAM_FORMAT_RGB = 4\n",
      "    IMWRITE_PAM_FORMAT_RGB_ALPHA = 5\n",
      "    IMWRITE_PAM_TUPLETYPE = 128\n",
      "    IMWRITE_PNG_BILEVEL = 18\n",
      "    IMWRITE_PNG_COMPRESSION = 16\n",
      "    IMWRITE_PNG_STRATEGY = 17\n",
      "    IMWRITE_PNG_STRATEGY_DEFAULT = 0\n",
      "    IMWRITE_PNG_STRATEGY_FILTERED = 1\n",
      "    IMWRITE_PNG_STRATEGY_FIXED = 4\n",
      "    IMWRITE_PNG_STRATEGY_HUFFMAN_ONLY = 2\n",
      "    IMWRITE_PNG_STRATEGY_RLE = 3\n",
      "    IMWRITE_PXM_BINARY = 32\n",
      "    IMWRITE_TIFF_COMPRESSION = 259\n",
      "    IMWRITE_TIFF_RESUNIT = 256\n",
      "    IMWRITE_TIFF_XDPI = 257\n",
      "    IMWRITE_TIFF_YDPI = 258\n",
      "    IMWRITE_WEBP_QUALITY = 64\n",
      "    INPAINT_NS = 0\n",
      "    INPAINT_TELEA = 1\n",
      "    INTERSECT_FULL = 2\n",
      "    INTERSECT_NONE = 0\n",
      "    INTERSECT_PARTIAL = 1\n",
      "    INTER_AREA = 3\n",
      "    INTER_BITS = 5\n",
      "    INTER_BITS2 = 10\n",
      "    INTER_CUBIC = 2\n",
      "    INTER_LANCZOS4 = 4\n",
      "    INTER_LINEAR = 1\n",
      "    INTER_LINEAR_EXACT = 5\n",
      "    INTER_MAX = 7\n",
      "    INTER_NEAREST = 0\n",
      "    INTER_TAB_SIZE = 32\n",
      "    INTER_TAB_SIZE2 = 1024\n",
      "    KAZE_DIFF_CHARBONNIER = 3\n",
      "    KAZE_DIFF_PM_G1 = 0\n",
      "    KAZE_DIFF_PM_G2 = 1\n",
      "    KAZE_DIFF_WEICKERT = 2\n",
      "    KMEANS_PP_CENTERS = 2\n",
      "    KMEANS_RANDOM_CENTERS = 0\n",
      "    KMEANS_USE_INITIAL_LABELS = 1\n",
      "    LDR_SIZE = 256\n",
      "    LINE_4 = 4\n",
      "    LINE_8 = 8\n",
      "    LINE_AA = 16\n",
      "    LMEDS = 4\n",
      "    LSD_REFINE_ADV = 2\n",
      "    LSD_REFINE_NONE = 0\n",
      "    LSD_REFINE_STD = 1\n",
      "    MARKER_CROSS = 0\n",
      "    MARKER_DIAMOND = 3\n",
      "    MARKER_SQUARE = 4\n",
      "    MARKER_STAR = 2\n",
      "    MARKER_TILTED_CROSS = 1\n",
      "    MARKER_TRIANGLE_DOWN = 6\n",
      "    MARKER_TRIANGLE_UP = 5\n",
      "    MAT_AUTO_STEP = 0\n",
      "    MAT_CONTINUOUS_FLAG = 16384\n",
      "    MAT_DEPTH_MASK = 7\n",
      "    MAT_MAGIC_MASK = 4294901760\n",
      "    MAT_MAGIC_VAL = 1124007936\n",
      "    MAT_SUBMATRIX_FLAG = 32768\n",
      "    MAT_TYPE_MASK = 4095\n",
      "    MIXED_CLONE = 2\n",
      "    MONOCHROME_TRANSFER = 3\n",
      "    MORPH_BLACKHAT = 6\n",
      "    MORPH_CLOSE = 3\n",
      "    MORPH_CROSS = 1\n",
      "    MORPH_DILATE = 1\n",
      "    MORPH_ELLIPSE = 2\n",
      "    MORPH_ERODE = 0\n",
      "    MORPH_GRADIENT = 4\n",
      "    MORPH_HITMISS = 7\n",
      "    MORPH_OPEN = 2\n",
      "    MORPH_RECT = 0\n",
      "    MORPH_TOPHAT = 5\n",
      "    MOTION_AFFINE = 2\n",
      "    MOTION_EUCLIDEAN = 1\n",
      "    MOTION_HOMOGRAPHY = 3\n",
      "    MOTION_TRANSLATION = 0\n",
      "    Mat_AUTO_STEP = 0\n",
      "    Mat_CONTINUOUS_FLAG = 16384\n",
      "    Mat_DEPTH_MASK = 7\n",
      "    Mat_MAGIC_MASK = 4294901760\n",
      "    Mat_MAGIC_VAL = 1124007936\n",
      "    Mat_SUBMATRIX_FLAG = 32768\n",
      "    Mat_TYPE_MASK = 4095\n",
      "    NORMAL_CLONE = 1\n",
      "    NORMCONV_FILTER = 2\n",
      "    NORM_HAMMING = 6\n",
      "    NORM_HAMMING2 = 7\n",
      "    NORM_INF = 1\n",
      "    NORM_L1 = 2\n",
      "    NORM_L2 = 4\n",
      "    NORM_L2SQR = 5\n",
      "    NORM_MINMAX = 32\n",
      "    NORM_RELATIVE = 8\n",
      "    NORM_TYPE_MASK = 7\n",
      "    OPTFLOW_FARNEBACK_GAUSSIAN = 256\n",
      "    OPTFLOW_LK_GET_MIN_EIGENVALS = 8\n",
      "    OPTFLOW_USE_INITIAL_FLOW = 4\n",
      "    ORB_FAST_SCORE = 1\n",
      "    ORB_HARRIS_SCORE = 0\n",
      "    PARAM_ALGORITHM = 6\n",
      "    PARAM_BOOLEAN = 1\n",
      "    PARAM_FLOAT = 7\n",
      "    PARAM_INT = 0\n",
      "    PARAM_MAT = 4\n",
      "    PARAM_MAT_VECTOR = 5\n",
      "    PARAM_REAL = 2\n",
      "    PARAM_SCALAR = 12\n",
      "    PARAM_STRING = 3\n",
      "    PARAM_UCHAR = 11\n",
      "    PARAM_UINT64 = 9\n",
      "    PARAM_UNSIGNED_INT = 8\n",
      "    PCA_DATA_AS_COL = 1\n",
      "    PCA_DATA_AS_ROW = 0\n",
      "    PCA_USE_AVG = 2\n",
      "    PROJ_SPHERICAL_EQRECT = 1\n",
      "    PROJ_SPHERICAL_ORTHO = 0\n",
      "    Param_ALGORITHM = 6\n",
      "    Param_BOOLEAN = 1\n",
      "    Param_FLOAT = 7\n",
      "    Param_INT = 0\n",
      "    Param_MAT = 4\n",
      "    Param_MAT_VECTOR = 5\n",
      "    Param_REAL = 2\n",
      "    Param_SCALAR = 12\n",
      "    Param_STRING = 3\n",
      "    Param_UCHAR = 11\n",
      "    Param_UINT64 = 9\n",
      "    Param_UNSIGNED_INT = 8\n",
      "    QT_CHECKBOX = 1\n",
      "    QT_FONT_BLACK = 87\n",
      "    QT_FONT_BOLD = 75\n",
      "    QT_FONT_DEMIBOLD = 63\n",
      "    QT_FONT_LIGHT = 25\n",
      "    QT_FONT_NORMAL = 50\n",
      "    QT_NEW_BUTTONBAR = 1024\n",
      "    QT_PUSH_BUTTON = 0\n",
      "    QT_RADIOBOX = 2\n",
      "    QT_STYLE_ITALIC = 1\n",
      "    QT_STYLE_NORMAL = 0\n",
      "    QT_STYLE_OBLIQUE = 2\n",
      "    RANSAC = 8\n",
      "    RECURS_FILTER = 1\n",
      "    REDUCE_AVG = 1\n",
      "    REDUCE_MAX = 2\n",
      "    REDUCE_MIN = 3\n",
      "    REDUCE_SUM = 0\n",
      "    RETR_CCOMP = 2\n",
      "    RETR_EXTERNAL = 0\n",
      "    RETR_FLOODFILL = 4\n",
      "    RETR_LIST = 1\n",
      "    RETR_TREE = 3\n",
      "    RHO = 16\n",
      "    RNG_NORMAL = 1\n",
      "    RNG_UNIFORM = 0\n",
      "    ROTATE_180 = 1\n",
      "    ROTATE_90_CLOCKWISE = 0\n",
      "    ROTATE_90_COUNTERCLOCKWISE = 2\n",
      "    SOLVELP_MULTI = 1\n",
      "    SOLVELP_SINGLE = 0\n",
      "    SOLVELP_UNBOUNDED = -2\n",
      "    SOLVELP_UNFEASIBLE = -1\n",
      "    SOLVEPNP_AP3P = 5\n",
      "    SOLVEPNP_DLS = 3\n",
      "    SOLVEPNP_EPNP = 1\n",
      "    SOLVEPNP_IPPE = 6\n",
      "    SOLVEPNP_IPPE_SQUARE = 7\n",
      "    SOLVEPNP_ITERATIVE = 0\n",
      "    SOLVEPNP_MAX_COUNT = 8\n",
      "    SOLVEPNP_P3P = 2\n",
      "    SOLVEPNP_UPNP = 4\n",
      "    SORT_ASCENDING = 0\n",
      "    SORT_DESCENDING = 16\n",
      "    SORT_EVERY_COLUMN = 1\n",
      "    SORT_EVERY_ROW = 0\n",
      "    SPARSE_MAT_HASH_BIT = 2147483648\n",
      "    SPARSE_MAT_HASH_SCALE = 1540483477\n",
      "    SPARSE_MAT_MAGIC_VAL = 1123876864\n",
      "    SPARSE_MAT_MAX_DIM = 32\n",
      "    STEREO_BM_PREFILTER_NORMALIZED_RESPONSE = 0\n",
      "    STEREO_BM_PREFILTER_XSOBEL = 1\n",
      "    STEREO_MATCHER_DISP_SCALE = 16\n",
      "    STEREO_MATCHER_DISP_SHIFT = 4\n",
      "    STEREO_SGBM_MODE_HH = 1\n",
      "    STEREO_SGBM_MODE_HH4 = 3\n",
      "    STEREO_SGBM_MODE_SGBM = 0\n",
      "    STEREO_SGBM_MODE_SGBM_3WAY = 2\n",
      "    STITCHER_ERR_CAMERA_PARAMS_ADJUST_FAIL = 3\n",
      "    STITCHER_ERR_HOMOGRAPHY_EST_FAIL = 2\n",
      "    STITCHER_ERR_NEED_MORE_IMGS = 1\n",
      "    STITCHER_OK = 0\n",
      "    STITCHER_PANORAMA = 0\n",
      "    STITCHER_SCANS = 1\n",
      "    SUBDIV2D_NEXT_AROUND_DST = 34\n",
      "    SUBDIV2D_NEXT_AROUND_LEFT = 19\n",
      "    SUBDIV2D_NEXT_AROUND_ORG = 0\n",
      "    SUBDIV2D_NEXT_AROUND_RIGHT = 49\n",
      "    SUBDIV2D_PREV_AROUND_DST = 51\n",
      "    SUBDIV2D_PREV_AROUND_LEFT = 32\n",
      "    SUBDIV2D_PREV_AROUND_ORG = 17\n",
      "    SUBDIV2D_PREV_AROUND_RIGHT = 2\n",
      "    SUBDIV2D_PTLOC_ERROR = -2\n",
      "    SUBDIV2D_PTLOC_INSIDE = 0\n",
      "    SUBDIV2D_PTLOC_ON_EDGE = 2\n",
      "    SUBDIV2D_PTLOC_OUTSIDE_RECT = -1\n",
      "    SUBDIV2D_PTLOC_VERTEX = 1\n",
      "    SVD_FULL_UV = 4\n",
      "    SVD_MODIFY_A = 1\n",
      "    SVD_NO_UV = 2\n",
      "    SparseMat_HASH_BIT = 2147483648\n",
      "    SparseMat_HASH_SCALE = 1540483477\n",
      "    SparseMat_MAGIC_VAL = 1123876864\n",
      "    SparseMat_MAX_DIM = 32\n",
      "    StereoBM_PREFILTER_NORMALIZED_RESPONSE = 0\n",
      "    StereoBM_PREFILTER_XSOBEL = 1\n",
      "    StereoMatcher_DISP_SCALE = 16\n",
      "    StereoMatcher_DISP_SHIFT = 4\n",
      "    StereoSGBM_MODE_HH = 1\n",
      "    StereoSGBM_MODE_HH4 = 3\n",
      "    StereoSGBM_MODE_SGBM = 0\n",
      "    StereoSGBM_MODE_SGBM_3WAY = 2\n",
      "    Stitcher_ERR_CAMERA_PARAMS_ADJUST_FAIL = 3\n",
      "    Stitcher_ERR_HOMOGRAPHY_EST_FAIL = 2\n",
      "    Stitcher_ERR_NEED_MORE_IMGS = 1\n",
      "    Stitcher_OK = 0\n",
      "    Stitcher_PANORAMA = 0\n",
      "    Stitcher_SCANS = 1\n",
      "    Subdiv2D_NEXT_AROUND_DST = 34\n",
      "    Subdiv2D_NEXT_AROUND_LEFT = 19\n",
      "    Subdiv2D_NEXT_AROUND_ORG = 0\n",
      "    Subdiv2D_NEXT_AROUND_RIGHT = 49\n",
      "    Subdiv2D_PREV_AROUND_DST = 51\n",
      "    Subdiv2D_PREV_AROUND_LEFT = 32\n",
      "    Subdiv2D_PREV_AROUND_ORG = 17\n",
      "    Subdiv2D_PREV_AROUND_RIGHT = 2\n",
      "    Subdiv2D_PTLOC_ERROR = -2\n",
      "    Subdiv2D_PTLOC_INSIDE = 0\n",
      "    Subdiv2D_PTLOC_ON_EDGE = 2\n",
      "    Subdiv2D_PTLOC_OUTSIDE_RECT = -1\n",
      "    Subdiv2D_PTLOC_VERTEX = 1\n",
      "    TERM_CRITERIA_COUNT = 1\n",
      "    TERM_CRITERIA_EPS = 2\n",
      "    TERM_CRITERIA_MAX_ITER = 1\n",
      "    THRESH_BINARY = 0\n",
      "    THRESH_BINARY_INV = 1\n",
      "    THRESH_MASK = 7\n",
      "    THRESH_OTSU = 8\n",
      "    THRESH_TOZERO = 3\n",
      "    THRESH_TOZERO_INV = 4\n",
      "    THRESH_TRIANGLE = 16\n",
      "    THRESH_TRUNC = 2\n",
      "    TM_CCOEFF = 4\n",
      "    TM_CCOEFF_NORMED = 5\n",
      "    TM_CCORR = 2\n",
      "    TM_CCORR_NORMED = 3\n",
      "    TM_SQDIFF = 0\n",
      "    TM_SQDIFF_NORMED = 1\n",
      "    TermCriteria_COUNT = 1\n",
      "    TermCriteria_EPS = 2\n",
      "    TermCriteria_MAX_ITER = 1\n",
      "    UMAT_AUTO_STEP = 0\n",
      "    UMAT_CONTINUOUS_FLAG = 16384\n",
      "    UMAT_DATA_ASYNC_CLEANUP = 128\n",
      "    UMAT_DATA_COPY_ON_MAP = 1\n",
      "    UMAT_DATA_DEVICE_COPY_OBSOLETE = 4\n",
      "    UMAT_DATA_DEVICE_MEM_MAPPED = 64\n",
      "    UMAT_DATA_HOST_COPY_OBSOLETE = 2\n",
      "    UMAT_DATA_TEMP_COPIED_UMAT = 24\n",
      "    UMAT_DATA_TEMP_UMAT = 8\n",
      "    UMAT_DATA_USER_ALLOCATED = 32\n",
      "    UMAT_DEPTH_MASK = 7\n",
      "    UMAT_MAGIC_MASK = 4294901760\n",
      "    UMAT_MAGIC_VAL = 1124007936\n",
      "    UMAT_SUBMATRIX_FLAG = 32768\n",
      "    UMAT_TYPE_MASK = 4095\n",
      "    UMatData_ASYNC_CLEANUP = 128\n",
      "    UMatData_COPY_ON_MAP = 1\n",
      "    UMatData_DEVICE_COPY_OBSOLETE = 4\n",
      "    UMatData_DEVICE_MEM_MAPPED = 64\n",
      "    UMatData_HOST_COPY_OBSOLETE = 2\n",
      "    UMatData_TEMP_COPIED_UMAT = 24\n",
      "    UMatData_TEMP_UMAT = 8\n",
      "    UMatData_USER_ALLOCATED = 32\n",
      "    UMat_AUTO_STEP = 0\n",
      "    UMat_CONTINUOUS_FLAG = 16384\n",
      "    UMat_DEPTH_MASK = 7\n",
      "    UMat_MAGIC_MASK = 4294901760\n",
      "    UMat_MAGIC_VAL = 1124007936\n",
      "    UMat_SUBMATRIX_FLAG = 32768\n",
      "    UMat_TYPE_MASK = 4095\n",
      "    USAGE_ALLOCATE_DEVICE_MEMORY = 2\n",
      "    USAGE_ALLOCATE_HOST_MEMORY = 1\n",
      "    USAGE_ALLOCATE_SHARED_MEMORY = 4\n",
      "    USAGE_DEFAULT = 0\n",
      "    VIDEOWRITER_PROP_FRAMEBYTES = 2\n",
      "    VIDEOWRITER_PROP_IS_COLOR = 4\n",
      "    VIDEOWRITER_PROP_NSTRIPES = 3\n",
      "    VIDEOWRITER_PROP_QUALITY = 1\n",
      "    WARP_FILL_OUTLIERS = 8\n",
      "    WARP_INVERSE_MAP = 16\n",
      "    WARP_POLAR_LINEAR = 0\n",
      "    WARP_POLAR_LOG = 256\n",
      "    WINDOW_AUTOSIZE = 1\n",
      "    WINDOW_FREERATIO = 256\n",
      "    WINDOW_FULLSCREEN = 1\n",
      "    WINDOW_GUI_EXPANDED = 0\n",
      "    WINDOW_GUI_NORMAL = 16\n",
      "    WINDOW_KEEPRATIO = 0\n",
      "    WINDOW_NORMAL = 0\n",
      "    WINDOW_OPENGL = 4096\n",
      "    WND_PROP_ASPECT_RATIO = 2\n",
      "    WND_PROP_AUTOSIZE = 1\n",
      "    WND_PROP_FULLSCREEN = 0\n",
      "    WND_PROP_OPENGL = 3\n",
      "    WND_PROP_TOPMOST = 5\n",
      "    WND_PROP_VISIBLE = 4\n",
      "    ci_and_not_headless = True\n",
      "    ci_build = True\n",
      "    haarcascades = '/Users/nhorde/opt/anaconda3/lib/python3.8/site-package...\n",
      "    headless = False\n",
      "\n",
      "VERSION\n",
      "    4.4.0\n",
      "\n",
      "FILE\n",
      "    /Users/nhorde/opt/anaconda3/lib/python3.8/site-packages/cv2/cv2.cpython-38-darwin.so\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# help(cv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8064c15850>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread('cat.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel intensity for [100,100]: [82 80 79]\n",
      "Pixel intensity for blue [100,100,0]: 82\n",
      "Pixel intensity (better code) for blue [100,100,0]: 82\n",
      "Picture shape: (300, 450, 3)\n",
      "Picture size: 405000\n",
      "Picture type: uint8\n"
     ]
    }
   ],
   "source": [
    "# Ugly way\n",
    "print(f\"Pixel intensity for [100,100]: {img[100,100]}\")\n",
    "print(f\"Pixel intensity for blue [100,100,0]: {img[100,100,0]}\")\n",
    "\n",
    "# Better way to write code\n",
    "print(f\"Pixel intensity (better code) for blue [100,100,0]: {img.item(100,100,0)}\")\n",
    "print(f\"Picture shape: {img.shape}\")\n",
    "print(f\"Picture size: {img.size}\")\n",
    "print(f\"Picture type: {img.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f80648160a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modify pixel intensity\n",
    "for y in range(10):\n",
    "    for x in range(len(img)):\n",
    "        img[x,y+100] = [255,255,255]\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f80654f6370>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modify pixel intensity with better code\n",
    "for y in range(10):\n",
    "    for x in range(len(img)):\n",
    "        img.itemset((x,y+100,2),100)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f806529b5e0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9S68ly5Im9Jl7PNZrvzLznnOrupvHgDET1EggIVoIxKxHIGDCAKlGzKkxo/4L1KAlJgiYtGDQ4iEk5jVB4iFArVZTXQ9V1T333Jsnc++9IsLdGJiZu4cvj7V3nkdXHlX6OTtXrFgRHh7++NzsczNzYmZ8SV/Sl/QlfUk/n+T+qgvwJX1JX9KX9CV9WvoC3F/Sl/QlfUk/s/QFuL+kL+lL+pJ+ZukLcH9JX9KX9CX9zNIX4P6SvqQv6Uv6maUvwP0lfUlf0pf0M0s/GXAT0b9LRP8PEf0jIvr9n+o5X9KX9CV9SX/dEv0UdtxE5AH8vwD+bQB/DOAPAfyHzPx//egP+5K+pC/pS/prln4qiftvA/hHzPyPmXkC8F8D+Ls/0bO+pC/pS/qS/lql7ifK928A+KfF9z8G8K9uXTwOAx8O+6sZEhEA4MfUD+h739i+k2Bl5NX37Ydu5fPacnzaPZt1d/FD68rvXVuvTNst+yltfr2U9Iqvn/CedKWNub6meouyD21oveXZ+jm8USubGnRRHsuP7auVRe/l1g1g+z9du9UuzFHKS1V5intSjTBW9bV6dn2u8cDX1FxVOD39+rHHqaDb6TXXvJTqpjtPZ8zz3CzoTwXczfdfXUD0ewB+DwD2+x3+zr/xr9n58pqLY4PEi8w3OixtNNC1367dU15DcCByq3NbeRER+IV3q49LdajMp34OEQHEW31xVTetemLmq9cwA+DX1QkAkPv0Dnz5zOvfXypDfbz12+pcgke6qG/5Wt6vmOMcXNEHnKMECkQE5+w3Rudds1whhMvyECFERogRzrn0Z3VR/5XnY4yr/O331TvBwzmHruvgnAMzI4SAEMJmHcUYEWNECAHzPKfnlGWLMWIJM5hjKouVK4TQ7FscL9/Jyl3e3/q99VkeO+cvzm0lAkCtyaHxzDrPa2OorP/W+a37/rf/43/fLOtPBdx/DOBvFd//JoA/LS9g5j8A8AcA8HB/x8DrAPP7pB8730/Nr3U9M18Hlvr7lUnBjlvFaj3n2u9b36/1+TYgbl//fctgx59Sjq3fmmVGlmyJLt8lfxZSKDiNdiICOUqALZ8E5xQkDbidEyGzAiIQwZFIwpEZIcpvzjn0fY+u61IdGKgZsNWfNVjX7+6oQ9d16Pse3vsVsHZdlwC9rHcD9nmecT6fMc8ziAje+1S2EALmZcI8T5jnGfM8Y1kWLMuCvu9Xk4SUVWuxAYAxxgR29l7lNS8Bn9WdHb80br8PcLfKU15XP7esT3u3EtDLc9fSTwXcfwjgXyKifxHAnwD4DwD8R9duaEmSn5J+iPT8qfm/Ns/ynUgHZCuvLJWtQcS9EogAwBGaek59Xd25aimgmRjbqmWrjGQ3ra/bqrdaQvw+6SUNZutzVT6o1F21WysvIgLcZRt77+G9T6Dnvcdut8M4jui6PrV3Cb4GYpYXM2MJAYtKv33fYxxH9L3cX4J0LZHWwH3xjvp873r0fY9hGFb9z3u/el4J3vY8A27TFGrgPk9PeHp6wuPjIz58+IDvvvsOj4+Pq/4WQsCyLIghIjYk7qiaRn0MbEu55W/5uBh/xW9NQQgvA3f9jPr3+trW+GqBdg3ofyXAzcwLEf2nAP5HAB7A32fm//OneNZr0jXw+mfxzGugsTkhvOKa9fXfT8q9NtPn7y9IKnWZKA+Ya9eun/G679fK0Krf1qRYHl9Mog2apDwu/0AAOSQpu/Mdur7DbrfDbhwxDAP6YcB+t8Nud0DfD4lWKEHbJFJ7TowRy7Ig6Lv3fZ8kbmunGqgNVLeAuwRtIkI/7DEMOc+Sjum6DsMwJKnb2qF85rJk2sM5B++9li0ixgXzNOHp6QkfP37Et99+i/fv3+P9+/d4enrC+XzGsixwzmGeZ3TwF+9RTlDl88t+8RJ9cXlMuOTuizpCewwRA1xw/cwGsqIxlPpXmVeTz6/a5NXCU5V+KokbzPwPAfzD115vjWWpPs4vRhcLM2VnbklSrU58raI+rRJfr+Jsvd/W84Q/UvCCUCGMLB1KPjm/a/j2WlWsJZVsw3CRyK6pVpuKfJpSzieA9pba2XrGFvheK1MGbnmhDHaZ7ijP+d6j630CuFHB+ng8pr9xHOV8P6LrhizBMhBiKMA7gFnGQFBp29raJFoD0bK/W720JO9rEw+T5GmAW/LUJRCX2kEtGZZ9avUsDun3EEKSun/729/iV7/6Fb755ht8/PgR0zThfJ4Qw1rzKD9LYKvLsUWV1NJr+duLQkhrLBKllUPmEtyln6c7mPVSTuPBjpsLqw0Non6frfSTAfenJCtmDS6ozktai5atTmzngayGXxvQ5XM+CbRZmq01WdT5amFS2ctO1QYXBiMKhUr6zmQ9QI5L0BZJ4NqEt05bAF7XXy7Ldj7NXrlRF9d+e2lCrTWErbzK+vTeX72+/pS1xXyt9y4Bp1EHiXPuPcbdiN1uh64TSft0OuF4PIrUvdtlyZU8vB9AlQVui+5gZkSOiMjgW0rMlsq6sn6+pZZf3OO6NZAXgHgB8hsSfHm9XeOcg4OHUy0kxohxHHF3d4f7+3vc3d3heDzim2++wePjI5ZlwTyFxJkbh74sS+LUDchrSq1suxYGlPXZ6gOttOr1L1Ae9fOtHcuJY5Vvxv/VM1pY9xIOfRbAjUbhNyVCMMC0qpzXDvjynnIAlNddS5cSm/y1pJrW9XEjLyvT+lnbUmFLktrKt+5cW+e237Gd71a5AVzU7ZYE9JqBVKfXvutL79GWRJEWhe3PpNKu67Df7zEMA4ZhSJL07rDH4XDAMAzYjTscDnv0/YBh6NEPAzqfF/lE3fartQtGwfGzTo/MAOXJcqtPWZ22PlspURHMYFpbW6xoF2awEM9p4bAGsaTxGZWi+Toi9I7gfaZerM5scjscDnj79i0+fvyI8/mMp8czPn78iI8fPyYqxeiUGsRbE9S1fsWIMMEi38JrANX31NGcfs/Hdj2DSI8tA5Lz1mZEDETLj5PGLAftdtkaH9fS5wHcuJSMr9IHeBmstlSmWtJd5X1twmioioTtAdW6Xwbv6wFRpPl0JUrSovVO1/JtXf9SHnZe8muV8dMl6mvH19Tc1+Rp369NeJZqSbyUuL13cN6j81546r7HMI64OZ2wPxyw3+2w3x9wOByw2x+w240rgC8/i5IhBMjAL8uINg8vcsF1qaslqW21Rymxpk9eUxSWh50rz7eoEWjZSwHAOYfYOXiXNRWjeQy8x3HE7e1tAuewMD58+IDf/OY3+O1vf4vf/OY3+PDhA56fn/H4+AjTNGpBo9ZSmphR9KdtakL+IYhBABd0SMJnlZbttxK3mQE4wHE+pjJfEtCOgYp81+Nti4baSp8NcP9UqSVhlZ/1ta0K26zEKotrwLhVntZv+XglFgBbZFlVmDqf1wB06x1eStuYfZ1LfAl8t8695v4tqRvIIGPH5XVEYorX9Q5d55OUaBYh+/0eNzc3OBwO2O/32O32GMc9hmFMJnXr5zswY6U+C3Bfp69K4CbXBuet72Vbr6TOQqKOMSKGiBADAnOSZmvgtgXTkqawa0ySNgsa48PLiaqkNeweWwi1+jocDlKuANzd3eHh4QHv37/Hr3/9a3zzzTf45ptvUj62mFnTIC16YlVnCBf3tMA+T9zbNG19TynMlb+V757amwDH7uL675s+G+Bugc0Pub8+bklir5W4t/N26oRTmf1V0nk6vyEJtsriHGveW2p9fc5d5NF6l7Kj1h2wvOeyg7ZN9toA+7LEe629r2k+3we0V+CsgG0me6V07Byh8w7D0GO332G/32O/P2Cvx6fTKS1A9v2ArhvgXQ/njf6QZy5hEacSADHa2oNpUQDHANWhMzVy8S4C3KlOYFJcmxO96BuU6YwSUEIICDFiXiKCWa9UknUszpdWLyVwm9lg3/epPnOZ8vvWwGrly3biDhyB3W6H4/GIu7s73N3d4fb2FrvdDt57vH//PvHfuQ7zZBKZV++60hKQF0pb4FpemyXuywmyBdj1b/X5ul9TsdBbj786UdGfWumzAW5LNQBe/L6iSdaWFJS+E8zVeAu4rwH0FsBc/uYUvC/LzeC1mzKhMCla55M4TyotGoQvzMAtlgxAeU3BzZKr6kbvq4R0zmSTrhesObzo3OqcvYuZQF3kVTZReg1XeCDqD6QSb3Fhfo9crpQ3Iy3olJmX/xo4Wf3Ix6rWZZHMSZkcOTgvk5wtNopk3aPvenR9j3EcMA4j9vsddvvMXxs/K2Z5Ht73cL6TNmUgAogxrIBD3iP3hRDzWzIAqoG7Mixj4ryopcuaDOGgjUVh7edOBYNkzlj0DZP8YwwIQQA7FKaICRC1HC0puwZEqVsB8Iv3jTIBEjlQiKksc4iVpM7oHKHrBPz7ode6lkXf/X6H3W7AN998g+fnJyxLwHleMC0BsaRyIoOYlfoJ4BgRQoSYJkYwsqkh1KMzGIefzpeTZyERM2BeoDXfH2OUUUQ1gNuwY21LtoaSumD7VRonCj2ezQeZKpr0Mn0ewP0CkFZnVy7GF9fpbL8CsRekcTtezY4NCb2+zwbG+hGcALaVrk8KZd6ues6WpK2SJNa/r/JvFEXeldReJC+ilAsqa6nCFfcVeaT3f3kitHZbXUsZwOvyNd+FrW41z4L7FHXdpd+IAOcB57NJX+c9ur5D3wsNst/t0BcLjsOwLxYfBwzDiGHo5d7OnGu8eD86l8ECMsBDjGmhzoDBOkdgQuC88JfnpGKySZJirlszLUvtpYCSJmyiPHE7p21IiT8XCZURIhBZ/tr9Ac0xYNK0cy6ZGZYekHZtCGFFm9g1Vg4igvM+8d++69B3EX5ZRILvOnjnMO4GbTPAEeOw3+HDh+/w9PyMx2nB0xywTFNerIwMFLw8J1APaVJK17KYXZrdPHMER0rjQQJNZOCWSenSll1ao5Ts83/k1yaUMUaADOite1LiwY0bL7UGag3aIn0ewP2ZpddK3C/d+1OlkqtN6v/3p8tWwNc6b8fAywtirXteokno0sDnohzpGAJSnIDLzNEu7Y+dc/Cdg/NIlIh5BB6PR6VC9onHHvoRvhuSNG4La6Un5IpK0s9YDNBrjjARLl+vg7is8RoYgAjTHPXlVQJcq9+OZFIicqDKHyIUedtz2SaPGEHMAlXablG/g2QScABC4Xpel7O09CjbqtVHDdDrv07573Ec0XkP74Cu63A8HtF7h+PxgPfv3+O3v32P754nPM3i4JMWXINSO8uCGFQaT1TPsuLsY1zAMSQ3f5kE88KtTafpHaND5DWtEmOekK0pRKtRYUiBWM4B5EgnWr85fl4aV3X6LIA7q7t/xeWoAeUFSf3aNd/n2VsSfuu6i2d/j+dZalFS9fmXNKKt+mnde/n7y2VM1yLTImU+pat5yV27Li827nYj9moFcjgcsVMbbFuI7PsR3q+B2vKr38FAGwWY2WcdN6R4CfmuUrnlU9+H4hd5bnuAAwBxBJNZQlzaVdc0huVT0iPltasJh4uFTs4mtGWelk9tnbKaPIt2Ka1tElfuZaKc51klby/2886hH0bcWBs4B/f4jP4sMVBiEFqEo8ZRKYA7cfTLnCihaZoQwowYBMS5oFayKWSup7odiUgBXj0maS1ZWx1bXxHthGFMTAo3xpeLmqVA8Boc+SyA+3NL16TsrUp9Dei+5nmvzedCEsang3ddhlqiKp/Tum6r7PX1LwF8S12o78vXU5JAE01UgGzpLDMMA8bdiGFUWkQ563Ecs5Q9DAn0xcHGF+Z5lBxJylQOusilpF0cl9Jtaquibjnz3QYMZfS8lubSOm9/IeQoglZGkzTL9rK6MoqjlJrX7X/RJM0J3u4PS8C8zKtFRCJamQOWIM66piLBt3qMQ4++F1A3mmrU78532B8OolF0T+iezzhPEzjEVMclTVKaM87n5+TUM00TwjKLS75GN4yFVB7ZJObcjq2JqV4TKN30SyA3ailZwxRAn+v5cpxtCVJl+hkC9z8byfxTpcYf63kv5VnP0D/Wc2swqKWCH+tZrfesFyatPFsTmnHlJRgYSBg/fTgcBKyP++TFaNK10SB2bBK78x6Rq1C9xqHHmKkRHagLM+bACIsM+gQeSYItpDUADrKoKINYtQcihCUmN3cV5WTRKlZUCYD1YbXOUWgHJXhZ+5Wu+yFkR5YQ1tJyDSbBFucSLVAuZMpCYIwsljRRKIMYApSFQAy5LU3aLu3KbdLslOfeH3JbHXbSnuQ8+nHEEQTne4zDpAGq1hES03f9C/N0AdwhzCuLmbCok0+MSm/kuqs9N1NwrGrRti6Hfa7APGZJ/ELw+jlSJZZeBUZ8+WI2yJsUxhWA3ZJo6uMtwNkEoh8AdC0J99r3dP57PKsl1dWq30v3l2mrw5Xt86kTzuX7C2coIEXwPruiD8OAg0rVx9NJgjvt9xjSIuOQJED58/DegiwRiJQnbr2XgncavCEgcJTPQiqrpbSyLn2sXgSiayzLgiUEzGERC4niua12qPtfCdqJzlCJfxW8igmOAapAJ6jk2XTGsTJQSQ/lyZajLaQSXOfRE4GCUzAPADmNI+CElrDFwhgQQwSD0QWfFjaXrkuTyTzPgvwg9L068fQDmKWNTJto/pnVSBiT5jHPM8IyIYRso77MM2YFdzGVFPrEOPHSnl3+RDsLYSna2VU0kwF5Kb3rGgNY1nSi1inrQqStX0ANBH6ui5NbA1w0rEtprAWmrwHvrefW+bwUZe5qmTeohU9JzfdaX7Bq6pees1XulpS9RY+0pPFWGev8X/t7LXVncCJ0Xd4IwLjq/X6P4/EowK0Bnnp1kDEp23edLICplG6LeyDzai2Np9UkEpxMzMysblkWzDFgUYDK6nTEsswVkAAAIwTBMLPnZwgwGmjPy5IkewLE5M8oFf0kqRwpO7JG4ArKyPJOUjuK/qOLosLWxAvgXpQjjtGAW+93Lpl/imWL3C+WLDZ5iNbioi+ATM1dCaCoC3cxakwYyZM4S6JLCJiXBW4SH4Zp7uG9xP3uezHb1Hi66LquqSWs6CkOYG03AeAZHEMhcc9Y5syDzxVglzHFa7v2UvKu1wfKRVs7XpZwUcZa0l6PM2ymzwa4W8C0JW2Qa0u65XHKj7CqgS0KxD5Lj7rW57Xj1veX0rXraym1dZz+kFXq19IuW2Uxfu41E841UG9dV2tJ+iuI8rnWpJzoDKVGzKbavBoPh0Ph1bhLcUW6foCrrEPWUf4K6wdkUzlOVgFrDrUcvHMIWDheXFNKgvauYMClGGNi1hehwB0lOuCkC2kG0J6z9QrqQZ2sSTK/n56FtVVHmVIOmm/meXPZS6eWMr98a+Z2gdKZyWz1tWxquZFsrdWhzKm5HHxFEahkOi9Leqfn5+eUx4EJXT+ktkxURwV+Ep1EaCmHqOZ2uoYQl2QmmMBc690mjhKYp2labQZRn6tplRK07RyRrEGYUJAsWCrwvugzV8buZwPcWxLtZXodkJbS9rXft4CwPHftea/5/lK6Wv5GOZp/uATuGgTLtEWF2IJKXYbX0j+fPqlZR11fUwMrESV6YxgHnE6nZM530M8UQnUcMQ7i2UjOg0oJu5gEyvoxgCxfs5Se6mh1s0lnFXCXi3N13RGTacQCMMwIEGeQOQSczVICYtvrQMmxhG0mAQBy8C4KeDu14CBxNIlKtbhkGSO3RGYJflRMBHY+RllcNNrHyiBllusd0WrnnliADs0zyIkVCBWCTxrTiW7JEyQafcsWelG4qoWYgZKZcQAw9AM6XwTrMnNEkgnRwSgIwINhO+lJeUOSuDOYF9/ZeG8F6Vkk8iR9K3BP05QnuVDUXczS/aLXy/3B3lzNCUvwLuthvbi5lT4L4K4B82oSfXZ1b53P6vwVIGwBXG1/+tIE8RrV/5oGcS3vVjyNrT8UwLcaNC88bzXDa6ql7ZqyKFNJrXzKhFZK2+XWX/X7l5YiYg0y4nCUuCFmi20WIitKxIt3I5EHdEHOXUjZZoebF49Km93WIlUyLdNBGZC54mxylvdtXL0/Mv8cmRE4SrwQHfjTsiCy2nczwYlL3spCBUoxJGnbkS5SMqKWxRHBhaxZGNAiSrjYRMWICwnCEjLvawt7CrRkAEjlZgltm/Wy75Ueklv9IOVVgigzOucw+xnufBYPTEcYHh9Vyg04HYQO896Lt6hJsESoHXw7jivgBmQFNdEasfSwZEQOK0l6LmiUkjqx83UfiTEmUC+vXZYFhGw73lq/qCXubhWkbJ0+C+AGtlXsOnH6R7/z5cLX6vMTgXszn6qc18rdVFGvgF8rv1b+1yTpJHVX7/aSpNzKp3SosHPX8mlRHK38N4/dmq+1373Pu7GMO7EUOR4OON2ccDqdVoBdRuUruXCQA5GHI1fUjQOv3AdJF48iFlXrI2swpmJwpgWtJH3JAqVJn3mQho268EnaDjFgUWpgCrY4GWCdW5xpkHhqAd4ILmzY123NacGwBE8io304TwJKIxAJr2+LdEYTJJ5db3ZEGHyHjvOknjnj2nLF6UKvg/MOvtiAotX2AIAIBUzROBw5tYAR3hyI6DuPEBnLvCAuAc45jLsdHBF818lkqLVgC6kEggdhtXc1ix12erRK+GlRkcvJSHhpW4hclpAk8XmeEeLaVND6SkmtlM4/Ydng4UutrwRujQPTSp8NcDtaL64BWKtTgKhcREBDmMwYXTtnXJ4DUQoKlECjArzkZkzQVV65j6o8UxlL/pGy6m379ZDlh4vLi9ek1bF5zjstg6jEWhvlRMDWTYs6LMC3Vk1Vns1gXE2ETis4WQ6oB195zq5dZ832Fkm6TKVKVV9MPiDhBEjVWSJ4R3BenS28w7gfUwjVm9MRx+MJ+/1J7LGHUawNfJesDlLb6jFAYMdgMmn10kstm+2pNBaCRM8zx44QsYQFyxwSuE3zjClEgBzCEjHNYp62hIgQGOCY3dOBDLhaKyEylsDpORwBMCGm/ReD8szmFBKzBYfVIyeiSScml/sIifOHQZgpNgbcmaJijRbIWBbGsmTgAiRMATlg8kDvOXkcJmlb39dM37yCvnMRFB0c8WrcEcmEkuifKHUFjitLDTDDOeHPvSN03mOOwDQvAAidWRKNA7y2eVTADoz07h4kYzAN4RwYjiH7KoIznx9j0OGj79eXErWVcYHFQsnAbdZEEXNBoWRA54u1jzrVgN532/D8WQA34frGuMZXQSu79dpbUnepqtWS6Cbt0CjDS5JvOVPaebHDvZyQ5JrWOzSOC27QjstbM+GwBuZUjuq61bUmjhG0e5fPXJ/j4t5Vx2u9B5CCIOUyUDEZUrLksHnYead/Gs+i89jtRxxOx7SrzOnmiHE4YOh32O/2KTyoszYmUZXLeNewhWydBCVA03rBL0ZbUAoIccGiABIiZ/COEfOcqZLzPEuEPbhEkdji1oU6bG1YTLaRVZoPhZqepH2hPSLyYLaJxaidsqlkWsjATcUVJv2WXYiZQSqGZkqopAai8twC+r7z6LqIqWN0PoMcq/22gBgn6TxyAKXNFKL1CARmOJL2SoGZYoRLGk2OP0KQvGwHor7zmKNMdGBWQFdKpu+E0wcjqgBXbJ8A8HpsmZRnAlvZbzt0qzovqaCSwzZJfes3O3d5T27TLbrSfu8+d+AGXV+crCUkbqEe2uBd8r0toK1B21e8UkvFq5/RokFscaG1SLWVWo3ZnMSa72/M5eU17eMceS49zyaU4hzplXkeeQXlw8jIDTOlKEN7QttcDhyZA4yD62RbsHE34nBzxM3NDW5uRMLeHwS0e593VCGitCAGAOzWE285oWUwVXdkhgClqboxYFomVY/VysCkShZrh7CIyjzPM6bAmCJfmIu1eUwCIWRTQANMG9BGYxilAQh4r4D70nwst+s6OmQ5+FdmgkoJcMjAXdJBQstELDHbc7tA8ItuilAsCrJKlVY+SzFmqxCnW6SBCEsIcM7DOw/4Qm1eAmZb8AuLaosMcoRew+32fS+ml8sMjnFlUTQOPTxRAmoq2r25hyTWY9k+CYAvxmwJwFaXZTuUEndpFti6t7Tvr4H7sn8q7fT5c9zbdtLAJXC3IkO3zPhekqBfK3G3Grn+bC00lNdcU4/K57QAu5VXfS2zUA7MRrdY0HbAQkomaZmQqIytctffWxTJD0mltYh3BPIO5AW0T6cTTjc3ON3e4HRzxOF4wDCIxUjfjehIdycXY2CkCHhYS1aJp4WpwYUEG2ovuahmeUuWrGOpIpuzTcS8qP0vE6Y5Yppmte0uXaKjSrc5eBFbORlCpbBI3pxspgtplqzMsbnYWXOkjiwU6NrtuhYs0iSAy0XYluQnv7FOVkuyHDETO33JojyMyEJnEDl4H5KEGwODXFCLF+W+AcQlYJoDzudZeO4YABa2a/YdOi90VAyMsMj7DOOI4+mEu2XBPkag6xLdmrSq6n3q+mthxZZQxlV+ay2IN//qeq0n3602ZWb4n4NVSQ28dcoAAtMPL/LYkojLa8rffyhVYt/r2fNTpOz6HVtA3zpXD8oLekK/uMJxIpWRt3f6aJ4rFr5e8z6N1YrVu9R16TuPfhjQDwP2+xF3uqns7rDH/iBWI17jj/Rdj97JbulmQZBM0JApgvw+Wn42m+XMSXIUt/W4yMJgjFHMvxahS5ZgKnzEHGRRbInZ7I/hJT70NIEjYwnLakEzUxsyd0Yy4ObUJla/rVorNwtA6p/Qd+FV28fULmuQWOZFpHFnUrJYkBvPzYwUqMkmdZsF7TkWtram3ihXtmgJiQqI+qNavnjxSBWJgeBCgPMSwpXIKeUCpaVi2vHegeA9I3gnlBIDIQKMgN3TDk/TWbSgGBPdyhrrOkoHe7XAVL5bee6a5myOV/XYWUvl3DxfPqfMt8yLPnfgBi6l2KvXbtx/Dbhbv78E2lvgXaZr4Hdtxv++6ZokVXJ29pstGl3kA75adhQyRMoAACAASURBVLsGBnwbwL3dXpm6WR9X9e8A13UYdQeU43GP27tbnG5vxGqk2Cm973sQPIBs9gWohKVSXSojUQIfZiAwK3erTh7zLKZwISZqJKgt9bKIxcgSogRPskWmRbhuW6AEMc7nCefzGQCyGVlhUpcGLQAmJ/G4Nwbuqg/qn1xKeeJtAG0k6KJ1KVSwgrz2F5skWFrSFuHSOX0O2SIqMRzJom4kXbQTJF/laRqCSbhpUjJqzDm4ECW+jJfNLGKUe4PzcMRAkHgmzIQQgSWwhr1Vvp+VMjBPS68LfbFYpyom7wzinJxzau3UAHnVfzewopa6twA99ceKyy6fvwXcrevc5tj6jIC75JZbFEQaADYSq3RNUm9J3a9NdRk+5f5Pvbf8ve5UZWer8xPQTmQBmO3ZgHVl+273hFY0fbsca2nb7I6vvV+dB+dDlRYlNxAErNPmBg5932F/3OP+7QNuTrcpQNRuL5scdF0P8oQIB0+usHoRsM6SdgYtK3Ppjr7M4lpu4FsGd1qWBdOyYJrEs26J4hgTliA227MsJC4xYDpP+u4BT89nTNOkdWZuzZzcmwkSzxpOqJKoC1rDIFrDNE1p+y9YHUGAnqyNrM0NPLROQZTGg0xeSGNjBQgmplvtsBpzVJN3EraJRErWiw0SZR1AAksRi9YCINEmxo9TsUO9LUaSd/ChA7Rf+wB4j6QZMrNu8kD6/E7eC2LXnXo4iwXNMAzohz55URtNk3te6qQAX9Id5ffE5WudvlbzvngWrLnWNORrNfALiftzB+5r1EYNDjajtvK4lnctVV8rS12mcmZ9DXBvqUqfQqHEGC86ABElF9qLsmrXrstfdoD1+2+rYXWZE1g0rrtoHyIkOwKyqaQ9Idl2YLd3N7i9u8XtzY2a++0xmH123yerETPlsh5AQF7sq7aXimqWlhbcQsS0BKVAQpKklxASfzvNs2yLFbOJ2xLkt3lekqPMPAnXu4SI5/OUAjmZza59EuWdYsT9W4BuHHcAgPks8aeJq34pL1FMvEgWPsxIy28JjHn9tUwSy2it/ZiEzYBwOKXZBQO2SRoRqx21gDzFvNjPMc0nKaaKLCKocKXZBUTEACBGLCRu3857sJdJRxyjnD0Y5B066vT9o9jy9728sXcYdz1Op4N4zu526DsxC4Q+s4TvJDw0BIxaM019x2qpIfC9ZuzX4+1CwLqSxzUapU6fBXADl4uLdlyrKY42euhGalX4tQppg9xluYDr1MhLwF1+b4GsgU/5zHryWN0HlgBGVl9gBQSAC2DIz7g0SUw4oNKLfM9g2KqrspzpGatr8nEZgtXijdze3eLu4U48IU9H7Hd7jBqHZBgGkEbvy/kTVjwJOJl+mZRdSlHJYmKR4E+TWn/MumvKvATMs3DWycTPghIZsM8Sl2SaZ4RFbHK7rsP5ecLz8zlrgwVwhxBkEU+l5t55cJTJypPXjQAYfdcZQaHUjvUXQnL8TmgCFCSK1AlsO7N8obR/CdW0Os7ArWOJSPY5VO3FFrK9IxAcFoiFi3NFXy6kclbQJq2DEJfUOpEKd3tS4SIwomc1//TwJH0isPgLOO9UEs9bnHki7HYj7u8P+MX9Ld4+POD2dINBw/LmcpWmgG3wtM+y/1qdcfXbdcB+GYdeq+3XmsBL6bMB7mtAeXHtJ+b9qRRH85kVbVEeb/FXdRla91re1xqr/r09i6t6qiPPBjSUs8zHCuqSc6ukCvYrtLiaag2AOSSQJfJwzuyJga5zSdK+u7vFw8MDTne3GtXviGHYJUk7g7aAWrSNmbGeHCMhSdj1NmJhybEj5mXBPM3CXbPsdD6pNH2eZ0zTjGnONs1LDBotTl3SJwFb5zwiRzydJ0zzvGqXZOLHDIoRQevFAxjVC/R8PmOeZ4zjWOgPSC3CKHz79ASX36WyE9CDxPPTeHBmTrOwTOpIM6hJluYeb71FWae0CJnnBgFvB5fQwp6RAlxBzSu9TIqIRd+M1iZCm5hAsMQAYrXhdiFpJowAAuCdF0rNEVznMIwj7u7v8PW7O3z1cKfAfcLYiykgIOsYphtGrSvH6/HToi/TuCVK9VQLU238aI+NTxEUv2/6QcBNRP8EwHeQre0WZv5XiOgNgP8GwL8A4J8A+PeZ+dur+eD1M9PW79cAc2vWfW0+1yTs8tikvDKv11AmLbWs9VmXKf8ui1PqEH2hrrUker+xsNJ+x7aSU9ejvYuZ6JbPTttU9T32+z1ubwW0b+/ucLw5pYXIzlv0t04kQbgEZLYTti38iXsyZ3vnoh3MPpqDxQJZME/qqm6Uh9In8zwLTTIvmOZs9reo9ci85O8xRHSdxPgwmqVUAtNEA6F2ANZ3l1grth9iMl0LIcWkIAUOEZ4Z0SxBKoBoAVEtWFyb6K8JGK18CIW5rgfshUnfgbDWpiR8q1JXBCVeAEfq3GJvJCel36qnKQjpGu88fC/1djqd8PbtG7x9c4+HuxNujyfshyHFn4kpX53ISTQzIki8lQtBZ92HoX3M3qsE7O26ap5u1udLmFZjykvX/xgS999h5l8V338fwP/CzH+PiH5fv/9n1zIoVfFWRZmUcDWPKxJrCd6WPgW0W1JyC5S3QLo1WFYdprL8sOMySFCrXPaZqA+nSjGJOSCp9QUphykWAypZcNzseLm8AMCyYLQF3IQUwCmyBAzyan5GRMn7TRYhewzjgOPxiLv7OwHt0wm7Uey0+25Qpw3ZRR06+GwgE5wAgtEgUSTnGOOFl2GI4sbNQZxoljkkauQcFsxTkBghym/Py4zzvGBeeLVoOc3i6h5CfpbzHrxwokWsLmyCIsoefwDpZCWaxMfzs2wEQQ7LMsP5rtm3JWxrKdMl5T9fI62TJGaZ1Nr9sOBKgAyd634HAIiZ44Z5mcY8CTuC0wVwybswEdRrvHOy0BiC9kUzt1NzSLKpTSdl7YvJvlyf03Ud9vsd7k43uL+/xbs3b3B/e8LpIFubiYNKngjKPyoqdUvibvXnkipJfVxuvGyjOhtjtpImkydj4pK8unhyfr7ea960W+mnoEr+LoB/U4//SwD/K14AbgA5pu6V2aZ+jRbA16lWc1qNUp6rHYFaoP9SqgdNObhbqX7fxLldkcYv7iNboDEVGkliTcQl9BK4ZEInfyYxWn2o6q3XM3PSPVdLODoAEaOETiWJM+JIFq68A7yX3Uv6YcBu3OPu4R73Dw+4vb3F8XTC8XCDvh/RdX3ayYYhMTucy9YCzIwlziv76OTtxxZvhBOIZzfumKiOEIE5sID2vAhNonG1yXnMy4zn5zktTArVwsl8sO97LMuMft/pNlhLqgvTspkjuq7DsixJ/TfQ/vD4EfAiiccYhaonKS85WnHOcFmazYCQepg+K0uuwX5zUG/QcKEBrvqcAa4DYOCvkjVBIxRSVOpC+zJHY9T1fck6ouQXAc+EsDB8kPdk6yQqTEhX9UK9EAEQ78oQIhYKiAiIHABidH2H2+MJ7x7u8dW7B/zi/hb3pz32vYN3gCPhxGMxEUko3LY0XAo7La0ZEOqgFvC2aNwLQTBBWJ4kqGg494L4WUv/167+ocDNAP4nkhb5L5j5DwB8zcx/pgX5MyL66lUZbagzW1LqS79tpa1KbwF0KQl/Ck9V3rNlR12nlzpLeb71LDmuLUWSLFTIRa1nrz/LMsmANccGrIGbOcUCESnTq6TPcB5iETD02Gm87Jvbe5G0b4XT3u326JTP9q6DyHKuGFRINEkpTQsoqcStAXxiFJtdAavSI5JTkKjJpOtZPPVmXXRcQoDzlL0ji0BL5Wa7rT5a9zsisfwZhgEhhLThwzRNAiYqlUeNzU26tZfZIWcBr2gv1jZUsAYDEWLBkbXVy34he0teekQCEOB0uX8IrFSCgkq+CJz3kzRNrBJETcaUeceBS4sTEKChaO15rNoYUabQAgcsYUaIQO8djrsdHm5v8O7NPd7c3uLmsMM49OjUlJTcWpJO79aSjhv0yBZ+tKTzlyT2axq03bdlUtvKJ4o6tZl+KHD/68z8pwrO/zMR/d+vvZGIfg/A7wHA8XgAcFk5Pxapf22Qlb/Xx3UeZdla9EeZ52vzLX/bAuXXfBIuO8FrebUtOih9N0lcfszgnQafUjUkVhOOAOeBYRiwP5xwf38vMUfu7nA63eB0OmEcd+h7sdH26gmZ6srKQEjScwLSEDR6X97vMUZRt2XDXk4eh4sCt8UcmSaxHJmWJZn/LQr8yVY6ruN31JqThUu141adl+15OBwQo4T6JK/R9oys32gjkX1NnQFg7SMVkwBAv2qbaF+AbqZMAu7JlJUBJk4RBiMzECD8ryOlQwAwwZwc2UDX2sMAu9o7UyZcKL8cQeQRnSxpigmkeEiKW35BH5ABcITvHBwTvPPo+w7H/R5vHu7wO1+/xddvH3B7c8Jpd8DQORCtNdKtfn0ttcDbvrc03a22eu1zk/ZUny/G/Qr8KY+7VvpBwM3Mf6qff0FE/wDA3wbw50T0Oypt/w6Av9i49w8A/AEAvHv7hstZqq60HyJpt6Ql4JL3al1z7Xkt76jW9zq1ZtirgNxQ0Vq/U3VN61n1O1zTalbvwVkVFTzRZ6a9BoESuDsvTjW7wwG3t7d48+aNONbcnLDfHbDfHdSxRrcToy61R/J0Q94Rxf7mkIM/JccZBV5mieQXNVKdLUgGdfhbYhTQTnGnQ1qEZAY6XLf1NwC0zQEApBCnZX3be8QYMY4jvPf4+PGjtDM8SO2inYKogbTFx04Ulp5XokjBDgLQsXSu0rbhol1UUnbsJJxt0Z7spCWXYNOvhgEw+gUAI/PrkQGwxibR55SA4pCDW7HcieDEooYVxFNf0/cq49QAgHcMRwFd7zAOB9zdnvBwd4s3d7d4c3+Lu+MBx3HEfvCJUvohoF1fW/f5eozX4+QaRmxhSGRO1i/1fS3BSRZKt8v+vYGbiI4AHDN/p8f/DoD/HMB/D+A/BvD39PO/e01+Wwt0ln7IzNoEuo3PrV1nWvmWdtZ1ebak8q0y189qUTTXgNtVeb02bXWc1XvUeVN+tgXOt417x3HE8XTAYb/H8XTC7e0d7u7usNfofn0/KKed94BkuPQc6bT6twLhkMDaQq4uaqERlB4JzLrRLYQCUWeaCEJUd/ZpmvXeRV3dxZPEJMG6vsu6DiEk6wkge/vWfcy+Hw6H5DAlUfq8BmkikXw1tKqEtVUqxIKwI9tis648MoTD5fR7YeoXc5nZ7ialMhKTkidF8roLT4xAEG9RdaeUvSAVuU3QrrVg5sIcsI4+GCLYmW16CWSc6s/bBMcSTtc5h91wxNs3d/jq3Tu8fbjF/emIm8Me+16iEvZOKJbAl7Lo1jh7rZRcj8t6bL9mTLXG/EqKvnZvziQvsl7Btx8icX8N4B/oC3UA/itm/h+I6A8B/LdE9J8A+CMA/95LGTHavNDqmu8J3GWHu6b+tGbVl4B76/l1w10D6/LzpfPXUhqbuKRoWnnX5S3LWne6RLcZEJDZZWe3dd/5tEvN2zdvcXN7KzvVHE/YH44YdyPGcadR4fzKG9LAwTzuOOaJMXPVGbhnixuSQDwisDl/sNIjEmtkCTFt/ZXujSyxSMxFm/XdizAArf5ClPeqrL1a67odhgHjOOK7775D3/eIMcIraDkiMOmGA5A69S5z2ClaIKQuQBB3d7ULdxqzw1pH2IuYOkLWwSotidS+n0RACTGCdLPdFKJU6wMx7y8J1QYcUQIfo8hs0+LU30i0B1doa6TvyJB1j74jkC6AO2J4T9jvB7x9c4tffvUWv/zFW9ydTjjueuyHQUK7al0tyK9ldV5TWltCyJYwuAXeW3lsTQqlpN4aSzWLUAtM5W8C3M3iAPgBwM3M/xjAv9w4/w2Af+sTM1u5cltqSYLXKr9VCa0YKK3jLfCsjy+L/rI0balWver8P0XNs+tLqqQu5bWOstVpysWs9QSiHTHFfUYy87Otxe7ubnF3d4f7+7V99jCMGAeJ8JdMHCnvQgIFTpBRAwU9ohJ1Au1lSbbXyewvmNOLCI1lfOTA4mQjpmcu/R7UYUfA01zpcz+yclp9GFViwe27rtvsc845sdnW9ra8Oie703hni3IOnZN401KXkAlmyRSQxJThpD4TJEJe4GzuyTGql2Nu60ZvSRMtE4GdPN87wuKAMDNC1MBNDJhphnMkMVOiPN8BGmkwWyQhMezSE50TYHak6wIkXpgg2Uex91mr8M5jt+twf3+LX371C7x7eMD96YSbwx67XjdLoGKHrMiJcmn14VpSTqXa6PstULaJ2dr32vhvYdTWX31NOe5LDBLgpjQ1t9Jn4TnJuHSbro9fmk23GqyulFbepWTdAq2thvsU0LYytjSAFpf20mTx0rWW/5bEcU3ybl1XdmggO1yM44ib21NyqLm/v8fN7R0OupHvOIqpX9cNSrNkGkDy1U/KXo8mbadYImUgqCCb6s5LjpktYUAlL7ElN7NA2R5sXnRbAmYsMWKeFw3OpA/W93SN/RHL940xrnZUqjdktvqzvS/NO5IUuDxYdqnvO/RDj3EYMA69eP91AqKsMcGnacbz84Sn8zPOk5ooghXAuABpJEed1E68HvSpD5As4iZAhuzM7qnDAvEkjQhiaqfWekaNMQEWUkQrLC2gXvQkNtNG2U7M6/6R3hN6e/+uR997DEOH02mH+ztxY7873eB03GNUN3dScV20irb2aGOoFTa1vnbreyu9pBGv6hZt0C7LlIK1qUTdAm5OvxOu4PbnAdzgNagB22qIHbdAc6vBrgFWzWOW323W/T4S9zWwfy1fVpezlhheI6mXk8JrAL9OVh+28axpMOM4YLfb4Xg64u3bN3h4eMDDmwfcnG6w2x8wjCOGYUxekKR7Ior8SLr/YcwWEpzpkVBx2rNutrqozbWZ9ZXcN6u0zQrctomvhAkNieuJDN1eTAc8y0IaiOB8B6Ipvbd9llxuDdytNrAwtNM0pV1TvHcYHGPoO+x3OxyPexyPexx2I8ZhQN95eO8AVvf8acbTecLj0zMeH5/wPE04nyd59yUqf8/5ncx5JWO0flIx/lVqFQ4EzolFiScP7zr0HgjRJTCWUK0AOwVuLuzqYZpDfpKxMxLuVTl4JjhP6LzD0Hf6/gP2ux3244jdfsTxuMfpeMTdzQ0O44hROXCbNABSk9A2eNdjcMt+vTUhb42BerxsCTP22cKnFWhXTmJ1n2me+9wlbuB1/FL9ctfA3NJrpe3y2P7M5OtTyvZjppZq16I/9EshDL3sMPQpoJ3BG8kj8HA4CDVyf4e3b9/i/v4ON7c3GiTqgK4f4J3uBaiDRKcQKStTojZEGskmeHMByAba4nouG/ROS0y7bC9Bd0axWCUxc+MREibU8vJO3OgNBIR2sPuQwHyrvkuN41p9DsOwkrrMhLDvgP2ux+m4w+3NEafDHvv9iP1uRNcJhUBQuiREnOeA81mk7sfHZ3x8fMLT84TnacbT01SYM0aQI4QV3QOYBUjRY+T9AI0DonQXCAIF1kJmUqnbt6nXqFFaVr+kGwknGxgCoLmRxZUhhnciaR/2O+zGHof9Dof9DvvdTrcfk+P9MKB3Ei2RI8QCRqMXMpVRJ9vCVz02rmmcNSi/JGhtCUovYdAKwKvz9uxaiCrbbyt9FsDNfMlxX1NHto5fmmVf0+ClhHkNtK+V59osXjZUa1bfUs/qZ9adyODkmtayVe66jHVZnKq6nQZJGscRb968wdu3b3B3f4eHhwfc3Jyw2wuf3Q87MfHTOrQymTcmEWkcIgKxgG4sJGyTrqdp0ljYAtrzvOAcAs4a2S8E3R9RvRsldoly3LZ1GBHmWeiUvkfaDsreP0ZZDLQNb+sBv6X51M5Z6wnO4fn5GQAQlkV28HGEcfQ47EbcHA+4OR4UvAbsxl53MnfovC4gMmHRRdRpWXCeZjw9neXz+YzHR6FQpkU0jzmGvBawBIRiNx6Ry7Wc6m5v/Vs24u3QdT6FLoACd2CxmV+i7LkJhuxKX9Q9oPxzWqQU8dwZBw5ZfBy7DvvdiN2uVwAXt3Xb1WjUKIlgnTRInb60DaPLfcdtjPPUZ639CtCsx3g5Bl/CiLIvXAP41hiqr3mJLbC+hZ8Dxw0gOQaszq2+8OY5OdS76xkPQF5VT8oigMzfEWWnBRKxa23pQqZiVo1mM2N6Vu5cq0bjfEC4HOgWuyFxidr5YM+sj0tw1vOmQpYlbHWx1GHTFbWEYAtqHuQkaL33sng2Dj0OxwNOxyPevH2Dt2/FeuTm9gb7/QHjboD3HbzvUXpxWvHTJrPM4v7LwkNTlD/lS2QiV8l7DovEFlkWnOcJ5yXirIt3BPN2jJkeiZR2SgeLZBmDmBYuWHRvQoc5TEl6DmEBa7wMcY6Rdo8hJrMsVmqHGcmVnsghciyAUBf/YsQyz2IJ4WRZdOw6HIYBY99h7DwG/fO22KsgBRZzQedkx/uu6zHGiP0YcdrvMU0LpnnCVATMCiFiZg2EZdrJPKct1qDQLZOKgGuKqeI8us6nTYXLnXuypYnw6wLcEUFNKWOQTSNQvD+RQ4hCRVkP8N6hdw7jMGAYxGR0Nwzourz4KE5BYvHD6rwjQO6Ee0mDxAaU/El969iBOIMyUbqCwDpsbazqJwkPb3ViGoOFQG5psoYvCZiLMbX1tx5b+a9M5eQgPgkK5J+/xI20m8Zr6IdPolUMCLFNm8j+hRZIB3nGru65nLXbZVGsvyibOVkQ2Q7nRQXUnaH4jVGAOdEKkE2asgmqJY1fSAlcTmCEYvPA9GTnhJv03mEcBwx9h+PxiNvbO9ycbvDmzQPu7u9xPBwTp911vfLZvniTVCspXrg8SuJeEHP2qFP6ApwXcmZdjDzPM56mM85zwNO0YFkivO8EkENQE0KjSnK1eqeWMpGxxAUEWYRk5rTZQYgLQlwkVgoBsku5S7u7m7YQmRN1M00LIjtEDvAupgh/XdcJoMUIck7BWUK67oYeu74TPtskVAAatARg0rJn8OicA5ND74HY99j1ASGMau6YTSJtdxyxT1+w6BqATErrfiBSMdI5AfLcXuVCn9EtCSqZk+eqWdwkQUAFoUUj/ZlZoyOCJ+G4nZMFUUrdTeLIQ7Wl4AFxv5f4KQRIXPk0DjLPbaUyZyF7BSaA1VYehXUI0NCkiCT8gAloZdgIorRgDuR4SkkTtVFzRVPL+GA4ksuxxiu79gIBmukzAW5WySB/Lz9fm0fzu4i4ctgA4Uu1CVevLZOBd5221CmH9eAoF0heonnK93oNP/1SWj/P8iSddGwhTkz99vs9joe9LkC+xc3pBvcPDzio6/putxOPya4DUaf5X39+dhsXibilsq5olhAwT7Ps8TiJ1YXTzQnmwqpEALyYOVWSLgeWWXo8Pz/De48QAp6enpLUKXSDbJAwL6WFAEtwqRBwnp7VeUQsTaC7tHgClnkGOCanpEHpAHHn7pMpYQwR7IUmFNSx6NwMSoJEEXEQQF+YIZZ/gVk1AlYaKXuYlklAtgwitl5IMzC2Ty400LLvbEmWUhYFbj3v9LnmOeiI4FhiZWu4qdVfkZlG1cvSbkyIb1Ip502yi34DiOSNaoGwLK/1ra3xD6zj5FwD7vKzzldKrBrgFfokS93XXHUkfRbADbCoV3KIVcN8Ui7p1lRRNi9vAXEN3OZYIv2Vi+M8I2Ytak2V1OlCQtd70mKdUjGtBa+aq96Unr9nynN7fgEirHaoScC92+N0usHdvZj7nU43OB1PGHe2xdgg1IrZZmcFIj/vysS04hpJ+FLvnCzYdeI151RK46i7sp8nGYwMLLPQKpwWGJ0uinqAc5B+kyStPEH5dGbG09MTDvt9Whx8enyE8x7TtIgkr209TxNCjLKzeylhdR0Y4hI/nc9KQxSehS47KwHQhdc5S7q81qSSJlgBo5X9YqIrpLiu6xLwtiJTCg2UwawEeasXoHAksf7Sai9cApdLEbixmsG98raOtH29R+czbVNSEKvuU+QRY9YKoW1CxSRhUrM4OXGiFUsw3KpT6TvrOCihfHZ1X9KYGukCkBOGvHxt+vvcOW5m3byWy6JeB8U6ZTBd32+crXDcKlGmY1bVKBYdx/bby6rNepCsAXRrcqknBObsQFFK25ZHS+oun/FjAXbKOz1DLAPsebZg1fUdhqGX2Nl3d3jz8IC3b98Vkf0O6PsevpPIflJOIE+6l89sSWiASt/McMzw8Oh0oJUS67IsGPoe07SIu3SMOCt4T1PA8zRJgCmdXLuuAzkNeKXgaHk+Pz/jcDgkqdsA/Hg4wOnE8PjxEa7zOD/PINUOQJQAe57n1Ca9bp9ldRhjSIOaYzQGQTaHKMphICk02BoEDMxa0ld7IudVuwpfzRLmlfliNcOkU/IeREBQl0Rpn5jqMu3Zme7OC/fZTDJraznv1Ohp67KybJ33aWKrabWSXrCFujSetYyENQAbxZbeT52ALOtSe7lGbQDrfhqK+g/VPb5o8y3tOOevf8gTol1Txz0qwX4rfRbADSBJAGX6FIm7rLh1I2S5krRHlceyqEGJmA667dYWTVJL0a8tkxYmL3RUHeU1+f2YaS09rZ/tnMPQD9jvd7i5EVrk/s0b3N7e4nA4SpAoDWTvvStGaX6fVtO1OuiKa3UOXvnKqNLO0EXwOMr9GhBKJN8ZYZa4I0QRy3TGNC/qRYkVsJR0Q50+fPiAZRF+ez+OGPsOS5jx9PQI7zyepjO6rpf+SYRpEmk6LAsW7TOyOsZ5g4dlAXmHGMUu2xHpPoqUeHUAydtRtAlCLCRZ0w4sqNUWXbeSpO1cVIpBJKIEcmWjsE4e6fleuGIHYGax6pCdhSJiXBKAySTjAHYaHMzp4myuYyqshzIw5ftLCiyEmCxQZL2adSLgolsphcCsrv1rALUdbgh5AZxAgGONUMg5Lg5f0ib5ry39RjUZDbVrfYETdf9qTQiR6SLv8vr6mdfSzxjCAwAAIABJREFUZwHcpXpWn2+lrdltK+/Wd4vsVkovzAyxPOEE7IWPX/qeBxGr++92+V6SllcdcGNQ1ufb8X7b+W9J7bXUlsCkiMVhW4zd3tzi5nSDUXdf90MP5zrVVmRRzuITGSeJquNuSdsMzvcCungoknaWuyhJVLbTe1gk7N/z+QyOsunu8/NZHXN0s15yq/cyd3Vb0Ht4eMDHjx+TxH0YR8T9TtTsGPCb796DyGF2E0BOgldNE7oUX1sWbw2s+3EExwBxogkYenG+6bsOQ9dhmWcQXHaX10BTIQQ4uBVwl7FQtuLC1/RH2dbXgKHMt84HWE962kir+0otstWHiCjzv3ICKMxra+ElhpAmbQJhWczCx9aQON1nFALlLgZS+kUmP43CR9pz6DIA2Fa9WJTJVvA4e/aKJy/aqx5fLTyKvG6f+vmXoP6ZUyUAmkHGt8p9jftp5ZGVSYEHoysIsrO02KGuQU3aoPKc0sZalSO0g6aXf2ngFcW2xikBtKRQtgC/vid3GgC0BuRU7tV15tFmF6R/UnllyygBbXFhV3O/cScbH3SdbPxKmYIwpxYtZBO4rzRRBqsoO2d2zoF0wS+p9YBKdzK59F2HD49PeO4nMBPmeZFd2EmlxiULAwKyPtW7Ae84jvjzP/9zMDO++fWvsdwccXu6QYwR5/MZjiSUqOs6gAkhLOiHXuykY5dMAImArvMIy4wQFhz2ezgiDIN4mDJLfJSuGLyymKj8O6sHZ9VmdTiEun1XwCkHSbPjSqosOWsC1MIu8xvW24jM0cohBOGjV4uN+iz7c2Rx2QFiSNuVIMmijZilUF5/ItlzMgIuRszRpmh7J6EtSw3Oxn4qq/UdBXOxENPyFJtU12OppCqtXqT7XU5s5buU9UjOZWl/o33W/Xy9ZnENvF9KnwVwi2r8iTe8MjnOwJBFOPXMUsmaHYHVssHslF6SlFN+dCn5XKv41nJGDcIp/8bvrXtrraEl8ZfnCST2x6qil2U3Sfv+/h5v3rzB3d0dTjcqbasrt0hOkAHJnLbNSp3uisvxpVaRsCZLmxAJDcxglZJNBU7RBYlkcavv8DSchWdWdf3pPMF5j/M0pbglzJwWIu37r3/9a3z11VeJlvjNb77F2DkcD2JF85tvv0VEkLjWS4DrPJZlQucP6g4u/afvZHME76X8sq/mATFEHA47AOLp2Y+2FpABwDhuC6RUap9b2lKr7yQw3ZC62VxD9S9CufWiTwAM75SL9gTuhBIh50GFdY1zEk/ctqbzuk2drSUQ57LarkQlaFu8DgDgoNuuFdJ9ErGohHGosFFSKPm9xXnIwce8wQUxMNA6yNwW5WmTg22vZvRIGRGxrG+7pqzz61QnpQiOrwXvazD3WQA3cF0i+0H5QjrlpYR6aX5WphZtUQ4KuYgbMLydCLTZeepnlN9folBEbSs0iwbQlxoAYJJrVodtM9/j8bAC7ePxiN0orsl9NwBEiLqvkgzE3OmjOlG5Qs3bKntZKwba6X2h+x4y62bDGvfa8ogM3tmgcfCuVzf7Ht73+PD4KN6FT0+YpyVRIyVQhhDw+PiI8/mMu7s7fPvttzifxQTw48ePePvuLf7yV3+JsIg9NjknpnhRNkjoetmJxTtZnAzzjN5LHA4eejhy6HrCbhwFtAuPxbqNpVzIXHTRZuVOO1uqOLPw70kzaUjltdQYYrjoE/XYSJE1izzL38uY6uV7mfNTVK1isQ2dFcBtkU8mEGCpTBMNrFdaBEy6z+aFWQujZB/OxeIpMSNQDo7WGktlHxUBIr+neYRSjJkCxBp4y7a4DtxAXG3L117TWwH6FUj8bIC7Tlel1hcqaJ2RSdZr6WVbyhWoryXVpgSJQnW7Ih2lxtDjFh1i50uLgwtJuTF4t+pis8ypw+dBK042I47HI969e4N3797hF1/9Are3NzgcDhhG2WKMXKYaTL034BZXc/Gw6yh7iLYmzMu6aVvUpIEJgEnM63rfAb3mBQI5j64bMM2LAHc3YPfdB3x8esTuaY+nx2fM84xpmpIrvYH3siz48OED7u/vMU0Tnh8/JMl8t9vh66+/xq/+8hv4TmKc9N0AADgcDtjv9wm8+r4HIuOw32MYOpyfnzFNZ9zenNI79H13sR5i7ywcN682qi0Bsu4DdWJVW0rgrtNqMa5e3CuuL30LEp1ABKf27uVv9QJw7huUQhCkQGAxps8UkiAyAjR+egVk6z4vEzSRmBR6KuKBE6mHqlOnJv10ai0VY1o4Lcu6pf1d9L+iHlylxZQ3tKToizbA+vcW+G99r9PnAdyN2ef65Z9wLQqJm9bSdzk4UkPSJVBugb1wdevOXwN42UFCXId1bT2njI+yBdgt7YBcNseqryk7oPHt8qpyn4VnPZ2OuL9/wMPDG9zd3uFwPGA37tD1Ixz5htooE5fEt852roFEWkGSoJHUTgPqsn22OnA9cCyGhUnhXccYGbBNEn0vkQidJw0ZKhPO+TyhO58xz5O4gi9hBeBd1+PNwxt8sywAM/a7PeZ5we/+7t/E+/ffYRhGhBjRdwMcySQ3DMOqfOM4YH/cY5kmzJPYZ9uGwd47MWf0fXrHGCMiya7iYg4JkewqybjVB1aaVtkYdt5ENV6DxDrEaG6BTEFcro/Y+5Ujrpawy/LECEzLrADNKaJjjCGdk8+QpO+l8FAFbF/OXAaLgeKcgjYgoQKs34PgncX9duLG7zQPdnDewbNogq54p5YgxNzugy3AL+kMLv4pz5dUDxfA3cSwT8C1zwO4NbWkrpeueSlFKBgXS5QibQKAxglJVB/DV/e3JO90nMyesmqH+phsAUUHocYqpqJE+mgQQfcctDLlyaa0SS1N6Ox7dqcvBrpeamZfMYS0A0tEFFW36+D7HofTCfdv3uL+zVvc3r3B/qAb+uoGCLJlVI7mB5W4S6cWUimYI7BQmjK1chXMydoABdDIv3UHt/fJi0cOzjOACE8ecJCB6x0cCQj0nUfnGYMnjEMH9h54noC+A5070HlCWAKcAjgi4/zxGV//8pfgEDGfn7DbH/E0zXj7i69xe/eAj09PcF0P14vk7b3HbrfD49MT3r57h3mZcH97h857fPf8hDlMOO0P6AeP+fmMYb9DDGJWh+gQF43jRy7xvQsHRO8Q4STutpqlOidRFDXWXu4L2nFc6ixlZ9J61H0tJXxu4cYOQogZeGSBTUHTxRQ/u5RoyUk4wRxMysvaVMwemzEAS5C43rPGTLcJUkLpknLeeVu5EIHZYsuomOUcF2NGgNeRREB0cHCO4Uh3FHIOnuR9iAgeEd5HLOqf4GOxtZ6XhW3vHJxX5zdy+n4AR9JgWqZN2thVzZQoxUEJqm1mK3MTQpBj5Vhz2D9UCHoZYC4oEdI2ucaVfFbAvaXe19d8n3zXJ5B5swvJt33P9efS9nESMGXgrcRi2MxdnYZ1gpg0BKM3tspSaxGWxxZt47x0bOeB/X6Pm5sb3N7e4nS8wfF4xDju0/6QEgcjrCx/tiRlIlls4kKKS5JEvbt5o63rJZlS4o4a/6PTbpu1JAJULQczdn2HsBvAHLEPQKC8i4ojhzAv6HyH6TwBLIPwPE346uuv8Sd/+k8xBaFKGIyvfvk1/r8/+qNkNRFiwPP5GcfTEdM8pZjUx+MxTVAghjftxgHLMqt5nNfgVBHODYAjLEtAR7pYLnuGybuyhNFl80NsSHxUAgdlYWHVSIXIJwuDGigrVpIls8ZpASh32lU9r59vsXpiWgAOGldmmhfd7EJiyhhNIhRKXK05LBGYQ164NIA0DdIT4JJtN0BOTAWFGokJuK19IxFidLLLPBGW6BS0xdzPOcmri6UUT6Ag4gSnMZntt7foEa2dBNo2gWUQz5qPdNFY3JU/SYfGtXFQp88DuCuV5fql7eu2zrd4MzvepiKu51uriK893kovXfPaumlROlvJObmu8x1OpxPu7+/TYqTsWtPp4pQALBfP2FT1rpTJjq1cdRmv0SXlmoB3TufD7JTCEeC+TxJgPwzYRdmH8sCys/rkCL1zODuHuZsxnRc4cimc7OPTI3734Xfx7t07zMuMu/s7PD0/4e27t/iLv/wLTNME58Us7vn5CXd3t/j48QMs3O3hsEdYlmzd4D2WRbw853lG33UIMcJ7lt1+IE4yEfKdISZzUBB3CRhNEnZJ62hTJXSx3lKmtDiY6JK1aZpL2p5qSVgvXNcbD4S4zjvYZszzjKd5Vol70f0/OW1eEaIsjAp4s+7/qbSjlr9zGmnQEZgcXCSJ+03FJxGi0z9SCsWJLTyTAydeWj1Qg9PQCTIhsPdqLuhkYpeXQ3IjxuXekbXbvI0NVOO97stbYyWBNlEOsAaT3n8OwA2sBqelzRf+RPBu/dbmDit5+QWAfu119e8tvvJSqgHI+YtrrtVJK99ryXuP/UFM/x4eHpI7uwF3ivHBUdRu5k8C7tdMYFuLMtcWKzki7bJS8rBpwwIAPAwSx4Q7dK7DMzl4OHgQzuRADOzGHk/PzxhoxDRNeHz6iF9+/TX+9M/+FMycdrD5+uuv8Sd/8icgEpB+enrCV199hb7r0HuH3W5E33mEeULnPIKXEKa28800z/DOKXCLFcayLMkzsnzXBA6MBFwte+K6bmLMkmg5WdZbegkAXbZjxiGTOWNzQY+TZYTw5CHqdnAaM/w8zzjPskvREmyykGvk2ELD2kbQYlEjC6a6/sKywCn0oFASFqCtpAQ5ENiJ0w07oVOcI0QnYO/IwSn1GJwTbUcl8eCDSNvO5518qCQwgRq065gukUUTSvRHNfbKa23SXfVnZMnczJbTs38OwG2zzk+S9wZ4tBccoWzGNujWx63rrt3z0rmX3uMlOqkctNeScw6HwwH3Gjjq5kYsSGRz3wEWs0TMoyBS9yuB+zV1VrdF+dk6n96rfH7FD3rnEBUIu67DHg6MBb3vMDiHnsTPU8zHCqnVOTAxnp4fcX97xJv7B8zThOPhiPPzM3751df47rfvxSHHOSyTAPFht8M49Oi9A4ExDD3myWOZZQHzfD4LB5zWQhyE1yZwiPAdqY6cqSRSF37vCOwdPGxFQL10lVMGdNw4CS1rsb/NPt/AJG2gbH9JzttOtkhn7WTeqiYjMst6QgixCLsroXfP04QpMOYo+4Ea3xuTVQlrDPWQnHI4ErhY9rb4JKu1KANsJpTekBxF2mZdnDTTQOPozVfBQNoomBCUJvGMzpVCj/wR4aK/Ry172mVJqc9SeLD6KyfLFLRLhXOTsKHgDcZq0Z9W+kc7fRbADWRAKtXAFgBtgcb3oRteel4L6K+V7fuCcnlPC9Bek17STuoy932fKJLb21vd2HenoVnLcghAMrWfcY3+uHZcl60F3vUkYVKKTfQmHZIOWDiH6IVLJAB+6AB49OTRkZhzgWWRdOx7PD2fwbsdlhAwjgMIjMePj/ilStjHwwHv37/HV+9+gXdv3+Kbb75Jz+2cx+l0kAUvAoCIw36H56dH4eF1z0nz3mQQfNdD/GDMekTcu9lX9eIIUc8xNKoeizOZucVnCsXslCVEKtFaWrOJI28TpxXIdXu0x1QJaFkWF0l7DgHnZcZkf7qBw8KyB2aIEWxmoixgbhL3rNIrWOgMM1EUOsRpUKoM3IlSkILBk+yiZN9jzPy48xGkHLYny5MQnG63RhCp3BG6yEKb6EKoxeMutZtS6rb6ZBZOmxrWNa3+yzqG7DoPSrb3Fo/ekgMQTRzfSJ8NcH9K+rGk8xpU6mxrsHsJvF+Sdre45+3vL0u1+fiy/JZCCCuV12Jsv3nzBr/4xTsN1XoSlb/vV5xmjAX5hm2QLcuU1+O337HOq8yvHCg1cHvvsfNetzMTusERgXRTXkKEB4nJGTN632P2MzpP6JxtWtvjPE8YdyMen5/zLvLThPP5GY9PH/G7f+N38OHDB7z7xVv89v1v8M/9838L8zJjWWYsy4Ln8xNuTkd8+PAdDocdOAQQR/RerBcAoaLOj0/ofIcYGcMw4Hw+JxpqnhYxGVxyLHoiAkUBdULmor33iTIxxxhrVwApCmJJGxmFUtZhctfGdihVkUTXv0dpGKGfloBpmjCHBdM84/k8y648IWBhxnleEgculiNqfsgumQVKcUS2lPfiRNWwiNersVYOBWJeB+RiWaQkFsmbgt0r1kcC+pmrd0457ijbw3Uhat3FvEkxcvnXwF18B0AF/XVN+AghJM9J4+JFh8mWO5YW1rq4GDE5fR7AXc1YLcDMl74OtL8PuJc8n+XxEhhvAVLr/msS+eUE8fLz1sftfAEk2sM5ia99PB7x9ddf4927d+sFSZ+7Q+qcbCv+MXXel+qAmJoWLVupBd6tfAFVoxXAbU/LaV4Sh+idXLPoXoxgQrffoR96ODUf7McB0zxhDoyu78RBZ55xJoD6TmmSAw77PXrvxSuy6/D2zQO+/fZbWUSMEcfjCefnDwBHeE9YwoxxHPHhwwdZRI0yhYUQMI4j5kWAzrhuAKBlWbmAuxTu1IEsGiJI1WzjYjWmt9EmJHvGiJRJcMRqfUHrhWUFULkl8+ZZkrXvax8E5hwZL7LZZqv1yCyLkLL7fMAchMfWxoRmK0K+AXDM/Su1cNF/qTjB9q9RN0bXVLAW1PWUIsRM1PqLmnQQxNTROQlmFf5/8t4l1pJlW8/6IiIf87HWqrWq9q69z8O+x7K5tmxLIIEshBAg0bVEC2RaNCy7g+SubTrQseQGgo5bbljGDR7uQQPJkpEQHRDCBsnyxb6+9zz32fvsR1Wt15wzHxExaIyIyJy55lxV5/haFCK3as9cOXNmRkZG/DHijzH+4STRJ4kTT26OwUz0Sh5UYtRgoRw4lOs0SywsRd+Wxk2RXAi5zuPkT548noqqTraTzFR/p7aPA7h5OtX+dWiCX/c+8H4a4sOt4vPbKQv9HPDOOXdjlg5ZH1K2Y8DL52TLK6vjXV1d8fr1a773PfWguLy81HD2pPWRrbRcpjzNjbPFyfc9//I5n9vOvev5ADT/PrskOucKXz2P6AzJ/Sw/cwh53yJscFWtyXV9gw+RVdvSDwN93zM0DWHU4JlxGEpE5cXFBXe3t3zv888Z+o7KOe7ubvnB916za5RiqZyl63radqU0jbNFb1pipG7q5G6mvs6kKbsv/Gd6LkBzWVK4UYG0yJZAJb0fP0uwbTk2EE61teO1ATk+t2hqP3U7zDRG5qZzKrlx8PR+pPejJjU+8ulPLTKTtSKqYZM0U3QBUsums4ZpZndEP5DBeoqDyJUyB2+9VzoieYFXYw/ShHTGgRtcCCmQyxYDQFOsLZ59ZmnPdbS13IZop0jnPBif8kYZQ1BaLD/zbGaUPVrKjAelSiL/HwBueGpx/0GC9ymwWzZ03X/6m/NW7vO0yLnB6NT+E+tejimK5bXnZdC/z3P0GcQ2mw0vX77k888/55NPXvHixQs2mw1t2yY511N6xarLLDKT0n8fMOee8gHbc2sZ81X4XK4sXl8CHIylcRYxahUioZRTtazV+rYWVqsVdV2rdT0o1aJZdiyNc4xNXagQ0NyTl5dbjDEMQ4e18IMffJ+vvvqKcRwYxp7Liy1D3ys9IkrV1JUjhqCZaCSqz7xzuqCX0CxPk4MPR+1BPRWCMsrOHEVTzs97Mh1fWGjPzVwkg+jcmJApY0/WsJ/qfQIwHfQ8fsyfHu9l0qrO707SdTJoC+Ts73poSuSns4hpP6t1lmKbyQAxhUN4aqxoL9A2m/uEqJrc7NpgoyFYtXSzKFWxuDl2ucx1sARjbR8cGTtzuYp5my2+6z6W6OIyC87016xPRZNmFP9/t7jfR1Ec7XOa2njumr/OJrMXN7/WU+v8/O/PfFOusWx4WfHv1atXpymS5LMtkvIgzhponqrO73rKojsuyRQi/SEzmyUwLcF8fnw+xZ6urQOFRoU6XAKXkCJFYVJys7Yqg5SGmksJ4qiCI0bloV3i0du2JcZYtLuz22Tf9+x3j3zv9Sfc3t5hjGG1WqV/a0II1I2GuGdVxa7r0iAypTTLmXTyM+dO7iUm50WetJXlOyiSqu+p76M1hRmoZOA2ua7tcZaYmLRHsm/2OGom+UxH+RjwcaLVtA2kt5LelREpvsoGUxL7AupSl17j/JmUAsq+27l/zttcBu/JC2PZTlKOCyT168nqVroCN6W1U4v72GiY19kyHVxyKikZkrLVvWyv5Z36UIDbzPzyS33N+5R5Frc/HuCGf3EUySmr7ixwm0XTyCN5HlT04MlJzFHHMVrz+fe5o+QpUcwNmkntbA5DZZp55nlK2cp+ni3MfX11KrhatVxfv+Czzz7j9etPeXF9xWZzQduuqVxdtChyo1IXrdw4cymPec9lQMZ8i3J87H28tYHktZKrzaRp72wQJVv+029IQCfJfcw6zVNZOZVZHZKFWBZagwcMVeVY2xbrUkYadOruqoqu77m4uKTvO7abDX3fcf3iWr02rBDGnh/91g/58pdfMA4dm806RWAKFxeq7eL9SAyR7bZl3das1y11ZXkcx2KV1UmuVqokspCfK2V/ETRKE+TI13vePp21VFZtd+F47UHSO8xt7+i7tBhY3rPRwTaDUJCISYuiSPLXDupFony2AvYQAmNQ7jYWoSgmOmMqTCo7aokbg7HaPkvwUWkfUizwo0GpgHo6LzM+uc0z0UAy9/woOSonLxVNVmxVg1Ik6ZpoKL1YkiWe+7O+nOxN4mPQuIZSXjAxUrkKYwKgbof5ncbsVZOCkEIK8zdWCFHblDEGT1LCtLMH/OehSowxfwv4s8A3IvKn07GXwH8H/Aj4KfAfiMi79N1fBf48yrf/JRH5e++7x+xe+rwLYPoQQF9yr+d+9z7aQ5imbfp3OeH471NlmN+Hyepg0emERYZoM7m5UX5npv4m5fbky6mVNJXdCtri0me2KJ1zqq9984JXn9zw4vqK9XqVXP8aXHL/y0Cv2QU1ok8pFu01duaFcMoaPqpjjt9Bec75OeU6ifktlTWVJT+nZBBPFRvzOaKUg4rxR4IPSPBY66itxbY1w2jLNN4lLlwzsENTO4xE9SOurS5sscKHSNuutBNJxPcdlxdrqssN+8cdNgx8//VLvvvuDV3X8fLVDbe3t2zWK6yx3Ly44v7hge1mxYurjbq3iaepLC5FWq7ahmEYaFL9z1OVhRCwKYlATO0jW+lV0poh5qS7Dsu0uJXrO4SQwr8XYdbZekTTgKk3sr6HIDpXCoKq6hWrVRjHgA8qGOVjZPCR0WvkIzHp9sTUijNDkgA5ljYtJfJRxBZLOJip95i0WGcScGUpXP0uGTmJD89CWWp0JDDPWdKS/Hj2LiLfH118dVat+RANIemJ57YuQRCTtUz0YUQkuTiKzi7Ku1HBK5GAwYIETGXKoOFDxAeZokRDrjPwksuiC6bOSlqEntr/ue1DLO6/DfwN4O/Mjv0V4H8Skb9ujPkr6e+/bIz5k8CfA/4U8H3g7xtjfltEnuYlW2wnQXRhKZ/i95bbObA4x6UeW9zvK+W/+O0UN37q+LIOImAjOgjM6Ib1es3NzQ2vXimnfXFxwXa7parqIw2QpbfIMmIuzo69d0uj06nnePpMk/U8f84nl5wN4k9mRGmKSvYNTmV1laM1jiG5Dc61VtS/WrDOUlNhDAxjxBuhqlyKztSpbPAjfqzYblZUxrDf7Xj1yY1aVCKs2xVyecWqaRER2qYBEZq6pqoc1liatsGIYRhH2qbBGWGzUvXAKIJxDhHNLzmMUhY3AZq61sXjROvoe4vH9WiPB9RTU/15nTnUXzovjGUvhxjVhU6SDa/iVJLEo5LbZPAFEFXKl4lqAY2yZXqvpX9lymdG1wQUcQvNN5/VcdwOC2iL6p6YRGtky3iiR6ZyzembQkqIZr5SiiYnBxdMpCQFyecfU0ZZCTOoWFY6T4yK0+XQ+RjHUpcl2XJUCYYcNYpRN0ZjINrky58qTavpnxO4ReR/Mcb8aHH43wP+nbT/XwH/M/CX0/H/VkR64CfGmN8D/gzwv77vPs8BwnOW24dupyiRE2f9Rtf+g9hOzTLy8eWznwL1kqLJTjOGpmm4urri009f8+mnr6fECKsVzs5C2mer5fM6mvtz52OnBtJT2xK0l4Po9Adl+rE8530W+6n9+fOI9wiOyjnq7RbvvXqPDEOaUqst6KzFNS2VgxAPeD8WQDCAqy37/Y7Ly60OhNfXGCtcXlzx+LjTIKaLC9XtTvdfp7WDq+2FSsLWtXqwdANN2+DH5MMdA9a6Qg055/BjQ93UGKN+z5v1mrqqGYehRADiZq50MrmnwZSTNL/fOXjP36+IIEVWIVm7SSbVpFlNDMnKDHmBLah3iUQFP8kui1LANZYXSwKiZJFnGiCzAHnSaEw5/4iHNuoup0b85AhIYcqftguREyH9Mln+c3/pTA8qQOszxJyN3tojY0LrIqi2TZKkLRNiY/CS+PhsXMx/m87R65AUCGM5N4f3G5feYZxX0untN+W4PxORr1LBvjLGvE7HfwD8b7PzvkjHnmzGmL8I/EWANmXxPkWV5O2cJXbm2k/+Xv5bnvf/ptV9CqhPgdb7nl9SQDNMKchubm54+fIlV5cvileFNe6kRTbnr+d1VbrKB4J2ngIvB5pT4D2fvp+67vy3ueHnkWlenrn0a/47pug9a9WSddaWOtjtdgncdTLonMPVjovNmkNnGIdeqRiruS1X2y1NXXP94gXOWtYb1Sh/cdnRNJpgofiV933xN6+s1YHCqNjU2DRY5xj6Ifmi1zR1U2YETVMjUWjaFmOtRnU2Dc5YhroqUaHz55/PmOaApVSXO/KIyMDoEigchVqb44Xt/LusR+JDxEcpyoLZVXT+yvIryZLEZAojveasgpfbhzWopOrsnTpjS3tT2mTWT1EaUETdLEtfWTbB/Lzld8dbbteSzi2+9GF6hmlQmeoiiiT//Am4Nfu8UVBnCpA61UOmhBEjlSvlAAAgAElEQVSab9QkLRaDpuWbZJ3tiV9P2x/04uQpZDnZw0XkbwJ/E+Dq8lJOgemvffMz1zgF2svvdP83vvUfyHaKGjpHG8w/dX86v6oqVqsVNzc3fPrpp7x8+VIz2dQrKtcw8cjHg8ISsM+V75QFtzwvyjHgzu+13C8OfJIbiw4Vdl4XqNUmZ6yQXPYlcFkjSNCAkRyKXjeNyq2Onn7oVfBJtBtv1qo/st9bovdsNmuuXlxxsd2wamrW6zXjOLJqV0TvWV1e4kdfMrcba1HFVp0qrz/5tCygdv1BOd1kuQ7jQN00hRLBGNqmQUSo6oaIplir61p57LBOABKP6jSEwDj4Mj2HKaoyW99zoSpnDNWE/uk6pdonflp0cS2EiPf6T4NsVNkvf69WbWoLxlD8qJlyhUqKbGRWbpPoBplhVC5fMSJyW8wWrsSpvOl4fo6p7S5mZ9Ny/8IrJQVrkWgxJMkPGOX4jTlqx4mPKQ4FIVvTkN7JlMEKmFE1KWVblFSfpFUkXVR31oBLropZed08DXSbb78pcH9tjPlesra/B3yTjn8B/KHZeT8Evnzv1RZTi/dZdh8CZktaZGlpT5lglkA+7f8mtMyHDDxLS//XHbROzhSsWioaaOO4vLzk5UsVkFJfbRWPUg+F42c7ZWnn7ZQFfHbanf/NFidPAffy2JJK0WumRa2TYH88Hc2LsDBZn2W2kLwLJGrAcUyc46ptkLphtdKckP2g2XGIgaZyVBcbnNN6vHnxAlc5mhRlWdc1+91OeeK6xo8jMbmK5fvmhcGS2gyoG3UVy4E1Ofx9bh3PB4AQEwgu2sgR75p41LH2mgosuUDmxMg5m/3cC8gli3s+o5IEwDkTTVbtmxIjhPLPx1DSjc3fV549FeA0FDW/QnfMLG5EueHs7j0vX2mT+eKztlXEmuYzxTN91Sz2jiiMefkTRRGMlGCkpXeMIemKGFNmlUq/JP/02TUztx6iZveZ1gRyIE9aXDVANBixmnxEREHcLlO6HG+/KXD/D8B/BPz19Pnfz47/18aY/wJdnPyXgP/9Qy44pwdOdeb58XMA96GgPW/IT3+rf5+yEk9t84HmOWt5WZZTgL18tpMAvRjg9FlUZKhytqQhu75+wc3NDRcXKZNNXafGoNbHsm5PgXa5nxx30iVwH4F2mjrLiePLd1oa+WJh9FTnymWcg9xywAEK8JUOEjQAI1MReaoqIWKdo2lXrFerEo4+DAPDMNA2NZcXl1xcXFAnbZHsxzuOo1pjIdDtx6PBwjrl1HPZgvdTOLMz5EVFY3ThWGSKHFQL06bMNRpFiXHKqRI123p5R5K8NJT9rVytAD6OKfDIMQxDqaej+k3W5dFRCyIGohCCxwdhnIG2ekfEpKc90SSzlzbtzj9NzsRuyrG8V9pGOtGkz3kwSvG+yu3WGEyaDeQBLfPIU7ua/zEvyzG1lttVnjFkzjtEXbidyjp7zLygGyN5gbSkUZu125yWLZIXNlN7T4NUECkTE1Pp4BmjEJKc7jyy9NT2Ie6A/w26EPmJMeYL4D9FAfvvGmP+PPBz4N9PBf7Hxpi/C/wO4IH/WD7AoyRX4ByccwWcstKeu8b8WnCc/PTU90/B9fyU/kOeYfmbc+D7PgCfl/3cdfI5xhoqB1WlQSDX1zk68hMuL1X5L0u1ziO8lnVx6plzpzgHuPP3kztDlMknfQ68p3ROAHzIAUep8yaLyhXh+/nUGXIqqnkdnKobEVGZVJEj0I6ADz6dL9iqUnXABMaHriOGwKqpqBPYjsOAiJRUXEByP5siBg0gyde5RMalNh1FpWbTTY9CnnPSgjw196NGJFr0GiqhGjAmaOCGoSzaiagXhXWUAQ207pqmoa7r0neyh0Myr1MdkVzbSJah4IMw+Kj6I2POaBMUxMNkQRbjgVn2dX1Asmm9BOEjw4NMy6h3RTFC5u179i7zoiOpn+bFPb3jfIA3xOTlUs0iGed5LecgatK7JCbjfjYDmLepYtnPI3qh5LrMtM7SYMkzR8EQk+ukRNLiLhAoGXxMOfd53PkQr5L/8MxX/+6Z8/8a8Nfed935ZjhvUeb92fXPguk56/o5cHy6/+GUxXOgfu76p8p1bkB5Drjn4G6toa4tTVOx3W55eXPDzc11srYnxb9SXDlfP+fojGOL5sw55QZPn305g5kvpmU7bJlpJZd7+azzBav3zcKcTKWZewIEiRP4zO7ZrlZsVqviVTH4kbHvC2gfJxmulJE0YFLCAx98CurJAUGawNhZi485bVgAQX2wK5c6vi6OIik5gY+I9zoJt4YxBQ8V0MoLYHnQMBNFkcuWKRrvNdKxDJzWqO/1ArBDjIyjArbKtPqjf6P3eJlmLqB0gcuAA7qmkGp57tqXaYbcOiYLOgExHGmGpIebPEdEivzpXNc6N+rjtqwKgPk3ecZoYVF2Cnee24gtZSMBuymACpTECUYLUJ5zPigdGQlZ50RSQhKZZi0hDaBKq2mSbYMhBFLCuvPbRxU5CcfAupyS5+0UYJ4D6HnHPwVQS9BeluNDtucs9HOAOwfm980K5tdZ/j5b3E3j2G5Xms3m5TWXlxfJg6KaBgB5Ovk7VSdwDKxqFT3/rOcGsfeBvIhgrZue5cTzZ4pC5VDdk7qZ/25Oy1g0hDlfz+XnMAYbAlVijlTUKRJDxEq29G3yvY2FgsifyxkL6G+EBH7Jb1xECnVVVzUhaWiEEPCjV6XCulZ3RFdRh7okrwCHH0b64TDJEZjZzNRMQTs4S11psFRuF1k6NpezCFaJICqSDaLBJFnWdvSiPPaYc0eO9IPH+1D+hWSp5uCTyWrOdaHWdm5py9kSmTSRybJMk4endF2mM0QBNIUpADmQZnauedo3EM3snnWvi6tebjiG47atpZkWHPN1Sa5+JpdBiuhXwZFZWyiWtsx47pmXU5Qpq72IRmO6qBolkRRpaaZZ0antowHuU6B7Clw/xNr+57W4z513avsQKudcec79O12u09fQKbmlaSyblIbs+vqG7UUG7qYkR1gW75yluqQ/BCY9ibn1PbNm53u50c6ni/l4vuecezW2SpbkBEYqzZo4Za9gWVc1TTsFtZQ754jRWXtRiVc7y6NIuUc6aZLWtJYguUPr8/qQKJGgCQyMzMSC0gKgWuHq21vVVZkhNE1TrNwM9IMdsVWDxemC36h+ZzFm2kTV4+q0gOysI0TY7w4lWErSs4pRSmVI13ZVhW8MVZ2FonTQyW621mpGnjxrGIYRydZfyMp1GbgTRRLCJCTlQ7HIszRBfv/51ZeJE4kSsdmtTbB2okkU4CYr2jC5z5VBMPd/azFROfBolNvO3isiC8yYUSXGTsFopNlNBnZjUkKKVGiTwLq0kVk7ogxE+T5zKs8c9YV50FvpJyJTMFAIJV2bKiQyiRhmyVhjCQguQmCiG09tHwdwm5xKKi9Q5MNzUMnA9XR/+jzeh9Spj47Pzk0XmV8zw8GHAjc8Be9z4MuCr82NIfO4uXxHjYTjcud6Ag3hztPxpqlYby64uLxivbmgbTe4usZV1cyCSOHNBgS17KIsFlWO/IFBJFsgWQ9C7y2Sp4g5Hk2SB4cc5acsIvlodOB8wDHJiir3iKp5EQTlAtPySD+ow2AwonkGXYUhh4RH1f8OgehDSeuVdZcbB03iynNHyPyzSOYkQ5k2x6RxrS5woxqmKczZp0W6ECLDqNRFDJEQPLZ3tG2grRtspaHo1KgY0+hV/jPaKRetUf/qrh8TeFX4CD5qdqLaVlhXYZyjGwfVfnYWxGoG9VG1xgWD8SOVt9hKaCrHqqlxNhK9B2uo6krBL7uliaQBJZRp+5h47BBEqZJR9UhCmH4jaJJgbaMzIyL1I4xqj1hs8vIwYJzSRjlLe2ot898WCmXWD8vfaVA2GPW+MKSIVlF/6jRmT7MpwEhRS5Q0eCg3LUn0KvfTfLtpoVY9RKzmuyQ/kyEYUg9I1xeOeOi8wKoGiw4sEgUJYAKqlR6NZvYRcCIzoS0dxCQqbeJjrqWP3OI2MC3c5GPvAcwPoRTylNJYc/a3R9eQY+A+VYbnLNTl/vJ8OQHcZVp35pnO7cM0pW+ahrZt2GwuWa+TF0nT4FyVchLKjJfL5UoKfrKkSPIgNB0PhgUvqB0uRtTbIWUYV+COiImLQczooJUGHess1lbFIhl8Ft/Xzh5JLlcJ3MS15Kwhuz5wGAeapqGpawW/w0EBnGR5mUQHSKA1gcZq+2raBmfdBPalAibjMaZFo8ILp2QGMUb6fmDIqnjep+MQgoY4j+PIUA1UdaWiVFWl7TpZaOqNEjEpW7wOEGkh0lncWOGqiqauWdUNFk36MEZPP/YwKr976AeG3lNVDdbW+tQSEONpm5rtuqFpDL6t2azXVJUOGFWlnLqMRvVGkrStyOT2F4WkAjim2YXeM5aZ+zRo5/o2TBx3pqJIRzOlMRlTWRtlau/z7nncvcwEXjmiU46DaizZIqdQMRjVj7covZTLG2OKkiTrnpfOMFEdJj+N0YHRapyBmbUVFoCasWNOsUg0SAbqCE6Uqsspy7QbzbysJAf3GELSaXmGKflIgNuYAtwfYuF+KGhDmuKb4++X15qmW6ZM007RK8v7wFOgnlMDy7KJPb72nDZYlv9UGU4BtzGmZLXJOiQ5OjDX6XIWcFSmxWxhuYh45CGz+H0G3rxfvExiCj/LqbRSthpjswqhIYTErfpACAaJFNpHp/RJAMlYXKV0TwiBfn+gH/dYo9N/YwzdYY9ILF4cADEGjARM64hEXKUetwlHsSaH/Ux8qQBD0uMOPuiCUeJ/Q4wMw1AWJ3UmYY5mKb0IPnjqUGFQy7lpa+W+Q0jZWQIkLWqXM9VUAgQkesQ7sDr4YSoaZxmdY+gi4+i17gaP+ECUAc+YFkUjYnRKXjtDXdVgLN0wIMbg6grnapzz5AXhbGnHSFIAjMkF0ON9SjkWMgeS4XbiRzJo57ahyRw44p+dMYUfVgvblmtMbftpu1xuhWZbJFKQ3A4VeVNJNSIxEo/a7FwC4Pz9UvtJxg4xB/FrJvZkhOdCPfkduY9aUzISZYu6UHhzQy/9K1l2kruoM8+gNh8RcC/B633nPwfe8++iOf5d3uZgNv9NbmQfcp/3Lcgt7zsH7qOAiBPAfWrgOGWpZ/4yA/fc9S+X8dR15uVc5iXM35UBSHLXnTrL9HAgkhZcoi9WjcFijcVYp1N+axNAZIW1qGm8fKCyTeI88/UMIWp3adoGMZYhRPp+pPeBbgj4ocPuDrhKp+LD0CvwifpoRyKVNezMyKquWK1ahtHTpkGt9L30XMaobOyQAnFCiGlWEY/yW2aQnucZdC7rMVPqs+SxzK6DRlhVNcZEYuJdtV4jlUl0TPBEo54bNgaiqfGjMHYjvo/4IS10+QRIEhm8aq/YpkGw9P3AA5FxVInazXaNj5E61EnuIPmKR3R+b12KaNT3Mg6+qODpmJzkXlGr1iTf5WL1GlKqtGMDyZiZJGsewEv3mXtqzAyDE/1r3mZFiW1drFxY5uVtipmJXGUufE5bayueH5tvcdbeiYJImIA6e+3MBg/kyDsQmM3kZl4+xqqk7ZRcmkmm2KhLrCY8zv3sX0zk5B/s9mtY3OdAdf79EXCT3aWeWuZ5KyAK5Lwcy+s85yv8XLmPzk1vZQncp4D6fVZ3Bm3nXALtbclmkz0KTlnaedoay8oIR4uJuSNNVIkUakQk+2lPOs8J+tMKulqp1laJz9Z/USxEq1PzkJTVIoRoiMESfVC+W0ak92AcEc0K7sWXjOExCsMQ2e17Hh/u6fqeMGoCX4zqUxtErW0MTe3Y1MJ23bAe1+z7geZwSNRSW7hZnTlM2Ul8Auriox2ldKTclvLi5PyfKr8JwSrFE5wgRmcaTVUVudQ4m6nMrTcR9SOPPuDHSFM5YjR0XeSwj4g4EEPwyteKmQJRQhB8HAnBJ/rF4b1SOPMZgjEULXCsDq7BJMnSEJFZLzBGwGbAlSMgLMBskzugze0zfZeeLWeyURCf2qNlWrc514dO9etCWUzVdkTrFQt8OYM8vvDTmWX5baoaM4FnfiYBXaNIbnsm8eRRZutki8FA+6r215osuJVC4mUKhzdYgpX8Woo31LntowBu82sC93OUwvLvU8B96jqlQR2NzDPr4bkgjxMDyKlzVXHsNFg/V6ZTg0i2+LIuyWqlIe0528oy7dfxfcDHWePX1Z/ScKfGLIn3L71jEtuJUUXlQRuy0Ykz1iDGgjjKAmjQKaAXXXgZvUpc6vUMMqhf9JgW3WxVUbUNGMvt/SP7Q1cWf4a+4+7dLW/efFfCuf04MPqBuqpoqqrUcVM74kVD9AOjD6xXHuc6BKUxKueo6rpYc2XmkV36kt5HVbliNZaciSbx+qlzx9TWYhSIHoylwuJ9AgARglXuXbPx5AXa6f2KSSJOIRC7kab2tM2GfXfg7W1HXa3YbLYYWzGGnhgGxhDBWs1K4z2VNSAVQlQw3XdsUZ/xqvLJnNMcmD7pbMc4IinzUV3XmCS8RZgt7qEzRh0oBGdyc56HqGfQlvL3tCntZTjmtJd9ZNmH5p5IxphkDmdzORkhyXLN6xOlHUdDOGG5nnNNJZE/oKBqRPtFPmoMU0JmZoqcKPCaRB8dzVZtDhgz5fe5AtRVUD2YjDPFaCx18aTk0/ZxADcnfDjzdyfA68nL5OkLL0BsJivpHGVQPjlvcc+PlY42539PlH1ZrlMc96nnPHWv5b8M3tl6XK3WrFYrqrQgtvSJLmWQ7O3Bk2Pz+07PJhP9IFMWDw1/jvgYFdScxVU1lasI0Wo0ZMrgIkYXHKOoh4j+XkGhqWpCssiwhmih60eG3YEQA7v9gcfdjiDq70oU7u9u+e67b9k9PFJVFZv1SjvY2lLXOjjudjtqZ7BSE9Yreh8YvLrIqQBTj8sBMtaVBexxVMDOdVA5lfdsXK0UlFGXxawVPYwDj90e7wOuqtRLI8Qk/zmwXm+TTkqVrq16zm3T0tQW7z2rlGDY+xFoEYns+5G7xwPrVcUYGvajpbt7ZL3zNI0jimeMHYPvaJoKjLDb7bHOsomrkkk+dr0ufFaWqrbUlaOuHE2sSzk1AKjCeU8/eE3Q4MDa9CwxgGiduCTC5GZAnfIPFH9s5py2kSlKdG7DzIA9Z7A/1Y/ygKqgPYWG+0TlRJRmyjMyBe8MnpMFnekLSdz4bKJD8ZQi+3EnTlofJQ0PCcSTkZIXGU3KlINJqfFM8nBK3lQmAXxdO10vcLbMCqJEbMyRntOMD5nNxM5sHwVwkyzuc8B9Cujm3+X95XfwdHHynBWbP+0zjWhZniVwnyrHcVkob+R9A8mpsp4C7hwhV6e8kac0WE53hrk/9hQ9limQvDgTRTSreFQaRHMMZqnPlLbKQ1Wr10ef+FcJ5jgyMXm3eB+V7yZpfYQREbVV9Peed3e3PDzu6MeBu7sHdrudusX1PWN/oLKWx4dHvvzyS4L33NxcU1eO7cU2pS1TKmO7annE46xFjMXakSDqomcEjdRz6rpXgEHU4q1SMEudg18kJV2oKvWlTvTNOObQecvDwx5rHN5HDt2AMZbDPnAYBkQMgxeV1DUG5/aanDYE1qsVTV3TuKrkoHRuxf1Dx36/Z+hGfvef/ZRD13F1ecn1i0vWm4bRd2CE0Q9YKzhXq+dMVROiUkoX25Wq+o2B6CM4R2UUeGvnCLVLFqMAqgs+EhAPPknZGQTnTKkna9MifupaNgN37hc6DVMXRjNFvM4DYIpXa1re/JC+nFck5pTG/O853aEW90RwZSA/ogJL25fyd4i+nJcS0WBM8jYzk/WMUa1yk54hR/MqRz7HBSZX51xCyRl7Mo1kdU1H1Ksnz+ieA++PAriNmTwk3md5Tr85DXrL77Of5/LaJzlmTlvcp657DrjPnQ9PLe5T+889+/x4FhKqU3YUt7CyQQH6pOLf7B/LzwUdIiJYiUjUwJMxKI/rRU0sMRURwxgrxl4YvFfluKAdBwOVq3CVxTqnFuk4TIExTn2D+6Fjfzhw//DA27dveXx8JEahHwa++/YNfT9gDBz2j7RNRd91jEOfgl1Ghv7AodtjYqRdtWw2GywBa1q6PgN2pF2vysMaI5gQsSlXoEBR+cuiXaFWoHZNxeh9qZ8cWNMdBsAQI/TdiIq6Gb7++jt2+47Dodd8jWPk/rGnrtWN0Rj1da6c4/rFC4L3rJPg1WazoWmE/X6kcpFvvvuW3/v9f8Zmu+b6esu+e8BLReUs3WFP3VTUqwrrhO7hEYD1umW9ahjGQBum7D/WaJ+onYXGYWjwxmLNCDISPQTUI8eaiKu0Vzg3rauoj3yaoeX2OuOvo5msxqlf6UCpeD/N7kTO94fzi//mqCFn27Z4mmTDJEcgcsx7z699HGymFKKgbddmKzvVm7EGGy3OpoAgO1OhNFNdZM2W+XMCGqmbOH0r4KNy9jFVlokpBeGzJIluHwVwk/m+DwTuc6A6/13eD4WfOg+aR//OWNzPgfh7n66cl6yUZ4B7Wf7lsXmG8EyLZL72VB0uLfBsPRbrZdY5ZAHaeVHLSMRIiq4Lkjw+LLgKsTUi0PWBru/VrSz7/AoJAMEFy3qjFmHwI33fqaVnK0xdE4JnN/TcPj7w9v6O3f2DRiXGyMPjPd2ho64qhu6AeIcQ2W7VQ2TslfYYugNhHDEI3X7Hw13FZ5+/pm4bghi8F6KxZWERKOp6UmYdubOBiAbu9MOAEAnjkEA3eY6MQvDCMPQMQyD4WMLEf/z7P+ebb9+w3/dgLP3gGfuItbom4Yylco7Nek3/2PNHfvRH2LStZul56OnxjB52h0d8GPhX/uU/weeff8Jm3fL4eEcIkbZueYieiMqj+qC+5qP3Kf2joaos61ULorMLYyyIp078tGkqqgymEonBq160GKLYYicaq0khnLOzgLEsDob6K6e682aa5TozRahW1lLM2NLIIYm3nuzXT91V8xdpoDV5PWZBkaS8kCGpQ0qyrMv+/LrpeChtNy02m+wCmCI8rUVsomrtpE+iwJ0iYNFF42xZl6owaABWKm0wQmXSzM0YTEwzVZlFYz4D4B8FcBuO9TryZ94/p2Fx8lpL4JvvnwHfAnhMo+aH3g/OWwZH55T/T9bEqRnEcv+cZ0j+N+mV2CfXWC5QTvy2+jRP1klaYEtgnekCn1zgwGNEkni+QUyFcTURDcvuR2F3GDj0A9ZUGFupd0UYQYSq8lSVUiXb7TolzHX4cWS/eyQ0LZ0f6cPIrjuwPxzovdIZu/2OuqrYvnzJum3ZPd7TDwcuNhtGP7Lf76iqlJ9RHNGP9P2hLFs9PDxwcXFB07RENLgkZ37XgfrYuhPJEW2CMzZFFga8Bz8OdGaKAoxeBYGGfqTrerp+pOs8t7ePRLF8+un3ubq6BmPxY+CrX3zF7e090Uesg+1mzW/98A/zZ/7Vf42riwuGvmfoB+7v7vjZz76g6wd+9KM/xMvXV7z69JLrlxvGoQP5lOAju4cDd5uWb755w9v7O4aoPHvdNkgkqfuF5JeeuHtxiZaKSQtbNCCodhjbUlcVdcp2P6aBE2M0CUUyDpyzE2BnPthKAUE3a4eutNNMMRyvn1B63dO+tmz7825WFPyyhTrjskVSmoKo+jPL9ztv8/PjQSBI9vWOme2ewDfJIURRyzimDDbWgFg7nWgi6pCjgxupnR1x/PnexhTvFNUEnz3kx06VzK3QCTDR6WSqjKxN8SFW7vwcZ91JKzd/zsEPeJbjfgrQ09h4DrzLtWDS+1iU8aT1zUTxLL974id+4g0XS+CkRc0UxpySwUpa3MlgPUYNQgkxYGJIa/cGa2tc5XB1Q8Dhu8DQj/gQsaYC4xjGSNf39F0HRNbrhtWqYdWqS6C1Ri23qiYOI2/fvqMfR969e8fD4wMiuvjXdQeuLrZcbS9wxmEN/PD7rxnHntWqJfiRN2/f4ENAQqRta77++mvefPeGtm1wldOgktEzDh7rppnKyUQauT6MWmzeepwHxKqutlcd7rquqFzFOKpvdVO3bDY13u/YXqy5vHrJH/8Tf5rr61d88slr9l2PeGE4eO7vHiAt7lXWcXN9gzWGx7s7Hh4OhOCRaNhuL6ibkeuXV2y3LeCR0NM0kVVT07iWXdsgw0C4ucQ0lq/fvaXven2/daRtWmIOZ+8Hxr5GGoerHJVxOt2Plsoph12lNQtjlJct/usyyQTkdZSyEJlcJeeGgU3eJ8noT26DCnLztmgmfuFJP8ifcwt0Tm7Pe8C8/efzJ0DWs+dW9pEue76+TEqJMabBCDBWklhZDh5LHjZB/6eL6ulGyWssIlgjzDX+jKEMAkDxFRcU+GMurKGkeuM0pAAfC3BD0nBIU4wygOqIrNrDs44mp0EPphf2tBFMerlw7MVyBJju+Pe5JJmPy9u8YejYYsq5x5aCHJUhN7JjkF5QJBzvz/+zaTBz6KhvRduNw2LFYrFUpsLiCl2Ry+RThFz2EsmpwCQtOo45aMQH+qFnHD2CUKVpXZWi79p2DbbGjxpN2HUd1lXU60YlQA89fd+z2+8RglIV0RBthbgaj/DwuMcHT1XX1NXI7dt3jPsDF3XDi+uWzaphu16zaVds1iv14jCGSOTu4ZZh0LRfL2+ueNztkmtVwLU12+sr3rx5QxTDYQi8u9thbM3Vi0u6caQx0CQ51XHQIKDNeoNIIIYR6ywikTBGDn4oYFQnWqrfD0QGHI66atl1HVdXL/j+H35FGCPGOKytWa0aQKid5bu37+j2Bme2SBDEVBy6QHc44EfPMPbsHjuieF69uuYP/fZn/OLLn/Pzb7/lM3PFq2rDBTVj33HYPygfvr7ghz/6Hi8ernhxv6eqK7786mse7x6omhaHZVVfEQPFg4ScDNfYtEKovFbtHDWksHz1phkHSz+YlJVc1ygyeGs/1Aa49JvOwmR20QetdRM1kQEsgXOeMWbQLbPA1F4+8Z8AACAASURBVN2jQZ2bJYKJOJN0rg1KZTjtjJJkZbOGuUhS25sFmamcqt4/JzrI4F06NZnrVoMrGh1obObpTRKyIoIkULeBYBKlYpJui034lXEizRD0DhPlZFOmJptmwj5mR+bT28cD3O83pGfnnl+oPOeidwqon/4j1+zJe+YtA7OILMp9fkDRT3MauBefp/ZP0SOn5Ewzh6cHp494tBw5dY7s2ueDpx9HxtEToiQN5pEokdrCtm2oq5amWeFczRiEvtN8jXVTga0IwdN1HcPQcTh0ajk7mxYaI93QFwU970diiko79B1xHFk3DW7VYhFWdc3lZk1lLVYC/eHAw90th6Hn0Hd4H8CqOx3WUtUNrq653F6xaje07YbdTj0yjHE67Q8a3dl5T2wqVk2LMULXd8QQadsKQ1T+VASJGp4eknXuA4xeUlqxiPiR7UZdMqPA27dv6Q8jL1++pG0q9vs9u8cOEWEcIvcPPWF4pDsMGKkIXjRzTYzs94/UteXyxYZdN/DN3Tu++NXX7Hfv2B1eUjU/5OpFq37axvCwe+DQ96zaLc264SrCZ5+8xPuR6vYOLzD4gb7vCb5JdKSbmX7TjG7e/urk164RltpyRq/UWra2l/k9c3s6aofP9J3lOfO+KSKE+W9k0Z+swSZtHBOzYFScgqVEjtiGubWdKZQJlo/1uYHkEXJc/vzbqc/P8CcLqhmTvERMmllM5ZckhmUX11zWx3yt5X3bRwHcSz52+d3R3zwPdKeOzRvGcwt4SstMDs5LmmF57LltbnUbY8oiz7ntfaA9X5RczhJOhaxn+7/wfbPpYdYI9kGDNjS7iYoqDd4XDQuf/JlxFbZqcHWDSVGB3eDph5EoJP9l6Pqe/X7PYd8rWMuU//D29lZ9iauKzWbD5dVWFx4f7vFe6ZP1akVdWWpraSqHAR4f7vj262/46pdfcPvuLY+Pex4eH3VKaR04y2Z9wWq9YXtxRdM0XF5dcbm6ooo17/o7whjo9geGzRpVF1B1vJy1RCTSDx3OrRAiK1dj0kKeMRYJYaKSiFTGErxqj/hhJPjI4+OBcfCs2o3yyuOB3f7A7vGAMRZnG/reIMHRDyNhFA57dRPM2WyCGOQ+IBJ4ODzwyy9+ye27r3F25JNXF7y8XtM2IKGnHzoMHeMYaJs1TdtwfX1BIGArx+3DAwIMY8cwNoyhxcdYfJ/nbWve1uYRuaXNjUHLOaMUl8A9385lOsr9Yi4d8JQiNSU/6PL7XD4nQg5tL/RLMVzkqKdlzvvUwJLPz/tzpHlfPy/fm2Q/p2AqKzq7EUMSkUrPZgzBPgXvOC/D0fFnb/9xADfwXuAu3/86pjnHIDgHv+X3pfGYp3z1Kcvi1PXn5y/PyZyVzKiTJ6M3Tweg50B7+bsyhU1TNYNGkuUkpSEFz2ggTQLtYWT0Y5IK9UlQX2VLTdJBadcb2tUGV7UEMYRRM35LYr7HfqAfRnb7ruRs7PqDBsHUyon3fcdqteLlqxuMFW5vle7o+w4Jnu1mrb7eQSmPfd/x9rtv+L3f/V1+9pMf8/a7b1UFMEcWRrUgNQ+jw1VNAu6WT16/5vVnn7NerWmqWkExCMOhp24c1kFjdXEUoKodEmEMAQwMo1JGEqUE5uT6tS5laxSDH0ceu5GqajDGpoTMLYLlcOi4fXfH48Ne3zUWTIMRy9AHJFq6YYRoi8BW2HnlhwncP97xi59/wdA/8oMffMq7d7fcPVxy/WKNSZxoDAHpD3iJrCqPqwyvX99Qr2rGn3V0w5CiPjXYw4fAGKMKJ9nTwJ37CUDTNOnvUOR/5+cvF/jmbfpcX3hCZUJJwGuMBjc5ayFqsoHsZR4zcKMLgSKCixrYlWk0a/J5UgLv5gkL5vz3sVfJaSNtuc1/o31aCBhcyiaETZROGnh0kMm4ololc+2kJe+u7YQSTPQcdn80wH0KAE95mszphqffnQbNU+A3/25OlRyPu8e0yG/yTFNnMCCnM90sn/98+WZWx2zaaq09UuArAxBTo5wLH8Uk8JSzmw8px+EQkhdC8vutrMNVNa6qwdZELGNQ0A5BQ5ijRA6Hnn4YERHqyqn/s/d0h0PyM9bMLnXl6HZ7dg8P6plgLX2nwN1UjnXbUFnH/vGBr375C/7p//07/OzHP+bu9p0KSKUkBtkrRjPnONTxQX27ja3YPT7yePfAp59+Sr1es7lY62LbMCDR4Gr1QGmaGu89VVUTRej2HWDZSceh22Ot5eriAldVjMPIatXSNA1DPxDGkX5/4HJ7watXr7i7u0dElDYJkd3jjnfvbtnt9mnRV/lW5xoMFet2S904Kttw2PfsDztCHGlWLYfDnl/84he8/e4Nl1cth/2Bt+9uedy9oml1MTEEzYMZDwd1K2xXbDdbVm3FixcbPvn0hi+/+hVRBoQVuoQIXsAkH+VTPv7LWSqAcyq7m/td9kaS5IGRDZIlDaKf5glIGpst0XRPNVt1s6aILZVFzkQzpFzGM+8vjbuwRsWbCihHM6M/FgbXGdBeDijvA29SefJA4kQpHE10kR8neeQYPeaYJC9SUbR+ohTc0epM5X8Gcj4K4M5gdGph8SnImeL3OT93/vfckp1P/zLgnaIiJuB+ymktrQg4T52cAtpJ/e/5NGrL51k++3IAKj7cOWoy/7M5uYFueWoaoupMhxjpZxnNNZ9gSNm8Ex/nKuWNq4YglkPvGaNJCQY0O003enb7jofHHaP3aK4/i02ufuMw0A8d3o9cX99w/eKSvu+4f7gHES6vLlmtVmxWV9SVppp69+YN//Sf/GN+5x/9I958+zV+6NU/O4y4lKJNs6hb5ea9KhKKWBWpEsvQ79nt7um6R1bbS15/9hkXFxtCCoBwVU3f9+qS6EdENC/jftdhXcNut+Pu7hYQxk8+4ebmZnp/YtjvdiDCy5sbNqs1flSq5/r6Gozh0PUcuj37w46Hx8ckjxqw1tA2K5xrGEYYhghUNPWKaDRN2Rg9b9++4auvviIEz6p9wX5/4OFxz+PuQNVY1itHpetd9OPA40OP365xlWWMnnq14fPPP+HQ7/jqq684dA4fNklHRgf1GMNRezvVj3Jbc3bmP81kCBRrceb7n78/RU2UbEr6Gp60dQX/3MMNEmI6L/1jmnBnytRazfqj1xeiVatWkUKjH4+BetGf52U9UfaMAXP652hGYSgJhEWMugGmBUwNo6QkzwiiHiqSR6NUp5pMRMscSfrn7zEUPwrghvMcb/57ArEcUruowAX4naIT5tsyclL3AU6f/xwl8tyAc2TVyFNQP/e888/lYqSbre63bVsSAmcQN86m4INQ9KTHpCMdQihW9qFTX91hVMokpHRP1lbU9ZqmXQOOwQsegRTxOPpA3w8cDh2jn3yix3FUfYwYadqazXaNdYbDQdjvH/nuO8vd/R273aNGPAbPq5sbGmsw0fH1d9/yu//kd/jpj3+f27dv2O0eiGOPs/C9159weXlJu3LUtbaD0Qd2uy5FKA4cuhE/9sRxAEa+/LLj8uoVBiGGl1h3hYuWunE0bUPfD4hAjD4ttAYOD3fc3d9zf3+nz2Ms282Gpmlw1tAf9uwe7vnBD77P5eUFbdXQ9z3rVYsx0PUdu53SROrdEPAxpkS3nkP3CFicrYEKaxo22zWt1Dzs7mnEMo4DD7sH1uuKrtvTDzVRIvt+4JILeh/po3p/rLdbnHXs9ntCjFxcXnLZ1NR1yw++/z38qMFDmrxCxaisMRiZgPecrHBuezr7PwaSYhzILHs8x1TJ0gI/1xfn/cmK4NPfIQTNdmNMoUdM4oQjVuVkDQq+ZCpF1wycValdYw2EWVkWFvicVzbMKIszg8+8for1b0CSa6CNBhzF8saYBOzgiUcZ7OeGYVk8TUbWewzujwe44f3Wpkmj1KkHmp97Kpx9ueBy6voAIvGo4c0bcD42/ywCOCfKvKRnrHHF6j4H3OemrctZQ13XRQ3wSBEwpegyTIsfIfHbYwLwMXmQ9F7zCg6jp08i/VXV0NQr6naFMbXqBENavdf6GXyg73OqK33+pmkxxrLb7fBBSnRi33fs9zseHh748U9+TAjaLa+vr3lx/YK60ajPw27HT37/9/npT37Kuzdv2D3e4YywWrX82//Wv8mf+OO/zXazpuvuefPuO7761a+UnkDlTKt6zXq7Yr/v2O0P9MMjxtdYW/G2qrBW2GxbtvVK9ahF6QtrDMMwIBEO+45D3zP2PfvHR8ZxYL/b8vj4wMubG82oQuT6xSUvX1zRNk3SJkli+0YV+YaxYww9xkLdVNgEer4f0wwBnAvU9QqMZX+4Q6gwLmJqw2q7omkr/DjgqjWHfs+h7xl84ND1xLbCSIAYsdZR1a12eGPohpFqv8deWJracX19yTAMGrVY2kVMsrJy1D7P9kOb9TbSJtl9Ti1Fa2zKBJTaSOqkBXyy++5zwJ2szKiLF5gAIg5jtI+p3Ie6rmaNF3UVDEjUoJi60mfLNH7RAU+gr1HAGWinxcw5/23OAPf8c1bkQttYSWn4EAix6JCIUUrRipDlkTHmyDycDx7qTHCeqsnbRwHchvcsGC72p5Db6fz5qL60dJ87trTKnXWcGmmXI2O+53PlnlvJxhgqV50E7uVvl8eWoJ0pkgzabdtS1TW2UnevXMYM2Nnq9uPIMI4Mw0jfe/peZVTHlCgWY3HU2GqFMQ39IAzjgGCwroaoC2fBaxbw7GIXYzgeHJ0l3N2pi1aM3N/d0Q9Dsv6mYA5rDH4YePvwwBc//xk/+8lPeLy/0+jAGLh5dcPrV9f89h/7o/wb//qf4Wc//Qn/4Pf+Cb/88he8vbvFjwHrKrabjYbgi2F7sWWzO3B//8D+0HM4PGKshtv3/TXtSrPTDMOQ/OcrusOOumoYh5Hh0LFqG0IYub97x2bV8tmnr1g1Fc4Im3WDcytWba36LRI0Ma4IwWsShige66BqHbV3xCFJxDowXvApy44KSjn6sce6GmPBx57t5Yrf+tEP+flPf4wPAyuzUZdOEfrBK5ACEiKGkVXTgq3BqJjUvuuom5a2bbi+uuJwOGiyhxCQEPAoxz3HhjyDm7e93MaNmQyB1GG17nIEaTSI2MRJH9MK52jA+VZ8tkVlfk2c/KW9NVNEb0DBOykOxiiYoG54KSKGGFWFL5opkcNyWy5ELkH8XN9f1o3SO8lfTMDkGYDJlEkOhU9UyKL+8n5+EQIlcXAuz7ntowBuDEeNBjgLbDrKnQa5UwBdIiJPeGYs76PWxfE0b74/n86cm/6dtLRnFMeva3EvB4E5gGcQd06j4cxsVpAXI4u17f3k8jeMHLqBbvCzhUZH06xpmhXGVHgvDIPKfA4+4sMh5V9UoM4iS1XlcMkqKpKyxnF9dUXwA0N/4NNPPtGkuWECrNpZuv2er/qe+7ff8fWXX3F/d8fjwz1xHLm5uebm+gWb9Zp/+A/+D4Zuzxdf/JyvfvWVWvoD+AAkOdXVZq0Dj/dYW2vnsXvubneICHf3NXe3V1gL682KGITVeq2eKeKSRoVhHAdubx+4ffeWbr9n93jHuzff8ur6kov1az795CXGQOWMemgIKnVq1Dd9GDsOhx1df0CMRTRFPELUKN4qpoCnSIyeGAOBSNtuWG0v6HtPFOHV6xu++7Zhv3/g8npDCIFDP7AaW3WrtEoZdv2IEY1kdJV6vIxe6AelrTardVHyc8nSM5nrPeFzNnf5y9uy/S/beZ5dWWuP+sbyGue2Oc0SY8Tmz9T2sx+9MaYYAy5YQhJ5yry5kJI9u0gMKoRlzPGM+EmfXjyfOdPv89/TYJZn0CTvEuWvTQSxkjL8GLA5hZopGvhanml/OdCJSFqwPL99FMA9f/mnKvkJsMl54F7ywaes7vn5T/bt6enRKeA+NxLPAXu+72x90tL/TYB7CeLzoIg5YIfko+29T+53PX0/0HUDXe/xQT002lVD26xxdYsfAyGq2FAMqExpSpQb/JAymwecM2zdhmh09T+XIcbI9mJD12+5f7inrjU4p7Y1TVPT9/oOuq4jes/du3d0hwOPu0cOhwPXl1s+/fQTKkvSTDH8X//nP6QfeozRbDrWtFjGJD1qGPqgUa/GYIzSB+s1jIPQdR33d+94d3uBsUq/WFdTVTXeK+Dsdh0PD4989923fPOrX9F1e01GPI50hz1tU/Py5prL7SYpCEZCUNctBELQNYP9ocM5o0FJxjKmReEoljpJm+rilAbxEBJgWMAKdePohwFrYbWqeftux9D3mrw36az4EHX2E1S5cTSBqnE4Uyl15CN+9IQ6YmrLqm1ByZjihZF9+kNKrbbE1aM2mqy/3O5zG40xngTvc1b2OfBeLmD6dJ8QgipK5ryfs6xEMWgyDhsixgaM9QqUogNaTD7rY5yEo2KMmlkmUp77iCqZDTrFAi/7PFnYLNCaOJMoKRlxkpONoi6Lxhpslgxc1HG+13w/U5zPbR8FcIPBpSyumTeC4/10GiblMoSn9MIpkOMEeBtTLjYF9KQR0uQV9PlLK5uO6DYDN9O5ZGsmA7fV4A7rUnmNoXJPgTv3i+k58v1OeadoQEj2IHFVNbkBpvvnKLIY1ftjGDzDGOgSNXLoPYdu4DAM9OOID0Jdr7Gu0TB2D4dOM8ZgXBJvUp4zBE/f9ylJQGTVNslbJXHgxqY6ivgw0LQ1lxdbuu7Adrvh+uaaVdvy8PjIm2+/47Db0e/37O7u6PYP7O7f0Tj4/vc/4+rFJTF6HJn2gapesdvt1T1v7Dl0XaIQIrY7sNlesN5uqGtNAlBZlQV463v2j/e8/fbbxAtbrq6ucUnZECy3t7d88/XXPN7d0u/Va2TwB+5F+CM/+i1+8IMf8OrlS0LwjMNAU1c4VyFWGIeRfhzphoHRj0SEunYIhqayIBW1teCTlT1qmjdI8hbGIDHQHfY09Yq2rvHi2WxXeD/QDweC76krp30kwohy3JWz9BIx1NSmAgl4P9D1A03TEEKkqiykmZJE1ULXbDaq1hdjbucpfNuqdolak7kT6uActcJTuVM3yrP69P7dzGA/R4/MtyVwmwSiuQ9Hq4uNwdqU2CESbcRGwVrBGqVpHCZla4oYqbAIPupDGASfklJHJEf6TxhTqBLKAqgUrxRdLCxPkkQOxUWmdMnadYvmSP40Sv1EOxOd0opZ8N2FfH92dpK3jwK4jQHravLKbjnOCQuU85rZpyxusaf57KX74ZEFDKUsy0o09tjSfp/F/ZQqMU/uueTc5s9yZLEYg6sUtI1TtztXV2kCIiAaNKJWqoordcNI34/su5HuMLI/jOz7kW7sGWNAxLGuG6qmZQzC0A887g74KFRVw2rVFkvCoFSJBqEIwzjC4UBVVeq/jCZHCGHgsH/kcOiIcaSpHcMw0lQVF9stm/WaTbPi7u6O+3ffsbGB7ari9u3XyePD4b0u7uHUco3R0B0ODCFQI4y+Zxj2DKPnYacKgO2qQmJNVVes2gqJHt8YtpuWcejY3d9ikrdN9JEYoF2teXjY8ZOf/Jj7d++oCIyHHowGoLy8eckf/aN/jBcvrpVTRf3wgghehDEnlIiirnbWQohUzjGMaQERwVVWEwcbMM7gxGjwDQlAg0rnjuGAqyrapuLly2vaVnW3w+iJ3hOGgdjWRAlpqVQIXU8QBfGmrhDjGAbP4dCxblvqSvW/M9iKKKAZoxZ4VHNRJQjScps1lPRRORmJYBOICcErsLrspZH6cbaG8mLmsn0v2/i872SL3YharNaoGFecAbg3KtEQjf5zVlRtMpiUIEJwRqhMoLKSBJ+SsWZGVQvUdcJiItk0Y5TEuRR+ORlvJlMc6f95gTPEkJIkm8x0F9DOM5Vs/Bmh6PGnWpgZkbkOyh5G4jQAnNjeC9zGmL8F/FngGxH50+nYfwb8BeDbdNp/IiL/Y/rurwJ/HgjAXxKRv/e+ezy1bMu9jz7zvuGcR8gxAJ46nn/z3Kj2XFmW15gfnwPtKbpkWa7ntiWfOL9n4dhmVAnkNFMyeYr0Q3Lb69kfeva7jsf9nsGP7IcOV9fqStisAHUVe3h85OHxAMbSrgWcYeg6YhiQEKirSsWZQKVCvVcRHu8Z+179g0Uzsj/udjzePwDw+eefq2jUek3btnz2+jWH/Z433/yK7v4dX/7yF8g/jazXF4hEXNVQVUoBeR+UN2wqalPj+477+zvu7+85HA4EhMvLyzLjMKjQT1052qpiqBxNZZEYeLi/Y3/oGPqR/b7j8sULvvzyV7x9+x1j31MRdaHXGi4vL/jss8/49JNPWK/X7HePrNoGay13d3dEWxGtKhC6qqKOQj9oyLoPIWWL13B5DY4yuNqxsq1GiAbV8w4+aq5EH3G2Qkbwo0cksr1Ys73YcHl5oR4VKbgpEHFJKle1TvZUGNzVJe16jYSRrtdZSe0sq1VDnTLQhjJjRBeeczsjB7+oRrSgIdzY0/1ouRB5OmDuKbc8//05mjCveWX3OJssbmsjzscjujIvXtbWUVmVTKiMwTlPNAFsAKvccxx10A2JKy8cN9kCN3nptlAjRQI51ZItXjILw+24cmD+3OgAsOzTyzrLv32f1f0hFvffBv4G8HcWx/9LEfnP5weMMX8S+HPAnwK+D/x9Y8xvi6R54bltxrUtrvd0VEYr9xRw66UmYIsxns2sfm6V+Ny21F84VbHLqMxzFve5+y2vOZceXZ77RA8icXAhxhLK3idOe3foORw6doc9+/2BmPjZpm1YtVuqqiWmha59p0L8rmmIIhy6A3d3b/G9JjKYZ38xxtC2LU2jyQW81+P73QN939M2K+Im0nWHxIlbttsNm80GEJyDOF7zz776gjdv3wH2/2HuTX4l27I0r99uTmPt7bx78SIiQ5lkVWaNGDGu/wAxZMKAQTGAGX8Ag1INYYpUiCkghoi/gAkIIWpCFaWqQhVkxosX/vy6+73WnHY3DNbex46Z2/UXmSkhP0/3uV27ZsfsNHvttb/1re9jGEeMLajqmhBcwpLHlGE6vB85Ho48Pz/Tti0AN7c3bLfbyXA6D3bxU5TszxqNsVZs18ae58+f0Frz8eMjTduz3a74+KHFFhZbVyyqiru7W5arhRxzL81KWiu8cwyDx1QWNzr6YcD7IEydrmdI3pJKie54iJKlRx1SAU/UBrNrjPdDvoAJK3V4P6CNZrVasV6vuX+4xxRSkHbe0fYdq/WKuipREQyCqQ7DSFkUQhH0iq6T61ZWBSiTVkQex2l1mFO9uZZNiOLOE5VCx/N60WUxcb7J32XhcRmYr732pSL/tTGV3gXxnIWWr/dUsM/jzIwEhhSUNT6IfrpPWTw6EkNqqZ9lzCnxnn5Q58qg2b0phnguPkJ+A2dBOz9/UmA5P/5rY1zFv2NxMsb4vyilfvNzr0vbvw/8DzHGHvi3Sql/A/x7wP/6M58xOXa/FJDnMEZ2qbkGO+Qba3pv5jV/JWC+BFvMP/ePqZRfQi85U8j/XhZfvwaV5NfMi6x5UrLWfgHX5Mwhd0eOo+iHdP0oAv3DwDCMODeilGW52LBcbqmqJaDpB0/TynsCitIYfAwMQ8/hsGfsWinWhTAFzCI512Q64DAMABI4jGSmLJi580AInhA9VVVi7ZLoBm7v73H/+l8LXJM0wL33UuCLnqgMRTS0ree5laB9PB5RSrFer7m9vaWu67MsZhoQxGTDBaW1aB/oo6frGj68f48yhqpaoKJg9jfbLavFgu1mTV1XqcGppEiMmbbtRIOlLFHK4L2savphpGv7pK4YEPEo4dv7ZGarfUDNRMy00mCgKCwG0SrPLonWGopyyd3DPav1knpRg1KiiqgibdsSQqC4v8dYA86L/sw4TisWrQpCcAzjgHNyHKQs0/nU6ZpXA+k7BcRrskgZqazokmTwjKGVi4fzfyeoAyVmA1cSqmtj7ue2+fvknJ2vdieLvVmhPv/dT5O4xjtFMApvEzwVAuKomX7UCQq6Rj44G98Z9L6MC/EcJjn/089j1/lzLh3fL7e/C8b9nyml/iPg/wD+8xjjZ+B74H+bveZ36bkvNqXUPwL+EcBmu7nayHJtqZVpNvOTOM+yL/cRT+DbWdZ98V2ufmbert1087/lbR6g5xX2Kfu/mF2/lnHn185hkcusfR7UQ3K9dj7BJMNI3/cp8+6FjpdYCUVZUi83lOUCgqHpBtqm43l34Ni2aGtQVpogRjemJWOg67rpOPP1ys0/3nsOB2GFaDTfvfuO9c1Kmmtm2bhgn5F+6LFasVwt+c2f/RnP+x0fnz/z9PSJ/aFhc7MBY1AxUpoSYxRtf6RtG7q+QynFarXi4eGBzVZUAXPWVRSFnENraV2fDBAQN/QxydcOA23XUVULFosFCsVvfvMb3r59S1VaxmHgeNizWa949+a1nIc0MQ7OY0stPPFhlMJvN9B2PaBS92jKXhVJI1pqAzZmzF7cWWJy/tZRjGq1sSyWC2yhMTrw3S9/IRNHWWCtIapIWVWog+Lp6YmylMkmAv3Q4/wRpRUbVhRGinpdP9B0PVUtfps+CPMEJfeonsUTcWM5OaYbk4q/Sp2avGb359w96TRWvtRAIRfy0ya9GKQV0c8nRdO41FpkuWdjKX+2SQyUebyIUQSndM6rc1zwXizDVEiNVYkJAl9m3NMRTF8uVQJOnZDyeeqLcDv/HurL0HM1dqWz9eWLZ9vfNnD/18A/Ro7lHwP/JfAfw9Vp4uo3iDH+U+CfArx79zZecyS5hoHF+PMHNc+SU4lxupjXNAfmJ+4S7jh97stZ8fn3O78I8wtzeVzzfy/3m3/P5+XaBHCGn6e/jaO0H4/JEEF4206W70G6uIyxWGXxLtCNDW030hw79ocDx0YE+bXRYCJt1zD0HcF7gnOSqaVlpRsHnCuwRlNVJfudoUOq/LvdLjX/DLRtw2K54HA4UKR9F6Wh60fqqsbYgtdv3vL3/+Iv+Zf/8l/QtA1dNyYKJWSfwq478zyYJgAAIABJREFUKQ7+8pe/5ObmhuVySUiFRGPtZJqcrdcE1uixRkSlgthrE3zCTZ1DKUVdVbx584bXb9/gx4Eff/iBxaLmH/yDv+D+4Z7d7hlrLV0/AJqm6XAx0jvPOLjEO9YJ7ZBOyiwUNCUZWmMKTVROGkeUJuDRMenEBIeKnnWxYnuzBjwrtcQYQ7moqOpqmvjyvdA0DXVdU5cl2huGoWe3P2CsZrteCTw0DsmKzFEW9rTUV0IL9M5NA1fl+zjfg6ngmGHdy5rN/J7Mf59Ltl6Os/m9nTt9OeM3X9+mMZTgJAn8SUpVHJqJIduDSaKhtUwKWYZ8rrXvR0cM4J0mapHoFVXBmLyeJMqECdnOgfz0+2X8mH/Xl8bz17azuhzqhcgp298qcMcY3+fHSqn/Bvif06+/A341e+kvgd//7P74edhhCl5k3P/lAuUZbJKXNFwpcl4E5vnfL2/OlyCTa7DL1WP8SvB+aVKYP5cHRA5I86XcVLxJf3M+4JNM65B0s0W+1ZPdQNq2IUQtnO5+YOgcQ9fhx5Fh6EGL5HzTHgnjgEUKf+MwCHxQlgJx9R0//fQeay2Hw562bShsmSYJsFZjC5v0PgzWFlJQ9AXej4z9SIwKU5a8++47xnHk//6X/5zPn5/R+paqNAleiNRVzS9+8R21kSw5i/574tSMxIzPboxwoq0tqBZLYhTNcDd40IphGHn73Svu7u9ZLte8efcuBX7F3/vLv8+bV/f8+te/IhIpSiuOP6MTTZN+wJRVEt3yeC/FqODF5i3EKGJd032Trq2SEBCR+zIieiY+OCLSCVqUgkn7IPeItWkihckpfbVaTcfZNA1Ga2whKowxeLpuwBhDXW0pylKMhIcBYzSjc3SjTFiZtnp512ad6BAj0RqhM3KqQ80z73zPXvK804CQc5ATlFmAlx0ooroe6C8TpgxBAMkJ6mL1O9FRFYU1GI1k1EZNGf6U8ADWCLSnhhHFyOjjxLCRhXqUhppZ/SGH1fxP5lurdJxzXtwXkSCeP/m1QP6yorlsf6vArZT6Lsb4Y/r1PwD+r/T4fwL+O6XUf4UUJ/8c+N//mH2+dBBfQCCc6ICXmetZgE+vz44XXwva1wL4vLngGqzxN9kuZ+DLG/KlFmE43eA5856U/lKRafoJcTKGlQ5JnwL3wDAOScY1SbbS0XUijt92A03TSnAfPcM4CBXLiBa1GwZUDOjCQszFyHLC2XPjxTAMbDYb3rx5I84z/YDzA9bW1FVF27UYs0hYe6TvDDEKba4bktFwUXL36hV//ud/n7/6f3/L8ThgzBKtNF3XYU3Fw0ON9qnRyLnE1CimZXz29RyGgaaRzH2zWmPLiv3+IBx1L4F2uVrz+vVbHh5e8/DqgYeHV9zc3jAMHQ/3NzzcbFmvV2J67MWmTTpEC7SLqadAobXog6ukRRHmq6gUtJQOhNGj8nfUMYmlRUxhiAoKZ6kWC9HTDiOBQGEsyiZcVwsFTSs1YbneezTgnNi2GWvoO0fTdWij6McFi7pkHHqarsMWBVFp+n7ExzhROY061YaySbmTf9AJTviyEnd+b09j52J85nv+7L6OoIJwvo2a0MyfHW9Kn1hll2ytPF6mIrVI96GNxmgjipe2pCpHyqKlLGVyK7qOxkA/qLRKTb6TKJRJY+60Bkmfx+y5v/l2LVGdxwUVv858+2PogP898A+BV0qp3wH/BfAPlVL/LnIUvwX+k/Th/1wp9T8C/wK57v9p/DlGycufe/XxfMr6WsY93VDMuJRXsvLLfb0UXOev+2OD+EuriMss4muB+3LlMXcPydt5UE/0MncSlpJOR/mRzruO4Fu8D3TdwPHQishUEJnQsqpQ1BTGoMo06A8HxmSWOySNlPVqjTWG4/FAjLBIWtLOjTSt8LgLK4a4r9+8xo2OgztiraWqZL9FWVAvFyJ8NQysN1vwYsD76fGR9z8+UteW1aoWNss4YlATc8AoWSZnVpJJ+LZzYqO2XG9QxnJoGvaHI0OyZtve3PKnf/rv8PrdOzabG16/eZMofI6iKFksFlLw1DB2A8PQ0yYFQbQ0PY1OXITmqx9lEkvjMnvU0tiijcFM1zPik/clKIqqpKpKlIo4P6KLxHxQcg/r1IgS88or0Q1dUVCkxhQfRbLX6oj3Ff0wsKiKKcjHGGVVYW2S3RXWhdV6SnBM5mJjyCv2OWx3CYV8cb+q0wrjJRG2EyaegvFl9vxS0FcyfSgtsEj+U1TyP610KjUafMyTpkFr8UstTUFVjuKxaTu0ApMgFWsUXS9Al/Mi96tQeBVRIVnakXFzhUJLDSPHE2YkAi4z7i9X1V+FUuJXkZI/ilXyH155+r/9yuv/CfBPfm6/8y3jRS/BE1+89krwvvgO0+NwccKu7vPvkE2/tL0Ehbz02mu/X64GLoP2/HtLFp70SbxnTAyDDJ2Mo+iO5Pb39nAU/HuU7soYQJlCsL4YwHtMaamWS5w1fGwb6RgshWGxWa9Zr9dst1tifM379+/FnswYbu/uWC4XtG1LczywP+wIMXB3c8Nms+F4POJdoK4qjseWfSsMkaIo6UaPKWru715Tlwu6puH582faY4s1Ck2gNAqVsv4QAj4xkrTWqKQz/unTJ5q2RUfNcWjoxxFlCu5e3bDZ3vHnf+8v+P77X7G9vRW9lhAxRcHueKCwmj9b/Zq6LhmGNgW4fmLnRF0kl5wLCy6tk9FwgrA4TwDmxT15fcTESNO0jN6JGbOViUibpOmsBW0N0U+BMIYwWcC5cUQphfMO45zg4VUlPO6uYxgWjD4K/x4S3dJOhTeR6XVSCM73mFKEeGqtEZNcTs4zM3mKaxlyDtqXNaXL8S1/BzXNdS9rCeXfdYrc6iKsqel/pA5jUEGBFpMRGwKFCWL4PFqsMVLwLQxlZanagqbrafoEK6ZJUcaVImJEPyQdU4iRiMbF+Rj/CkySUPLLFcq1GCCQ8Ndj0jfROQnXvRSvZb0x4W7XMuyrr7+ASuavm8MQ19gmZ9/wbxHc5wE4f87f5H1ETm4a+sTmmF/0/FgodCLZmgWlBu8ZhqwG2Itg1DDS9x2H3RNt04pxQtTEqDG2oKxqrF1QVyWr5ZKiKIh1RVFYQvCsVquk7Ce2ZsMw0nUtWmsKW7A/7HHesd6sqeqSxeIBUBwPR56enhKF0LNr9+ziDhdGxpiKlMZibcHNtuJ4OLBaKX75yz/hsL/FuZ6nz4/sDnsKw6Q9XhQFRVVitMZ5wesPhwPH5oC1BcpaNss1329vWCyW3N0/8P2v/4TbmzvKaklUCucjz887LMJ+ub8RDe+u63CjuNWLVKzUDdBqar3O11fw1YvsktkAjhGtzztnBfLQGKPwEaq6RCkYxwFtS4FSlMgnRFKvw0w7u6oqKTYGGRODG6m0FFqJBd4NdH1H25YUm5U074RIoTRlwsMvk4E5dh18wCsv9FudCpNGmn7mcM21MTtNMhf36uXqmIT1nyRYQ8KvT7EgFyIFQ45TNvq1cZ8nAYMS1koM0sqfVi3GGNF3KRRFZamqguVQ0w6OsRcK5ehGxuTsNAXstNoJMTJ4GIOaJCYy/h7S6u/Sd9xHz7xYfTbWZ4/lnzy1Xt++kcB9HeN+aUmmdG7ESbNcWp4xBbwT7+Ra9jrff77A+XFh7NTSqlJ7KyA0qanpVf4eT9WKF5c/50vLi8lh+roXxy6TMycLp5SpRFJLe+KmBunS814RYiAgnGoXPEOItL2nzQp//UjwDu0drmsYenFpGQZxjYloiqICHVmzZLNacHd3g9Zi9muMoW1boqwYCYnpoVDEoCiLivVami+cHymtZMTHQ4NSsF5v8M6xPzQsl0u8jzx+/Ij3wvw4mIZxHLnZblnWC/G8RPHLP/kT+r6jqgqsUTx//szT50/sds/sD3ue9ztoxKvR+4AtLOvtK27v31KVJZvtmvu7O+7v7imKguVyxZt37xgHLyqDyLGUyxLvBuLQcrdZEL2jd4GhG9kdOpou4AIEJfCBaHkYMS4mslgsxNYtNRqpIIW4DOFI7PCgFOPQY8uS4F2iqCFGyUXO6gLjMKKtRYXEnjDZJiw1xhCI3hMQhoQxhsIA0RNC4o870adp2p5FYp5YI3of+ADBCxyWMvBp7HhHSJo3bnBEo4nWiD0X0mhvE2SjycE4ZblRsOVsSpyL4SFGOS8ZTgBiaut2WomUq5JGKa0iSXBRPCfTxBHyiYRTEJ9YY6cxFfMgUmncqgTfINdMa3nO6BKroLKGZWHpR0/Ti42fqFm6BEcFOR95MguiQ987zxAQaeNsqxcDIZhTgI7ZmFtqSqAnWYopLsRZjMj1AfV3hEr+/9quZdsv49wvvx/yUkO2a91aL36evDlHZSQbyM/DFKfzsigFr68VVs9m1Bcy7uvvVyjM9JiYRH7CeSaTs5ZpKgviuCLmtAZMgS4CVRUhBEbd0nWWYeiTWuCQ2AuGSKQKJUpHytKyrCq00QxOtEaapkUpaXoRFslxWrJ77ymKkpubW7x3/PDDDwzDMLEfxkGW9LmNPWO2MRrarqNt98m0N9JVLXVVMTrHDz8+s9ms2d7ccHd/x/e/+g0xQt91PD8/sds9sd/tcKPDWsM4DqDg4f6O9WrNYlGwWi3ZbDZiHAxYWxBjT1mX7NuO9tjQ9T34kXcPt1iReKPvBz4/7dgfWmGOROEim5R5dn2bMmRxsZ/fo5fKjSgpmFZVhTVGJqvjYZoUlTVT5hZjJLhIoS1+jMTgKFWBMqc6h/MDBGHbDGNH7AMbvcFW5rTKNBbvxqRZM7Cs6yQAJayjruvwMbXrJ113BUSjBTIj6X4Doxdx0nxHhhCxJorPolIpGApR1AVZa8wz1JgmsXM1S01QEZcmNI0wA22CZXRExljMY+403qLOZgUvxwVh7uT3yWOVipWlssSgKYyisoaxsAwusKhCMs2W7lfn3dl4Owvc3gsTJf0uzWgxmWVkCWRhHQ3O0SQZ5SFIk5ROEx6ZuTKN+zhRSV/avo3APcsqX7oQX2TdV36fL52uve4l7Gz+2Zpz3G7+mst95Fnx2lLtqwf7x2xp4pBJOyQ4I2f8eTnK9Fy+obMLidaGoqxYBI2Klj4oxr5nGDxdL9RAlyRfQwhUpaGuS25vbnj9cM+rhztu77bEALujOJVn04bFQtghudlB2BudsDyUEgXB1AwzjiNF6rjMz+92O6qqoq5rDocD3jvKsqBpGsZxoD2KvvSvf/0rvv/FW4wRfvLj40/U9QKtDE3ToLXi3Xffcf9wz9B1lGWBJlIvau7ubgjOgYLlUrjQfdsRQsQYS3AiVnQ4HIghSFehV7x+85ZFXcnkkLQ+nJeg7ZyoIpqYil/OC5QUI33fU9c1WuuJfZLvl/lyPgczN45TlnaJfZMz0hSgVVCi+V1IkZE8YafimVJKVlWjwxZhWiUWRYGLYdpXjAFjCozW1HUthc2+o+06BueEZZKghEy3Q2VDAjXBOzm7DiF9B30OCc4x7kuYZLq9Z1ixix7SijbqQDSGaER3RCth6ZyGj0rZ9R/J9kp66FNCnh5MDKQMqRiDKcCUYRoT85+z7xxCasSKuNlrfDiJvPm0Is6yysMwUnWOtu/lPlcy74YQcdHN4odMu7kR6KXtmwjcinPlvLxdYsTzx9cy5mvvnb/vjwnc9gJf+9pKQFynr+NV156LfwTEffn6+XfU+nSTzVcXkomL9KQ2VjoEtSJS42NL2zrazrF/3vP0+TP7vWSoWQDJaM1qteDNqwd+9f0veP32LavFgnEceX7e8fS8p+0HaWiZdUjWdU1VVVPQzswFgUbWE7OjbVvRzCgK6rqmaRoeHx8nnNpaS9d1kmWPPU3XUpYFH97/ARU9m80mBX8prmkTKeoCQuR594xSsFotWC4qbrcbNusVCmnNXyxWdH1P3/eUlWiyNE1HWVX8+NN7lNY47/Ax8KvvvhPIoazY7XbsdlJUlXMdU/AOoqKXomM+J5mCZq2dsuKcbebsuyyKE5wH4lyTC3ghKVlk6A4QydXE5EgmFt771ExUTnz+qhZDCJRicJ5SeyKkYxHBrBgCSgnMUljNMGpp6LGGbhwZ3Eg79Clwm9R1aRJVL5JdpxwCWRh1wsMN6ixIo6zAJi+MyZyBS+AWql1eJUelT7rY1oIWd/QYZAkQQyqUxsTiSODCCRfOgV3OJQlujGnATgtpTjh4VBqtrbSx+4BO2P8lVp+PIf/ugyhExigdsD7KNVJRSVYePN4FxlE8XhetGJg0ZUnbtXRdTz+OGG2k1iQegRJTfqYe9k0Ebji/yF8L2PnxtYz4MvP9WvB+KXCfOKKy3LsawNNNGaKYm8rNkCCWK587fb5WV5+/fE9+PDVdpMwA5AacaH8+JEEgBcqIrGdV4IniCzkMPD83fPq0Z7870hw6+t6jED7rei1UtLqWrsFf/epXvH33js16S0TRdh1d17Lb7dgfG/p+kCJkUbBcLieT4rIsGYaBImWEsjw8GQcfDodUyBT2x2azmYL1freX1XAIDF6w6s16w2JZs14t0iAXHHiz2WCKkn3TMvQNhbFiVbaoebi/Zb2oBMN1gk9uNiv2h4YQ5Lo6J9jx4dgwPO8oioK271Ex8OrulvV6KbCOG2nalsE5QKXsSgJ0QApcWhusUnS9aIIbawXLDCmIpwKWXHdhNphcHFHQts2UwRZVSVkUjImXXhQWH+R+MqkwGWOYluCQXHdyzUUbqnox1UWyabMqK0pjIPhklyZSsFEphlEKlwEw1lBoNYn/xyBYrcZjlMJqI3ols/s3X2fhzZ+ycik5nYLOvKA+juMX4xBkUvEZWphp7QuDJBJUKlgCyii0AZ2x/1mNKc73DQnavKD+TpNL/g5p1arAEon6nA0m5yOc9g2n8Y4oDZKCdxbpIgrfPgQ5l7mvYrUQLfxuuaDpWo7HhmPbiZ2gc4wuZe3eCwT1YrT4ZgL3uTrgtYA7f3zpjXe5LLvcx7WZ/9oSK0axIFIoGew5kF/8J9C3msxN48U+XqT3XWlgmP/9y+Pw0/efsu4QQCkql+locg8VRY0pDEPoGY4dHz/t+OHHj3z8+MR+fyD4EaULlqstarUCNlSlZblYsNmsePfuDb/8/nuWqxUow6enJ4aUqY5uxGjN/f09Nzc3VFWF1mIM3HUd3vvUWDNMEMbNzQ11XU/Mj/1+j/d++jdn6LawfP7wEaWgLAucE0OBrjtCvOXVqwf6vidzm30Q/Q8fHIu64hffvWOxqEV728t7tY5UVUnbSsFTIdKrbpTmmyF3DaJ4/foVZS289NViwdj1PD/vGJ04M7YpK0oXQibf1KodowRslErHI1rpaIVCozETtzr6iLZSnBvGnufdE6vVinpRy4RnNM5nDQzBYpUW1sk8U53+jRqFBK7Ryfez1mIAN3p6BqyxmLKaCo1EKSbKZF1yOO5pepH31abAZKZJck4SQTBFMAETZNVgg4hORWPECk1BjAKvqJTKzlehE2Y/C+Dzcay0FmglyMrRq4iJELxAKCHZgGklk7eK4qQuydYpCOf60WWCZbWsGM7Ge4yopIMzQSgJZTZKEfOklF4bryR4cyBjPm7ze0IyX5g4986zqhGXpL5kNSxYLxccWsm8236g7eVeG/qBUXmuhKhp+yYCd4yy5Pzy+fPgm3/mbJB8Mq8xUC4z9/nJv9RGeQlyubafvM3dmK8F7C+OI4bz3y/ed/n8JU0rCyjNcTelFGVVYYslY9CMfuTDh2f++q8/sD/0tI3neBzxY0dZKBaVwBXr1T032xX393fcbdcsF8I6qAqRPq2qgqouKYqCqqpZLAzrjYg55S1jsxkqGcdRGnPWUpB0znE4HHh8fBTxKa25u7ujKAqRmz0eaY5HtFaE4Gnbliq5vjs38unTJ2L0PDzc07ZHCdBK4UPk/uGe+/t7Hh8fqeuSh/tbumFAqUAMcDw2U9NRvt6HpkEpg7UlKCirgtVyRdc3qMISg6dpGvbHI4MTuYBcSAVFUVTC4ghR9LRdamhJiUR+nLtKx8Qp11qLG83Q0XUdTdOw3WwE5qiqVPTyYjic7kub2vlVFA62SRKrwJQFToJmaRKyRSkTjhZN8WEYoK4x1lAWRs5tKoKWhWV7syHuYX9sUMaxNJrBe7TSFEWJAtwwSNORSbrXTlYQ1mQ7Po01Gqfmre1fjsNLuAGYKHTnAlVy3oKWlYvyKgXuRAvUKvG+T4lVjr7XVsenpOkkPyDvOz0fIRVGhTGTC4uS4J2OJUOVc7wfdWokugzmeWUs3HsYh0BVFiwGaYzqlwu2w0jTtVPgbvuOrunp+nHSYLm2fSOBO0543eXzeTvHek+wSOZgf6nbe30/l4/zfiYe9/ziXgnsZ/vNPxc35NkMPAvMp9tF3ngmlpV+P9tHyq5BloaRNGhCskzSojFtTEFUlnYI7PaO3WGkaT39AKgSa0qic+AdwXlUkKp+VdVslivWqyV1VVKWFhUDpTUs65pxdGy2a3wgWZ9JsI0xsl6vKYqC1Wo1UZvquma9XtM0x4lRslqt2O/3aK3p+579fs/Nzc2k4GeLgvViwfF4oLBFmtwCy+WGEAPGKJrmyHq15ObmBmMsm5sbrFE8fviJuq642W4FA0bRdwOb1YrdscUaQ1XVtG3Hfn9E64K267FFhS0Mbduh7TOLukCpwPPTZ7puxPmAQidPSgkgPgiG6RMcEZGM2OpiWlKTMq45RGITfCTZcEnwnt0oGhmLxWLiKDvn0v0geLIEaogEnB8JQXRMTverIX1k0hvRhEjKwqWjpa4qnHMsakO9qKnLitKILyVasahrsiBZ10nRrCwrlFaMwYnOt5Euy8nOK4TEU9ZYFJAkVdUpd5Vxo78InteSlAyXEE8ohvcS6EJ0yQVnbv6NBO40VvNkkX/PATVL1cZZ4TQHb6XyqpmJfidBOyY6X/gi9sy3U2xAvkyEzDAjZuw/EjUTjTAGMFoavYrCUlaWehRxsdWyphtGun6gG3qpC3XJqu6F7ZsI3HANJvgSMpk3yZxmwXM1ssvZ9gzf+pnPh2T+Otv/ZQA/ew+nOfbyprz2I9//Sxz8ZagkTh8QlEJFDV5RxOyoIvoLaEM3RPaN49B6XLCYckUVPN63WFOCdVglUqEheApbsllvuL+9ZbNeUJZa7LWcNJjE5OROKgr54Ml+l/m89H0/FeaWy+WEW3/8+JG7uzvKJET16tUr3r9/P7FQnp+fU9t7hdWa9njEJWuz0Y2gIkVZsFjU3N5uqeuK0lrcOGKUom+ONN6zKCvWyxV+9HgkWzWm5nnfMjqZFGKEtmvZbLd0vWP34SO/+P6OfmhZrVZUlaWuSuqywA8OlBfuehAZ1rHrUUZ0VUbnJVime8soNd0D8x+VEgltDDZf9ygiT33XTgwPSJOzyZEoQjz9rUgwjLAUHMbYhKemjDUlLtbY6bpYWwAK7zxmqaWQWRRYrfFRMPS6LDFunMaIC8JE6YYRNzpUoaSQ5yPjIMXr0hoKa4la470IbYWkm6K1TrCJ5K85454nVPPxdBa8lcBKIu90gih89OgQk3XZTL1T5Sz4PA58UbPSAiPFWVcmMH1PpVRSBDz/Pj76szE4z7ZPnzML5tNQPcEneUKFPJGmCcQIbdIYjS0Mvswcb0mS+qwtNEj2XRQvh+dvJnDD+UnMv88f59/nmfL8pL88M16vbs9/V6c74ew1Xwv+Mb3+pYB9+VnpPn0RErnkZ6s8i0/HIpKsRVFMWhqiQw37Y8vTztH0gahrijIwDh0KB9GIqL8Fowaic7RNw+fPnyk1dO2Km82C9WaJ1tI+7ccRYqAoCtarNUWxIEShvbVtO1H/vBeIwySmg/eeuhblvmEYaNuW/X7P8/MzTdOcFSalacSwqCuWdZXcYrywXJZLUeQbBgYiA2Cs4JpPz58xSrNar2iORx4eXlFUFXW94Kf3P2ETvHNoBkoTKYuS1WrN8+492+3NJC+7Wq0oK01ZaKIXdT4lwhXExOKQpg2disByvaXlW6ESaStDJDlozO+9GKV+0xz2PD1+4LDfUZZiMtE0DTFGiqLAWMtisQASBGWk0UcrTVQBH0/1FPkamtNdpFOGqynSvvu+o+96Vjdb6qqmLA1KiZGFwrBeLCnGEaIUuYmgmpahHxn7gaKQBioVwbmBthsZrRWKXipQy32cEp55tAoneGrOgpqP2XngS9aW02vmWH5Q6mT2kMoLc5jjcoUsBt0GFbL2u2ia5Ezbp/fp9B2JMRkC53HnppVvHnOZ0SVYeSABK0jj2pWYcmXsQ14pyArCpveG7BFbWGof8K5iHMV82ppvPONWijP9g3zAGcOT13w5KOYzen78Eh98vp/LCWH+RX6u9f38e5/cdeb7n9+Y59/jy6xjPhlNlfqEreWqeOQ8m6jrOrE6arSS5pi2czS9Z3CgVIFSBaPrGEZHDHJzqhgpy4LlYkFRlLhBioVKOQoTKAtFURaECMYqVqslRQmmG+gen9jtdgnzriastu97tNZsNpvpKIui4OnpacLi27Zls9lwd3dH3/cAU0GzSBOQTdiwMSLJaUuL1rBZr4gh8OHDBz48/kTXNDzc3/Hu3VuO+32CigyLxYLjsaWqVzRNw3pzy+HQUiy0tOQbgWuWqwXPz3uUQpx8VMGylE5N7z3jIH6RMWXwtrCy6FBKCpHkCVSjori2X96DSqkJ584T2+enJ37729+ye/rMzY1Yrd3e3RFrEc/SRlOYcsrWlZqmBUwSrsqYsIRLEVTSRsyifQgU1kzfswxSizBJh7yqS8pSeNHOOcqioiwK6tSwJTo3AastfT8w9gNOOQwabRTWFoTg6ZyDGEWu11opVF7cx4ovaz75/HwBH6o40WqnYv8smcl868wOCTmhuSgnnVrmNSa/L4lORVlAYFTCw7UUPzO8oRI+LRN1LlN+uYI/sWoiRJVYJLOn0oMTH2SWiKZGIKWRyT9BXVonaEwbyhCIRcSVBbX1Db3kAAAgAElEQVRzct1f2L6RwK0pUvWbcKrOGmOm4oFS5xq8p9nwdMHkhHxtaXa+bLr4FvJPnv7T53I2a86WQ7Lz9Ey6AVTqrJtofHCiLKmzmy1OVzrho0hXljAATrdPRIKu4KTCezZaND20Mowucjj2PO8HnvaR46Fn6EPSJRlom5YwJLW4GCmrBQ+v77m7v2W1XLBeliwXhqrUGCP4YkhBwSY96+PhSN/3fPfdd2it+fDhw0RNE5lTccB5fn5OzSfnnXKbzQY3jhybRlqIg2edNE/apqEZe2IUHZTVYgFKimn9MPD7H37gd7/7HbvdTvjpwbOoCj580Kw3N7y9uwfg+ekZpUWidL8/8OHxkeA9ZnvDw3rD+/c/0Q2O7bai6zvu7t+xXK2wFtphlPMUFYOT7reoFKMTeGgMHqUNVolfZMah56LJ0z2WKHISvALejRz3Oz49PvL58xNPnz7z9Lzj9uYGZQTqevVwn6zQ0v0V50wGJZBYFANhsUHz0mFoLYYU0JUi4gnRYbRmsawwBBaLEmtzhijFPWMNx+NRVm2FeIt67xl60WFXVc2ofWr7DkQvHPCyFNaJc1Lv6PshFWNFp8ZY0bCZZ+IxZgNiACnWnQp/gpGTgvdU0EurHWKSfdBq6pLMbjaR5L+QTtkUB4ycB03EKI1Jxc2oISiZKHQEn1gq0w7iKbCqyNSoo8h4fa6hncxcZAKax4uYY/rpOkamkYwSSzKtRIM8rxgmRk6a2JRW2MJgvpJEfiOBW1FWi1NIjKdgPX8NcNIR+WI21F88nr/vpc+d/5sD+ylAz2ZYMnZ1Qf2Z1nmz/c73n78juSvz9LrJ3y5Xsm1SgQsRH5NCm4roxGMubcGqXrBZrihsiQ+KfvTsDwPPB8e+iTStY+h6mmND37UE5zgeD9Sl4nA4sts98fHpM6/f3POLX7zFhQ3arhDZSzsV4EYfGQbP8djQdf3UBZkDdl4hlWU5sURy23deWuZzMAw9T58/SSFsHGR5XlpUtLx7+wrXdzjvJMMvClQU6t7nj4/89re/5fHxA8E7bm9vpdjZdNTrLWW9kKVmkEwp+JH9fscwDminqOqKP/z0yHK1ZAiA1jR9x/ZuS7WsCBpsLe7tTlfsdnsIhtEnCp8pGL1H5AME91dKCU4aRRMmnwfvPQpSO/tA9Irjfs/u+Zn/85/9Mx4fP4pTTtQYZVGmYL8/cntzS9/1BO/wwVMUVvwlEX6+ixF8CnRGYbSwamLwaanu0egErUSIHm2gsprSWupKY21EacmqRwdFadCFiHJprViWFnyJ6424GqVj1rYkqEBwA3hH1/mUZZvJJizEyOgj3o/EfpBiYuJ9C+6uTvB9LkIGNd3zAQjaT+PLe2HYTKvE+eo6QSEm4eg+kyeTgYIxYGKAoFE2okycNFA0UticxqpJSVGefdPqNr+ePGJjmqCVaPLkwX2+ojjl2KQJKqakbJbrEaLsI+SGpvRyBZOpOchkHU/B6Or2bQRurSmrCriCC13AGulSfRG489+/KIZofRZUv9z3eTC9xrXOmUAO1pmQ/+LxqFzQOId21AR5pAufZ20SLSoGYpTBYIPCB2ELgJjdLquazWbDcrXG6JLgoe9Hjk3L8ThwOHj6pscPnnFoGbqWtj2IfomTrKfrOoyFH9//Aed7msOWttlyu1ny5tUDRWmTya0hECY89njcs9vvp2PL2XTGOkMIUzdfVUlDTtd1acCdisg32y1D37Hf71IX5YFFVXJ/f4tS8Pz8RPSecRw4Ho8AVGVFWa6kpdwYVus1r1+/pkr3TC4ohwRt0LW4ELHesDscODRCRVyvV6ImWBSpsy3Qdl3SIhdOvAgMOVmSZ55xsuMQVcSMi37JDZbzIEyI9nhkt9vxww8/8Lu/+mvG0bFcbUQTuixkxaRF3Knre9o+UpUlRSkFbK00zvsJ280QjUoyrz5pgRtrsdqexoYGo6VFPtcERNlP7mzhs3tpeU8CSmVpKEtLVZaUVgymnQtoUyZXHUVwMA7DRG+EEx00hIBLVNegFD4Ao0Mh8F+RLOWKnCBdjJepxhNnolQhSvCejx8lfpMqZboxB20l49FGTUEEI1i0xhCiRZn0oTGN9ZQJK2JS3zxh5nL2TwnXfDznL3/5/fOfLyGiy1g2h04mOvLFK6b3fPHe8+3bCNxKUScj068VJ9MLzgL3/G/Xgnn4StC+xLuF1vRlQSBG6ZCEUwFx+tu1fcNER5qsoa59XlpCnYqSCWOLQWb3kN6PFLBuNlu2N3csV1uhtg0jh2PLbn+kObaMR0d76HDdiBs9pYGq0By7keDhZrtiHwfW6xVv371iHFuOTcNqYVHeEbyThpCyxpQL6TQcR4jiOt7sGsbUOBNjnFzdY4zs93uAZAQgx1lVlSytx2HCxp+fPictEKGAvrq/Y7WqeX5+pm1blsslYy+88H2aKLbbLcbIPbJcrVit15RlKW3sRZm0TAZGJ8yLOLtOtze3vP/pJwAeHoRD7rzDBmk0OXTtpKEyDg7v44lZBBNWHULAKJ3uP5mI/AyHVakA570jes/T0xO//+EHfvjhB4JzLKpSsrd075Zllb63Q5sCrcGWJSiD84hKnkYKbRl+yC3bnALD1KUYE1yHgSidnYUtMNqQ0528Uo1RuNJ1WeK9yBIorVmtlnS9o0hu84EojkjBU2hNvVjgnGPo5blxlHthgkjSvayVSlBHQCc8I8RI8PNeDZ8gQcDMCq0ZKs3BOx2nREeNJqTESex/s5i3UooiGlkdIb6nWmlcaqkzadWk04XNEEaeSq7FEGYQ7LXta6v5S8ICQOBLgsVL73t5z7J9M4F7cua+MtOcH6BkO18+f76sOnvvlbNwmRXnz34pcF9Ww8/gkiv7vgbdzAN4PpbIqWv0bCACRmVvPMtiueTm5p7VeovRJf0YcS6KoP/owY1UKhALaHvH0DeM/cCyMqyrO56ePzGMHev1iq5tubnZsFg8UFjForQYFUR8KUbatsO3Pd3gOLY9bhwoi4I3r18Ro+hUPz8/U1qDJnJsjvhRTBbcMDDEiPM+mS5oghc3+Mef/iDdlq0wKO7vbtFa8/HjR2KM3N/f03UdIU0EmXWRBaiUUtw/PFBV1al4lYuAQTQmrLXUdS0ZWIJwFotKfDKritw+n64UQz/Stm3CVsG5xCQxyWE2npT+mCkz5lpK5CSQFoLHjyP73Y4ff/w9//b/+Td8+OknYgiMY8SQKJxas1wuWS4FokIpirICZekGhxocpQ/J1d2jks1ZjMJsifEUWETcyKGUPbuvFGqCNGIU6dFoFDp9vsgSuKkoHpFMtqoKbKNpuwEfhYFijBGJ02GU87tcnUw6QsCPHjhpsmRICTQBlcw93AR35BXnRON1YSoBxRgZndR6XIwEnxqOppGWKz+JWpsCdMaDlRIdFaeFjeKy9W+atDApyw1xcl3P3yffGDm7VxlynUGeL23X4tYXDDPOA/bl/s6S1vyGF7ZvJnBnkZ5Lqtz8NelJrqk1zQPxWTZurs+Yc5rfvIB5LXDD3GrpotPrheM5Yb36auCeD7Jg0804m6WNkiWvNYa6XrFcbqirNVDQD5GmEyZJN8jgIQas8qwqTW2WWALPrse7jpvbLTGu6IeW9WrFx49HHh9/4rvv3uBdIAya7XbJYrUGIl0/4p2I5Bit2W43KF3w6fNnnp6eOBwO7Pf7iQKolGKxWEzaJUOCOapSAvTxsOfjx0eBV1LWUxaW/W5HjJHtdsXt7S2fP3/GWkvrPX1ym1FKJUcTuUdsUVBUVQrMwpxo+26STB2GQQo+CYN1zrHdbqnrWoTxx+HsbyEEurZHXMEtowsURYlJzS4+yOonK+aFKO3gMURQwl8mYdzOSafk8bDn0+Mj+90zQ9ukrF2w3Lqsp5WI0qKzbUwB2tCPpyY0H3vpdEzHnzHiXMCeTyQhBKI+3XunYKFOdRkyhuzxXiCuIXUrl9ZMWW5hjeh9By9wia0Es07t8H0vDSLZqzKvnDJLKEbxscxNMHlS0Ah2Ld2WqXkuFfC0VH/ycEjjLQot1SN1lzlUqRJejkYryfatTVm7ihhlxNoMjTKScaPBRD35gkaiYDP6xAybj111QXrIE3T+ipdxah5DLuPMPHBf/u3a4/QE16OLbN9M4M5FnrxdoxPJrMh1/GM64Tp1U6UTlWfMK5+Z8bP8/q/NcPn7RRJuHjMbZFabnGVy+aKb1Ighk72evuNUs4hx0nwQ2ET2abWmKqTFfbHcUhYrvFf0jaftR47tQD+MtJ1gksGNKCcWZMuyYvvuFdtVxQ9//TsOh2fWq5qbmyWLRc1qVaEQKc16UVNZEZ1qmlaCgrEslwuquGB0QQTm25Hj4TC1qK9Sw41S0ohTWIu1hsN+T9d3FKXwuH/8/e85Hg+UhXgc1lXFer1is9kwDD3Wijb4v/pX/4rb21vBxlOHZlYg9N6zTlZpWftEWsMlwIcJboKmbcW6K8EBIUqg64deJoAUTIZxZHTj5BAk0rIKpYxMDmWZCm8nwXuUmmhrLkm6KqUZUys73tMcj3z+9ImPH97TNUdC8LjRUVULqtKwWS9ZLKopUMak3+ySzrNOpgbeOZaVpRwX0+RIvveUcJ2VViJyFk/HH0IAY6VNPWaoVEFiPHkX6GNmg1iCF/aI1CssPkaWdcmxtAxjy9i3OHMSDwOBecZhoDnKpFRWJWVR4k2YIJTMsFBazBFMCoYmRKKW8ZlZZCE5B0WVDBhCmLTPQxoT03kP2bg3Ow4Jlu2DOcFYObvO0ITSk5xAfoFOhcM8ZNVFnDjVo07Z9iV0e4ln/+yPOrkLXe7n8vkpsLywfROBO29XMW3OD0ioWtfeiwRrlWk/X0eJJsjj8rkrS6J5Vn42oaSsQV+5oNMkkqrwSolk7JzxMt9X/gzpLtQs6iqZvBZELPtjz+E40raSZQ8p0+7dgHMRPzr8ONB1I0Pb8fDwwKuHW6yOPH58pGn33Nxs5Tlr+bx/ZL8/UBSGoW1pWykiFkXBarNJeKB0erXNkefnI24c2KyljX0YxCJMKXF08W6kGQf6rmO9FR0OYZlE/uTXv2K327FeLnh4eMAYw/v37zkcdsQoOPrd3R1ZuKrve2KMk9pg27aslgt8EuyJaWDbokBbMzUDOTfSdh2L5XLSC/cEVJRuyKAgeDctm/c7weUDYhSgQ6Qqi0k4KqSgna+Xc050PsqS6CTD9M4xjj1d00IMPD09sXt+omtb+q6FIIqCQ98RtVC8YnRYo8hoDEqhjCWi8KMEvq5t6ayiqjrQUi9YLheTGXKMYvprrNQa+jBK1lqVqBjRQTMMo2DO1qKQSUIgYDWds5O+iEAmZVGwqGsWdS0rr27AR4i6SLWNgBtFUKuqaoZhYL87TCsipUQzRWAdYaKHPFxcwKuA0TOcN8ZT2/qU3eo048i5ysVKlxT4Mr9dWvwDKk1cCpvodum8RpIio0EFxUiaCKLCaoWds0FIBhkJYlLmBJXk7wXnAlrzMTz/met4zyHVOT8cvoRpX6rvXdu+qcANX1+ChET7+mPeP+3nBWzqcgaVJ5mquZdLp8vn0qedXfhLuCZ3jWW4xOrMLDm/YHKDCsZcllJYKsuCAHR94HDYsz8MHA49Xe9xXhGVDAzvRzECKGuaTuzJhr7jxx87vvvuF3z37i1lqXn88IHnp8/c3mx4/eYVt2rD/rATDLgsKasiBUSkINkJNumcZ79/5scff8I5z/39PYfDgcPhMA3+Ii2jj8cj2+1W2nmD5+52ixsX02e/ffuWpjny9PSZjx8/SuuvPbVrHw4HUSMcR9brNbvdjqenJ6w1E2yitU7ei6dzPAyD4KAqt3BLsAyKyeBVhKzC1AAkuivNNHML+6FEaYN3kq37GJIKYJqMoxJMGsF8bbIHy4XAx8efeH76zIcPP8nKRIG2CfMlEFzP7ukTQy8KhloxrRiqeomxxVRsM1o47sdGXHaGoefu7p6b2xtJFrTo1IxupKoq3BjwzvPu3RuBjazokLjRE6wYU8QYJ4609gZwySqMaXwppSiLgvVqyehk4mp6x+jiFMi01iJBqxSmKIjIPTN0nZzLvpesVmusNkJv01LoFXEqdVpx+nCyd1OSoavEdbYhCKafudletD5cqkeEBFcppYhBej6MSnom6ZisT2m1QgwaUuFSqJTyN6WE4pmpjDJ+Tzu5hlNfizv5OF4O3Ofx4VrGnuOI/5lY920E7ngO2r9UDJSlWrxabJxeOwu0L1VuQaCPaQkEU9aRSEbC4UwQhlCG8lJVnR5foCtT4J7BNvlHMomUuTPD0k53FWVZYqwRJTEPTdfTdY7nXcfuuadpPc4DQRNEnQM3dvRdw7KoMKagrpccD3uen3copah+9UvevnnDalnzV38V+N1f/5bFouD12wdWq5p6UbNerqQY5LM8qBSkxqRnEaKiaR273X7qmMwt69ZaHh8faZqGu7s7Yoz0zy1FWTCOYrRqjOb777/n8fGRrmuo64rb25sps+66To7dGLbbLY3R7BLLRGuRkz1BZYphHCl0iUu46piKbEpLa/owJL9AP4rXISHBHD4xSgr6fkiYLFhTUFXSQJKbWxJJk+wwZIyhqquJEqeU4vHxI+3xwHKxoO9amuOe4/5Ad2xwYw9BnHUKW2GMFm68cwztkafHKK499YJxHNjc3FEv15hCjI+jNTht8E4mkK4b+P3vf8/zfke9qFksFpRViRks4zhQlQv2uz1VVfBwLx2qi7pKAmDSqj7BAQl28Kkt3CSCs0ijSgeKSBGUhLAkqoFjN0562plIMGXtxgjVb5QMfxhHWbFphZuNP51kaq01WG2m4qAYSQA+Scaip0kmeE/00pQTXEicwUhwSdI4SbYmW8k0MlMBWoMdxY81U24VFq9UsqeLkJqSpkLkFJIS1JMD7ClUfZFcXgbqy3+n98EX8egyW89x5Kwr88r2bQRuvsyAX8J9vp5vM2XMU5YeT9Xis5eFL2VdVZqtUWkmTtrL84LiZdady6SXMM/ZT654azXNukrSCymuaNFWNokhMYwjo4fRKzwFgYAn4KI4nAxdz+gGrAWFLK1/+rynNAXr9Yr1eksIkU+fPlFazV/85d9juaj47ru3hDDy0/s/sN4uqOuKKmlSHJtG3DjMqdh2OOwFEmmkacY5R9uK7+QyOcBnm67M6fbeizD8KFDFZrOBuODjx0een5+5v79ltVoyjuOkY2KtPQUBLUJXnz59QmvN7e0tVVXRNscJZ828cGFrjPi0zE/jkNHlRiFPUJGoitRYJA0f/TDQdj2jEwlTyeh0amxRoKV7TSuVei/kOo7JH7K0BV3bMg4DiyQ/MHQtSmuGoaPvexF3qkqWdYVSEe8cRI+ymtEFuuMBNzrq9YYQRetjEyLL1ZqiWqQVgHzvrumpU4A/7A/0CQZaxhXajHg/4n3E6pIPHx6pi4LNakHf9fjVYtK6npb+zAtpOUGSyBdDEFXFumTwTtyCihIXDd4LyydPqPl6Z231KRny2S4Ngp4FudRIREREl9Spzd17wc/nzvExMDX55ICtIpgoyUScgpsoN6aiEeDJtAwTAyFoaWYzAqtoIlZlHDvNZfn+yecjEwWnbJmz36fHs8B9CZdcxq7LGHLtvdO5mv3/2vZtBG7FdMHywcyx4nn2HV/IuOGF2eyFjFtfCcgSOE5iQfOb6Pw1JyrYfFK4BqmciiRJKyFdDK0SNSwF7piaP45NS98PKFNg6w2FsVRjSdFqaBtCBBfg2LSE0FPXhkVVo7zi8HRgHD2vX99z/+oBY8UP8g9/+AOb9YqqLPmzP/tTPn78yPF4ZBh6DocD9XLJ/iAGB6vVIp889vtnKeCNAY/h7v6Gm7BJJsM9w9gxjAOb7YrjEfqhTXztkt1uJzSyYSB4l6hnPi37hXXinWNZV5jEDlmv15O293a7nWCYGCKr1YrNep30OkjFOUNU5zKczjtiN2tsMnLunRP37hACzbGhbTtZDZRm1kjiCV6JIqKWTDK3nufJTBvD4B2fPn7EuZFFvU76GSqxMWTpv1qvWS9qoh8Z2oaQjx8wOjK6gbZziSs90g0D/eC484HF2lOYirIqGb2nLEqenp9EUbGuGf1I3/diPWZEDfCwP7KowRj46cMHCvuWuhRXHZmgxDXHagtKJmGjhe3ivU94+wk6EIszi9aKcexRGOp6Qd93GGOT/nqb7OeKxCxx05hxs4CkprEb0GHuaC4TLUpN1EQTzAmuiLMVbJK/GEcnq6Q0kkKGU7zHe0XwiuCT/VmwRG8orcZ5Q7AFmV9O8EJVDYZgNATxuvQpBuggYmNaqWkFBtcy7us497XtGvT7tcD9zWfc88IGfKmSN39O3nBiZKBm7JAcRGez4sUHTQ/nmibzJpmoZvi0NmiTuhfTDa1T91q+yfMkMi214pRTo5VNjQkQo8fojLVGCltI9h0UowuMY6DvHMfDSNcMlAsRWarqglAFxoVh7ALKDyjv6Og5HPe4I6j1hvubO0pKdvtn9rsD25s1Dw9v2O2f+OH3f+DNm9esVwvqsub1u7cMYys6Gn2Hc0NixkTcODI6h3MjXSd4sAxGEfY/tC1Pz88MfS9QTHLDGYeBMWlw9/1A3/Xc399hreXTp08cDgfKouKwP8r18z51EFpcEC3v9+/fT9emXiwnk+CyrKjqihCVYMreYaNNbIwUDK3oTA9DL004Udry67IijA5SK3XfdnRtm7wbberqk3Zx5710/QHGFOItiRbNCyNGCn3b8vnTJ7q2ES72eiOFR6BpGp52u9SgI8XScehlqW40SgnvXcWIjYE4Ct8+N+1oxL9RAWqJaFcQadojQ98xDsLQWC8X+BhomzYNbs3Qe7rume12gw89f3j8JGbRo2eJMDgG5zEmyxWACxHlvajKRpVkagWCCPHkWWltT5uMlosyYdrJENd1neDRSXDKjSO5r1gb6frMWbnS2QTZiyRCwhq9z/6nkaAD3vhZ41Aa2zFTcmVCluaZILWDmJrWosJHJbUIIioGCIbgNd4bYpHiSYw4rym9wXmdjDs8NjUSmeRkNPHSJajIYJ9CTB4xFxh1/p6zGKRUTuKEex6j1F4mtozPXdMp058g2G88486Z1TWMG84Decalrwbu/F6YcOuzz8nFiNnrz7JorSHxuC8Li/PXKnVy44iKBBXI7/jAVHyMchPI7waFaFFIsMkeiP7/o+5dQmzrtjyv35xzzfXYe0fEeX3fd2/eR1ZmmllpiZgplh0hsdKitGdLsSMKBdURRLBRpf2CahXYLbChoGiBgvZEBRuCD1BKrfSiFpWZN2/e73lOROzHes2XjTHn3CvixHczC6H43BAn4uzYsR9rrTnmGP/xH/8/l9HhHXgP66w4nzy9X7HWM7SRwSr0bYM1lnkKBG/p9cpXYeFyXpiPE49Bc7jZ8/bNG86XE8fjkZubA3d3r5mXmT/+/AvevH3Fwe1pO8vQWZbo8G5l1YrXebAFwLZtDUTzPLP6gPOi8qeAu5sbXC+MguPxWDnXKaWM9y7c3b2i7zoeHh5wzjEMA3MedOn7XuiDpmGeFw63N1zOZ7744nNubm65vb3l7u6Ob775BmO0SJomcZ5xwaPMKhOW3uFDdlrPDTvvXT3t1nYYrQnOE3VkmRbGy5kEdK2twyiCiYpxQdNYUdsLQdglGpZ1JpmGpD3zeCF5x2Ho0dbiIUMwRR5VsON1WVFWAl/b7cWUWGgQxBhoZzFQXpYV72bWKPQ9HWHXi7SBai1o0KfMlCCRvIMon6s1Uo2Ml4m2HQghcf94ZNgNGLtyf7rQDz13dweiVuKDGUSRLiSRstUqVxspkULIq0TlGQJhafjgaEzAo1iWkRCvqn0+qwVKBi9Yuco+lyHE3JAUqYBCzwzwZF0FF6qBcMiDPEGHJwyschObjZR7PDl4pwBJzBdCBJUMDoF9UjCERuOtIfqsguilKds2RvB2Izi/NSL3YMraN6bOEFCSNnWNITHVSAMqS+Ny3Ry2Pa+UA3dKVwQh5uAdwtbRSv4JqeidvHz7jgRuTWO7J8H3+fcnpUQJ3E+eQ9UDVpt/+bHPH7f9DteLqATw7X3fFrjl+fMOqmPWgwClkiiUpUSKCW3IZWhDCo3IOUbHOM45M3WcLzNGW1SyFUde3cywa/C9orGa3U7TtnvWvcXohrevb/js09c8fDjz/usP4mQ+i57Gzb5HGcUyj5A8h/2OyyUyTyOKxIf3M598csthP/DJJ58Q8kUWQhDsum1Z1pWmabi5vQWlOV+meg7meeZ4PHJ/fy9Zb7Yte/XqFefzWSh3seH+/p55ntntdpxOMmzTWMOyTsxe9DKGYeDhw3vmeaazFmtkxD96J4s/BjpruT3shXI4jTS2qQyUYuVW6HHluijwx5KbqOs8czqd8TFUJb5SIZXzbawFbVmdNDU1XD0DE9UM9vb2FmLEKxHeCiFWrJ/MiOj6nn3foo2Y/0rqKeYMjdEw9HmYZeF0urCsnsv5RPCRftjR7ffs7atMA9yxjoKpA0I19J59EN63aSy7QeR+x2kUPF0pxmnidLlwnnZYPWAVMqzlJQNXNERd3GZKU13XwKS1SOwapRndzLxIRaJ0UzNygOBkA3Vura5Nysi6cc7VtbYV5No6Xql0hQ3Ket9aCz7pfSlV9UxSzbRjDfxApXGGYIhe4Y3Bec1qDHZdRJJWy9BOYyTjboyRwK2NON0XMa1CMFBP8Xfpf1ytzWSESHD7TZssxyV576JikepsQcjfXfAVRlE53X46Lfrx7U8M3EqpHwH/IfA9ZMP7Wymlf08p9Qb4T4E/A/wB8C+nlO7z3/w7wF9G3G7/zZTSf/UnvU5RDpMTV1Soi5xXPhJPypWnmXXZ/CpBr0An5b+bMof6TOXoih9SOSFbHLsokuXPlZ+rXGy5WZLxNxnFF1oWSAA3jWQ4EEjBMp5XlnVhnCdiiFzOI6sLtFayc9tobPKPxk4AACAASURBVKsJ0XEZH9jvDbbtaRoZ5ilO3bd3Pa9f/RL+R/DlF1/z9dcfWGaXXWkcjbYMg8W5FaVgGITZoJVCpcTDh3uMkYlH7xzjOEoz8faWthM2QtGlXlbPsrg6Ql38QQtMUoSbykRiCIH7+/vKPhhHGdQYhoGHhw80jWGZZn74wx/y+eefczqLuUDXdbx9+7YaMJSm5zAMKKX48OEDkcSlMXz19VfEGHn77h1DhrtikKAsuGsjQTVP9U3TJO7ntqkbcd91IthV9EhAJkZDENuvEIgh0HUdKiUMCmsaonPZbUczrwvBCaw0L7P4bnYdu2Gg7yzF9DembJhgJGhgjDTpIqSDgstMmGbmZeLh4QN2tyMZw2F/YD/siHee+/fvxZczT4h679GtFamCkPje93/AYX9gXmWSdHVWOOHzwmINmESjDCbbpcU8/GMwmLzRpUxDU8pglaZvO/quY1wXNAEXIyk4UvmbkiABq/cClSjQ4SkltjSgy61OIaaEW9YngfvJ+tskTWXF+yeB++WGYNkgotEEE/HRYHRg1UooiYp8LoTpYk1DY02lMJrGYEyuFrRGG51VD8tU5nXCUmiE+hpykkCiFWqptmZZDTEnA9vvNXDnGBNi5BfE7T9Vxu2Bfzul9L8qpW6A/0Up9V8D/zrw36aU/oZS6q8Bfw34q0qpPwf8K8A/BvwS8N8opX4jpRS+5fkrhavcSqd4e3tCq1FPGwQFA9sS3F/arV/6Wakss5hSDmoZZ89wSNKauOFdPyndkkIlTfJZHFIJZKKNZMmtbWis4JRuDRwfLjx8OGfq3ZqnAiVbUyiwIoLfD60I+i8zyzxhrcI2nTi19FYoeZcjbduzH2741V/9AZ999pbj44X7hwfOp3OeClzp+4bgA7axaCOu433XEeIs9lOpuLfIZnH/8MDd3Z0YEBuTnVRWlnWt9L6UEsMgLjcuU8CmjBsXrnThY0PJ3BppbCnN+fHI23fvqpNOWbAl8D88PNTx6k8++YQYIz/96U95eHhgt9/xzftvmOaZm1sxZ2iMwbYtFMw9V1/LsqBAnLNztlrOYdu2tF2HzRi7y1mjNh192+G8q1n4FaKThT5mUSqBHq485BRl3Ns0pnpNKiV5QQqBtpGWmjT/bA4EDRFF56VJOc2O8+kR/U1LahraxtbA2A8Dp+MRFDJNaQxt28kg1jIzjhe6ricGwb9f3d2iTZM1WBINEDTEJtNTg3CiGxSqgUYbfPTEIBOG2lh623Kz2zGvK/PkUJAHoQRyMEWGwFpUhoG8c/WYlEx1y8PfVrgKoReWDPx5o+5Jtp0SVDeimuVVZorozQThlWR5BW8EDrFRJGaFkZQxcC0DOlppbCOKmKUiMk1zhXm0zFYYo+vPOgftMlQnSY3KlYrOA1YGk65Fv3eF5y2VwvPm5LbHF0L8aNhne/sTA3dK6XPg8/zzSSn1E+AHwL8I/LP5Yf8B8N8BfzXf/5+klBbg95VSfw/4p4H/4dteI4bI+Tw+f90n3+v9XKeXth92y0Ip/3+OkT2HR8p912YkrEqy5u3ff9tzGAUaVVXO2rZjt9uz63fy/Cmxzo5xnJjGhfdfj4xnYQOkFOg7kzv0Z7lIUqRpwDaKFIzg4avn9HgixcDt3Z5dP2C0YZkX1nXhi+MjQ7/n1d1buu4Vw84yTTdczhfu7x9EtS8JHNU2BmhYlsgaEtO00DRtNsOFZZWMyPmIj8smm4mVvue9r1OJpVQuGXLJtkvgNkYkPWvm61ba1hKGgcYo7j+IQ/vxJH83DAN//Md/LLBHfm5jDA8PD3z99dcy+DNeWNaFu7s7Xt3diXtOI5KkxZx3HMfMSkjVw69UBo21HA4HyfSy0YTLn6VtO2LyzN6LYJU19X0AROeZ1rU2qoU+KXiq0mXqVUx6VcZ/m8ZU+l1w1+Nm+r6+H2UatLHCS3cO7xfmeWQZhQ9+OBww5oaYAtMiFLyGxH7opYwP0iV///4bbm5uaLuedVmZ51VYSCHiQ8IrmJMHhEstoDqZdhdJJtKahjXIZozO05Rti7VNlbSV8yxrcc1QiDWyWd2+uuN0OrEsS82wy+ZeqrIt/Aiyhp5n2/AxSSHlirawSSq0GiMpT9TGfA2WdZuUfFZnCluMa3WsACIaJcHdGrQBa8wmcDfSZNW62rahs8tONhspZhJF9lcyeDkejREmVUw5cCv90Wd6wpqrxzd8FPu2t38gjFsp9WeA3wb+J+CzHNRJKX2ulPo0P+wHwP+4+bOf5fu+9RaC58OH9x9h3E9fW74LnfOqh30N1ABPM+3nwXuLeW8Dd4VHAK1i1TqoQbtgWrm0sW0LJFJcsSahtWUYDvTdAdtYYkAC9jRzvly4jBdigOkSuFxmTGNRRiYTh92ex+MjKXqUilirGAZL9A5rWkiG4COn4wVjGm5u9rS2xzYdyzKzrp6vv/5KRPlfvWa/37HbdXIRavELnGfBHksAa2zDoT0QYsYac3VxuLlBKcWw29WDvi6LNNay68k8C42uiIJN01Tx3bI4tVL0vcAFY3a9SdmENXjPq7tbHh8lsz+fz+x3Q9YumVmWibZtAcW6rrz/5msJAm4lRs/lsmKahjdv3rDb7em7vp7Lrm2Zc6ZfoJKt9GzXdexvDmhjsla4wefMsLCaQtbAthlSUfm8xyhyoqv3kjkbCThrzhRTxiQloBRvx2uCEaNwiJ1bCdrk4ycQym63Q2vDMk8E3zOOM36ZmccLwXlsNlZeFqFvluNttBaq4PhISI5EDiRNi7Utl3HkeDxxsxtwIWfcKaK1TMiajETGRhiQzgdMlxUFfbYpKKV/UeDLjcgY5dP5HGSmvNk2jeZwONB1XW1ul6BUFAW3mbdS6pnnY3oCqTxvTsqAVMpvvPCuJSaEGK4MFYrVmVD+yoZB7oPl2l2a2uTErVGbwC3NSWuaK95tyoYjmbVR1wZn+X2ZBm4aIwqP2Q0rpoR3YSPXIdDvNWjrjKZIouT9RiPnhdufOnArpQ7Afwb8Wyml4/MDun3oC/d9FImVUn8F+CsAh8MNP/ujn16j80cNRvknf9QsMPQsCy6BFlWpRirvpEXUafMHeUpMMO466UhCqsjMGqkbSWGOZMwqqxMOveLt2wOffe8H3B5eY/WeZYl8/eXX3D+eWWeHNC+lzHZBcMCYEl3TSOOtsaLDEQKiy+DZ7TrJqBdPYyy74cDqZs7HEaMa8UFMkcb0vHvTopJkpV/MM8MwsNvtsW3Lm3dvQCkeH4+iW+ETy7rgFkc3XLHg1UnTT2sxKRiniZBhlGkan7jebN1uSjab6qIVHHO3GzidZcoy5qZV8A5jxDBjnieaxnA6nWqQv7k58NVXX2Gbpmbpl/OZ4H02RbbMs1DW3r55w6tXwlrRWtdGZEqJaRTNcHK2XUr1ks2sy4qPmbngpdxHFR4xaNXQWos1DSkH8lr2A0prlnUVyV2tq1WbAnFBTzLxp4xkdN57QpQGbqnQSDLE0lhJAiQZsOx2AylF1nXBrwvLNAlmHMUgonDky2bk1lUaaUpGtZURWMyvK3dv3jDsdwSfGMdZmr67nuQd3gf2uwHTqKwdIrBeQuFDpguGmPXGE9roWqGEbDCcYsKVxm3uBQiTQga/+syMubm5qQbTJfMOm6xYK6lYa6DYJG3lnD7BsMuJyDHiOabt68xAgVIUMZintmpV9z6zP3Lg1ga0KWbNgmkX6Kv0dwo1mNzMbXOQtkbX4N21kjj5JtR4EUPMScLTxLJ8tmJ3WHRZiv3ft93+VIFbKWWRoP0fpZT+83z3l0qp7+ds+/vAV/n+nwE/2vz5D4GfP3/OlNLfAv4WwN2r1+lnP/tpDa5XrFpvAje5b5tqI7L8fwuPqE3TAHjCwd58HtT1STd/BxCeHNjN+60HMoTAu3fv+I1f/2U++94v8eruLSFo3n945OHDmdN55nIWXelht6ezHaYxwp3Oo9i9soToQUUON3uWZSZEz+Imbm7eMvcdx2XEB0fXv6JpNefzmePxzH6/E23pIHSi3W6PNg3jMjFNM5dZpt26rqNpLfubPUMUOfnL5SKl7LqIu0kUpbt5XgkxsqwOtKpsjdPpVLOgki2V7OlyudTMO2SVOZVLxWkc8e2KNQ1uXXLjSwZB1hBou5bT8ciuHxiGoQ71xCgUsuPxWAPUbrej73t5PWv57NNP6duW1trrSLSOT2iJLi/kLjdaldIEE1jditKidzLPi2SS+bO2rcE2Ld45Vuek+WZlM5rnGYNs+G5dc4lsK3tImFECYzjvIClMI01z55w8Z2YPzMuKD4m71694++5dHrKx7Pc7Ygx0bcNpXJmmkcvlyLreYRpNjMKvX5aJZQG/zrj9HmssKOGyqxzsrLV5w+u4jKJeGF/d0llDMJqkJvrOSoWJiGs1jcYFme5EKUIUvNhogbyKK493Hh+EoeJDwKdI8oEyY1jEwk6nE13XVTirVC8lEUhJkrDow0e4dglq2/UHV8bIS1BqCEEgOV+yblnfJmpiaGpMeD70UkkIWl0Dd07SipbOlh5cbloplhywi9l1YzRr73NAb1BKlB59CKT4lK32EnRbN7Vnn+357U/DKlHAvw/8JKX0Nze/+i+Bfw34G/n7f7G5/z9WSv1NpDn568D//IteY10XfvoHfz9nyYWLnXJpwzXwJp6UGtugDmV8VbJblQO71h8H7s1fP8nmKV3hZ0F72zwD+PTTT/mVX/kVfuXP/BqtNdx/uHA+zpxOM+fTDEj209oG0zZgFW1nWb1DW828zgxRGAchBtquQZmWdYVlmokpsL8ZZKJunpmWkWHosW0jrupG02YXGedFQtN2LfumQSkrVL3LEa01+/1epuecWGqZ1nC4PfB4DJVtEXIm471ndTKMU5gcBXYwxjBNU8WvC2xSAnz5GoaB4+OjYIgxsviFmKfUQi4Du77FLStDJ5KtjVZ8/fWXhOxHaVTCrwuiaOdpsgzobujod6LdnXIzOXrPOI4Cr+RTVsyLyxLz3ku22naiJhgCl8sF7wO7YXedIUiJZV5EfrQwYi4XqUBCwGphD7VZXCqm7FyeqzPb2BycEi6JF6QxQombM17tnWNaHKZpub17hVKNTGxm6MM2hr6znMcFt4q87TzP2LYV8SwFOlP0tNasy4JLK7YbMLarn9c5R4oK3TR4JxKsOJlU3e97ZqdJakfbKGbnaLPsbWtlMjSRxGA3yAJsraXtWppR5hF88DKAE8VCLVZMVs57qWLLtaLUdVirfFUmib7iultK4Et9qpC9OQsZYRvcYn4vPsMlMRZTZ0XUoSZxZcNImw3gCq0qfCPnQmuNN6Fqp18FqHLoUDJkJBCKTJq2jZFmcW5WFmjJh1Alnm3TiNRzjVsqw2uxvu/GaH5B3P5TZdz/DPCvAv+HUurv5Pv+XSRg/22l1F8Gfgr8S/mA/55S6m8D/yfCSPk3fhGjBMA7x1dffn4NzvLPE9DlSSDl+rtC6Svk+G9jlOQHXwP2n3CTHR8KC0Ayso4//+f/KX7nd36HH/3ox6yz4+GbE6fjzLI4vBcxprYz7G52dEMHJqJMwAwwpJabdc+8TiQVZNLMrxgtU5Jt2xB9Iz6MuwO7Q8fiRu4fvyHyCts2hGRY3MyHB89+v6ff9RX+UMYy7IxQIjOHVtTl5BhFEss8SybUdpVPO85zZYG4bGX18PAg+tc5MB+PR6ZJhkYKVtn3wkU+nU61+ff4+Mh8OXN7Kw3AUuo758SZJiWh3OXs3TnJLMfLhcPhULP6vu9Y14WUh5uMMdzc3HD36nXVSCmVwLQsdUS+wDkFJknpamgsTi6B0+mUNyQJziVYLHHFaisypgh74jReqvtOMNKga0yRkk1C60MWcT/0Ink7jSQCUUOMnvP5LIF7FfU8aztubm+xrcAetrWZ/0y9DowW2GKeZ7wTNofJWasPgbaz7Hc7og9cTmfatid5TwhSNT3cP7Db3+Bcm+EIxcPjiceHR/b7nttXe5JK7HpLag3t4jKDQoavqvxEhiSM1rSNpTENpgmYiMgZxFCDrmS5EZuV9cp5B0l6tgYMpVJTXNUlC9X0JcGm8nOMoU4Z5nhzzcbz3xVjB9G1iURVpqNFS6WwTkq1VE5gzbx9qPztLZe7BHPyJq+0ksnqTP1rrcXbBhekstQKCse8VJJN0+A2ipjXWJPqZy86NVs3rOe3Pw2r5L/nZdwa4J/7lr/568Bf/5Oee/N4uTivELe86WsHsr6BqHiyS1IfsoFLnmFI9TE5yMvjcmfm2a6W0gsUpNzY+sd/68/xF//C7/JLv/QDTscTj/cj49njnWj8Kkw22rV0XUM/iEu7S5GUhFFxczMQHxca29A0iuBXYqMJ3tNmnPN0PmPbjn7Xcgh77u8fGOczr4bXNAgd8DKNrH5l5/eCx2tDCDK23bQth5sbpmlmvFyEBRLFoXvxjtPlzPF0Zj8MIh0751I6Rs7jhctFvvb7PcZa4R2TspGuLMTD/kCMgWWesU1zZQWAKBwmaYY2piGVjNIYvHM8Pjzw9u1bPnz4wH6/Z55nDoeDuOVkPe5iUhxjRGnp8scok40x46NF0GocR25vb3MWLg0o50TutFAFxcNSFBO9c0QfaNo+44+hcrlDEipWylnr8eGR0/lI8JE2NwmncZTsqu3RNcgo+n7H7d0dP398wDZCp5MBHWGXGC1uMt2w43B7Qz/0GCuyp1D0azTaZMecEFg37IxGm5q1juMoQlaZAZEAFzyN7SAlLucTl8uJw2GP0uQBGRlq0tYQj6JNs+464r6XjNo2WCumGomUewUCk7TZNDhl7FUa+aLnYjKbA0AlaSCWoa5SkRU2TYyyGW3XqHkmc/xtHO0QZCCrZMolwStN4W1zswTmGF1usupaHQGbjSGX8eo6gW2MIZSqIP9c7q/8c8jnKnuDlgoipdw/K58nVG68sIyabMBs6udVZKgxY/O2aYjtxyJV29t3YnJSutPxoztFiF2hVHoSdEu03X4sUTcrkEe6Yt2bB6Y8npP3581zbWCTEuwTuYsuXeY/+2u/zr/wF/8SP/reD3h4/4HHhxPT5Bkvnv3+Rho6JExjsG2gbyP7XpGSZl4TFsFZdWtQ+4GGRKstq7t6+a2r7PTDsGceJ/quY9/v4BbGSTwktW4EU9UNq4ssj0IltHk3j9HhnAwAxeSIBBa3irqDUhV3H8eR0zjig2e8jIjOx1qz6bLAyA3G29sDRisup0d5bBbLNwYZaLCWfhi4nM/cHnYsy0QZR1ZJBlqWWZpthddbgnMImVaXN4XzZSKTMjGNZVocTdvj8+NSjKyzDJmM48ibN28IefAFpbicL6SYcqPTigFtNppIKYF3mKQI60Sjd0LFWz0+JLrOkJJiXkbG85nz/XuOjw+Ml4mbmxu6tmN3uOHt20/ouz6PrYu+SwqB3eGWoBXEwOIcMTiMTsJSaQa62jzuabKMrzQDpXGsdEOkQWmLiYrkHefjI2/evubmcCCRuFwuPD6cRLtFaTANa0zsuyE30MRkeJ1HxsuZYeiJKnGeJwCC1rx/XHj7OqKMZV3OLGvE2h7dJLQO9Lahazqc94Tg6DrL3asb7o+PPJ7PrE7MKSzZaV1nXe+kSSFtAqtMGDe5wQlXKFSkVnki/VoSpdLLqv9PKUNtEJJQiMXOLFZWikBOofK5BSsuI3lPKb6FeZLS8/UPIZbHCSxSlQ8z8aHCN5uAvg3EMVpZfxkaLI1UoxXGR/nKOuW1MsnyxEopOpsIUSQevu32nQjcCiiqfOWWUkKlb+Nhv0QXVM8ek7PvtA3419fb6mqXO8uziqGsQifhp/6jv/mb/PN/6S/xq7/8y9y/f8/5dBIsVivu7vaysagAGtreklREK4dKFlTMbAKwRnEZZzqr2A29aCIDyQdM26GQk9hog2oSblnouh1vXt2htcItjqS8iEAVTRSlmf3CnCasbXIGKRnF5SLNTOeFvWCyy4rejIOL8E9knhdpnObKR+hwclCUUZweH5hnoeqdLyPTeGEYhgqftG2LImGtJnqHz43FJQlU0nVdpSQW/LLve3lMHkvXmf3RtjazYSIxCiRjbUsaQGnD8XjkfD7XTLOcc6M1a862dsOAVhq3uppVx+CYp5llnpmWmf3hNjfANco0GN2wzAsJWKaJdZ6I64LynugWxhO0rywqRmk4ObdRPgRlDG/eveP27jXvv/mclDzJzRz2e4ahR7ctTYZtFMKjjrEM78hgRogyLLMd6y7OLNaY3HAU7XJjLW3XEaMoRoYUMbrJx8sKO8Ya5jkPRyklXPyU0Akejhe6buDQWy7jyv3jiUYbWq1plAhakaJQALKq3jD07A87pvtHTscLKBn29sHVyqC6t6fN0Pa20fjkvkK5vd53zbR5AhdseykhXN2QSnCUbHwzkZiZLjUWqKcc8RJnatxQkFT6aGpT52Z2+fk6EamewHPbadDnlYNSov+idcDk6qPAuyGG3MD2lW74fMjw+e07EbiNMbx69Qp4AabIt6cB+fr7b/tw18e/jPI84XdvsfByghHq1qfv3vG7v/sX+I3f+HWmaWQaz8zTGaMbum7AtL1g1gm0Uegmc4o0klEAxopGidWK25sdx+Mj6zxyuDngvWTBjQaMkUWbAo0ROcnLeGSn9twcdqzOM84LisQ8jrggvGnbdgTvWOY5Cx3JsZnnhfN5rOwMpU2tSvy6sCyCOXonKnbrukqWTe6ElwswOJZ5qhoLzhUKoEihqozlrU50qOdxxGXOeLl4t6wUYXRIuWzbJjNtJEMq58W2bQ1QwnMWDL2M55/PZ3b7PYebm2pSXLjm5fw651C5oXi5XATvDIE//tnPONzdss+La11X6UXgCVHofOPpxPl05HI+M10ujOczqEvWqu7x68qEHIOUoRCAvm/59LPPeLx/j9YJO+zYH3a0nQzZFOeekgeKSpyHdB2+8HkAJmZnd50piFwuzGXgJeP4cl41OmehIFIE5dgBV6glY6spJZQ2OOcZpwlrwDaaeRad8s42MgWoZNKzsktyteOco7Mtvk+cLxcxW0YagSXAPV+/23X2/P7tWnyOXW//H+u0Yca7wxUSIW1w9pSIwYtmTnqayBWbtOcc6RoCsljc8/iwDfyVf57x7q1fbrnWn79/yAN7WmO8eQK7lF5AgZMUoFL6/4Zx/8O4Ndby2WefAU8P0rcH5Zd3teePLzvdS8H725qYLoBpRM9j3w/8k7/9T/Bbv/1buGXm+PCBvrcYdkIJaxWmi1nnQTKoEKPAJdZgtHSdW92ItsnqGLoeP3Qsy0oKjv3QMU0zfp3ph562b6XZ6FyWFQ08PLyn6wb63T7rTMixmS8XRkRvpHCop2nGOQmQEbDGkprEsq54t+RAEZjGESH6XwPqPM9PNBQEukgYI3z48TKzZiaJMobgHI3W+JSYp0mUAfPQS2UH5XMik5RZlGgTpCXAG/GLHC/Vn7CxLTEhrJh1keokJE6nI24VRsv+cKDv+7pBjONIUnI8KhNIaRmhb2SI6Oc//3nFEudlIRwf6dod/W6P1g34gFsXpvOJ+XzCTTNumVnGC8ZYzqcjn3z6GdZo5vHCbrejuN1rLdnT3e0d/dAzj2cOt3tCSjgfaYzKQyMlUGzElLLrS9ENV0p6BU3TVFGsaZqY1qWem3WeRQ5WG5SWDThk2l5huJyPR0zTyOwDcMibIECTJQYej0c0B+5uD8zryuo7zBpFx0NfnYfKZ5yniWl2aNPQtR3OudzcLjS2j2vil+i15f7tY7a/K+u7XO8p48fydb1OU8zNyODr/aVJqV7aPHJz8cn9OQgrXZQPs3yz/LYG9o8zbk0yBpWEVkks3O2P41FRRXw+PbqlSJbrtmxQ33b7bgTupuHdu3ffGkxfCsgy63+d+b+KtQCF6w21lHvxpsounLMglXFVLQ2Tzz59x5/9zd/M2dtK27cYoL/ZMc+KkAIaT9sobKPrhKEyMtAg5VF2tomJVTmWZeTmRtzWnXMM3S5zc2dCYzCdjNYGrZlmEao3KXIZz4SUQMk47e3hIL6E05y1IUTlzfvIOE61ERKisDhiCEQfKv/6cj4SwrXZ2LYt8zRW52+FdMVDzuKKMt1+v6/87hKwvPe1YVhEoXxezOX8LouMbpfHlCab4NaalAwxJjFCSMIt7/LgTRn0sW3HusioP8iGXzi34ziyLAt9DqRlMxKHHdkYvslj8945vv7qK77/g5b9/kY6/euKW0cIgWm8cP/NV4zns2h4r7Jhdb3GoGiN6IQv80zbyqSomCr0OOdpbMu7d5/xh38gxha2EdNnsh5zaZRtNSpKQPLO1ewLfXWlb9uW4/mCW10dKFq9p40xC521tZoJ3meWilQdiSvVbBs02txUXpcV20xcxold34r1WEKGSlor4mZElBJDi76zfPX1e1xMdN3AbhhISUylJZu9rj9Zxkq6lko9iZc1QOu0WffUNRzjBisnW5nVwJxhkVCExCTDfoJxR9F53bLUZJN8Gg/qa+dsOz7jWW+/x5xhF6YKShq2ZLgm5oTkpbhFvvYLc6Q8b92ANrDKL0IT4LsSuE1TfQUL3aY2Fnm6A5fvpXtbAnbpJAMVXxNnEmkqvHTbNiuk2aCqm0nftnz/+9/nzdu33D8+0jaGYTdADKgYONwc0NpIQ0mJ4ljbdiSkoSNMAYVJ4j0diDRDx5pZBm3XYltZOLthwLsV52WRpZRHyrXmPF64ub3FNBbnRInY+0QKWWhI6YwzO8lWc8k8XkSvIwHTPIvjTM50L5czWiXG8VKPRQwekki/piQDHKRI8A6fosh7GlNHrm2mc5UBna7r6mTc7c2h4tnbico1Gy2UcXStNf3QscwFIhEmhQ8BpQLDIBh4maI83KhaJTzf2Od5rt368j7kNSTITpcz8ziJe/o08b3vf5+b/UHErOY5u6gkkluZzmfODw+czyc5oEoaS43W3N3dMXSdQEpJNDJQitPll5E+NgAAIABJREFUDEmYLT543n36KV999QXLujAMA0sINF6U+ao8KGLPRczXcsbNg3ekRIbBWpo8THO6jEzzTNd3HA4HMRO+XHh994phN6A3wXtZV7TJPP6NtGo5J4BYsWlN07YkNOO8sHoxXEgxstpGhM2SmD/IiHeT35dluUycTkeMlmne3W5XNWuucxKqHsMKDz1jc5U1t620X6qixaEoUJgaEqR9Dt6yrlLcJHIhVPhom+E/pwnrHIQrRKJ1FpnLshgl4y5/m64c85SDeQbkhaFUoJN0nQAHaRjHnI1v38c204at+/t3PHCbxvDqzZun+JH62LrsJYrQk2w7XjVM6u6Fru7fcD1x2xH2ehCVOHpLFgXnceT3fvITfvmHP6S/uxGBJL+iUxKuLdBbcV4xWjSXm6YlxpYQsjg/osLWNQ1BJ3QeDnE+gtZYKwFv2N+w+sC8CHXPtpZ+2OFC5HgeaW1H07W41eHcyry4fF5VbXBcLlOWdZXdWyYk5zpyLNxmoZ3Nbib4q+iRVtJsDYhc6bpMT46rCx6XB2R2fVeDcciOPss0VqEol0Woipa09z7rj1A9K11ml6RkMVqxhpVYzIrzhW+tpW9tzugdHz58qBtE27Z0bctut8u6I1p4zVA38XVdURGcExf4cRxZ5pmubbOxw5y79xJUDIrpfOT4+IHL5YQPK4RA23dordjteu5ub1nWlf3uIFVQlCGpZV65D6Jn3rYdMUZ++KMf80d/+PvMq2O36wk+YlqL95GUrnhmSThiCLh5wa9CYbNty92rVzS2YXUru93AvC58/c03GAyvbm4zP9yxjjP93tD1g8i9ZtbOPM0oJXTAQsmM3qM7MYww1ubBEC2WeNPMrm/p9p3oa4RAYXUJx9xye3tD/82HbJ8XGUfRWt/v9+yHgdmsFYIrFdt2PW9v2yC2nUp8ESbJlXYKnpCFy/y64FdJegpsso0LKYQM3aSPGpXPsWuURuumVjTxBdhWKUXMv0df/zbl1wq5wq5Bu3x2ZINq8sb3UuAWMkUCY2oC922370TgbrJo0EeBdHN7Gqxz130zbRXjtSSqZMH8c8x/T8ni84nQ6rrDlqaFQosOSGP4o5/+IV98+SWJRDf8Ol2/ox2slGhAa8SF5NqQ0RgtwxOQYZuUtVUikLPUlBRBOcGbXQDVMHtHShrTDiTvWVwgqYA2lpACiwsoF4hR9IjXWlLH3OxzzIs4sK/ryjxNjJOwP8oiqr6PCZxfr9xba0mmyFVCiiFnMCGX8aLDXPC5kuGWDaJgekUZsGyMZVFuz2sdMChO4U4WoUjGihWV0galzBOxL8kadc12ytBGSiLfWjRXTIZlvvnmG5mwDCkLHUkp652ja1seHx7ohp1QPpUi+Mg4n1nmC/N8IURhjDRGYDIgT2cWqprIgp7zME9URYhrzY1GOc9v333K8fEe5xO2MaCMiCSFiEI42wq4nC8cH4+M4wgxYhrLMAzc3t1hbcviHEoJq0QrTfCBJvOivXM462AWmzcVAufTicON0FRdCBUmqAHNgVKSGRvToHRLUgYfYV5Wdp1BlC7yxqISYPI5gt0wcDpfGEcxDo7B83D/gd0wsD/cVL2ZQnMr1xJQzbO3galU0SXg1ep6s/Yrth0EGgneiT2cW/El4y49mjwYlMLzKcs8YZ3pxQW2MqYE7kiKuuobqYx1wyYIp3DFypVQBGMw2ZJNE4IvH4o69KcUZObc86/tJlXOT/3w3xYzf2FE/Yd0U0qoYUoJob+My5ZAW6lFKdv8ZI+2ooVcOs4vfdBA2ljdX3dNgYuLnKuuryWDNPJ6b959wheff87f+d//Lh/uH/lHfu3X+PGPf8h+kCxyTdA3VvSW8wXn8xBFJEpgThCV2DkFpfKIsGYNCudEe4JsaRRCYJ4WVu8xjSbEgNKKeV4Zx0lgQq2Zl4XL6cSUjXVTTFymSUwZ5iUHaeFkr4vwsGOhxMUsBgQoVTZDz7qkCu9AHiLYlKoVPw2ZIx6vk16l9C56FAU3L8EcqMFa2ChmQ7FKdUQ7Vl6upu1s5qXHWjGI7kWHNnkQJfPBy+ZhrWWcJr788svKoLhcznnwJ1S4xuZm+M1+z+IcyxoAI2p245lxuhCCQ5Ho+o55Wenaln434GNEB8fqsw75eCEBtu3yxqc5nc90rcWHSGM7Xr1+x/l8ZJ0WWh+wbUNbKq8lEPzK+XRivFxyJaLodgP7w0HEpdoW3RgeT2ceHx8p7Ih1EhpmzD2MamqQg1ypTIpMgs49GG0MNop1W0yglMPnTapvLasPYlaQA4r3Tlgjjcp6JZ5xvKC0Yr8fuH84si7Sj5mmC/Ms8NAwDLStFfrlPAscFBMps1y2mLas97xo83rdQioy3BIgBqKXDWFdVxn5d0sddEoZB6/Xanw6ZfkRTLJpNipt0MbXjHv7++eP3wZupQQXjzlwbx9fIV+thVWUz43avG55byldk9H/X2DcUDrtqv4M1IbXRxAJUnbIUAmy62GePF8pT/KW/eRAlIO5PQnlAMpAgSKmyLtPPqXtev7oD/+Qn/zff48vvn7Pjz//gh/9+Ed8+smn7GzL6mWUtYj7+JCNaRO52RbqYglzZHEiVJ+SyGiuq2ddfYZPUuVFp5QwjUwsXi5nzpdLzjbJXf2JZREzhJQibnXiX+i9aHQWGleKMojjy0hyynCJVAUSOHNvIAdAyWQ9hfWwZe48PcYRpa74XDmeISQJCjl4lCBaHrMd95VehAgDAXkjSPSdDOfMk1ALK3TS9yQkMLTWMk1THYCYxlGMJM7nylIC0V354uGeMYtidZlLTa0cRBBqniYeHu7xbqWx2WYrSbZ5uDnQ7wYxFkaGw2QjmEHl0tZ5MZ21lvM4YqxlmTzDbsfqVh7uPzCOF1prGboun7c10ydngnNiGGwMwyBSt1prVrdiUqnWBC7o2pZGaWHrZMH/NjeWS0nulgXfySRlcJ6AQCYoh4/SRI0UbR/F6jzL6khqIJJwIWB9qufFLYvwtZ1nmWfWeSECfWdJMc8AJFBNZJovzMtYOc67XV9de6pk6SYov0RI2IpJ1WCWdd3XZWV1cx0aC95VASpyxi0NTL7l2r02HK9xwENxucm/3/68hVU+gnW1zvIML1sdJqVkoCo3Tus6exbkI2IFFzfwzEu370zg3oLz25P48ZvPpY66kt+fn/R6sJDdPPDxyds2Jrcnx2qDz7zVlBJ3r16z29/w4f6eLz7/nP/t7/6E/+v/+X2+973v8b1PP+X13St2+0EcVdo2uzZHQro6uq/eY7QSe6t5JfisVheiTN05UarzQUa1z+ezNL9UyjDIJA20KCXiusqwjPNOGpox5AZXqllGzKPB4r5ypUmV8u+J598GayvHY8vHLcG7XGylpFNKKGIFrir3r6vD2rY2jbfPUxZkUyRQU3GR8ahNRdR1IqI1TVOdOlP5Obquq+yWEEJlljw8PHC5XDC5cy94ugh33d/f14ZoaWBO04R3npQ0zgdhnAQvcEjeJAtEM+x3GCvjyj5EwXf9kvno0ss4jyf6fs/dq1e5whMoRGiNB/a7gYcPH3h4uOfD+/eolGhtYfHEnMHJWP/Q9/R9X6GftCygDUPfM51HlFFimLyudG1Hlx9rjKmZsta6QldFw7tpGjE2XiX7DXkKtzFWeP5aTKyD3w6PZPaWLwJWa62E5lzBFDs1na7wxpZWWqrqolHiMjwWQ6xQRIFJvm3kXZhRHu9mlnnBuedBO1CkMlIO3qpqdm+YJQg+fWX0qOxypQBPzJUjQKzZdYk9m8BtrkSK7dp4HuwL4SIYauVTHr/lgMvf6itE+V3ncYOq/nXa5FFTNshHSrVsyjDY9QAqdZ2CrAfriislZES2XgRkrGqTaWtVTgComGiNIUThx7YJFu344Q9+wC997/scT0f++Oc/5/f//h/we7/3E9GTHnp2ux03tzdY29YyqojphChYYqM187SIdGpKrKsMQDjnAcFZT+OFeZqBRPRrNTsIoeDUEqiVEjriujpi9FnnOR+1FDM7wVeaEkr8MctRFd75ZmotXzxVijIHbqNllL+IIBkt9k5yWhIifX3F6EIoU5iBArsI5iemuc5JdXE47MWZJI/YF30HrRTWtjSNyAEU/BrE/HY3z7x994nAIuOIbVuGvr9WZzFWV/HxdMI2DZfLWRg0SrFMMyd95nB7hx5HfEjYtiP5QNMYbg43AkMtUxbFt+x2B1rbZQdww3iZOF1GWqNYllXMeo2RABI9l+ORu+wEo5Sisy2xEUZJ13W8ev2aDx/ec//+Pcuy0LWtUC+9B+Vp+z39IHTPsqhjiEznUTj6KNERQdHv9mLegapMkhBFrmC/P+Ammahd13JO+rLicH7FrR5tLFY3BO8x2tSsOEWFUAq9OLs3DXoRiYZ5ngh+JTnPZZxou47Xt3dczmfc6iQY5/PhM3xxfHjA2lYYVU2DaTthEfkVmRoVyVjRgg85Ebg2JWOIBL+yrovQQrNc7pa7TQncuVoUw+dCKaQQXFAyIVfvVypk1ss1KVFKETKGTcHEuWr1K2Nq3NAqB26dewaqsFHUFRaxERWuhgwxNoRQEk6V151G6+ya813ncSsl04XbLBi4yi4qOXBKKUyFPtSz5/g46wYJUzo3iuJmZ0Pr+pxaNXXnNEZOX5NySRwjureQxK/v03dvePf6Fb/64x/zeDzzeDzx+PjINE18PX5dMwyhCWra1ubSMGB0KbNTFlaXi7SMfpeLqGvEjaNv95DFmpz3qMLBVULhilHE7SsvtGQ5ebpwmib8suaMWGh2wfucmajrQEz08plzxqYQEaGYm0GlxSsZbyCElCukbVV0bSbJ6H3ImOpKSiUDkXLXucCyCCYdfMCtYhjhvUdpxW7YCZa6rtVIoVLNvGfO8EjTNNg8zXcZR4xSBOc47PdMlwvTOHJz2DNdzjRaEZIEaWO7jO0auk6uu8XP7PuBdZZBH9sIZt22LTeHO4xp0QkapSAG/Dwxh4APCdOIfGnbNPh1plEwXU7c7Ics7mUAgY4EglG8++Qz9vsb7j98YM1yA1FB1+8Y9nd0/U56JTFmNcUAAYIXtpJSBh8VMY+6K5NQMaBdNj3wjnESWYIYvNA5tRL2kGlYVplWbbJpBMmzzCPr0qN3N6QkDfCuMaCsjOKvUk1553DzjJsnUddLkelyxq8Lfd9hjMoDX2JoUSov7xzBrUxjzi61OPbYRufEQ9QFExnHDj73tEKGPlKVGCga51cxqUL7yz2aJJsOQFJlvoN6jarnMTFBkbqI4WrU8jwmbePLFirRWgSptNYE5Z7EI601yhhMtBLYtcg7GC0bXIGqrkhCSYy+4xm3UoomG3CWkkRA/A20sf3+DAt76eBuf9ZkJscW4zby0YVPa3Igh6Zm7yW7v/JAvZOy3zaavt/x9t2nGadeazOkNMvmLIK0fT+laVfkVAs7olDl6vtRCqUSmjJino1sVdbz0BqtGjEEzk09cZ0PdYEsWao1Zsd5gWVmzsczl8uZy2XM5WKs/FepXsjZt6JMg8pVfcXBY8bQtxe3LBY5P9qYfNSfNihLGbktEX3wuSl81Yho7XVSsFiLmaLTkcWtgOocX6iPDw8PxBi5QNUKv5xP1am96Ensdvs6xIF8kjzJmb/nBnNjLfvdnr4f6HvRJ1+WpWZt6zwLnKE082WUsfsQmM5n3DLTNaK2F5xHN1KpdLmJ2XhLP+wZdgcupxMfPnzAnS/ophVtbSM63WGRASofxM6K0shDGoUJMTOwysiyCHIeNYKVOv3U3BaliCrkhqbPTbVs15dSnoDsibGTLDgzUhJkw41FNMrHMU/fgs8buVtXlnlm2O2w2hDxjONUoZLtcJV3LldwGsVV8vQKN2hA3ndQkFysTkKlSrsO3T0djd9EFsmG9cuTjM9vpZ9WvpfblhGzvT3Hsl/Cw2ts0hqdh/Oqm84znHz7BU/h4+e370zgtk2TK/ZcGilV8TDYwBv5/x81Gzcf+MlBzhd5SmAKVKIUIW2aDRkqIZc/JXAXmylxlY50ja34IUkuOmOtDD9kkfZCsbueeHHpkYak7PyVPaEkOJayKMaQBd4TiUj0rjbBBJ82pBwkY8x4Y8aqY86mQ25OUbihkH3zDMEHHo+PPD488uWXX9aMPxSKlc/4uXfEnOEINhhQymS1xlIubqhN23OCymPr1w213KxtchlZNC0KMyU82YCB+plB8NCbGxluMUbn5ymKc5HHhwdOx0e++upLSJJR3t7ecNjd4t0iQTtXPgBNY9BNy/F4BODu1WsZxFlFP2W339MYg8o6KQWDlWphxRippI5HOfaNMblxLMdimmeMMxztkT5j1dIMb/Ax0e924qjufd4UdiTxHZeML8mIvE+zCIr5mKu0lKl7pjqRax1IXpQQ5bLPm1rRKXEO0lphxxL0EwptxLHFaJXP/VozWhH/9+IcY67rynuB9y6Xi/QfErk+u17zl/OZYRiwrUAiyzwzZ3nasj7ganxACk/OfWmSb91nyvRoaXaWwL3NuLc9lKvkwSam/AmB+6UN4KVA/vImcYUXgSfXfW3I5x6LNtmnUpsrZKskgdAb2Pc735yULEs4o8+7yeX3Tzq0fBy4X3rOzf8kiaywiwTKj4K9UoCuxHqlJNXQ+dJUKNEkSKLYJu/3aVPVPJevzCc+mrgJWNcsoNqB6YSKoFPxxUuSDaWEaXJWkV8qIotYmwZjY23clHHpSugvF3MZLOgs+30khMSyumqKAAhX24lM6rqI+0pKpeEjGZxIlgFkCU/IdefmP+l6XJ/AXnUBSOa4rnKMfDY82A4mkDH2tm3BbdQF8/mzjaHRcrGv88T5dGS8nKtsa9da3r19gzGGebrgveinzJl1o40Y6qaUjXoVORi3uHVm34n2S0IEm3wQ4acm62uvzlXD6nVdqz1XMW8oX0XjfJfNl0NIKBKmETPkEISbbduOV6/fEKJItk6rByOyuNOybmAAaNuOrh0wrUzrhpiynKqYFBdlPsXVAKQKMVECilDTFKl6gjaNpoyLV7d0L9m8zoGkXL9rdrWZpkk2d66ZY0qyVqZsPtH3vUAiWpQbt/TNAivqp4SwvD6zMqIxH2WyZe2U62a71ra3lJJMob7AinopKG5jz/PAXT7bNpA/X+clMy/Hffv3Txhs5qr3XQK5yp+tJKdamyeIw/PbdyJwSy1WxktzCb7BreSTyHDMkyDB9kSU+54GbBmEkTI+bgJ3iqnKMmolVJ6kROKUJOLoFaPKJHzJTuV1Y8oiPGUjybzn8qrFbaVyNpUSGtD2DceIUdcsq2TOVWgGKi5PUiRVWvaq0iDlqWQBh5Spks+OzuodPsqkXiChGkPTdijnSf7qMINSdDnLjimhdCApD1FhFLVzX+dTN01ieR8it2nyQMM2aBeak5TMoWZeYqIrLjXDMOQLuamVhA8iSVs2pP1+X1kMxhhx3MlGEIUyeHt7i7Vi4VZMjZec8V33b8XN7auqDe69z2qHG0qXEubGlBUTlQa/COunuOqkzGffluMlKJX/T9OEagyHu9es3vN4PHJzOGD7jvP5TGMMu8ySSXCFuYIMVSlK1Xhli3SpJQTHukxSzQXRfym2bdupQzl2Ifc0DFqT8W4ZJgkOnBEbtHma8H6fYUIxUzBRobIF2zRNdcjLOSeYd3gWYHOl573n9PiItTJMtB8GrBELvDWzXWxjcHlidrvhb4N1uYa2gfV5T+tFGh6it/IPmnG/FMC3wbo+hpeDPZvkMiaRCygxQufjk9RTjPzjr6sp+Uu370TgLpln+fn5gVZKSYNRJVRSdYT923bQJ1h3aZolKsYN4DajuLoI4CjBltVmd3x+u+JPgegjWqXMib5uG5LlbPztQs6KUxRIhSt+pWuGnvnVRqEKmyAmwd7rZy+DCZBCrBvPc5F4ENutlINjiFdn7SvefG3OXgXjI00jmHuMUZw/tIYo6mdJa0J4Ko70fJGVQYltZpRSwnDNorRSubmaceYc7IrSn49JTO+QBVkMf7XWWQlRGpKzWzkdj0zTSIrCbd7td9zc3BBzBWFtkxusEuwLO6Drerp+oOvabDMlbuNthmFijLRdR9MY+r4jKcHUY85sG9uwG3pI8rNtGrrWsq4OrWBeFqxt2O0GYgy0SoaJ+l7MF06nE7vdjt1uR4wRozSHfA1dLhfWZWSNeUPIWTBKKh2FcPMJugorkQzRWkka8nGPUTbRpjEEvz1fGpKIXzXWEkl47xjnC0NnWJaZGA/X6zQpFOkqUHa5bIJVEXu7bloqXv0ci+DX8Xik67rKTy9elD54WtqPAvJLa+/52t6u+5cmrgsEwQtBewtlbJ/reRb90n1l7YZYzBxeztSfowfN5v1vk5ptnNv+/jsPlaSUaiPvowCscqMlBAkiJXDxMib15G8RjEt+/zRwF6gEstOOKhuCTDJqfe3uvnQhSUkYQceMO1NhnGJOkOLzDQiKRneZtoyZ2pdIZCsPqLzTiBKGr5TmZZotZaW0EGtWH/ICFs5qwdPLhRMrx7t8FWigXiiIYL5MoMrQRtG3EBebWAV8thevwEPSeFMFz4/XplGlFZqrpyCwmYqU4Y2iH2KMYZwWvBG2jclDN9a2OXPrc1bpWZcFSLTWCjshZ9uF431zOPDq9sCy5EENfx2X7/rhStcMgWBlQ7k9yHs4Xy7SkNTQDzKlaYxMZu72u6wTPmAb+6yUh66T91lgG611NlAQnvThsK8i/0XTPMZAYw2Hwz5vbpG+NTjXVT9QYcF0tNZK5aZF/7uU6Fpdm2u6XItKYMiUIYXiSC5DOmIOnJQSZkpMBO+zKbRUIVY3oBU6yWZWMu0rTKHIff5r8EyJbVh8HqRSSgzDUCGkpK+c7wrzbdbcSwHs24LcR5nrxp9y+/stnv5tz7v9/TYIl2rKb9bDFmt/HrTrHERKFQ94nnR+nIQqXt665PadCNwxRsZ5+ig4XvUCnuLbMX28g25P3Pa7vrZliJvnSokccK8XuTy3QCPFufvJ+3l2MUUSUT2lDj1/zPbElwz0+Xt+vkvn/0i1kLUhFNnpIw/apCxpq2V+VIwXtJaKAQ1JPi+55E1ZYyObBbIbOoxSrKvOWVUiNlp8MBtDZ80GG40yahyvMA75uVFXKKnwYoWWeG0ePR822F7YfXulgZZSP+Y6yVppBu8Ph03gHp6Yqu52u6pH3nVdxcKdcxwOB7SKdJ0Et8LM6QcJvI21mW2z0KrSZ5EsMQH7w57G2KqB0nU9h8NB+NJazHP7rq+vt8Xi+76vY/r7/V7EmlpxILJtA1iBjkh0+4F1EWPkZugwGta+QWU1vHVdhV4XMj5vDCpDUSLIZWh0w9ZFKmpITdF+NlfucYXmhJrYtZam7XLSEjObo1SN0hTdhpBibDGMU958E9swnVKiKSSCZ0FU66fVmlwTGm2uionbQPfiuuDjoP3Rmt9UnmX9P8/mt1Zjz2/fto7L5lI161PC54QmbN5zimVqeXOt+6Kb8jSTf+nz1mP0QlVQbt+NwJ0i4zyT0hWhjmTfSKidVwW1cSi3a5YDT3qPFCqQqf6T+gmuhH6KodWfY0aJk5IvrlhxqQDIWYVSG1xbbR5YSP2bz6hyA4m0ecbyc7r+X9UnkYCplEAmkuFLAG5MqsplUcvkl0GJB6HY/9EoCFHjjYegNpmAJhhNitBojW1Ee0LKcUMXLTE4nLtipRBRKWZrqPzZtMoVQDECyFVD/gwl+6vwiL6Ouhde7zazUkpVyp4yTa12Gms53NzQNDZDJX116WmzOmDRSCmvUTLQEALezXRdS98P+f0krG1lojHGLMGrK4tB69yvUDtub28F/w7FPs2Km41vsY0wJnQSmmeTh3WA7KdpsY3YiA3DQFIQtGjVKATqalqRR21Mg80Yc0yJthlIQyeaHilVa6vVrdfexUdBSotNX/5dXS+b9QNkJcCygYLWSuChtgUl1005njGBojTL5Pjsdjtev3mDCzFPY14DdwlE5bWfwHdKVUisZLvXIB6fUOReqm5fyqifrNvNbfscJi/M54F+C5X8oox8+5hy3YYQKkwSuAbeLZvlefYtE82y1kv1nFLMjkuhQqmpVNMxoj///KPPVm7ficCdUmJxvgaCcl8JCKpkC/nnl0D95zdVIqkiMyBS5Wpfs+4rvlvub0x+nRefs6yXDGtkXFpRspJcCm028e2zbLPVJzv95sKsEARJyrz8e2HsZqw4JRTiuPEUYpG2pM6ZtVIanYxALRnrA0RXIeUBiBK4g/ytYJbCUClUPVlwaRPI5TgUC6ntZlmweaP1kwwbuA78bLKW7eIuQzVdL9rmAE3bZgGyzPFuW0rTpm0trW1zIJIMUc5Rl0ewZ5I3NLah64f6+tZaEqby77Vp8nsAkvCFb8wNw24vjciuY7+XoZTGNqzeYbRlaLv/t72ri7nuqMrP2uec9/36UZK2FrXSRkDLBRoDxBCTGmKMUUBj5Q4TlUQiXkCUqDH8JAZDuNAI6hVJERNUkJiAkRASRdEYEwX5KVCsSJEmVhqKUcOPtn3fs5cXM2tmzew1s2efc96zzxf3+vJ+Z++Z2Wut+XtmzZrZs9FfXuLxx+PA46rreqjaa9ecRb4+O8OTvAU6V+4XF2775Xq9AjFwfvN1bG86w8UTT+LycouOAZz5Pev+lXNxXTG7hWhWQNj7lwaB9CsrOcXBze3uEQPAfW3HfV7PbW+EegEuAvNms8Gtt9yCnt0Rvc7STC3T0gxUZmWpFU5YdemMOQH8jMasbcmj3K+7YbjlginpnbtKgjuHOQB3bjXreyD9VmawtHv5IrzaBizPbrfYbnusV2V4PgngJuqwOfeLVds48gAIexo9QgKQo0GdlRF5JBwh6OlW6r2dwq4DEHX+FenON5xN+JrF2Yoi0HsS60SCmaXSnQXsKpy8in7hVO1wEdX1K6yx0XBSadJZBJgJFHbhuTRuiOi8Rc7QpVmFAAAfhUlEQVTszpsIe6HFl+bP21itgC3IAbfXh3sC2O2D3q47bPt16PXOHeMP6QlAIXUy3Ceb1qPPL6vD6WUB1J81svWNsldfv16vVv6FEz8orNa46fpNfmYkC8UOWM7PzrDqGGcbdxCTnDgoxwIACHvFmW/yC5PA2WaD1ca96OR2jKxDXqQNMjGefOJxbM5uxvXr18HsAOTs/Bzdao3Li0tc78jvrb7EzTc9BSu4bX+Xl5fhqNkApszhi0KrzRrn1PuwFSDnhPc9zlbrYJHy9Wtul0gPvy5x6YyPztX41n9n8VL3EfJv//rXuInc0RFdAMGVL48+zkp7xpaBi75Hjw7rzdrtlFl3OD/buF1BXTyLo+/7cKb72dk5br31Vue22vo3aVV/Zaips2oXq9Ua4l8j72LrOnLtPAHz1P9csrKHIO40iLtLIkLkA0LJiNKzwNxVk7gy4Hd9wV7A1LuK9H14PnsmAXWffnO2GfQxoZMA7s77XJkFXP02Gh8viyzOIPKgIVNBCdcuCIrp3fRRW+cuycrXqgNuBq3chG/lLQC/eui3CXo9WL4Dx2EbIMifcOBbiHMRRD+8b1Zu58JKAb5DYj+kuMHFzTb84mL4RzpbDpDddhXvkmCAelDnK917eJgJ3AF9L4tWq2hxBzc6oecOvAXYb8dkNcDJp+EQBj7fyCROTQsB+Nd4u1gPiFZV13XurAmpP593gP05D5tw4JQ72jce7tOz2099vjnDk5cXILpE113H+TW3JXDrTz6Uo31X/gWHrlv5bYXuYx0r/7FkECVvYMrAwgxcbp/iztFYr91Jf2drbDbOjcC9/wjx9gLbix7Xzs9BBGyuOV+vLFK6M3f8Szlqlrc6W/l90c590W+vue2Tqy4sZEMWpnsEQ4Z8e2Zp/xx3Mwjvzn/piZH6pB2Axz3W4s4Sb+DWL3g7q7vD2WaD880GZ36vvLxt+eTFBf738cf90QvOZXXujS23QO4HffiFeaQAK31DBmNxpRD825PK+El/8zDfv5HGM0s4RWyAvBktz0UXjqbo4eQUW0IwJ2mCyUXqWdUPtEFQ2m1S8nFrENcvIOZ0EsBNRDjfrEMDBTJXgiJ5wzCn1HpSo7f8GVMv8lbhqosHp+u0jqcUvuxEkRP25GhUZVXrRqROJfPNBSRzWU792iu/cEjyq7EPeTkQiDgMOu7QfnJOlKQxBNgPIgUUkkYju1XUolHeyCgy8OH6Q6YcolarLlv0kQbryiWusqdxXecsbvl+aNxi6NwX222Pa/6rO48/0WFzJq/Nr8PX1eV4W7GqNpuNe9EhLkMkFpc+lU2u+74Hd0OLL38LTnbKrNcb9P0W5xdn6FbiGtJtIbrhmN2bo7qcZeqt22ZYpGJGBwplJfpod1UC3KHNCoDG+hsSeetXkTeSu9UK55sNrp1vnBuHCNu+x8XlhRvw/Dno2rUwWFxjcZ+RKgvbWiaKA4vl9hi4S/y0N08b8xlluoihu6VG1kwyKSZdnn5QG4SrtLklbf2V0lquLqGTAG4Ag1VvTXmYzqz85gUnz6zVnux8QSKfPnVdF3p53pHc73owOGh58mtVjGM2HHDK+eBgxVtphyQgbssejPhIt+yZ+kbOyaE8pXThTbBsd4ApX1u7lO4oyH20fd8HN8T5tWvB2hSfuH7hhYiScy+2biNOzAvR4E9k9H0PrDoTuIW3xEmYfNhXFtdyGZo2m81g8Uq3p6RsmYGeEyDR4JhP53XbHiyKGSTWnDZwJI/n/vwcVwfugx9934cweSVenh/0R5RfktF5FSu7K2y71XmNFegk5H1Pt8ckDjb4lfpRS3jIp7K4dXxeT8kzlf6pwRuw95oLnQRwO5+t7cuyOhmQNvAw1spzcq2mRp3BA1m4JSMH5GIeDBDPK0m2Jg2siBLPzh7FrYGL/Ev51iBghfV8mYBHvu86qQfAf6R72Ah1nvMyzBunBq20bIcfwch5BYD2izoABuAOxMU3SX+5RfgkluY/GGREV4ICbnievlwZ3vXBwW8sHy6gME13z4nFKYzY6yvBzLqzyue1AIgP2JdTv92GdpzvcdblHD4Hlk27i+Sf7bou6QOrrsPGD3zMHN6ClAFRzgrJrUMpVwDuSzWqrIeiNbDqWattRVvAXeI3oILFXS2bLD5PG/qQrJ5l/UFv+9V50YO0Lru8vsawBmgAbiK6C8AfAPhWOH/8fcz8u0T0RgA/B+ArPunrmfmD/pnXAXgF3DcMfoGZ/7wmY7Va4ZZbbikAJ6B9XgCCL1P8dQw23BZ+6hg6tJuW5SSWvvjLOvHRCn+1kFIuJHXtnHsuLz5IQGHlfXPOa6GWL82Gx2AuuIT0gMXOVSEdIGlwgP8qtk7r4rf9hQePbFHEd1QBC/ntYFtDoQgKA5fcE8VzWtJG7eolb+jSeKVOwlZCnxf9xqa2trW13nWdO4u9j20ltqe4gBfcPuR0y4GbiMJup86/ikzk3kBkQL1o5Xy7K3UAlyt79tso4wmI+ojh/HkP23G7JcQFp11gw1mp6C9bzQYDiGoZPcd+4hYII3C7cvV7uS8usdms3Tnf2/jtSlnviPUZ+4qUVU4lN0RHxmElSu1gPoT+Mw6qEUQLvOu4GMoPyhU4kOkn6FK/7NOGjzloQRwNCN0m4i98n+bwbGfigqMWi/sSwC8z8yeI6KkAPk5EH/Jxv83Mv6UTE9FzALwMwHcB+DYAf0lEz2YLhcJD7lXvkMNYRCHzgwGIBPSgGnHoad5EVOmQ4mOs4BjHzH5nXWZFMNAjvmgzRvlUJ4ysKl43sNyFIx3B8uVLmoF1AhqWEVTekZbsZuVeNhkb2YXyNQI9FbbCk9lAAfAFuPWAk8+4mDn1m8tMioY7BJKDfCQO0brVvPU6RnLwF9J6ExJLV/vGLfeE1kN46BmGyNUfWpY8aB4Awg4jravw1CBYmo63UHCVAMHXvPKyeofe6FYd1pTK1PWay8v10WSFWe2jZhiMpR2LGwuPbVHPnpCFsxpQnfXtG1oAldSe8zNu715hht9EECcF8lQYmCpwMwrczPwogEf99deI6EEAT688ci+A9zDzEwC+SEQPAXgBgL8vyuh7/M/Xv5GBcIRtHTZwdxik3SQDF0z2rHYHgAiXOiybjrZSKS1BXsBxuRNKgTvGC67l1pUDrpSP63zWtNSeKVDSWEQ/FBoLhTizLvIZB+plloO5kp7MsOKRAxLPAHVAwScKpODtwE4P6rGuA7A6hdw1FQwxNXvKZxZx4Ix8dPokXNF6vQbyQc6nDc/0EQBCCjHgmJWurKMwNHSye2Y5081tyfNWdOctbhlEnIG9dnuVMRzIALuOSwN1CyiPgXDiHjIGrH10GQP73IWRD7S5vJxXHpfzy68H/V7RJB83ET0DwPMAfATAPQBeTUQ/A+BjcFb5f8GB+j+oxx5BHehBRNicbaKalG3bUeBqga/EQcVL2k7zkg5FFM4rHgCIH2Kdq8MDZGGwCPGD/HQmAIqrpIkI0KCsmBd42KiTdvBIvdsDaISPD1DWwJYKtTVsGfxKvPXMAtQN0mmLOnnRwkbi+J3DjHrzATtt+KTVnmR1XgJAGaCHNOreGhhkim+mZwDEoYq60EfEJRjfiO23PXjTu6MdDF2rbdHIVxkk65bzMI9DwCsDZqkc2CxHLpWzzJxUunRwdv8xEI7QEHdS6IGM6AqRcBbXpySJ8QdZnCSimwG8F8BrmPmrRPQ2AG/yKr8JwFsA/CzsljyoESJ6JYBXAsDtT7sdt912i9lRrXsTRLMptvxKw8zTlHivMAJKlWdH006Zting1nJK8konQNpgyWYt1abYcs6L1qec9/IgUiKrfs08U/zggNZDd978zdoxeUE/tA1cY3ympi0CdyV+l/sUdGX9yJehahLE0b3DHI8LrvmWE5m9beXmPu4409ia6ZM0oW12Sduq5tfVaBYuoG/PCktWt+mG8q+w13RxQfqlPKdXvE592cLC249FagJuItrAgfa7mPl9Xqkvq/i3A/iAv30EwF3q8TsBfCnnycz3AbgPAL7z2Xfzxn9IwbK4xkDb80vSSLpVgV+JZ76RY0rHtOQn4QaaEVC0/qS7pLxKNs5U6y9aOpp1CdAinKTuDHsE6AasgUpnp+HMQnZoRDnuWn9LsFSPOrxmtVi0Leg4Ng1voZIuJlhwBIWDgbXcEwBoH3l8w7Dv5eQRChZix/6D2xlwl40I2+K23I5uQa8O3En5+Bfq8jKzXDf5bLPmhrHkWXoncinWUY1/SUc9OFo8au2rZVcJAXgHgAeZ+a0q/A52/m8AeCmAB/z1+wG8m4jeCrc4eTeAj1ZlAKbrogawBV0Hz+XWdtWyA0w/cckSbbHgU0b2YmPdKmwtg67qE8sUMfeIl/hriG/SpXdbEwd8JgB3SZZ72ajs487bQOvMqapfzQqfYnGX5MovUZRFcUeUzCiiyBQArftaHOCPMVbWfZIdbZjDf1aLAFZWaq5Tks9sBlSK15kfc6sEsOudtdzihqnKHZGp4/NtrKHc1CzFmlmYVnpBlqmPmQtHLRb3PQB+GsBniOh+H/Z6AD9JRM+FK/qHAfy8F/hZIvoTAP8EtyPlVVzbUQIPmIXpcYuLxMutWuslC94iq1CnWm5TyB4U5DfPv+1XL9VyGbgEIMSK8dd68TH8H8EkGr8V/yYNrf9yR+YsrTVTIRVXrruc/xjAmDxsxs3PF6mmgwLQHKBLAGyrmaYv8XLWtIoLl5nfNvievVeg0eImAvQWTyH7fJBh/jTfQX7IzQRqedWUH6Vs6RL1tvnkM145B4jSFeEBH6v+8jTVcjRDHbXsKvm7Ao8PVp55M4A3j/EekTuaplZhcVT0VhdnoE0REEKjAWPL2zTdiD6mhVpKi3YMcDPazv2GRu3jirLtaVbZkgRAao4RFhUpAXGSkmJtjvlrcWdEyRPfMlaJczXD4BA7qzUoDDiqwcrqGDV3WzvEH4YYiI2COXyUA8xhUb0G5nndjlnb7trtQOIMwKNOEb7Z/7/y9RzkqX5kPZ+22/St09z94DYj+vcRJPsQUEPwCTsV4g4ZbbnqbZo6z53XMR905L2MsBjo+fYUO5nIllbIvr0zs/8ilT9zR4G0XI/VkzVA1dpsTifx5iRjaB3Vpn8WlaxxirAT+JEftUFpmGsYbZ28NT5JO2TfxLsmo1TZo88yhfzbDaj0vG0dDwa6gp5TKB9Y3XVdbmlm1QreB7Ct7XbaIM+ae+Qd2rEat07H0pOAdvJ8qqroM3XWwmpW2AJCIruazCszmq7APAFfKKsY8WCu5MUmQoi3KN8WO4ZbtfCpoA2cCHAD0ztZnj53CdT8a2V50aKcwquVnDtobCo2TU4JoMdBv628W/O4CzBP4RdnRXVQLgF3i45h8J6BzM47oUPXLLjhPccZTEP6qQDjrPlxK9Li25LXVn39TZVPK2l/dZBxEM679Z2TAG49jZL7PN56Zkp6HV7u9IBlaR4KuGvJ9wVvy5dWBO9g2g2thhZrdRcdj0mtVstCV0OHdDdNsfSviizQnptOArinUs3aytPlrpIxYNMsDt/5J0w3GxalrLjSVGwoIJ1d1HxwYw01T8c4bOcd6Eftft5amEWH0HvXjp3XIxlhNTlT7nPelvwp1wmfwn5vC/hKYaX7Goia/cDUcDpdlcVdqoOxNnQawK0qJu9gNf+RppLVORTVZo21+eVsXuUGXba6i89U8jTm/7TITcGDNmZai8dYmSbPjaQr6tXAn/P7SlspXdfknApwo9CB97mP1+oFkAOBdUrDV+R34a1BrAT21fxP0HtKfi2ZJcAdC2+RZ9FpADeGIDjF71rqjK4j1oEvlR1Xtsf0OQZNkVkrAx3vLIVxn/m+ckt67EqJf9baMkjpGkdtgK4NrFdFY4PWGEC0AkhLHCBjd5s1XNPBon4HIBqzsEv8xgyVFkAdA9F6Wi7qW5spWPxq+czpJIA72AETLamWexdY5q3DXBsQ8B7fJ9o6/dY5bU3ewrvVkgRyq5WRbu1rl9mavtXqbnHHJHIqC1LWM6V6vErwntIZizrxuKvECmsFXqpY3FNl2lR+2aVFrhXeCrADXg3W7ehAZ97zJN61tjfV6j4J4Ab2t8iKfCf5lQGiq9HD6VJfoEx1mbay3gLy4ZmCxd0isyV9K2i3ykzz6erUchHt24bcDG1/mgLcxTpsADYrrBksR1wlu9xHIpN/Tccpg8UuoD02KAAYuHdGZfEwTZ6uZfAphdXa4kkD91jnbLovvN1kPeNcJNFVouPHfMxzUasOCUCI+8gA8Fo97EM1UJ0G3gyx5nLXiNCui5NWxz0UjeXfTDcCOiW+TeBTAdZdZCZpG3VrATML/Gp6lAY/K80QiBvAPQlTrypVBldLt9YBq0QnBdyJVbgLSBv3etwad8E4i1uS7GPF2UDU7iqZImMyeAeDoQ2kS2VQ9M1W5E/hY6YZcZVYrpHWBe5D0RSLW3TKO/BV7ihB1i9q/Wg3AE/rqfbcrrLGwD5LXNS3ZOG26tJ6PWWwbWmbJwXcrWRZwcV730ht0I7tS67TMHsaW7L0cv0GeWzOYTl9CZ5js6NBOpZ7yZ8PLVncre6PKTOOQ1jcjpRvXiosTZjGTRh8DwbmU/kwp894EMmtufy6Sf6IBVoCqCmDRlGHgmw9KNWuAaTloNjrFRpS6fL0BD1ISd40t+zXx1GWjoLRxepaslYH7HyWk1/Dv0of265cl8v5NIA7G5FaFifH0ji2clg5oKEs5aHDYIQNAbvWcIko+ShoEs4T3Q6GmLzxDiN8vqznZHBCPMPBFJuVY0GVJO2+VBoAhwl7IB48GtPm6X399iPtaiBzT51FtkU13hZoaRmjM5JcbmlAczcDnlMs9vE6FxBMwVo/a4I0D/dG5wBd48FGeme0SboI0mZ+mG1dmOM9Rx762dIMIAXtIYArgfZ1gU4CuJMmVQHKqVPfAMYNPPLnazIsi3vMB24NNrvSLouW+/ipGXb57st3XxqbdbWkt9LMQa3AWKyHhjQxHtC9bj+QNiUgR55dB4Zd0+mwqbOHqXzH5CTXlXIvhVl0EsANNFgUjQtOA6uKYxNtAegWUC/pb6W1eB+KLB1Lfu+BfiP5ytPOQbZ+0aYaG1zdjAuD+FIdTAWpq5ht7OSWQLQQ24CubMUfRpd2GTWZrcDY+mwLv6k8rLTWNVBeVyjlp0YnB9z7gKf1TM9xGj0V+KfsTqi5cCR/h7C4x2YbNd2tGUCJ8rQmhB5oBlGi0gJv8NJzeWZRsq6vWmcta59nplrBGrTHQQ1otbhb7m1qX+Scct9k1U4A6DHwbuHfqo9+n8RKV5Jt0ckAN9DWuWpuCtMC9f/XwK7Vd23JLOVB30/d/VGjqfzG9D2ULqdCAzCfoN9VA3orTQVtCd+lJsbyvK9luK/Mlry38J7KZ8pzbfoycutntJ4rap4McNcAybKsgHG3gLsGUJlal/jPDUiWpZ/HlfKzq4ySHHYRk/nvQ+VZTdCoqT6RgbfVfg6p4yHStj6X5KXh2XhftxinWMo2EZitr9206NYms9WKbqUSD0uXXLb1zCBM/9+Q17E8nAxwA0NAGlt4qgH6Lun1fUnmvtQykziUHKLy9xYZ03ZQzEF2HbUNuKW6HvKbrstY+NgCaAtfHdcyvR6bNaZgAYyByC5Wf6QeuatkqowW3cZ1srft5XW/q5WeA3TLADImq7VNngxw1xqf5SduXWySxcla+lqY/rV0qel/lQNATnPNFHa1JPeV11oPpdnCIfRuBfNdwfsQIFeKOxxIt9E++teeq8XrAcpK02rtjoFqk+5G8BjA13J6GsCdTT+AumugtoA4iENcuBkbACwZtYGiZrXX0lr5PHQH2deNUuKb01UNFOWyLa9n5PdS/zhQ2dZ01NRq0bXEtwKs3r88lnYqeLfcpxS1mQrQLTpNs8QBGAux+/y26pFe14/SnTpYngRwM+rKTrGWByDrOIR74TdmSVt89bP6mZJu+XNm3g8Mrse08o9Ftbw0WdwGTSmbVsu6Fj91YJ5sGTfqZgGQDi8ZIC28VQrMtatkGFYHXOvZsd+Sni310wraWneLTgK4hSxglfAWkLTiZcSd2lF3lZ3n41ikK3wOF82xqKVsp9TRVdCxrW0AyZrFrqDdot8hym1qmRyyrlqs5BZdpvJxm0r2t7SFTga4mfsEbIlcWCTZJeC/IM2Ivkt9DfgzODh5Tk5/IKgCVF86j9fxBI/49We1JEZI3C9hw+HExa6Y7yHg5lRbPNX3+XUuIwkr6ENS+HLvmNayMAOl1ojLHiVqHmU84eHRAsWkmc6BXEMy08epNZC2Zx8++B8DgFAMlR7lhekxq9SKy6n3SkedsrNXVLjWpU0mw9qxossofS6RaDw3DswlXRgMyDHQnF1LxsI11wxomyrpTwa4hRyAAXnTisCmDkfSYKcL2rdtSR97tIZvf8fiC+WY1N8TBMz1EU404JPqd3hq4T0G3s2ynMA4OKC+++RYW+qGHSnX40hgPaAJC5/GWe/TLXIDFIy0+UA/ONRogszd3DyGy6XAk9AuszyAjFvCV+EqCbLDeOquQ1qaXn4tdFLAnU/zhZKwqbtKDH91Ta6lx667R0r5WejwdAy3kCVzksU9oQ3U3Blji5+t1rIFmDU+pbAWyt2gLWlb9ZjivhgD82m/7d/uHJuxmPGV5nwywD0GloAHSAXeElZq1C27UKx0pfQDwJ64w2GhdpoKELu6qvYhnjj7ZfX/OO9xYG4BaNNw8Iqz8dwU+WXlyQS0ku6WHmWZ9V0dLSDd8qwVPvidIHtq/BidDHADdQCU+Mm7ShosdAu0a9v/Sm6EKdb5QoelOWY0XHjJBBjWc8nH3Wrx1izuWtpaupLFXQOSlnIWR2Ip7T4DhVxO5WGlsyzuWnj+LMRFUuA5TF/W05RTKeoTAW6uAm4Sh3ojnmpxt4B82eJOy7bF4q519BsR3K2yLMW38Njl+V3IGrx35GSGmsBS6IljsnexuKs8rtriVqA9Bt66D7UOIq28pw5KrXISi3tiOR3K+j4N4GZbUdM/zVzd5VCyqC3eefox0LZ4t9KNCMpXSXNYyIemQ+RgilU6lU8RSHhobZcMm13IPd/WziVlq4Xs96yMpJnCz45vm21wMW1NbilsSrmfBnAr2gccT1FOiVpkH1O/OXzE/5/oMN+P30N+DuIzyDwWXaXcKbyvsk91V8J1oYUWWuiEaIplfCMQnUJmiOgrAL4B4D/m1kXR7Vj0qdGp6QOcnk6LPnU6NX2A09Lp25n5aVbESQA3ABDRx5j5e+fWQ2jRp06npg9wejot+tTp1PQBTlMnixZXyUILLbTQDUYLcC+00EIL3WB0SsB939wKZLToU6dT0wc4PZ0Wfep0avoAp6nTgE7Gx73QQgsttFAbnZLFvdBCCy20UAPNDtxE9CIi+hwRPUREr51Jh4eJ6DNEdD8RfcyH3UZEHyKiz/vfW69Yh98noseI6AEVVtSBiF7ny+xzRPQjR9LnjUT0776c7ieilxxRn7uI6K+J6EEi+iwR/aIPn6WMKvrMUkZEdI2IPkpEn/L6/LoPn7MNlXSasx2tiOiTRPQBfz9b+exFsjF9jj8AKwBfAPAsAGcAPgXgOTPo8TCA27Ow3wTwWn/9WgC/ccU6vBDA8wE8MKYDgOf4sjoH8Exfhqsj6PNGAL9ipD2GPncAeL6/fiqAf/FyZymjij6zlBHcm+M3++sNgI8A+L6Z21BJpznb0S8BeDeAD/j72cpnn7+5Le4XAHiImf+VmZ8E8B4A986sk9C9AN7pr98J4CeuUhgz/y2A/2zU4V4A72HmJ5j5iwAegivLq9anRMfQ51Fm/oS//hqABwE8HTOVUUWfEl21PszMX/e3G//HmLcNlXQq0ZXqRER3AvhRAL+XyZylfPahuYH76QD+Td0/gnrjvypiAH9BRB8nolf6sG9h5kcB10kBfPMMepV0mLPcXk1En/auFJlWHlUfInoGgOfBWXCzl1GmDzBTGXk3wP0AHgPwIWaevXwKOgHzlNHvAPhVpCdVzd5+dqG5gds6RWmObS73MPPzAbwYwKuI6IUz6DCF5iq3twH4DgDPBfAogLccWx8iuhnAewG8hpm/Wkt6DJ0MfWYrI2beMvNzAdwJ4AVE9N2V5Ecpn4JORy8jIvoxAI8x88dbH7kqXQ5BcwP3IwDuUvd3AvjSsZVg5i/538cA/CnclOjLRHQHAPjfx46tV0WHWcqNmb/sO2IP4O2IU8ej6ENEGziQfBczv88Hz1ZGlj5zl5HX4b8B/A2AF+FE2pDWaaYyugfAjxPRw3Au2R8koj/CiZTPVJobuP8RwN1E9EwiOgPwMgDvP6YCRPQUInqqXAP4YQAPeD1e7pO9HMCfHVMvTyUd3g/gZUR0TkTPBHA3gI9etTLSwD29FK6cjqIPERGAdwB4kJnfqqJmKaOSPnOVERE9jYhu8dc3AfghAP+MGdtQSac5yoiZX8fMdzLzM+Bw5sPM/FM4sT7WTHOvjgJ4CdyK/BcAvGEG+c+CWz3+FIDPig4AvgnAXwH4vP+97Yr1+GO4aeMF3Gj/ipoOAN7gy+xzAF58JH3+EMBnAHwarmHfcUR9vh9uqvppAPf7v5fMVUYVfWYpIwDfA+CTXu4DAH5trB0foc5KOs3WjryMH0DcVTJb+ezzt7w5udBCCy10g9HcrpKFFlpooYUm0gLcCy200EI3GC3AvdBCCy10g9EC3AsttNBCNxgtwL3QQgstdIPRAtwLLbTQQjcYLcC90EILLXSD0QLcCy200EI3GP0f226u3Nz+mqwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reinitialize picture\n",
    "img = cv2.imread('cat.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8065933a60>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Selecting portion of picture\n",
    "img_head = img[100:250,50:320]\n",
    "plt.imshow(img_crop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
